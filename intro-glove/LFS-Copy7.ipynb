{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using scipy minimize function, results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NO. of Labelling Functions: ', 33)\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "from six.moves.cPickle import load\n",
    "\n",
    "with bz2.BZ2File('data/ctd.pkl.bz2', 'rb') as ctd_f:\n",
    "    ctd_unspecified, ctd_therapy, ctd_marker = load(ctd_f)\n",
    "    \n",
    "def cand_in_ctd_unspecified(c):\n",
    "    return 1 if c.get_cids() in ctd_unspecified else 0\n",
    "\n",
    "def cand_in_ctd_therapy(c):\n",
    "    return 1 if c.get_cids() in ctd_therapy else 0\n",
    "\n",
    "def cand_in_ctd_marker(c):\n",
    "    return 1 if c.get_cids() in ctd_marker else 0\n",
    "\n",
    "def LF_in_ctd_unspecified(c):\n",
    "    return -1 * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_in_ctd_therapy(c):\n",
    "    return -1 * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_in_ctd_marker(c):\n",
    "    return cand_in_ctd_marker(c)\n",
    "\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "def LF_induce(c):\n",
    "    return 1 if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "causal_past = ['induced', 'caused', 'due']\n",
    "def LF_d_induced_by_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1)\n",
    "def LF_d_induced_by_c_tight(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1)\n",
    "\n",
    "def LF_induce_name(c):\n",
    "    return 1 if 'induc' in c.chemical.get_span().lower() else 0     \n",
    "\n",
    "causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "def LF_c_cause_d(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "def LF_d_treat_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_treat_d(c):\n",
    "    return rule_regex_search_before_B(c, ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d_wide(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)\n",
    "\n",
    "def LF_c_d(c):\n",
    "    return 1 if ('{{A}} {{B}}' in get_tagged_text(c)) else 0\n",
    "\n",
    "def LF_c_induced_d(c):\n",
    "    return 1 if (\n",
    "        ('{{A}} {{B}}' in get_tagged_text(c)) and \n",
    "        (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "        ) else 0\n",
    "\n",
    "def LF_improve_before_disease(c):\n",
    "    return rule_regex_search_before_B(c, 'improv.*', -1)\n",
    "\n",
    "pat_terms = ['in a patient with ', 'in patients with']\n",
    "def LF_in_patient_with(c):\n",
    "    return -1 if re.search(ltp(pat_terms) + '{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "def LF_uncertain(c):\n",
    "    return rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)\n",
    "\n",
    "def LF_induced_other(c):\n",
    "    return rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', -1)\n",
    "\n",
    "def LF_far_c_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_far_d_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_risk_d(c):\n",
    "    return rule_regex_search_before_B(c, 'risk of ', 1)\n",
    "\n",
    "def LF_develop_d_following_c(c):\n",
    "    return 1 if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "procedure, following = ['inject', 'administrat'], ['following']\n",
    "def LF_d_following_c(c):\n",
    "    return 1 if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_measure(c):\n",
    "    return -1 if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_level(c):\n",
    "    return -1 if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_d(c):\n",
    "    return -1 if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "                'seems', 'suggests', 'risk', 'implicated',\n",
    "               'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "def LF_weak_assertions(c):\n",
    "    return -1 if re.search(WEAK_RGX, get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "\n",
    "def LF_ctd_marker_c_d(c):\n",
    "    return LF_c_d(c) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_marker_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_therapy_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_ctd_unspecified_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_ctd_unspecified_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_closer_chem(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical closer than @dist/2 in either direction\n",
    "    sent = c.get_parent()\n",
    "    closest_other_chem = float('inf')\n",
    "    for i in range(dis_end, min(len(sent.words), dis_end + dist / 2)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, dis_start - dist / 2), dis_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def LF_closer_dis(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical disease than @dist/8 in either direction\n",
    "    sent = c.get_parent()\n",
    "    for i in range(chem_end, min(len(sent.words), chem_end + dist / 8)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, chem_start - dist / 8), chem_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "LFs = [\n",
    "    LF_c_cause_d,\n",
    "    LF_c_d,\n",
    "    LF_c_induced_d,\n",
    "    LF_c_treat_d,\n",
    "    LF_c_treat_d_wide,\n",
    "    LF_closer_chem,\n",
    "    LF_closer_dis,\n",
    "    LF_ctd_marker_c_d,\n",
    "    LF_ctd_marker_induce,\n",
    "    LF_ctd_therapy_treat,\n",
    "    LF_ctd_unspecified_treat,\n",
    "    LF_ctd_unspecified_induce,\n",
    "    LF_d_following_c,\n",
    "    LF_d_induced_by_c,\n",
    "    LF_d_induced_by_c_tight,\n",
    "    LF_d_treat_c,\n",
    "    LF_develop_d_following_c,\n",
    "    LF_far_c_d,\n",
    "    LF_far_d_c,\n",
    "    LF_improve_before_disease,\n",
    "    LF_in_ctd_therapy,\n",
    "    LF_in_ctd_marker,\n",
    "    LF_in_patient_with,\n",
    "    LF_induce,\n",
    "    LF_induce_name,\n",
    "    LF_induced_other,\n",
    "    LF_level,\n",
    "    LF_measure,\n",
    "    LF_neg_d,\n",
    "    LF_risk_d,\n",
    "    LF_treat_d,\n",
    "    LF_uncertain,\n",
    "    LF_weak_assertions,\n",
    "]\n",
    "print(\"NO. of Labelling Functions: \", len(LFs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "8272\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()\n",
    "print(len(dev_cands))\n",
    "print(len(train_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n"
     ]
    }
   ],
   "source": [
    "from load_external_annotations import load_external_labels\n",
    "load_external_labels(session, ChemicalDisease, split=1, annotator='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev\n",
    "\n",
    "#print(L_gold_dev)\n",
    "gold_labels = []\n",
    "for i,L in enumerate(L_gold_dev):\n",
    "    gold_labels.append(L[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def PHI(K,LAMDAi):\n",
    "    return [K*j for j in LAMDAi]\n",
    "\n",
    "def softmax(THETA,LAMDAi):\n",
    "    x = []\n",
    "    for k in [1,-1]:\n",
    "        product = np.dot(PHI(k,LAMDAi),THETA)\n",
    "        x.append(product)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def function_conf(THETA,LAMDA,P_cap,Confidence):\n",
    "    s = 0.0\n",
    "    i = 0\n",
    "    for LAMDAi in LAMDA:\n",
    "        s = s + Confidence[i]*np.dot(np.log(softmax(THETA,LAMDAi)),P_cap[i])\n",
    "        i = i+1\n",
    "    return -s\n",
    "\n",
    "def function(THETA,LAMDA,P_cap):\n",
    "    s = 0.0\n",
    "    i = 0\n",
    "    for LAMDAi in LAMDA:\n",
    "        s = s + np.dot(np.log(softmax(THETA,LAMDAi)),P_cap[i])\n",
    "        i = i+1\n",
    "    return -s\n",
    "\n",
    "def P_K_Given_LAMDAi_THETA(K,THETA,LAMDAi):\n",
    "    x = softmax(THETA,LAMDAi)\n",
    "    if(K==1):\n",
    "        return x[0]\n",
    "    else:\n",
    "        return x[1]\n",
    "      \n",
    "\n",
    "np.random.seed(78)\n",
    "THETA = np.random.rand(len(LFs),1)\n",
    "\n",
    "def PHIj(j,K,LAMDAi):\n",
    "    return LAMDAi[j]*K\n",
    "\n",
    "def RIGHT(j,LAMDAi,THETA):\n",
    "    phi = []\n",
    "    for k in [1,-1]:\n",
    "        phi.append(PHIj(j,k,LAMDAi))\n",
    "    x = softmax(THETA,LAMDAi)\n",
    "    return np.dot(phi,x)\n",
    "    \n",
    "\n",
    "def function_conf_der(THETA,LAMDA,P_cap,Confidence):\n",
    "    der = []\n",
    "    for j in range(len(THETA)):\n",
    "        i = 0\n",
    "        s = 0.0\n",
    "        for LAMDAi in LAMDA:\n",
    "            p = 0\n",
    "            for K in [1,-1]:\n",
    "                s = s + Confidence[i]*(PHIj(j,K,LAMDAi)-RIGHT(j,LAMDAi,THETA))*P_cap[i][p]\n",
    "                p = p+1\n",
    "            i = i+1\n",
    "        der.append(-s)\n",
    "    return np.array(der)\n",
    "\n",
    "def function_der(THETA,LAMDA,P_cap):\n",
    "    der = []\n",
    "    for j in range(len(THETA)):\n",
    "        i = 0\n",
    "        s = 0.0\n",
    "        for LAMDAi in LAMDA:\n",
    "            p = 0\n",
    "            for K in [1,-1]:\n",
    "                s = s + (PHIj(j,K,LAMDAi)-RIGHT(j,LAMDAi,THETA))*P_cap[i][p]\n",
    "                p = p+1\n",
    "            i = i+1\n",
    "        der.append(-s)\n",
    "    return np.array(der)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_LAMDA(cands):\n",
    "    LAMDA = []\n",
    "    for ci in cands:\n",
    "        L=[]\n",
    "        P_ik = []\n",
    "        for LF in LFs:\n",
    "            L.append(LF(ci))\n",
    "        LAMDA.append(L)\n",
    "    return LAMDA\n",
    "\n",
    "def get_Confidence(LAMDA):\n",
    "    confidence = []\n",
    "    for L in LAMDA:\n",
    "        Total_L = float(len(L))\n",
    "        No_zeros = L.count(0)\n",
    "        No_Non_Zeros = Total_L - No_zeros\n",
    "        confidence.append(No_Non_Zeros/Total_L)\n",
    "    return confidence    \n",
    "    \n",
    "def get_Initial_P_cap(LAMDA):\n",
    "    P_cap = []\n",
    "    for L in LAMDA:\n",
    "        P_ik = []\n",
    "        denominator=float(L.count(1)+L.count(-1))\n",
    "        if(denominator==0):\n",
    "            denominator=1\n",
    "        P_ik.append(L.count(1)/denominator)\n",
    "        P_ik.append(L.count(-1)/denominator)\n",
    "        P_cap.append(P_ik)\n",
    "    return P_cap\n",
    "    #print(np.array(LAMDA))\n",
    "    #print(np.array(P_cap))append(L)\n",
    "    #LAMDA=np.array(LAMDA).astype(int)\n",
    "    #P_cap=np.array(P_cap)\n",
    "    #print(np.array(LAMDA).shape)\n",
    "    #print(np.array(P_cap).shape)\n",
    "    #print(L)\n",
    "    #print(ci.chemical.get_span(),ci.disease.get_span(),\"No.Os\",L.count(0),\"No.1s\",L.count(1),\"No.-1s\",L.count(-1))\n",
    "    #print(ci.chemical.get_span(),ci.disease.get_span(),\"P(0):\",L.count(0)/len(L),\" P(1)\",L.count(1)/len(L),\"P(-1)\",L.count(-1)/len(L))\n",
    "\n",
    "        \n",
    "def get_P_cap(LAMDA,THETA):\n",
    "    P_cap = []\n",
    "    for LAMDAi in LAMDA:\n",
    "        P_capi = softmax(THETA,LAMDAi)\n",
    "        P_cap.append(P_capi)\n",
    "    return P_cap\n",
    "\n",
    "\n",
    "def score(predicted_labels,gold_labels):\n",
    "    tp =0.0\n",
    "    tn =0.0\n",
    "    fp =0.0\n",
    "    fn =0.0\n",
    "    for i in range(len(gold_labels)):\n",
    "        if(predicted_labels[i]==gold_labels[i]):\n",
    "            if(predicted_labels[i]==1):\n",
    "                tp=tp+1\n",
    "            else:\n",
    "                tn=tn+1\n",
    "        else:\n",
    "            if(predicted_labels[i]==1):\n",
    "                fp=fp+1\n",
    "            else:\n",
    "                fn=fn+1\n",
    "    print(\"tp\",tp,\"tn\",tn,\"fp\",fp,\"fn\",fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1score = (2*precision*recall)/(precision+recall)\n",
    "    print(\"precision:\",precision)\n",
    "    print(\"recall:\",recall)\n",
    "    print(\"F1 score:\",f1score)\n",
    "                \n",
    "           \n",
    "    \n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def get_marginals(P_cap):\n",
    "    marginals = []\n",
    "    for P_capi in P_cap:\n",
    "        marginals.append(P_capi[0])\n",
    "    return marginals\n",
    "\n",
    "def predict_labels(marginals):\n",
    "    predicted_labels=[]\n",
    "    for i in marginals:\n",
    "        if(i<0.4):\n",
    "            predicted_labels.append(-1)\n",
    "        else:\n",
    "            predicted_labels.append(1)\n",
    "    return predicted_labels\n",
    "    \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "dev_LAMDA = get_LAMDA(dev_cands)\n",
    "def print_details(label,THETA):\n",
    "    print(label)\n",
    "    global dev_LAMDA\n",
    "    P_cap = get_P_cap(dev_LAMDA,THETA)\n",
    "    marginals=get_marginals(P_cap)\n",
    "    #plt.hist(marginals, bins=20)\n",
    "    #plt.show()\n",
    "    #plt.bar(range(0,888),train_marginals)\n",
    "    #plt.show()\n",
    "    predicted_labels=predict_labels(marginals)\n",
    "    print(len(marginals),len(predicted_labels),len(gold_labels))\n",
    "    score(predicted_labels,gold_labels)\n",
    "    #print(precision_recall_fscore_support(np.array(gold_labels),np.array(predicted_labels),average='binary')) \n",
    "    \n",
    "    \n",
    "    \n",
    "def train(No_Iter,Use_Confidence=True):\n",
    "    global THETA\n",
    "    LAMDA = get_LAMDA(train_cands)\n",
    "    P_cap = get_Initial_P_cap(LAMDA)\n",
    "    Confidence = get_Confidence(LAMDA)\n",
    "    for iteration in range(No_Iter):\n",
    "        if(Use_Confidence==True):\n",
    "            res = minimize(function_conf,THETA,args=(LAMDA,P_cap,Confidence), method='BFGS',jac=function_conf_der,options={'disp': True, 'maxiter':20}) #nelder-mead\n",
    "        else:\n",
    "            res = minimize(function,THETA,args=(LAMDA,P_cap), method='BFGS',jac=function_der,options={'disp': True, 'maxiter':20}) #nelder-mead            \n",
    "        THETA = res.x # new THETA\n",
    "        print(THETA)\n",
    "        P_cap = get_P_cap(LAMDA,THETA) #new p_cap \n",
    "        print_details(\"train iteration: \"+str(iteration),THETA)\n",
    "        #score(predicted_labels,gold_labels)\n",
    "    NP_P_cap = np.array(P_cap)\n",
    "    np.savetxt('Train_P_cap_conf.txt', NP_P_cap, fmt='%f')\n",
    "    np.save('Train_P_cap_conf', NP_P_cap)\n",
    "    NP_THETA = np.array(THETA)\n",
    "    np.savetxt('FTHETA_conf.txt', NP_THETA, fmt='%f')\n",
    "    np.save('FTHETANPY_conf', NP_THETA) # save the file as \"outfile_name.npy\" \n",
    "\n",
    "        \n",
    "def test(THETA):\n",
    "    global dev_LAMDA\n",
    "    P_cap = get_P_cap(dev_LAMDA,THETA)\n",
    "    print_details(\"test:\",THETA)\n",
    "    NP_P_cap = np.array(P_cap)\n",
    "    np.savetxt('Dev_P_cap_conf.txt', NP_P_cap, fmt='%f')\n",
    "    np.save('Dev_P_cap_conf', NP_P_cap)\n",
    "                    \n",
    "def load_marginals(s):\n",
    "    marginals = []\n",
    "    if(s==\"train\"):\n",
    "        train_P_cap = np.load(\"Train_P_cap_conf.npy\")\n",
    "        marginals = train_P_cap[:,0]\n",
    "    return marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train(3,Use_Confidence=False)\n",
    "\n",
    "#test(THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 207.013624\n",
      "         Iterations: 20\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n",
      "[ 0.47844004  1.29668512  0.61060496  0.53903927  0.73890189  0.60851199\n",
      "  0.39646162 -0.64617727 -0.7060489  -0.50304711  0.18643678 -0.03844427\n",
      "  0.81023496  0.4939991   1.02149272  0.84749134  0.2348705   0.66393911\n",
      "  0.74300491  0.54768663  0.89075     1.01976587  0.75587943  0.49980697\n",
      "  0.53499946  0.49288678  0.72534036  0.69471096  0.68106339  0.48964412\n",
      "  0.6509262   0.88324222  0.75345992]\n",
      "train iteration: 0\n",
      "(888, 888, 888)\n",
      "('tp', 224.0, 'tn', 311.0, 'fp', 281.0, 'fn', 72.0)\n",
      "('precision:', 0.44356435643564357)\n",
      "('recall:', 0.7567567567567568)\n",
      "('F1 score:', 0.5593008739076155)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 206.649140\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n",
      "[ 0.47844004  1.29668512  0.61060496  0.53903927  0.73890189  0.60851199\n",
      "  0.39646162 -0.64617727 -0.7060489  -0.50304711  0.18643678 -0.03844427\n",
      "  0.81023496  0.4939991   1.02149272  0.84749134  0.2348705   0.66393911\n",
      "  0.74300491  0.54768663  0.89075     1.01976587  0.75587943  0.49980697\n",
      "  0.53499946  0.49288678  0.72534036  0.69471096  0.68106339  0.48964412\n",
      "  0.6509262   0.88324222  0.75345992]\n",
      "train iteration: 1\n",
      "(888, 888, 888)\n",
      "('tp', 224.0, 'tn', 311.0, 'fp', 281.0, 'fn', 72.0)\n",
      "('precision:', 0.44356435643564357)\n",
      "('recall:', 0.7567567567567568)\n",
      "('F1 score:', 0.5593008739076155)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 206.649140\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n",
      "[ 0.47844004  1.29668512  0.61060496  0.53903927  0.73890189  0.60851199\n",
      "  0.39646162 -0.64617727 -0.7060489  -0.50304711  0.18643678 -0.03844427\n",
      "  0.81023496  0.4939991   1.02149272  0.84749134  0.2348705   0.66393911\n",
      "  0.74300491  0.54768663  0.89075     1.01976587  0.75587943  0.49980697\n",
      "  0.53499946  0.49288678  0.72534036  0.69471096  0.68106339  0.48964412\n",
      "  0.6509262   0.88324222  0.75345992]\n",
      "train iteration: 2\n",
      "(888, 888, 888)\n",
      "('tp', 224.0, 'tn', 311.0, 'fp', 281.0, 'fn', 72.0)\n",
      "('precision:', 0.44356435643564357)\n",
      "('recall:', 0.7567567567567568)\n",
      "('F1 score:', 0.5593008739076155)\n",
      "test:\n",
      "(888, 888, 888)\n",
      "('tp', 224.0, 'tn', 311.0, 'fp', 281.0, 'fn', 72.0)\n",
      "('precision:', 0.44356435643564357)\n",
      "('recall:', 0.7567567567567568)\n",
      "('F1 score:', 0.5593008739076155)\n"
     ]
    }
   ],
   "source": [
    "train(3)\n",
    "\n",
    "test(THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n",
      "(888, 888, 888)\n",
      "('tp', 224.0, 'tn', 311.0, 'fp', 281.0, 'fn', 72.0)\n",
      "('precision:', 0.44356435643564357)\n",
      "('recall:', 0.7567567567567568)\n",
      "('F1 score:', 0.5593008739076155)\n"
     ]
    }
   ],
   "source": [
    "THETA = np.load('FTHETANPY_conf.npy');\n",
    "test(THETA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sparse Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals=load_marginals(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator()\n",
    "\n",
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev = featurizer.load_matrix(session, split=1)\n",
    "F_test = featurizer.load_matrix(session, split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 5. Search space size = 125.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<888x1 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 888 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "from snorkel.learning.utils import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "# Searching over learning rate\n",
    "rate_param = RangeParameter('lr', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l1_param  = RangeParameter('l1_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l2_param  = RangeParameter('l2_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "\n",
    "# NOTE: A larger search (n) would likely lead to a higher score!\n",
    "searcher = RandomSearch(SparseLogisticRegression, [rate_param, l1_param, l2_param], F_train,\n",
    "                        Y_train=train_marginals, n=5)\n",
    "\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing lr = 1.00e-02, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=6754  #epochs=85  batch size=256\n",
      "[SparseLogisticRegression] Epoch 0 (0.82s)\tAverage loss=0.718038\n",
      "[SparseLogisticRegression] Epoch 25 (22.38s)\tAverage loss=0.557215\n",
      "[SparseLogisticRegression] Epoch 50 (44.60s)\tAverage loss=0.566103\n",
      "[SparseLogisticRegression] Epoch 75 (66.65s)\tAverage loss=0.570378\n",
      "[SparseLogisticRegression] Epoch 84 (74.32s)\tAverage loss=0.572765\n",
      "[SparseLogisticRegression] Training done (74.32s)\n",
      "[SparseLogisticRegression] F1 Score: 0.538043478261\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_0>\n",
      "============================================================\n",
      "[2] Testing lr = 1.00e-04, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=6754  #epochs=85  batch size=256\n",
      "[SparseLogisticRegression] Epoch 0 (0.82s)\tAverage loss=1.365198\n",
      "[SparseLogisticRegression] Epoch 25 (23.25s)\tAverage loss=1.215045\n",
      "[SparseLogisticRegression] Epoch 50 (45.32s)\tAverage loss=1.161629\n",
      "[SparseLogisticRegression] Epoch 75 (66.71s)\tAverage loss=1.140046\n",
      "[SparseLogisticRegression] Epoch 84 (75.15s)\tAverage loss=1.135639\n",
      "[SparseLogisticRegression] Training done (75.15s)\n",
      "[SparseLogisticRegression] F1 Score: 0.507853403141\n",
      "============================================================\n",
      "[3] Testing lr = 1.00e-03, l1_penalty = 1.00e-02, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=6754  #epochs=85  batch size=256\n",
      "[SparseLogisticRegression] Epoch 0 (0.81s)\tAverage loss=98.623085\n",
      "[SparseLogisticRegression] Epoch 25 (22.94s)\tAverage loss=108.223358\n",
      "[SparseLogisticRegression] Epoch 50 (44.37s)\tAverage loss=115.587349\n",
      "[SparseLogisticRegression] Epoch 75 (66.50s)\tAverage loss=120.052330\n",
      "[SparseLogisticRegression] Epoch 84 (74.43s)\tAverage loss=121.206963\n",
      "[SparseLogisticRegression] Training done (74.43s)\n",
      "[SparseLogisticRegression] F1 Score: 0.534351145038\n",
      "============================================================\n",
      "[4] Testing lr = 1.00e-03, l1_penalty = 1.00e-04, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=6754  #epochs=85  batch size=256\n",
      "[SparseLogisticRegression] Epoch 0 (1.36s)\tAverage loss=2.309676\n",
      "[SparseLogisticRegression] Epoch 25 (23.36s)\tAverage loss=2.240409\n",
      "[SparseLogisticRegression] Epoch 50 (45.99s)\tAverage loss=2.411647\n",
      "[SparseLogisticRegression] Epoch 75 (68.23s)\tAverage loss=2.533752\n",
      "[SparseLogisticRegression] Epoch 84 (76.42s)\tAverage loss=2.569252\n",
      "[SparseLogisticRegression] Training done (76.42s)\n",
      "[SparseLogisticRegression] F1 Score: 0.533685601057\n",
      "============================================================\n",
      "[5] Testing lr = 1.00e-02, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=6754  #epochs=85  batch size=256\n",
      "[SparseLogisticRegression] Epoch 0 (0.84s)\tAverage loss=0.713812\n",
      "[SparseLogisticRegression] Epoch 25 (23.40s)\tAverage loss=0.552405\n",
      "[SparseLogisticRegression] Epoch 50 (46.63s)\tAverage loss=0.568974\n",
      "[SparseLogisticRegression] Epoch 75 (69.27s)\tAverage loss=0.571064\n",
      "[SparseLogisticRegression] Epoch 84 (78.53s)\tAverage loss=0.570262\n",
      "[SparseLogisticRegression] Training done (78.54s)\n",
      "[SparseLogisticRegression] F1 Score: 0.535519125683\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SparseLogisticRegression_0/SparseLogisticRegression_0-0\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression_0>\n",
      "CPU times: user 7min 23s, sys: 18.9 s, total: 7min 42s\n",
      "Wall time: 6min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "np.random.seed(1701)\n",
    "disc_model, run_stats = searcher.fit(F_dev, L_gold_dev, n_epochs=85, rebalance=0.5, print_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>l1_penalty</th>\n",
       "      <th>l2_penalty</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.538043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.449541</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.535519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.534351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.438178</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.533686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.414530</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.507853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr  l1_penalty  l2_penalty     Prec.      Rec.        F1\n",
       "0  0.0100    0.000001      0.0001  0.450000  0.668919  0.538043\n",
       "4  0.0100    0.000001      0.0001  0.449541  0.662162  0.535519\n",
       "2  0.0010    0.010000      0.0001  0.428571  0.709459  0.534351\n",
       "3  0.0010    0.000100      0.0010  0.438178  0.682432  0.533686\n",
       "1  0.0001    0.000001      0.0010  0.414530  0.655405  0.507853"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.688\n",
      "Neg. class accuracy: 0.585\n",
      "Precision            0.445\n",
      "Recall               0.688\n",
      "F1                   0.54\n",
      "----------------------------------------\n",
      "TP: 1036 | FP: 1293 | TN: 1822 | FN: 469\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from load_external_annotations import load_external_labels\n",
    "load_external_labels(session, ChemicalDisease, split=2, annotator='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_test\n",
    "\n",
    "tp, fp, tn, fn  = disc_model.error_analysis(session, F_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.669\n",
      "Neg. class accuracy: 0.591\n",
      "Precision            0.45\n",
      "Recall               0.669\n",
      "F1                   0.538\n",
      "----------------------------------------\n",
      "TP: 198 | FP: 242 | TN: 350 | FN: 98\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn  = disc_model.error_analysis(session, F_dev, L_gold_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
