{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import load_external_labels\n",
    "\n",
    "# %time load_external_labels(session, Spouse, annotator_name='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "#L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "#L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "\n",
    "# L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "# L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "# gold_labels_dev = [L[0,0] if L[0,0]==1 else -1 for L in L_gold_dev]\n",
    "gold_labels_dev = [L[0,0] for L in L_gold_dev]\n",
    "\n",
    "\n",
    "from snorkel.learning.utils import MentionScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 2625\n",
      "2814\n"
     ]
    }
   ],
   "source": [
    "#gold_labels_dev = [x[0,0] for x in L_gold_dev.todense()]\n",
    "#for i,L in enumerate(gold_labels_dev):\n",
    "#    print(i,gold_labels_dev[i])\n",
    "\n",
    "# gold_labels_dev = []\n",
    "# for i,L in enumerate(L_gold_dev):\n",
    "#     gold_labels_dev.append(L[0,0])\n",
    "    \n",
    "# gold_labels_test = []\n",
    "# for i,L in enumerate(L_gold_test):\n",
    "#     gold_labels_test.append(L[0,0])\n",
    "    \n",
    "# print(len(gold_labels_dev),len(gold_labels_test))\n",
    "# print(gold_labels_dev.count(1),gold_labels_dev.count(-1))\n",
    "# print(len(gold_labels_dev))\n",
    "\n",
    "print(gold_labels_dev.count(1),gold_labels_dev.count(0))\n",
    "print(len(gold_labels_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gensim.matutils as gm\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = KeyedVectors.load_word2vec_format('../../../snorkel/tutorials/glove_w2v.txt', binary=False)  # C binary format\n",
    "\n",
    "\n",
    "wordvec_unavailable= set()\n",
    "def write_to_file(wordvec_unavailable):\n",
    "    with open(\"wordvec_unavailable.txt\",\"w\") as f:\n",
    "        for word in wordvec_unavailable:\n",
    "            f.write(word+\"\\n\")\n",
    "\n",
    "def preprocess(tokens):\n",
    "    btw_words = [word for word in tokens if word not in STOPWORDS]\n",
    "    btw_words = [word for word in btw_words if word.isalpha()]\n",
    "    return btw_words\n",
    "\n",
    "def get_word_vectors(btw_words): # returns vector of embeddings of words\n",
    "    word_vectors= []\n",
    "    for word in btw_words:\n",
    "        try:\n",
    "            word_v = np.array(model[word])\n",
    "            word_v = word_v.reshape(len(word_v),1)\n",
    "            #print(word_v.shape)\n",
    "            word_vectors.append(model[word])\n",
    "        except:\n",
    "            wordvec_unavailable.add(word)\n",
    "    return word_vectors\n",
    "\n",
    "def get_similarity(word_vectors,target_word): # sent(list of word vecs) to word similarity\n",
    "    similarity = 0\n",
    "    target_word_vector = 0\n",
    "    try:\n",
    "        target_word_vector = model[target_word]\n",
    "    except:\n",
    "        wordvec_unavailable.add(target_word+\" t\")\n",
    "        return similarity\n",
    "    target_word_sparse = gm.any2sparse(target_word_vector,eps=1e-09)\n",
    "    for wv in word_vectors:\n",
    "        wv_sparse = gm.any2sparse(wv, eps=1e-09)\n",
    "        similarity = max(similarity,gm.cossim(wv_sparse,target_word_sparse))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Discrete ##########\n",
    "\n",
    "# spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "# family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "#               'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "# family = family | {f + '-in-law' for f in family}\n",
    "# other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# # Helper function to get last name\n",
    "# def last_name(s):\n",
    "#     name_parts = s.split(' ')\n",
    "#     return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "# def LF_husband_wife(c):\n",
    "#     return (1,1) if len(spouses.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "# def LF_husband_wife_left_window(c):\n",
    "#     if len(spouses.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "#         return (1,1)\n",
    "#     elif len(spouses.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "#         return (1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "    \n",
    "# def LF_same_last_name(c):\n",
    "#     p1_last_name = last_name(c.person1.get_span())\n",
    "#     p2_last_name = last_name(c.person2.get_span())\n",
    "#     if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "#         if c.person1.get_span() != c.person2.get_span():\n",
    "#             return (1,1)\n",
    "#     return (0,0)\n",
    "\n",
    "# def LF_no_spouse_in_sentence(c):\n",
    "#     return (-1,1) if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else (0,0)\n",
    "\n",
    "# def LF_and_married(c):\n",
    "#     return (1,1) if 'and' in get_between_tokens(c) and 'married' in get_right_tokens(c) else (0,0)\n",
    "    \n",
    "# def LF_familial_relationship(c):\n",
    "#     return (-1,1) if len(family.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "# def LF_family_left_window(c):\n",
    "#     if len(family.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "#         return (-1,1)\n",
    "#     elif len(family.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "#         return (-1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "\n",
    "# def LF_other_relationship(c):\n",
    "#     return (-1,1) if len(other.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "\n",
    "# import bz2\n",
    "\n",
    "# # Function to remove special characters from text\n",
    "# def strip_special(s):\n",
    "#     return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# # Read in known spouse pairs and save as set of tuples\n",
    "# with bz2.BZ2File('data/spouses_dbpedia.csv.bz2', 'rb') as f:\n",
    "#     known_spouses = set(\n",
    "#         tuple(strip_special(x.decode('utf-8')).strip().split(',')) for x in f.readlines()\n",
    "#     )\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "    \n",
    "# def LF_distant_supervision(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     return (1,1) if (p1, p2) in known_spouses or (p2, p1) in known_spouses else (0,0)\n",
    "\n",
    "# def LF_distant_supervision_last_names(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     p1n, p2n = last_name(p1), last_name(p2)\n",
    "#     return (1,1) if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else (0,0)\n",
    "\n",
    "\n",
    "# LFs = [\n",
    "#     LF_distant_supervision, LF_distant_supervision_last_names, \n",
    "#     LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "#     LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "#     LF_family_left_window, LF_other_relationship\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Continuous ################\n",
    "\n",
    "\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "\n",
    "spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "              'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "family = family | {f + '-in-law' for f in family}\n",
    "other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# Helper function to get last name\n",
    "def last_name(s):\n",
    "    name_parts = s.split(' ')\n",
    "    return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "def LF_husband_wife(c):\n",
    "    global LF_Threshold\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for sw in spouses:\n",
    "        sc=max(sc,get_similarity(word_vectors,sw))\n",
    "    return (1,sc)\n",
    "\n",
    "def LF_husband_wife_left_window(c):\n",
    "    global LF_Threshold\n",
    "    sc_1 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[0])))\n",
    "    for sw in spouses:\n",
    "        sc_1=max(sc_1,get_similarity(word_vectors,sw))\n",
    "        \n",
    "    sc_2 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[1])))\n",
    "    for sw in spouses:\n",
    "        sc_2=max(sc_2,get_similarity(word_vectors,sw))\n",
    "    return(1,max(sc_1,sc_2))\n",
    "    \n",
    "def LF_same_last_name(c):\n",
    "    p1_last_name = last_name(c.person1.get_span())\n",
    "    p2_last_name = last_name(c.person2.get_span())\n",
    "    if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "        if c.person1.get_span() != c.person2.get_span():\n",
    "            return (1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_no_spouse_in_sentence(c):\n",
    "    return (-1,0.75) if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else (0,0)\n",
    "\n",
    "def LF_and_married(c):\n",
    "    global LF_Threshold\n",
    "    word_vectors = get_word_vectors(preprocess(get_right_tokens(c)))\n",
    "    sc = get_similarity(word_vectors,'married')\n",
    "    \n",
    "    if 'and' in get_between_tokens(c):\n",
    "        return (1,sc)\n",
    "    else:\n",
    "        return (0,0)\n",
    "\n",
    "def LF_familial_relationship(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for fw in family:\n",
    "        sc=max(sc,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    return (-1,sc) \n",
    "\n",
    "def LF_family_left_window(c):\n",
    "    sc_1 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[0])))\n",
    "    for fw in family:\n",
    "        sc_1=max(sc_1,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    sc_2 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[1])))\n",
    "    for fw in family:\n",
    "        sc_2=max(sc_2,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    return (-1,max(sc_1,sc_2))\n",
    "\n",
    "def LF_other_relationship(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for ow in other:\n",
    "        sc=max(sc,get_similarity(word_vectors,ow))\n",
    "        \n",
    "    return (-1,sc) \n",
    "\n",
    "# def LF_other_relationship_left_window(c):\n",
    "#     sc = 0\n",
    "#     word_vectors = get_word_vectors(preprocess(get_left_tokens(c)))\n",
    "#     for ow in other:\n",
    "#         sc=max(sc,get_similarity(word_vectors,ow))\n",
    "#     return (-1,sc) \n",
    "\n",
    "import bz2\n",
    "\n",
    "# Function to remove special characters from text\n",
    "def strip_special(s):\n",
    "    return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# # Read in known spouse pairs and save as set of tuples\n",
    "# with bz2.BZ2File('data/spouses_dbpedia.csv.bz2', 'rb') as f:\n",
    "#     known_spouses = set(\n",
    "#         tuple(strip_special(x).strip().split(',')) for x in f.readlines()\n",
    "#     )\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "    \n",
    "def LF_distant_supervision(c):\n",
    "    p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "    return (1,1) if (p1, p2) in known_spouses or (p2, p1) in known_spouses else (0,0)\n",
    "\n",
    "def LF_distant_supervision_last_names(c):\n",
    "    p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "    p1n, p2n = last_name(p1), last_name(p2)\n",
    "    return (1,1) if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else (0,1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# def LF_Three_Lists_Left_Window(c):\n",
    "#     global softmax_Threshold\n",
    "#     c1,s1 = LF_husband_wife_left_window(c)\n",
    "#     c2,s2 = LF_family_left_window(c)\n",
    "#     c3,s3 = LF_other_relationship_left_window(c)\n",
    "#     sc = np.array([s1,s2,s3])\n",
    "#     c = [c1,c2,c3]\n",
    "#     sharp_param = 1.5\n",
    "#     prob_sc = np.exp(sc * sharp_param - np.max(sc))\n",
    "#     prob_sc = prob_sc / np.sum(prob_sc)\n",
    "#     #print 'Left:',s1,s2,s3,prob_sc\n",
    "    \n",
    "#     if s1==s2 or s3==s1:\n",
    "#         return (0,0)\n",
    "#     return c[np.argmax(prob_sc)],1\n",
    "\n",
    "# def LF_Three_Lists_Between_Words(c):\n",
    "#     global softmax_Threshold\n",
    "#     c1,s1 = LF_husband_wife(c)\n",
    "#     c2,s2 = LF_familial_relationship(c)\n",
    "#     c3,s3 = LF_other_relationship(c)\n",
    "#     sc = np.array([s1,s2,s3])\n",
    "#     c = [c1,c2,c3]\n",
    "#     sharp_param = 1.5\n",
    "    \n",
    "#     prob_sc = np.exp(sc * sharp_param - np.max(sc))\n",
    "#     prob_sc = prob_sc / np.sum(prob_sc)\n",
    "#     #print 'BW:',s1,s2,s3,prob_sc\n",
    "#     if s1==s2 or s3==s1:\n",
    "#         return (0,0)\n",
    "#     return c[np.argmax(prob_sc)],1\n",
    "    \n",
    "LFs = [\n",
    "    LF_distant_supervision, LF_distant_supervision_last_names, \n",
    "    LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "    LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "    LF_family_left_window, LF_other_relationship\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' output:\n",
    "\n",
    "    [[[L_x1],[S_x1]],\n",
    "     [[L_x2],[S_x2]],\n",
    "     ......\n",
    "     ......\n",
    "    ]\n",
    "\n",
    "'''\n",
    "def get_L_S_Tensor(cands): \n",
    "    \n",
    "    L_S = []\n",
    "    for i,ci in enumerate(cands):\n",
    "        L_S_ci=[]\n",
    "        L=[]\n",
    "        S=[]\n",
    "        for LF in LFs:\n",
    "            #print LF.__name__\n",
    "            l,s = LF(ci)\n",
    "            L.append(l)\n",
    "            S.append((s+1)/2)  #to scale scores in [0,1] \n",
    "        L_S_ci.append(L)\n",
    "        L_S_ci.append(S)\n",
    "        L_S.append(L_S_ci) \n",
    "        if(i%500==0 and i!=0):\n",
    "            print(str(i)+'data points labelled in',(time.time() - start_time)/60,'mins')\n",
    "    return L_S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "start_time = time.time()\n",
    "\n",
    "lt = time.localtime()\n",
    "\n",
    "print(\"started at: {}-{}-{}, {}:{}:{}\".format(lt.tm_mday,lt.tm_mon,lt.tm_year,lt.tm_hour,lt.tm_min,lt.tm_sec))\n",
    "\n",
    "dev_L_S = get_L_S_Tensor(dev_cands)\n",
    "\n",
    "np.save(\"dev_L_S_smooth\",np.array(dev_L_S))\n",
    "\n",
    "train_L_S = get_L_S_Tensor(train_cands)\n",
    "np.save(\"train_L_S_smooth\",np.array(train_L_S))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# test_L_S = get_L_S_Tensor(test_cands)\n",
    "# pkl.dump(test_L_S,open(\"test_L_S.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def draw2DArray(a):\n",
    "    fig = plt.figure(figsize=(6, 3.2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('colorMap')\n",
    "    plt.imshow(np.array(a))\n",
    "    ax.set_aspect('equal')\n",
    "    cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
    "    cax.get_xaxis().set_visible(False)\n",
    "    cax.get_yaxis().set_visible(False)\n",
    "    cax.patch.set_alpha(0)\n",
    "    cax.set_frame_on(False)\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.show()\n",
    "    \n",
    "      \n",
    "def report2dict(cr):\n",
    "    # Parse rows\n",
    "    tmp = list()\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0:\n",
    "            tmp.append(parsed_row)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    measures = tmp[0]\n",
    "\n",
    "    D_class_data = defaultdict(dict)\n",
    "    for row in tmp[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return pd.DataFrame(D_class_data).T\n",
    "\n",
    "def predictAndPrint(pl):\n",
    "    print(\"acc\",accuracy_score(gold_labels_dev,pl))\n",
    "#     print(precision_recall_fscore_support(true_labels,pl,average='macro'))\n",
    "    print(confusion_matrix(gold_labels_dev,pl))\n",
    "#     draw2DArray(confusion_matrix(gold_labels_dev,pl))\n",
    "    return report2dict(classification_report(gold_labels_dev, pl))# target_names=class_names))\n",
    "    \n",
    "\n",
    "\n",
    "def drawPRcurve(y_test,y_score,it_no):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    splt = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score,pos_label=1)\n",
    "\n",
    "    splt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    splt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.title('{0:d} Precision-Recall curve: AP={1:0.2f}'.format(it_no,\n",
    "              average_precision))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2814, 2, 10) (22276, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "LF_l = [\n",
    "    1,1,1,1,1,-1,1,-1,-1,-1\n",
    "]\n",
    "import numpy as np\n",
    "dev_L_S = np.load(\"dev_L_S_smooth.npy\")\n",
    "train_L_S = np.load(\"train_L_S_smooth.npy\")\n",
    "\n",
    "# dev_L_S = np.load(\"dev_L_S_discrete.npy\")\n",
    "# train_L_S = np.load(\"train_L_S_discrete.npy\")\n",
    "\n",
    "test_L_S = dev_L_S\n",
    "true_labels = gold_labels_dev\n",
    "print(dev_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call this only once for a kernel startup\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# BATCH_SIZE = 32\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "NoOfLFs= len(LF_l)\n",
    "NoOfClasses = 2\n",
    "print(len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## normalized model with smooth LFs\n",
    "\n",
    "def train_nl_s(lr,ep,th,af):\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=af,\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "#         print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "#         print(s)\n",
    "#         print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "#         print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),\\\n",
    "                           -tf.ones_like(v))\n",
    "#             print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        ## smooth pout\n",
    "        pout = tf.map_fn(lambda c: iskequalsy(l,c)*s_ ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "       \n",
    "        ## discrete pout\n",
    "#         pout = tf.map_fn(lambda c: iskequalsy(l,c) ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,name=\"t_pout\")\n",
    "#         print(\"pout\",pout)\n",
    "\n",
    "#         print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "#         print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "#             print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "#             print(\"intsy\",out1)\n",
    "            return out1\n",
    "        \n",
    "        ## discrete normalizer\n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),np.arange(NoOfClasses,dtype=np.float64))\n",
    "\n",
    "\n",
    "        ## smooth normalizer\n",
    "        zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                   np.array([-1,1],dtype=np.float64),name=\"zy\")\n",
    "    \n",
    "\n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        \n",
    "#         print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "#         print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "#         print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "\n",
    "        normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "        \n",
    "   \n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "#         print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "#         print(\"predict\",predict)\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "\n",
    "#                 unique, counts = np.unique(pl, return_counts=True)\n",
    "#                 print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(true_labels,pl))\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "\n",
    "            # Initialize an iterator over the validation dataset.\n",
    "            sess.run(dev_init_op)\n",
    "            a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "            print(a)\n",
    "            print(t)\n",
    "\n",
    "            unique, counts = np.unique(pl, return_counts=True)\n",
    "            print(dict(zip(unique, counts)))\n",
    "\n",
    "            print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "            predictAndPrint(pl)\n",
    "            print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-mean 0.0\n",
      "0 loss 210993.73606317406\n",
      "[ 0.00217413 -0.00086366  0.00105643  0.000967    0.00205571  0.00017504\n",
      "  0.00265636 -0.00062412  0.00052894 -0.00028845]\n",
      "[[1.11654688 0.81322154 1.00860747 0.99966979 1.10539034 1.04173494\n",
      "  1.16823607 1.03211473 1.14724214 1.06563648]]\n",
      "acc 0.9253731343283582\n",
      "(0.3670886075949367, 0.15343915343915343, 0.21641791044776118, None)\n",
      "\n",
      "1 loss 210636.25317858346\n",
      "[ 3.17280988e-03  1.30576197e-04  2.01868672e-03  1.92918439e-03\n",
      "  3.04769271e-03 -6.19591714e-05  3.62170517e-03 -1.56230230e-03\n",
      " -4.07473515e-04 -1.22611713e-03]\n",
      "[[1.11554916 0.8122285  1.00765385 0.99871412 1.1044027  1.04213109\n",
      "  1.16726512 1.033024   1.1481516  1.06655238]]\n",
      "acc 0.9260838663823738\n",
      "(0.37662337662337664, 0.15343915343915343, 0.21804511278195485, None)\n",
      "\n",
      "2 loss 210278.973232167\n",
      "[ 0.00417149  0.00112483  0.00298162  0.00289204  0.00403972 -0.00029708\n",
      "  0.00458768 -0.00250162 -0.00134505 -0.00216493]\n",
      "[[1.11455144 0.81123542 1.0066995  0.99775771 1.10341496 1.0425262\n",
      "  1.16629358 1.03393475 1.14906257 1.06746975]]\n",
      "acc 0.9267945984363894\n",
      "(0.38666666666666666, 0.15343915343915343, 0.2196969696969697, None)\n",
      "\n",
      "3 loss 209921.9160540784\n",
      "[ 0.00517017  0.0021191   0.00394521  0.00385556  0.0050318  -0.00053027\n",
      "  0.00555427 -0.00344205 -0.00228377 -0.00310486]\n",
      "[[1.11355371 0.8102423  1.00574442 0.99680059 1.10242711 1.04292026\n",
      "  1.16532147 1.03484695 1.14997502 1.06838856]]\n",
      "acc 0.9264392324093816\n",
      "(0.375, 0.14285714285714285, 0.20689655172413796, None)\n",
      "\n",
      "4 loss 209565.09575973428\n",
      "[ 0.00616884  0.0031134   0.00490946  0.00481974  0.00602393 -0.00076152\n",
      "  0.00652148 -0.00438358 -0.00322362 -0.00404591]\n",
      "[[1.11255599 0.80924914 1.00478863 0.99584276 1.10143917 1.04331322\n",
      "  1.16434879 1.03576057 1.15088894 1.0693088 ]]\n",
      "acc 0.9267945984363894\n",
      "(0.38028169014084506, 0.14285714285714285, 0.20769230769230768, None)\n",
      "\n",
      "[ 0.00616884  0.0031134   0.00490946  0.00481974  0.00602393 -0.00076152\n",
      "  0.00652148 -0.00438358 -0.00322362 -0.00404591]\n",
      "[[1.11255599 0.80924914 1.00478863 0.99584276 1.10143917 1.04331322\n",
      "  1.16434879 1.03576057 1.15088894 1.0693088 ]]\n",
      "{0: 2743, 1: 71}\n",
      "acc 0.9267945984363894\n",
      "acc 0.9267945984363894\n",
      "[[2581   44]\n",
      " [ 162   27]]\n",
      "(0.38028169014084506, 0.14285714285714285, 0.20769230769230768, None)\n",
      "alpha-mean 0.1\n",
      "0 loss 200639.99497545062\n",
      "[0.10217403 0.09913589 0.10105025 0.10096081 0.102055   0.10023906\n",
      " 0.10265079 0.09938556 0.10053889 0.09972131]\n",
      "[[1.11654731 0.81322185 1.00861557 0.99967687 1.10539221 1.04173639\n",
      "  1.16823867 1.03209932 1.14722739 1.06562345]]\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "1 loss 200329.2553904686\n",
      "[0.10317261 0.10012967 0.10200652 0.10191699 0.1030463  0.10006554\n",
      " 0.10361065 0.09845679 0.09961216 0.09879313]\n",
      "[[1.11555003 0.81222912 1.00766992 0.99872819 1.10440641 1.0421344\n",
      "  1.1672703  1.0329934  1.14812225 1.06652665]]\n",
      "acc 0.9253731343283582\n",
      "(0.3670886075949367, 0.15343915343915343, 0.21641791044776118, None)\n",
      "\n",
      "2 loss 200018.5354261995\n",
      "[0.10417118 0.10112348 0.10296356 0.10287395 0.10403765 0.09989327\n",
      " 0.10457121 0.0975267  0.09868406 0.09786361]\n",
      "[[1.11455274 0.81123633 1.00672347 0.99777871 1.10342048 1.04253178\n",
      "  1.1663013  1.03388912 1.14901882 1.0674315 ]]\n",
      "acc 0.9260838663823738\n",
      "(0.37662337662337664, 0.15343915343915343, 0.21804511278195485, None)\n",
      "\n",
      "3 loss 199707.85102142408\n",
      "[0.10516976 0.10211732 0.10392138 0.10383169 0.10502905 0.0997223\n",
      " 0.10553249 0.09659529 0.09775462 0.09693278]\n",
      "[[1.11355545 0.81024351 1.00577624 0.99682845 1.10243443 1.04292851\n",
      "  1.16533168 1.03478646 1.14991705 1.06833796]]\n",
      "acc 0.9267945984363894\n",
      "(0.38666666666666666, 0.15343915343915343, 0.2196969696969697, None)\n",
      "\n",
      "4 loss 199397.21277434606\n",
      "[0.10616834 0.10311118 0.10487996 0.10479019 0.10602052 0.09955263\n",
      " 0.10649446 0.09566259 0.09682386 0.09600064]\n",
      "[[1.11255816 0.80925064 1.00482824 0.99587743 1.10144825 1.04332457\n",
      "  1.16436145 1.03568538 1.15081692 1.069246  ]]\n",
      "acc 0.9264392324093816\n",
      "(0.375, 0.14285714285714285, 0.20689655172413796, None)\n",
      "\n",
      "[0.10616834 0.10311118 0.10487996 0.10479019 0.10602052 0.09955263\n",
      " 0.10649446 0.09566259 0.09682386 0.09600064]\n",
      "[[1.11255816 0.80925064 1.00482824 0.99587743 1.10144825 1.04332457\n",
      "  1.16436145 1.03568538 1.15081692 1.069246  ]]\n",
      "{0: 2742, 1: 72}\n",
      "acc 0.9264392324093816\n",
      "acc 0.9264392324093816\n",
      "[[2580   45]\n",
      " [ 162   27]]\n",
      "(0.375, 0.14285714285714285, 0.20689655172413796, None)\n",
      "alpha-mean 0.2\n",
      "0 loss 190704.48036197305\n",
      "[0.20217393 0.19913547 0.20104263 0.20095318 0.2020543  0.20030376\n",
      " 0.20264392 0.19939658 0.20055018 0.19973241]\n",
      "[[1.11654799 0.8132221  1.00862698 0.99968674 1.10539499 1.04175094\n",
      "  1.16824127 1.03207768 1.14720646 1.06560552]]\n",
      "acc 0.9243070362473348\n",
      "(0.35714285714285715, 0.15873015873015872, 0.21978021978021978, None)\n",
      "\n",
      "1 loss 190437.1681229399\n",
      "[0.20317241 0.20012884 0.20199151 0.20190196 0.20304489 0.2001942\n",
      " 0.20359697 0.19847852 0.1996344  0.198815  ]\n",
      "[[1.11555139 0.81222961 1.0076926  0.99874784 1.10441194 1.04216402\n",
      "  1.16727546 1.03295038 1.14808062 1.06649125]]\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "2 loss 190169.70081555194\n",
      "[0.20417089 0.20112225 0.20294132 0.20285167 0.20403556 0.20008509\n",
      " 0.20455086 0.19755886 0.198717   0.197896  ]\n",
      "[[1.11455479 0.81123706 1.00675736 0.99780807 1.10342872 1.04257697\n",
      "  1.16630898 1.03382496 1.14895673 1.06737886]]\n",
      "acc 0.925728500355366\n",
      "(0.3717948717948718, 0.15343915343915343, 0.21722846441947563, None)\n",
      "\n",
      "3 loss 189902.09119194225\n",
      "[0.20516938 0.20211569 0.20389205 0.20380231 0.2050263  0.19997645\n",
      " 0.20550556 0.19663765 0.19779799 0.19697543]\n",
      "[[1.11355819 0.81024447 1.00582128 0.99686746 1.10244534 1.04298977\n",
      "  1.16534183 1.03470137 1.14983476 1.06826831]]\n",
      "acc 0.9264392324093816\n",
      "(0.3815789473684211, 0.15343915343915343, 0.21886792452830187, None)\n",
      "\n",
      "4 loss 189634.34708139126\n",
      "[0.20616786 0.20310916 0.20484368 0.20475385 0.2060171  0.1998683\n",
      " 0.20646107 0.19571491 0.19687741 0.19605331]\n",
      "[[1.11256159 0.80925182 1.00488438 0.99592601 1.1014618  1.0434024\n",
      "  1.16437402 1.03557959 1.15071467 1.06915956]]\n",
      "acc 0.9267945984363894\n",
      "(0.38666666666666666, 0.15343915343915343, 0.2196969696969697, None)\n",
      "\n",
      "[0.20616786 0.20310916 0.20484368 0.20475385 0.2060171  0.1998683\n",
      " 0.20646107 0.19571491 0.19687741 0.19605331]\n",
      "[[1.11256159 0.80925182 1.00488438 0.99592601 1.1014618  1.0434024\n",
      "  1.16437402 1.03557959 1.15071467 1.06915956]]\n",
      "{0: 2739, 1: 75}\n",
      "acc 0.9267945984363894\n",
      "acc 0.9267945984363894\n",
      "[[2579   46]\n",
      " [ 160   29]]\n",
      "(0.38666666666666666, 0.15343915343915343, 0.2196969696969697, None)\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 181144.68902163472\n",
      "[0.30217384 0.29913512 0.30103312 0.30094366 0.30205362 0.3003725\n",
      " 0.30263536 0.29940934 0.30056317 0.29974523]\n",
      "[[1.11654929 0.81322227 1.00864448 0.99970196 1.10540013 1.04178813\n",
      "  1.16824334 1.03204467 1.14717355 1.06557828]]\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "1 loss 180917.55590227756\n",
      "[0.30317224 0.30012816 0.3019728  0.30188323 0.30304356 0.30033079\n",
      " 0.30357996 0.29850361 0.29965997 0.29884023]\n",
      "[[1.11555404 0.81222993 1.00772748 0.99877823 1.10442216 1.04223901\n",
      "  1.1672796  1.03288467 1.14801505 1.06643739]]\n",
      "acc 0.9243070362473348\n",
      "(0.35714285714285715, 0.15873015873015872, 0.21978021978021978, None)\n",
      "\n",
      "2 loss 180690.12301438404\n",
      "[0.30417064 0.30112123 0.30291361 0.30282393 0.30403358 0.30028857\n",
      " 0.30452553 0.29759597 0.29875479 0.2979333 ]\n",
      "[[1.11455878 0.81123753 1.00680957 0.99785357 1.10344398 1.0426903\n",
      "  1.16631514 1.03372687 1.14885889 1.06729869]]\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "3 loss 180462.40029683936\n",
      "[0.30516904 0.30211435 0.30385554 0.30376575 0.30502368 0.30024587\n",
      " 0.30547205 0.29668645 0.2978477  0.29702449]\n",
      "[[1.11356353 0.81024508 1.0058908  0.99692799 1.10246558 1.04314196\n",
      "  1.16534999 1.03457121 1.14970503 1.06816215]]\n",
      "acc 0.9253731343283582\n",
      "(0.3670886075949367, 0.15343915343915343, 0.21641791044776118, None)\n",
      "\n",
      "4 loss 180234.39324383676\n",
      "[0.30616745 0.30310751 0.30479856 0.30470868 0.30601387 0.30020272\n",
      " 0.30641952 0.29577509 0.29693871 0.29611381]\n",
      "[[1.11256827 0.80925258 1.00497117 0.99600153 1.10148698 1.04359398\n",
      "  1.16438415 1.03541766 1.15055341 1.06902772]]\n",
      "acc 0.9264392324093816\n",
      "(0.3815789473684211, 0.15343915343915343, 0.21886792452830187, None)\n",
      "\n",
      "[0.30616745 0.30310751 0.30479856 0.30470868 0.30601387 0.30020272\n",
      " 0.30641952 0.29577509 0.29693871 0.29611381]\n",
      "[[1.11256827 0.80925258 1.00497117 0.99600153 1.10148698 1.04359398\n",
      "  1.16438415 1.03541766 1.15055341 1.06902772]]\n",
      "{0: 2738, 1: 76}\n",
      "acc 0.9264392324093816\n",
      "acc 0.9264392324093816\n",
      "[[2578   47]\n",
      " [ 160   29]]\n",
      "(0.3815789473684211, 0.15343915343915343, 0.21886792452830187, None)\n",
      "alpha-mean 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 171885.1931302566\n",
      "[0.40217378 0.39913489 0.40102056 0.40093108 0.40205303 0.40045142\n",
      " 0.40262464 0.39942533 0.40057939 0.39976129]\n",
      "[[1.11655328 0.81322232 1.00867496 0.99972973 1.10541532 1.04187171\n",
      "  1.16824459 1.031989   1.14711421 1.06553016]]\n",
      "acc 0.9228855721393034\n",
      "(0.3541666666666667, 0.17989417989417988, 0.2385964912280702, None)\n",
      "\n",
      "1 loss 171695.14240822828\n",
      "[0.40317211 0.4001277  0.40194808 0.40185848 0.40304238 0.40048759\n",
      " 0.40355864 0.39853505 0.39969185 0.3988718 ]\n",
      "[[1.11556217 0.81223003 1.00778844 0.99883388 1.10445252 1.04240677\n",
      "  1.16728226 1.03277368 1.1478967  1.06634203]]\n",
      "acc 0.9250177683013504\n",
      "(0.375, 0.1746031746031746, 0.23826714801444038, None)\n",
      "\n",
      "2 loss 171504.6952385699\n",
      "[0.40417045 0.40112056 0.40287701 0.40278729 0.40403183 0.40052222\n",
      " 0.40449375 0.39764241 0.39880189 0.39797994]\n",
      "[[1.11457109 0.81123768 1.00690105 0.99793709 1.10348951 1.04294265\n",
      "  1.16631937 1.03356103 1.14868218 1.06715661]]\n",
      "acc 0.9246624022743426\n",
      "(0.36470588235294116, 0.164021164021164, 0.2262773722627737, None)\n",
      "\n",
      "3 loss 171313.85882916974\n",
      "[0.4051688  0.40211347 0.40380735 0.40371751 0.40502137 0.40055531\n",
      " 0.40542998 0.39674747 0.39790955 0.39708574]\n",
      "[[1.11358004 0.81024527 1.00601284 0.99703939 1.1025263  1.04347934\n",
      "  1.16535595 1.03435101 1.14947057 1.06797383]]\n",
      "acc 0.9246624022743426\n",
      "(0.3614457831325301, 0.15873015873015872, 0.22058823529411767, None)\n",
      "\n",
      "4 loss 171122.63650125652\n",
      "[0.40616715 0.40310643 0.40473905 0.40464911 0.40601101 0.40058691\n",
      " 0.40636732 0.39585025 0.3970149  0.39618927]\n",
      "[[1.11258903 0.8092528  1.00512385 0.99614082 1.10156289 1.04401679\n",
      "  1.16439203 1.03514355 1.15026183 1.06879364]]\n",
      "acc 0.9250177683013504\n",
      "(0.36585365853658536, 0.15873015873015872, 0.22140221402214022, None)\n",
      "\n",
      "[0.40616715 0.40310643 0.40473905 0.40464911 0.40601101 0.40058691\n",
      " 0.40636732 0.39585025 0.3970149  0.39618927]\n",
      "[[1.11258903 0.8092528  1.00512385 0.99614082 1.10156289 1.04401679\n",
      "  1.16439203 1.03514355 1.15026183 1.06879364]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9250177683013504\n",
      "acc 0.9250177683013504\n",
      "[[2573   52]\n",
      " [ 159   30]]\n",
      "(0.36585365853658536, 0.15873015873015872, 0.22140221402214022, None)\n",
      "alpha-mean 0.5\n",
      "0 loss 162939.02480563402\n",
      "[0.50213641 0.4991348  0.50097271 0.50090368 0.50192124 0.49999946\n",
      " 0.50236435 0.49946581 0.50061593 0.49981886]\n",
      "[[1.11662934 0.81322226 1.00873726 0.99979417 1.10565044 1.04205862\n",
      "  1.16834186 1.03188672 1.14699176 1.06542715]]\n",
      "acc 0.9196872778962332\n",
      "(0.3302752293577982, 0.19047619047619047, 0.24161073825503354, None)\n",
      "\n",
      "1 loss 162850.03955358765\n",
      "[0.50309594 0.50012752 0.50185243 0.50180419 0.50277854 0.49999943\n",
      " 0.50303419 0.49860047 0.49976094 0.49895439]\n",
      "[[1.11571721 0.8122299  1.00791334 0.99896351 1.10492303 1.04278018\n",
      "  1.16747914 1.03256925 1.14765206 1.06613703]]\n",
      "acc 0.9196872778962332\n",
      "(0.32710280373831774, 0.18518518518518517, 0.23648648648648646, None)\n",
      "\n",
      "2 loss 162760.89086773156\n",
      "[0.50405515 0.5011203  0.50273345 0.50270635 0.50363545 0.49999946\n",
      " 0.50370209 0.49773232 0.49889577 0.4980871 ]\n",
      "[[1.11480548 0.81123749 1.00708877 0.99813227 1.10419552 1.04350193\n",
      "  1.16661808 1.03325505 1.1483162  1.06685036]]\n",
      "acc 0.9214641080312722\n",
      "(0.34, 0.17989417989417988, 0.23529411764705885, None)\n",
      "\n",
      "3 loss 162671.24163910563\n",
      "[0.50501405 0.50211312 0.50361574 0.50361008 0.50449193 0.49999945\n",
      " 0.50436806 0.49686141 0.49802777 0.49721703]\n",
      "[[1.11389414 0.81024502 1.00626358 0.99730049 1.10346796 1.04422386\n",
      "  1.16575871 1.03394406 1.14898413 1.06756708]]\n",
      "acc 0.9214641080312722\n",
      "(0.3333333333333333, 0.1693121693121693, 0.22456140350877196, None)\n",
      "\n",
      "4 loss 162581.1644993357\n",
      "[0.50597263 0.503106   0.50449927 0.50451534 0.50534795 0.49999941\n",
      " 0.50503192 0.4959878  0.49715701 0.49634425]\n",
      "[[1.11298319 0.80925249 1.00543783 0.99646823 1.1027404  1.04494596\n",
      "  1.16490109 1.03463623 1.14965582 1.06828714]]\n",
      "acc 0.9235963041933192\n",
      "(0.35555555555555557, 0.1693121693121693, 0.2293906810035842, None)\n",
      "\n",
      "[0.50597263 0.503106   0.50449927 0.50451534 0.50534795 0.49999941\n",
      " 0.50503192 0.4959878  0.49715701 0.49634425]\n",
      "[[1.11298319 0.80925249 1.00543783 0.99646823 1.1027404  1.04494596\n",
      "  1.16490109 1.03463623 1.14965582 1.06828714]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9235963041933192\n",
      "acc 0.9235963041933192\n",
      "[[2567   58]\n",
      " [ 157   32]]\n",
      "(0.35555555555555557, 0.1693121693121693, 0.2293906810035842, None)\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 161442.9431471251\n",
      "[0.6020958  0.59913476 0.60090896 0.60081304 0.6018042  0.59970344\n",
      " 0.60231306 0.59956964 0.6007225  0.59992423]\n",
      "[[1.11670352 0.81322218 1.00885935 0.99995197 1.10580745 1.04203967\n",
      "  1.1683168  1.03171181 1.14675397 1.0652012 ]]\n",
      "acc 0.9090262970859986\n",
      "(0.25547445255474455, 0.18518518518518517, 0.2147239263803681, None)\n",
      "\n",
      "1 loss 161382.87955052592\n",
      "[0.60301324 0.60012745 0.60172481 0.60162172 0.60254434 0.59899201\n",
      " 0.60293152 0.598822   0.59997592 0.59919562]\n",
      "[[1.11586815 0.81222975 1.00815817 0.99928089 1.10523748 1.04274253\n",
      "  1.16743018 1.03221953 1.14717671 1.06568701]]\n",
      "acc 0.9111584932480455\n",
      "(0.26717557251908397, 0.18518518518518517, 0.21875, None)\n",
      "\n",
      "2 loss 161322.49777803893\n",
      "[0.60393006 0.60112018 0.60254215 0.60243096 0.60328412 0.59828045\n",
      " 0.60354618 0.59807088 0.59922454 0.59846222]\n",
      "[[1.11503345 0.81123727 1.00745652 0.99860994 1.10466707 1.04344578\n",
      "  1.16654484 1.03273119 1.14760383 1.06617763]]\n",
      "acc 0.912224591329069\n",
      "(0.2661290322580645, 0.1746031746031746, 0.2108626198083067, None)\n",
      "\n",
      "3 loss 161261.78192378776\n",
      "[0.60484626 0.60211296 0.60336088 0.60324085 0.60402349 0.59756876\n",
      " 0.60415735 0.59731608 0.5984671  0.59772479]\n",
      "[[1.11419942 0.81024474 1.00675448 0.99793918 1.10409623 1.04414941\n",
      "  1.16566083 1.03324677 1.14803531 1.06667301]]\n",
      "acc 0.9125799573560768\n",
      "(0.2682926829268293, 0.1746031746031746, 0.21153846153846154, None)\n",
      "\n",
      "4 loss 161200.74120397968\n",
      "[0.60576184 0.60310579 0.60418077 0.60405089 0.60476242 0.59685697\n",
      " 0.60476502 0.59655773 0.59770488 0.59698326]\n",
      "[[1.11336605 0.80925216 1.00605213 0.99726871 1.10352502 1.04485339\n",
      "  1.16477823 1.0337662  1.14847113 1.0671731 ]]\n",
      "acc 0.9157782515991472\n",
      "(0.2857142857142857, 0.1693121693121693, 0.21262458471760795, None)\n",
      "\n",
      "[0.60576184 0.60310579 0.60418077 0.60405089 0.60476242 0.59685697\n",
      " 0.60476502 0.59655773 0.59770488 0.59698326]\n",
      "[[1.11336605 0.80925216 1.00605213 0.99726871 1.10352502 1.04485339\n",
      "  1.16477823 1.0337662  1.14847113 1.0671731 ]]\n",
      "{0: 2702, 1: 112}\n",
      "acc 0.9157782515991472\n",
      "acc 0.9157782515991472\n",
      "[[2545   80]\n",
      " [ 157   32]]\n",
      "(0.2857142857142857, 0.1693121693121693, 0.21262458471760795, None)\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 159838.21141220749\n",
      "[0.70199852 0.69913478 0.70064994 0.70050632 0.70158372 0.69974812\n",
      " 0.70241884 0.69989864 0.70116151 0.70031885]\n",
      "[[1.11684696 0.81322209 1.00909608 1.00020124 1.10603123 1.04198871\n",
      "  1.16832555 1.03148073 1.14652464 1.06476873]]\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "1 loss 159805.78696832046\n",
      "[0.70281529 0.70012747 0.70120386 0.70100447 0.70210101 0.69908186\n",
      " 0.7031378  0.69948201 0.70085426 0.69998286]\n",
      "[[1.11616003 0.81222961 1.00863201 0.99977902 1.10568825 1.04264001\n",
      "  1.16744852 1.03175497 1.14671635 1.06481849]]\n",
      "acc 0.9090262970859986\n",
      "(0.36964980544747084, 0.5026455026455027, 0.4260089686098655, None)\n",
      "\n",
      "2 loss 159773.37383745587\n",
      "[0.70363076 0.70112018 0.70175788 0.70150161 0.70261734 0.69841559\n",
      " 0.70385253 0.69906167 0.70054384 0.69964374]\n",
      "[[1.1154744  0.81123709 1.00816648 0.99935546 1.10534549 1.04329149\n",
      "  1.16657206 1.0320314  1.14690984 1.06487073]]\n",
      "acc 0.9108031272210376\n",
      "(0.376984126984127, 0.5026455026455027, 0.4308390022675737, None)\n",
      "\n",
      "3 loss 159740.97272019568\n",
      "[0.70444494 0.70211292 0.70231177 0.70199827 0.70313272 0.69774933\n",
      " 0.70457044 0.69863868 0.70023113 0.69929936]\n",
      "[[1.11479008 0.81024455 1.00769954 0.99893059 1.10500298 1.04394314\n",
      "  1.1656962  1.03231    1.14710509 1.06492547]]\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "4 loss 159708.5857508321\n",
      "[0.70525781 0.70310569 0.70286519 0.70249357 0.70364712 0.69708307\n",
      " 0.7052864  0.69821305 0.69991616 0.69895049]\n",
      "[[1.11410707 0.80925197 1.00723119 0.99850443 1.1046607  1.04459495\n",
      "  1.16482094 1.03259076 1.14730211 1.06498272]]\n",
      "acc 0.912224591329069\n",
      "(0.38306451612903225, 0.5026455026455027, 0.43478260869565216, None)\n",
      "\n",
      "[0.70525781 0.70310569 0.70286519 0.70249357 0.70364712 0.69708307\n",
      " 0.7052864  0.69821305 0.69991616 0.69895049]\n",
      "[[1.11410707 0.80925197 1.00723119 0.99850443 1.1046607  1.04459495\n",
      "  1.16482094 1.03259076 1.14730211 1.06498272]]\n",
      "{0: 2566, 1: 248}\n",
      "acc 0.912224591329069\n",
      "acc 0.912224591329069\n",
      "[[2472  153]\n",
      " [  94   95]]\n",
      "(0.38306451612903225, 0.5026455026455027, 0.43478260869565216, None)\n",
      "alpha-mean 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 158004.07635994116\n",
      "[0.80178978 0.79913531 0.80032776 0.80022985 0.80131484 0.79985737\n",
      " 0.80241737 0.80023174 0.80141598 0.80085236]\n",
      "[[1.11707343 0.81322156 1.00951067 1.00057442 1.10624016 1.04183987\n",
      "  1.16838797 1.03134808 1.14644998 1.06457373]]\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "1 loss 157980.1437335581\n",
      "[0.80238924 0.80012853 0.80055975 0.80045272 0.80156051 0.79930025\n",
      " 0.80312747 0.80015058 0.80136757 0.80105712]\n",
      "[[1.11662203 0.81222855 1.009462   1.00052521 1.1061083  1.04234269\n",
      "  1.16757533 1.03148884 1.14656606 1.06442774]]\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "2 loss 157956.25471070939\n",
      "[0.802987   0.80112175 0.80079227 0.80067594 0.80180566 0.79874196\n",
      " 0.80383489 0.80006835 0.8013183  0.80126177]\n",
      "[[1.11617199 0.81123553 1.00941282 1.00047563 1.10597657 1.04284709\n",
      "  1.1667632  1.03163029 1.14668268 1.06428221]]\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "3 loss 157932.40873757977\n",
      "[0.80358305 0.802115   0.80102532 0.8008995  0.80205029 0.79818252\n",
      " 0.80453959 0.79998504 0.80126817 0.80146628]\n",
      "[[1.11572331 0.8102425  1.00936312 1.00042568 1.10584497 1.04335305\n",
      "  1.16595156 1.03177243 1.14679985 1.06413716]]\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "4 loss 157908.60567244943\n",
      "[0.80417739 0.80310825 0.8012589  0.8011234  0.80229441 0.79762194\n",
      " 0.80524155 0.79990064 0.80121717 0.80167066]\n",
      "[[1.11527597 0.80924944 1.00931289 1.00037535 1.10571349 1.04386056\n",
      "  1.16514043 1.03191527 1.14691756 1.06399259]]\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "[0.80417739 0.80310825 0.8012589  0.8011234  0.80229441 0.79762194\n",
      " 0.80524155 0.79990064 0.80121717 0.80167066]\n",
      "[[1.11527597 0.80924944 1.00931289 1.00037535 1.10571349 1.04386056\n",
      "  1.16514043 1.03191527 1.14691756 1.06399259]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "acc 0.8923240938166311\n",
      "[[2398  227]\n",
      " [  76  113]]\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "alpha-mean 0.9\n",
      "0 loss 156188.47493084203\n",
      "[0.90147816 0.8991364  0.90000635 0.89991441 0.90110193 0.90141249\n",
      " 0.90239705 0.9002277  0.90138711 0.90076081]\n",
      "[[1.1173339  0.81322064 1.00977608 1.00082567 1.10638394 1.04033989\n",
      "  1.16861103 1.03141907 1.14652839 1.06464761]]\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "1 loss 156168.19810846492\n",
      "[0.90175623 0.90013069 0.8999173  0.89982265 0.90113362 0.90241151\n",
      " 0.90309004 0.90014349 0.90131081 0.90086872]\n",
      "[[1.11714846 0.81222674 1.00999147 1.00102604 1.10639642 1.03934135\n",
      "  1.16803173 1.03162974 1.14672183 1.06457851]]\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "2 loss 156147.96799112097\n",
      "[0.90203378 0.90112499 0.89982823 0.89973088 0.90116546 0.90341051\n",
      " 0.90378066 0.90005927 0.90123451 0.90097658]\n",
      "[[1.11696337 0.81123284 1.01020677 1.00122633 1.10640875 1.03834283\n",
      "  1.16745487 1.03184029 1.14691516 1.06450945]]\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "3 loss 156127.784367168\n",
      "[0.9023108  0.9021193  0.89973915 0.8996391  0.90119744 0.90440951\n",
      " 0.90446891 0.89997503 0.90115821 0.9010844 ]\n",
      "[[1.11677863 0.81023893 1.01042197 1.00142653 1.10642095 1.03734432\n",
      "  1.16688046 1.03205074 1.14710839 1.06444044]]\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "4 loss 156107.64719544147\n",
      "[0.90258731 0.90311361 0.89965006 0.89954729 0.90122956 0.9054085\n",
      " 0.90515478 0.89989078 0.90108193 0.90119219]\n",
      "[[1.11659424 0.80924502 1.01063708 1.00162665 1.10643301 1.03634583\n",
      "  1.1663085  1.03226108 1.14730151 1.06437148]]\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "[0.90258731 0.90311361 0.89965006 0.89954729 0.90122956 0.9054085\n",
      " 0.90515478 0.89989078 0.90108193 0.90119219]\n",
      "[[1.11659424 0.80924502 1.01063708 1.00162665 1.10643301 1.03634583\n",
      "  1.1663085  1.03226108 1.14730151 1.06437148]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "acc 0.8933901918976546\n",
      "[[2407  218]\n",
      " [  82  107]]\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "alpha-mean 1.0\n",
      "0 loss 154429.9212835355\n",
      "[1.00221163 0.999138   1.00080599 1.00000681 1.00210088 1.00143328\n",
      " 1.00272322 1.00131025 1.00249671 1.00168307]\n",
      "[[1.11763236 0.81325018 1.0095614  1.00062431 1.10645085 1.04135549\n",
      "  1.1693823  1.03121971 1.14646807 1.0647551 ]]\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "1 loss 154412.16877106891\n",
      "[1.00324086 1.00000045 1.0018498  1.00000744 1.00313107 1.0024703\n",
      " 1.00374865 1.0023487  1.00352371 1.00271732]\n",
      "[[1.1179115  0.81253047 1.00960441 1.00062431 1.1067042  1.04147572\n",
      "  1.1697856  1.03132086 1.14681626 1.06491989]]\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 154405.4651393359\n",
      "[1.00426285 1.00000045 1.0028813  1.00000799 1.00415361 1.00349671\n",
      " 1.00476839 1.00337596 1.00454441 1.00374216]\n",
      "[[1.1184141  0.81253047 1.0097917  1.00062431 1.10718171 1.04179665\n",
      "  1.17039526 1.0316135  1.14738094 1.06529977]]\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 154405.4642637172\n",
      "[1.00528048 1.00000042 1.0039047  1.00000835 1.00517159 1.0045171\n",
      " 1.00578454 1.00439686 1.00556119 1.00476158]\n",
      "[[1.11909374 0.81253047 1.01019352 1.00062431 1.1078431  1.04233188\n",
      "  1.17114856 1.03212298 1.14810411 1.06588544]]\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 154405.46289797986\n",
      "[1.0062952  1.00000036 1.00492326 1.00000841 1.00618655 1.0055337\n",
      " 1.00679821 1.00541381 1.00657531 1.00577754]\n",
      "[[1.11988979 0.81253047 1.01079317 1.00062431 1.1086273  1.04303077\n",
      "  1.17199147 1.03280351 1.14892806 1.06661932]]\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[1.0062952  1.00000036 1.00492326 1.00000841 1.00618655 1.0055337\n",
      " 1.00679821 1.00541381 1.00657531 1.00577754]\n",
      "[[1.11988979 0.81253047 1.01079317 1.00062431 1.1086273  1.04303077\n",
      "  1.17199147 1.03280351 1.14892806 1.06661932]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print(\"alpha-mean\",i)\n",
    "    predicted_labels=train_nl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                           tf.truncated_normal_initializer(i,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 159838.21141220749\n",
      "[0.70199852 0.69913478 0.70064994 0.70050632 0.70158372 0.69974812\n",
      " 0.70241884 0.69989864 0.70116151 0.70031885]\n",
      "[[1.11684696 0.81322209 1.00909608 1.00020124 1.10603123 1.04198871\n",
      "  1.16832555 1.03148073 1.14652464 1.06476873]]\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "1 loss 159805.78696832046\n",
      "[0.70281529 0.70012747 0.70120386 0.70100447 0.70210101 0.69908186\n",
      " 0.7031378  0.69948201 0.70085426 0.69998286]\n",
      "[[1.11616003 0.81222961 1.00863201 0.99977902 1.10568825 1.04264001\n",
      "  1.16744852 1.03175497 1.14671635 1.06481849]]\n",
      "acc 0.9090262970859986\n",
      "(0.36964980544747084, 0.5026455026455027, 0.4260089686098655, None)\n",
      "\n",
      "2 loss 159773.3738374559\n",
      "[0.70363076 0.70112018 0.70175788 0.70150161 0.70261734 0.69841559\n",
      " 0.70385253 0.69906167 0.70054384 0.69964374]\n",
      "[[1.1154744  0.81123709 1.00816648 0.99935546 1.10534549 1.04329149\n",
      "  1.16657206 1.0320314  1.14690984 1.06487073]]\n",
      "acc 0.9108031272210376\n",
      "(0.376984126984127, 0.5026455026455027, 0.4308390022675737, None)\n",
      "\n",
      "3 loss 159740.97272019566\n",
      "[0.70444494 0.70211292 0.70231177 0.70199827 0.70313272 0.69774933\n",
      " 0.70457044 0.69863868 0.70023113 0.69929936]\n",
      "[[1.11479008 0.81024455 1.00769954 0.99893059 1.10500298 1.04394314\n",
      "  1.1656962  1.03231    1.14710509 1.06492547]]\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "4 loss 159708.58575083216\n",
      "[0.70525781 0.70310569 0.70286519 0.70249357 0.70364712 0.69708307\n",
      " 0.7052864  0.69821305 0.69991616 0.69895049]\n",
      "[[1.11410707 0.80925197 1.00723119 0.99850443 1.1046607  1.04459495\n",
      "  1.16482094 1.03259076 1.14730211 1.06498272]]\n",
      "acc 0.912224591329069\n",
      "(0.38306451612903225, 0.5026455026455027, 0.43478260869565216, None)\n",
      "\n",
      "5 loss 159676.21800496726\n",
      "[0.70606936 0.70409849 0.70341905 0.70298753 0.70416055 0.69641682\n",
      " 0.70599817 0.69778415 0.69959866 0.69859913]\n",
      "[[1.11342535 0.80825937 1.00676148 0.998077   1.10431866 1.04524692\n",
      "  1.16394632 1.03287367 1.14750087 1.06504251]]\n",
      "acc 0.9125799573560768\n",
      "(0.38461538461538464, 0.5026455026455027, 0.43577981651376146, None)\n",
      "\n",
      "6 loss 159643.861584211\n",
      "[0.7068796  0.70509131 0.70397245 0.70348175 0.70467298 0.6957506\n",
      " 0.70670615 0.69735214 0.69927847 0.69824521]\n",
      "[[1.11274492 0.80726674 1.00629044 0.99764832 1.10397686 1.04589904\n",
      "  1.16307236 1.03315872 1.14770136 1.06510483]]\n",
      "acc 0.912224591329069\n",
      "(0.3821138211382114, 0.4973544973544973, 0.432183908045977, None)\n",
      "\n",
      "7 loss 159611.5236444864\n",
      "[0.7076885  0.70608416 0.70452492 0.70397548 0.7051844  0.69508441\n",
      " 0.70740986 0.69691709 0.6989559  0.69788916]\n",
      "[[1.1120658  0.80627408 1.0058181  0.99721843 1.10363531 1.0465513\n",
      "  1.16219909 1.03344589 1.14790358 1.0651697 ]]\n",
      "acc 0.912224591329069\n",
      "(0.3821138211382114, 0.4973544973544973, 0.432183908045977, None)\n",
      "\n",
      "8 loss 159579.20351616436\n",
      "[0.70849605 0.70707704 0.70507816 0.7044681  0.70569481 0.69441826\n",
      " 0.70811402 0.69647955 0.69863121 0.69753061]\n",
      "[[1.11138799 0.80528139 1.0053445  0.99678736 1.10329401 1.04720369\n",
      "  1.16132654 1.03373517 1.14810752 1.06523711]]\n",
      "acc 0.9129353233830846\n",
      "(0.38524590163934425, 0.4973544973544973, 0.4341801385681293, None)\n",
      "\n",
      "9 loss 159546.89125116487\n",
      "[0.70930224 0.70806995 0.7056322  0.70496111 0.70620418 0.69375215\n",
      " 0.70881408 0.69603941 0.69830433 0.69716942]\n",
      "[[1.11071149 0.80428867 1.00486967 0.99635513 1.10295296 1.0478562\n",
      "  1.16045473 1.03402654 1.14831316 1.06530706]]\n",
      "acc 0.9129353233830846\n",
      "(0.38333333333333336, 0.48677248677248675, 0.4289044289044289, None)\n",
      "\n",
      "[0.70930224 0.70806995 0.7056322  0.70496111 0.70620418 0.69375215\n",
      " 0.70881408 0.69603941 0.69830433 0.69716942]\n",
      "[[1.11071149 0.80428867 1.00486967 0.99635513 1.10295296 1.0478562\n",
      "  1.16045473 1.03402654 1.14831316 1.06530706]]\n",
      "{0: 2574, 1: 240}\n",
      "acc 0.9129353233830846\n",
      "acc 0.9129353233830846\n",
      "[[2477  148]\n",
      " [  97   92]]\n",
      "(0.38333333333333336, 0.48677248677248675, 0.4289044289044289, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl_s(0.001/len(train_L_S),10,tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                           tf.truncated_normal_initializer(0.7,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 177593.6089042592\n",
      "[0.41854278 0.11520687 0.31047011 0.30153524 0.40736582 0.34136772\n",
      " 0.47013164 0.33035577 0.44548349 0.36387167]\n",
      "[[1.11655652 0.81322315 1.00867167 0.99972798 1.10542697 1.04178828\n",
      "  1.16826229 1.03197667 1.14706397 1.06550782]]\n",
      "acc 0.9068941009239516\n",
      "(0.26143790849673204, 0.21164021164021163, 0.23391812865497075, None)\n",
      "\n",
      "1 loss 177396.56970193452\n",
      "[0.41954094 0.11619926 0.31138325 0.30244885 0.40835387 0.3413951\n",
      " 0.47105875 0.32949968 0.44462813 0.36301599]\n",
      "[[1.11556877 0.8122317  1.00778122 0.99882951 1.10447602 1.04224007\n",
      "  1.16731925 1.0327495  1.14779659 1.06629769]]\n",
      "acc 0.9086709310589908\n",
      "(0.2702702702702703, 0.21164021164021163, 0.2373887240356083, None)\n",
      "\n",
      "2 loss 177199.12666951108\n",
      "[0.42053909 0.11719167 0.3122979  0.30336394 0.409342   0.34142099\n",
      " 0.47198704 0.32864074 0.44376979 0.36215742]\n",
      "[[1.11458114 0.81124022 1.00688941 0.99792959 1.10352504 1.04269297\n",
      "  1.16637726 1.03352561 1.14853279 1.06709081]]\n",
      "acc 0.9136460554371002\n",
      "(0.29850746268656714, 0.21164021164021163, 0.24767801857585137, None)\n",
      "\n",
      "3 loss 177001.28635498337\n",
      "[0.42153725 0.11818411 0.31321404 0.30428052 0.4103302  0.34144541\n",
      " 0.4729165  0.327779   0.44290854 0.36129601]\n",
      "[[1.11359362 0.81024869 1.00599624 0.99702825 1.10257402 1.04314696\n",
      "  1.16543643 1.03430495 1.14927251 1.06788713]]\n",
      "acc 0.9175550817341862\n",
      "(0.31932773109243695, 0.20105820105820105, 0.24675324675324675, None)\n",
      "\n",
      "4 loss 176803.0511289301\n",
      "[0.42253541 0.11917658 0.31413164 0.30519854 0.41131849 0.3414684\n",
      " 0.47384712 0.32691451 0.44204442 0.36043183]\n",
      "[[1.11260622 0.80925713 1.00510178 0.99612552 1.10162297 1.043602\n",
      "  1.16449689 1.03508745 1.15001569 1.06868658]]\n",
      "acc 0.9193319118692252\n",
      "(0.33035714285714285, 0.19576719576719576, 0.24584717607973422, None)\n",
      "\n",
      "[0.42253541 0.11917658 0.31413164 0.30519854 0.41131849 0.3414684\n",
      " 0.47384712 0.32691451 0.44204442 0.36043183]\n",
      "[[1.11260622 0.80925713 1.00510178 0.99612552 1.10162297 1.043602\n",
      "  1.16449689 1.03508745 1.15001569 1.06868658]]\n",
      "{0: 2702, 1: 112}\n",
      "acc 0.9193319118692252\n",
      "acc 0.9193319118692252\n",
      "[[2550   75]\n",
      " [ 152   37]]\n",
      "(0.33035714285714285, 0.19576719576719576, 0.24584717607973422, None)\n"
     ]
    }
   ],
   "source": [
    "# for i in np.linspace(0,1,11):\n",
    "#     print(\"alpha-mean\",i)\n",
    "#     predicted_labels=train_nl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12),\\\n",
    "#                            tf.truncated_normal_initializer(i,0.1,12))\n",
    "    \n",
    "predicted_labels=train_nl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12),\\\n",
    "                           tf.truncated_normal_initializer(0.3,0.1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 155264.53954891075\n",
      "[0.92690352 0.9971321  0.89117171 0.89079329 0.90543897 0.98363892\n",
      " 0.9542917  0.89181359 0.8937952  0.91162108]\n",
      "[[1.10009277 0.72704278 1.03085428 1.02047423 1.10633782 0.96621163\n",
      "  1.12864769 1.05197377 1.16535794 1.05758622]]\n",
      "acc 0.8941009239516702\n",
      "(0.33126934984520123, 0.5661375661375662, 0.41796875, None)\n",
      "\n",
      "1 loss 154352.82584004718\n",
      "[0.94538075 1.00003227 0.88239876 0.88170429 0.90954794 0.99722517\n",
      " 0.98051568 0.88340816 0.88622291 0.92065953]\n",
      "[[1.0884174  0.72649249 1.05094155 1.03924606 1.10629312 0.95459477\n",
      "  1.11214221 1.07165552 1.18340155 1.05207841]]\n",
      "acc 0.8948116560056859\n",
      "(0.3333333333333333, 0.5661375661375662, 0.41960784313725485, None)\n",
      "\n",
      "2 loss 154345.657013675\n",
      "[0.95711568 1.00017134 0.87422725 0.87406136 0.91291265 0.99776011\n",
      " 0.99031907 0.87564378 0.87869541 0.92818664]\n",
      "[[1.08146765 0.72632277 1.06995853 1.0570634  1.10656614 0.94945574\n",
      "  1.10669314 1.09036948 1.20057795 1.04758399]]\n",
      "acc 0.8941009239516702\n",
      "(0.3333333333333333, 0.5767195767195767, 0.42248062015503873, None)\n",
      "\n",
      "3 loss 154341.1192211615\n",
      "[0.96473516 1.00014065 0.87002874 0.86936931 0.91573331 0.99703065\n",
      " 0.99419881 0.87566606 0.87567845 0.93511696]\n",
      "[[1.0772874  0.72628999 1.0882641  1.07415257 1.10708575 0.9450955\n",
      "  1.10472967 1.1084319  1.21700396 1.04402819]]\n",
      "acc 0.8862828713574982\n",
      "(0.3154929577464789, 0.5925925925925926, 0.411764705882353, None)\n",
      "\n",
      "4 loss 154338.10484061058\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "acc 0.8791755508173419\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "acc 0.8791755508173419\n",
      "[[2346  279]\n",
      " [  61  128]]\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl_s(0.1/len(train_L_S),5,\\\n",
    "                            tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            tf.truncated_normal_initializer(0.9,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 155548.10499263214\n",
      "[0.93326346 0.98037827 0.88953763 0.88821575 0.91311962 0.98554735\n",
      " 0.96406621 0.89759127 0.90964637 0.91662847]\n",
      "[[1.1032539  0.72197787 1.03206361 1.02162306 1.10767904 0.96823482\n",
      "  1.13417441 1.05126276 1.16661986 1.05815618]]\n",
      "acc 0.8855721393034826\n",
      "(0.3147632311977716, 0.5978835978835979, 0.41240875912408764, None)\n",
      "\n",
      "1 loss 154383.652287932\n",
      "[0.94953699 1.00003838 0.8767362  0.87537624 0.91583377 0.99209049\n",
      " 0.98585481 0.89384701 0.90618009 0.92479421]\n",
      "[[1.09328744 0.7103856  1.05400886 1.04201962 1.10870954 0.92510664\n",
      "  1.12145815 1.06944685 1.18536492 1.05320904]]\n",
      "acc 0.8855721393034826\n",
      "(0.3147632311977716, 0.5978835978835979, 0.41240875912408764, None)\n",
      "\n",
      "2 loss 154346.07266892138\n",
      "[0.96029182 1.00012677 0.86560251 0.86458486 0.91794999 0.98825132\n",
      " 0.99431731 0.89279564 0.90488922 0.93167133]\n",
      "[[1.08722855 0.71028976 1.07575335 1.06207778 1.11012153 0.84748815\n",
      "  1.11739958 1.08540677 1.20247734 1.04934008]]\n",
      "acc 0.8781094527363185\n",
      "(0.3121951219512195, 0.6772486772486772, 0.42737896494156924, None)\n",
      "\n",
      "3 loss 154338.96566033977\n",
      "[0.96760865 1.00012473 0.85225636 0.85189594 0.9194952  0.98042366\n",
      " 0.99813295 0.89525075 0.90660047 0.93801452]\n",
      "[[1.08354231 0.71012754 1.09771802 1.0821421  1.11199203 0.7512131\n",
      "  1.11605471 1.09861973 1.21776018 1.04669099]]\n",
      "acc 0.8742004264392325\n",
      "(0.3049645390070922, 0.6825396825396826, 0.4215686274509804, None)\n",
      "\n",
      "4 loss 154328.02467496082\n",
      "[0.97290781 1.00012272 0.83648652 0.83773746 0.92044744 0.96624436\n",
      " 0.99960116 0.90305713 0.91281119 0.94217553]\n",
      "[[1.08125315 0.70990132 1.12052711 1.10269218 1.11442038 0.64725766\n",
      "  1.11577799 1.107643   1.23052228 1.04508611]]\n",
      "acc 0.8567874911158493\n",
      "(0.27983539094650206, 0.7195767195767195, 0.40296296296296297, None)\n",
      "\n",
      "[0.97290781 1.00012272 0.83648652 0.83773746 0.92044744 0.96624436\n",
      " 0.99960116 0.90305713 0.91281119 0.94217553]\n",
      "[[1.08125315 0.70990132 1.12052711 1.10269218 1.11442038 0.64725766\n",
      "  1.11577799 1.107643   1.23052228 1.04508611]]\n",
      "{0: 2328, 1: 486}\n",
      "acc 0.8567874911158493\n",
      "acc 0.8567874911158493\n",
      "[[2275  350]\n",
      " [  53  136]]\n",
      "(0.27983539094650206, 0.7195767195767195, 0.40296296296296297, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl_s(0.1/len(train_L_S),5,\\\n",
    "                            tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            tf.truncated_normal_initializer(0.9,0.01,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## normalized model with smooth LFs + penalties\n",
    "\n",
    "def train(lr,ep,th,af,plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=0,p3k=3):\n",
    "    \n",
    "    ## lr : learning rate\n",
    "    ## ep : no of epochs\n",
    "    ## th : thetas initializer\n",
    "    ## af : alphas initializer\n",
    "    ## penalty : {1,2,3} use one of the three penalties, 0: no-penalty\n",
    "    ## p3k : parameter for penalty-3 \n",
    "    ## smooth : flag if smooth lfs are used \n",
    "    ## make sure smooth/discrete LF data is loaded into train_L_S and test_L_S\n",
    "    ## plv : all possible label values = [-1,1] for binary, \n",
    "    ##       np.arange(0,NoOfClasses) for multiclass\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=af,\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "#         print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "#         print(s)\n",
    "#         print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "#         print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),-tf.ones_like(v))\n",
    "#             print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        if(smooth):\n",
    "            pout = tf.map_fn(lambda c: iskequalsy(l,c)*s_ ,plv,name=\"pout\")\n",
    "        else:\n",
    "            pout = tf.map_fn(lambda c: iskequalsy(l,c) ,plv,name=\"pout\")\n",
    "\n",
    "#         print(\"pout\",pout)    \n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,\\\n",
    "                           name=\"t_pout\")\n",
    "    \n",
    "#         print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "#         print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "#             print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "#             print(\"intsy\",out1)\n",
    "            return out1\n",
    "                \n",
    "\n",
    "        if(smooth):\n",
    "            #smooth normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                           plv,name=\"zy\")\n",
    "        else:\n",
    "            #discrete normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                           plv,name=\"zy\")\n",
    "\n",
    "    \n",
    "# \n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        \n",
    "#         print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "#         print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "#         print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "        if(penalty == 1):\n",
    "            normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                      +tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas))\n",
    "        elif(penalty == 2):\n",
    "            normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     -tf.minimum( tf.reduce_min(thetas),0.0)\n",
    "        elif(penalty == 3):\n",
    "             normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     +tf.reduce_sum(tf.log(1+tf.exp(-thetas-pk)))\n",
    "        else:\n",
    "             normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "   \n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "#         print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(true_labels,pl))\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "\n",
    "            # Initialize an iterator over the validation dataset.\n",
    "            sess.run(dev_init_op)\n",
    "            a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "            print(a)\n",
    "            print(t)\n",
    "\n",
    "            unique, counts = np.unique(pl, return_counts=True)\n",
    "            print(dict(zip(unique, counts)))\n",
    "\n",
    "            print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "            predictAndPrint(pl)\n",
    "            print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha-mean 0.0\n",
      "0 loss 194264.85326121486\n",
      "[ 0.09947401  0.09596     0.09735473  0.09725704  0.09894004 -0.01030508\n",
      "  0.09894431 -0.09624256 -0.09494115 -0.09586474]\n",
      "[[1.01984608 0.71578729 0.91326762 0.90408304 1.00926658 1.07292658\n",
      "  1.07212253 1.12601357 1.24131725 1.16021693]]\n",
      "{0: 2806, 1: 8}\n",
      "acc 0.9342572850035537\n",
      "(0.75, 0.031746031746031744, 0.06091370558375634, None)\n",
      "\n",
      "1 loss 165944.78653442475\n",
      "[ 0.19790907  0.19411453  0.19583783  0.19573171  0.19731637  0.00760686\n",
      "  0.19744465 -0.19395243 -0.1925366  -0.19354266]\n",
      "[[0.92264118 0.61691555 0.81792812 0.8082795  0.9130418  1.0849647\n",
      "  0.97551319 1.22139401 1.33701538 1.25683504]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 145426.3452882983\n",
      "[ 0.29704017  0.29296915  0.29497276  0.29485531  0.29646632  0.0399873\n",
      "  0.29663876 -0.29182634 -0.29029167 -0.29138179]\n",
      "[[0.8261613  0.51767846 0.7251858  0.71477777 0.82094729 1.08603578\n",
      "  0.88155871 1.3152654  1.43122333 1.35249425]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 129826.68522984035\n",
      "[ 0.3965422   0.39207137  0.39443259  0.39429967  0.3960568   0.07599614\n",
      "  0.39621449 -0.38993288 -0.38828145 -0.3894509 ]\n",
      "[[0.73526719 0.41834843 0.63658532 0.62519367 0.74518257 1.08494332\n",
      "  0.79750861 1.40760353 1.52378527 1.44700078]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 117293.74879868481\n",
      "[ 0.49677966  0.49105991  0.49399921  0.49384786  0.49619953  0.11179939\n",
      "  0.49619988 -0.48814211 -0.48638682 -0.48762274]\n",
      "[[0.7522436  0.31907066 0.55577511 0.54350837 0.74399203 1.08535089\n",
      "  0.76963201 1.49848879 1.61471096 1.54024589]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49677966  0.49105991  0.49399921  0.49384786  0.49619953  0.11179939\n",
      "  0.49619988 -0.48814211 -0.48638682 -0.48762274]\n",
      "[[0.7522436  0.31907066 0.55577511 0.54350837 0.74399203 1.08535089\n",
      "  0.76963201 1.49848879 1.61471096 1.54024589]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 185781.95847627256\n",
      "[0.19967327 0.19615971 0.19744814 0.19735001 0.19911576 0.09226008\n",
      " 0.19894121 0.00368871 0.00499454 0.00406713]\n",
      "[[1.02003556 0.7157202  0.91386131 0.90455327 1.00954362 1.07559231\n",
      "  1.07237539 1.12539065 1.24081911 1.15986489]]\n",
      "{0: 2806, 1: 8}\n",
      "acc 0.9342572850035537\n",
      "(0.75, 0.031746031746031744, 0.06091370558375634, None)\n",
      "\n",
      "1 loss 159483.32056801888\n",
      "[ 0.29834619  0.29456714  0.29622298  0.29611599  0.29773821  0.10580634\n",
      "  0.29768761 -0.09462073 -0.09321636 -0.09421548]\n",
      "[[0.92345526 0.61679842 0.81989008 0.80995456 0.91485833 1.09507768\n",
      "  0.97699202 1.22065646 1.33651883 1.25658421]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 139408.32185090086\n",
      "[ 0.3975604   0.39348825  0.39545592  0.39533679  0.39700739  0.13221124\n",
      "  0.39698284 -0.19293461 -0.19142947 -0.1925003 ]\n",
      "[[0.83099436 0.51762236 0.73035262 0.71948807 0.83356164 1.10505495\n",
      "  0.88993698 1.31460596 1.43088955 1.35239227]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 123858.68372792944\n",
      "[ 0.49756632  0.49258738  0.49496802  0.49483458  0.49696945  0.1628117\n",
      "  0.49681511 -0.29131805 -0.28970991 -0.29085113]\n",
      "[[0.83285096 0.41841009 0.64885145 0.63709209 0.82459795 1.11250385\n",
      "  0.85509316 1.40718658 1.5237811  1.4471387 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 113020.3875257964\n",
      "[ 0.50000013  0.59156907  0.5844681   0.59021834  0.5000003   0.19376208\n",
      "  0.51123288 -0.38976341 -0.3880604  -0.38926297]\n",
      "[[0.92591555 0.31930299 0.58000265 0.57207223 0.87728778 1.12105543\n",
      "  0.89176137 1.49844003 1.61517635 1.54073868]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.50000013  0.59156907  0.5844681   0.59021834  0.5000003   0.19376208\n",
      "  0.51123288 -0.38976341 -0.3880604  -0.38926297]\n",
      "[[0.92591555 0.31930299 0.58000265 0.57207223 0.87728778 1.12105543\n",
      "  0.89176137 1.49844003 1.61517635 1.54073868]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.2\n",
      "0 loss 177594.2035698463\n",
      "[0.2998713  0.29635755 0.29753524 0.29743639 0.2992909  0.19452654\n",
      " 0.29888345 0.10360372 0.10490988 0.10398125]\n",
      "[[1.02046742 0.71566814 0.91490631 0.90540562 1.01015783 1.07973837\n",
      "  1.07289938 1.12436596 1.23996459 1.15923948]]\n",
      "{0: 2807, 1: 7}\n",
      "acc 0.9339019189765458\n",
      "(0.7142857142857143, 0.026455026455026454, 0.051020408163265314, None)\n",
      "\n",
      "1 loss 153274.7976608556\n",
      "[0.3987608  0.39498448 0.39659098 0.39648244 0.3981468  0.20352977\n",
      " 0.39785555 0.00476452 0.00615457 0.00516393]\n",
      "[[0.9259043  0.61673024 0.82351894 0.81317403 0.92070084 1.10797379\n",
      "  0.98135213 1.21926386 1.33544443 1.25587701]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 133649.26813170992\n",
      "[ 0.49836711  0.49397731  0.4959534   0.49583306  0.49775627  0.22341711\n",
      "  0.4974006  -0.09395993 -0.09248529 -0.09353668]\n",
      "[[0.90100356 0.5176436  0.74036327 0.72908607 0.89365752 1.12841482\n",
      "  0.93170971 1.31317643 1.42988121 1.35176352]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 120090.01885759828\n",
      "[ 0.50000078  0.59308803  0.5859046   0.59131064  0.50000104  0.24768838\n",
      "  0.51653763 -0.19269018 -0.19113024 -0.19224044]\n",
      "[[0.99217384 0.41859694 0.67015697 0.66244417 0.93906287 1.14633091\n",
      "  0.95828995 1.40607873 1.52320186 1.44684248]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 111705.38536236154\n",
      "[ 0.50000114  0.69205658  0.66524157  0.66324452  0.50000175  0.27312621\n",
      "  0.52859743 -0.29127515 -0.28962538 -0.29079428]\n",
      "[[1.08372211 0.31976297 0.61793727 0.62134597 0.9883906  1.16473381\n",
      "  0.99630666 1.49776328 1.61514372 1.5408448 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.50000114  0.69205658  0.66524157  0.66324452  0.50000175  0.27312621\n",
      "  0.52859743 -0.29127515 -0.28962538 -0.29079428]\n",
      "[[1.08372211 0.31976297 0.61793727 0.62134597 0.9883906  1.16473381\n",
      "  0.99630666 1.49776328 1.61514372 1.5408448 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 169683.52358332893\n",
      "[0.40006244 0.39654585 0.39761115 0.39751119 0.39946103 0.2968958\n",
      " 0.39873967 0.20351808 0.20482092 0.20389316]\n",
      "[[1.02164921 0.71564148 0.9169104  0.9071246  1.01196031 1.08614671\n",
      "  1.07439769 1.12256292 1.23836416 1.15803103]]\n",
      "{0: 2809, 1: 5}\n",
      "acc 0.9331911869225302\n",
      "(0.6, 0.015873015873015872, 0.030927835051546386, None)\n",
      "\n",
      "1 loss 147341.3047459415\n",
      "[0.49927003 0.49536291 0.49695314 0.49684306 0.49865141 0.30143638\n",
      " 0.49798158 0.10420372 0.10557752 0.10459595]\n",
      "[[0.96098571 0.61673248 0.83092475 0.82015039 0.95689325 1.12502221\n",
      "  1.00522847 1.21667679 1.33325105 1.25427689]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 130754.29555342294\n",
      "[0.50000051 0.59445316 0.58784302 0.59255759 0.50000047 0.31379893\n",
      " 0.52728408 0.00498614 0.00642668 0.00539627]\n",
      "[[1.04388695 0.51777637 0.75788739 0.75010021 0.98346727 1.15850694\n",
      "  1.00710826 1.31053049 1.42776614 1.35026805]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 119915.01827076054\n",
      "[ 0.50000205  0.69355416  0.66785191  0.66540137  0.50000267  0.33073439\n",
      "  0.5449851  -0.09395686 -0.09244154 -0.09352388]\n",
      "[[1.131576   0.41900493 0.70354088 0.70594911 1.02190754 1.1893871\n",
      "  1.03480614 1.40369236 1.52145764 1.44561437]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 111929.6503662495\n",
      "[ 0.49999995  0.79251571  0.72138576  0.70825856  0.50000011  0.35003533\n",
      "  0.55367597 -0.19269192 -0.19109407 -0.19223071]\n",
      "[[1.22143754 0.32065982 0.66426053 0.67554094 1.06691918 1.21979513\n",
      "  1.07672563 1.49581689 1.61396201 1.54002997]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49999995  0.79251571  0.72138576  0.70825856  0.50000011  0.35003533\n",
      "  0.55367597 -0.19269192 -0.19109407 -0.19223071]\n",
      "[[1.22143754 0.32065982 0.66426053 0.67554094 1.06691918 1.21979513\n",
      "  1.07672563 1.49581689 1.61396201 1.54002997]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.4\n",
      "0 loss 161998.03791505986\n",
      "[0.50004368 0.49671878 0.4976573  0.49755639 0.4996605  0.39996828\n",
      " 0.49848657 0.30347631 0.30477385 0.30384766]\n",
      "[[1.03043541 0.71565441 0.92121984 0.91115652 1.02617647 1.09669756\n",
      "  1.08433716 1.11916339 1.23507266 1.15545617]]\n",
      "{0: 2811, 1: 3}\n",
      "acc 0.9331911869225302\n",
      "(0.6666666666666666, 0.010582010582010581, 0.020833333333333332, None)\n",
      "\n",
      "1 loss 144794.7257024554\n",
      "[0.5000039  0.59572574 0.58995087 0.59378903 0.50000253 0.39974949\n",
      " 0.54096173 0.20370231 0.20505923 0.20408605]\n",
      "[[1.04276126 0.61683495 0.84408496 0.8362443  1.0170567  1.14981159\n",
      "  1.04887586 1.2118703  1.32878794 1.25081125]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 131998.81618999186\n",
      "[0.49999978 0.69484919 0.67131239 0.66866807 0.50000187 0.40426826\n",
      " 0.5673085  0.10419873 0.10561312 0.10459709]\n",
      "[[1.11295515 0.51813914 0.78585255 0.78676092 1.03153308 1.19926236\n",
      "  1.05092249 1.30523562 1.42297787 1.34652946]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 121756.68062099442\n",
      "[0.50000124 0.79395621 0.72680098 0.71420508 0.49999974 0.41349753\n",
      " 0.57876457 0.00501369 0.00649256 0.0054314 ]\n",
      "[[1.19529865 0.41985641 0.74358907 0.7524142  1.06103448 1.24588008\n",
      "  1.08111453 1.39843059 1.51683113 1.4419827 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 113596.81499379182\n",
      "[ 0.49999942  0.89292764  0.76766756  0.7458067   0.50000148  0.42607836\n",
      "  0.58059854 -0.09390152 -0.09234912 -0.09345881]\n",
      "[[1.2825767  0.32265668 0.70825459 0.72391885 1.10027682 1.29120224\n",
      "  1.12627646 1.49091646 1.60982412 1.53675556]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49999942  0.89292764  0.76766756  0.7458067   0.50000148  0.42607836\n",
      "  0.58059854 -0.09390152 -0.09234912 -0.09345881]\n",
      "[[1.2825767  0.32265668 0.70825459 0.72391885 1.10027682 1.29120224\n",
      "  1.12627646 1.49091646 1.60982412 1.53675556]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.5\n",
      "0 loss 157889.89764038645\n",
      "[0.58517833 0.59686387 0.59179784 0.59418346 0.56453853 0.49954881\n",
      " 0.55875418 0.40426153 0.40557605 0.40463714]\n",
      "[[1.03433954 0.71574596 0.92898791 0.92150586 1.0504195  1.11453611\n",
      "  1.09857672 1.11192803 1.22694152 1.14875655]]\n",
      "{0: 2811, 1: 3}\n",
      "acc 0.9331911869225302\n",
      "(0.6666666666666666, 0.010582010582010581, 0.020833333333333332, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 146478.77296745367\n",
      "[0.53338662 0.69595146 0.67474378 0.67138814 0.56400598 0.49732819\n",
      " 0.59363951 0.30444514 0.30581848 0.30483133]\n",
      "[[1.01621361 0.61717488 0.86621487 0.86592647 1.03540186 1.18550765\n",
      "  1.06752881 1.2011621  1.31727085 1.24125633]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 135427.40164752337\n",
      "[0.50000098 0.79512653 0.73337827 0.72151411 0.53204293 0.49594704\n",
      " 0.61037182 0.20466859 0.20609253 0.20506636]\n",
      "[[1.06801229 0.51895373 0.81971805 0.82609229 1.03869969 1.25376835\n",
      "  1.07146865 1.29299437 1.41013139 1.33585511]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 125405.84016562754\n",
      "[0.50000037 0.89426097 0.77755085 0.75854575 0.50000204 0.49786435\n",
      " 0.61321995 0.10519558 0.10667399 0.10560908]\n",
      "[[1.14167675 0.42182486 0.78115818 0.79334306 1.05738007 1.31948832\n",
      "  1.1008312  1.38573543 1.50370148 1.43105489]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 116605.14990806696\n",
      "[0.5000016  0.99333059 0.81427612 0.78807099 0.50000143 0.49994052\n",
      " 0.6071867  0.00605514 0.00759675 0.00649004]\n",
      "[[1.2250806  0.33255217 0.74747221 0.76514592 1.08892232 1.38322829\n",
      "  1.14569017 1.47835999 1.59697771 1.5260231 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.5000016  0.99333059 0.81427612 0.78807099 0.50000143 0.49994052\n",
      " 0.6071867  0.00605514 0.00759675 0.00649004]\n",
      "[[1.2250806  0.33255217 0.74747221 0.76514592 1.08892232 1.38322829\n",
      "  1.14569017 1.47835999 1.59697771 1.5260231 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 157991.9273150094\n",
      "[0.6795881  0.69694286 0.68036809 0.67494236 0.65479552 0.52810075\n",
      " 0.64552101 0.51358779 0.5116442  0.5146183 ]\n",
      "[[1.04209224 0.71597229 0.94364073 0.9396716  1.06152254 1.11429538\n",
      "  1.09960328 1.09758571 1.20738949 1.13202018]]\n",
      "{0: 2804, 1: 10}\n",
      "acc 0.933546552949538\n",
      "(0.6, 0.031746031746031744, 0.06030150753768844, None)\n",
      "\n",
      "1 loss 149890.4524416201\n",
      "[0.63517439 0.79606018 0.74042151 0.72783358 0.65830195 0.49973105\n",
      " 0.66098025 0.41594672 0.41344938 0.41707058]\n",
      "[[1.0245602  0.61790812 0.89321778 0.89494098 1.0469892  1.18544783\n",
      "  1.07651752 1.17792288 1.28771034 1.21557518]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 140843.32704875\n",
      "[0.55467212 0.89527658 0.78803363 0.76928979 0.64085904 0.49916193\n",
      " 0.66137083 0.31625729 0.31381667 0.31738998]\n",
      "[[1.06092116 0.52085337 0.85143295 0.85802938 1.0445405  1.25504755\n",
      "  1.08379033 1.26536747 1.37633633 1.30636633]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 131295.16355218485\n",
      "[0.5000025  0.99450918 0.82876637 0.80416523 0.60633751 0.49926701\n",
      " 0.65081366 0.21650832 0.21411722 0.21765146]\n",
      "[[1.12035276 0.43212292 0.81520945 0.82614038 1.05175243 1.32277117\n",
      "  1.109827   1.35623743 1.46835251 1.40013485]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 122448.0816656167\n",
      "[0.50000052 1.04166262 0.86270516 0.8344728  0.55329724 0.49993973\n",
      " 0.63411773 0.11704817 0.11471163 0.11820607]\n",
      "[[1.19577783 0.47262262 0.78343188 0.79851332 1.07087894 1.38833399\n",
      "  1.15007873 1.44833139 1.56136341 1.49479543]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.50000052 1.04166262 0.86270516 0.8344728  0.55329724 0.49993973\n",
      " 0.63411773 0.11704817 0.11471163 0.11820607]\n",
      "[[1.19577783 0.47262262 0.78343188 0.79851332 1.07087894 1.38833399\n",
      "  1.15007873 1.44833139 1.56136341 1.49479543]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 158212.8522800911\n",
      "[0.77087208 0.79694338 0.75412759 0.74790735 0.74332603 0.6327147\n",
      " 0.75463405 0.64182257 0.6555505  0.64997963]\n",
      "[[1.05734786 0.71648474 0.95949486 0.95479823 1.07546053 1.10905675\n",
      "  1.09420418 1.06925986 1.17392468 1.08443623]]\n",
      "{0: 2780, 1: 34}\n",
      "acc 0.9292821606254442\n",
      "(0.35294117647058826, 0.06349206349206349, 0.10762331838565022, None)\n",
      "\n",
      "1 loss 154348.3761304055\n",
      "[0.77263302 0.89596836 0.80257895 0.79042664 0.75614468 0.56453736\n",
      " 0.76715262 0.55974273 0.57711215 0.57169421]\n",
      "[[1.02828292 0.61972025 0.91371768 0.91361822 1.05859255 1.17850022\n",
      "  1.0599696  1.12614622 1.21932561 1.13508549]]\n",
      "{0: 2808, 1: 6}\n",
      "acc 0.9328358208955224\n",
      "(0.5, 0.015873015873015872, 0.03076923076923077, None)\n",
      "\n",
      "2 loss 148674.50052367026\n",
      "[0.71298399 0.99519271 0.84536896 0.82868936 0.75261895 0.49992505\n",
      " 0.75771159 0.4676792  0.48250959 0.48073334]\n",
      "[[1.04703092 0.53143197 0.87508763 0.87905982 1.05094218 1.24860456\n",
      "  1.06862649 1.1983685  1.28659245 1.20818878]]\n",
      "{0: 2813, 1: 1}\n",
      "acc 0.9331911869225302\n",
      "(1.0, 0.005291005291005291, 0.010526315789473682, None)\n",
      "\n",
      "3 loss 141690.61760315942\n",
      "[0.6376874  1.03615863 0.88112431 0.86068779 0.73946686 0.49980896\n",
      " 0.7367295  0.36867394 0.38352841 0.38169815]\n",
      "[[1.08401739 0.56628003 0.84135859 0.8493403  1.04859637 1.31761282\n",
      "  1.09512983 1.28119471 1.36890912 1.29368938]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 134060.52406763134\n",
      "[0.55027909 1.14479221 0.91317572 0.887704   0.71555997 0.49982088\n",
      " 0.71102893 0.26895489 0.28383171 0.28196331]\n",
      "[[1.13831214 0.67998815 0.81054042 0.82215634 1.05193462 1.38542238\n",
      "  1.1312991  1.36987315 1.45825034 1.38526294]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.55027909 1.14479221 0.91317572 0.887704   0.71555997 0.49982088\n",
      " 0.71102893 0.26895489 0.28383171 0.28196331]\n",
      "[[1.13831214 0.67998815 0.81054042 0.82215634 1.05193462 1.38542238\n",
      "  1.1312991  1.36987315 1.45825034 1.38526294]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.8\n",
      "0 loss 156888.22334408545\n",
      "[0.85123254 0.89699092 0.82577004 0.82400889 0.82325765 0.73955869\n",
      " 0.86698799 0.78653308 0.79197839 0.81933757]\n",
      "[[1.07921274 0.7175971  1.0012327  0.99298176 1.09320986 1.09959202\n",
      "  1.09771072 1.04887393 1.16077117 1.05241636]]\n",
      "{0: 2523, 1: 291}\n",
      "acc 0.900497512437811\n",
      "(0.3436426116838488, 0.5291005291005291, 0.41666666666666663, None)\n",
      "\n",
      "1 loss 154869.17196782224\n",
      "[0.88113199 0.99595084 0.85332608 0.8488132  0.83906596 0.67486726\n",
      " 0.90783491 0.76021487 0.7730442  0.82764111]\n",
      "[[1.0533548  0.63000863 0.98195173 0.97564956 1.08106245 1.16378688\n",
      "  1.05333171 1.07305276 1.18029171 1.04355757]]\n",
      "{0: 2697, 1: 117}\n",
      "acc 0.9211087420042644\n",
      "(0.358974358974359, 0.2222222222222222, 0.27450980392156865, None)\n",
      "\n",
      "2 loss 153683.83081138183\n",
      "[0.87925825 1.01938122 0.88183616 0.87394576 0.84835123 0.60954498\n",
      " 0.88697858 0.72138928 0.7452723  0.83293699]\n",
      "[[1.04283978 0.6462597  0.95165635 0.94807965 1.07050391 1.22972392\n",
      "  1.04344798 1.10336035 1.2041132  1.03653448]]\n",
      "{0: 2788, 1: 26}\n",
      "acc 0.9321250888415068\n",
      "(0.46153846153846156, 0.06349206349206349, 0.11162790697674418, None)\n",
      "\n",
      "3 loss 153059.99167423995\n",
      "[0.85027622 1.13190199 0.9117698  0.90019485 0.85329039 0.54451263\n",
      " 0.8628413  0.66823563 0.70821727 0.84146342]\n",
      "[[1.04285826 0.76580839 0.91969358 0.91894948 1.06155393 1.29622425\n",
      "  1.04881245 1.14072224 1.23221509 1.03110537]]\n",
      "{0: 2798, 1: 16}\n",
      "acc 0.9299928926794598\n",
      "(0.25, 0.021164021164021163, 0.03902439024390244, None)\n",
      "\n",
      "4 loss 151958.5183988523\n",
      "[0.80827158 1.23714934 0.94081911 0.92669989 0.85593964 0.49995562\n",
      " 0.84428695 0.59469571 0.6572689  0.85025923]\n",
      "[[1.0498893  0.87312588 0.88985932 0.89177947 1.05347871 1.36299581\n",
      "  1.06589468 1.18957504 1.26595552 1.0271375 ]]\n",
      "{0: 2805, 1: 9}\n",
      "acc 0.9324804548685146\n",
      "(0.4444444444444444, 0.021164021164021163, 0.0404040404040404, None)\n",
      "\n",
      "[0.80827158 1.23714934 0.94081911 0.92669989 0.85593964 0.49995562\n",
      " 0.84428695 0.59469571 0.6572689  0.85025923]\n",
      "[[1.0498893  0.87312588 0.88985932 0.89177947 1.05347871 1.36299581\n",
      "  1.06589468 1.18957504 1.26595552 1.0271375 ]]\n",
      "{0: 2805, 1: 9}\n",
      "acc 0.9324804548685146\n",
      "acc 0.9324804548685146\n",
      "[[2620    5]\n",
      " [ 185    4]]\n",
      "(0.4444444444444444, 0.021164021164021163, 0.0404040404040404, None)\n",
      "\n",
      "alpha-mean 0.9\n",
      "0 loss 155264.53954891075\n",
      "[0.92690352 0.9971321  0.89117171 0.89079329 0.90543897 0.98363892\n",
      " 0.9542917  0.89181359 0.8937952  0.91162108]\n",
      "[[1.10009277 0.72704278 1.03085428 1.02047423 1.10633782 0.96621163\n",
      "  1.12864769 1.05197377 1.16535794 1.05758622]]\n",
      "{0: 2491, 1: 323}\n",
      "acc 0.8941009239516702\n",
      "(0.33126934984520123, 0.5661375661375662, 0.41796875, None)\n",
      "\n",
      "1 loss 154352.82584004718\n",
      "[0.94538075 1.00003227 0.88239876 0.88170429 0.90954794 0.99722517\n",
      " 0.98051568 0.88340816 0.88622291 0.92065953]\n",
      "[[1.0884174  0.72649249 1.05094155 1.03924606 1.10629312 0.95459477\n",
      "  1.11214221 1.07165552 1.18340155 1.05207841]]\n",
      "{0: 2493, 1: 321}\n",
      "acc 0.8948116560056859\n",
      "(0.3333333333333333, 0.5661375661375662, 0.41960784313725485, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 154345.657013675\n",
      "[0.95711568 1.00017134 0.87422725 0.87406136 0.91291265 0.99776011\n",
      " 0.99031907 0.87564378 0.87869541 0.92818664]\n",
      "[[1.08146765 0.72632277 1.06995853 1.0570634  1.10656614 0.94945574\n",
      "  1.10669314 1.09036948 1.20057795 1.04758399]]\n",
      "{0: 2487, 1: 327}\n",
      "acc 0.8941009239516702\n",
      "(0.3333333333333333, 0.5767195767195767, 0.42248062015503873, None)\n",
      "\n",
      "3 loss 154341.1192211615\n",
      "[0.96473516 1.00014065 0.87002874 0.86936931 0.91573331 0.99703065\n",
      " 0.99419881 0.87566606 0.87567845 0.93511696]\n",
      "[[1.0772874  0.72628999 1.0882641  1.07415257 1.10708575 0.9450955\n",
      "  1.10472967 1.1084319  1.21700396 1.04402819]]\n",
      "{0: 2459, 1: 355}\n",
      "acc 0.8862828713574982\n",
      "(0.3154929577464789, 0.5925925925925926, 0.411764705882353, None)\n",
      "\n",
      "4 loss 154338.10484061058\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "acc 0.8791755508173419\n",
      "[[2346  279]\n",
      " [  61  128]]\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "alpha-mean 1.0\n",
      "0 loss 154393.62099487986\n",
      "[1.12557558 1.00003874 1.12538632 1.         1.1255733  1.12559693\n",
      " 1.12559615 1.12558608 1.12562009 1.12560506]\n",
      "[[1.2446198  0.8130261  1.13596722 1.00062431 1.23341265 1.16815488\n",
      "  1.29646792 1.15796988 1.27354245 1.19163599]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "1 loss 154240.38810601758\n",
      "[1.23195306 1.00011647 1.23182941 0.97335436 1.23195643 1.23205636\n",
      " 1.23194859 1.232052   1.23202169 1.23205054]\n",
      "[[1.35319708 0.81299169 1.24458075 1.02949871 1.34199253 1.27678313\n",
      "  1.40503345 1.26660157 1.38214293 1.30025738]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "2 loss 153643.17077206614\n",
      "[1.33616409 1.00011389 1.33608252 0.94751831 1.33617116 1.33633815\n",
      " 1.33614353 1.33633812 1.33626476 1.33632289]\n",
      "[[1.45865316 0.81290146 1.35005184 1.05738902 1.44744962 1.38228268\n",
      "  1.51048536 1.37210272 1.48763033 1.40575372]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "3 loss 152087.7456070251\n",
      "[1.43950052 1.00009376 1.43944006 0.92449415 1.43950928 1.43973284\n",
      " 1.43947322 1.43973513 1.43964047 1.43971262]\n",
      "[[1.56283252 0.81272882 1.45422781 1.08297519 1.55162825 1.48649707\n",
      "  1.61466876 1.47631698 1.59184955 1.50996871]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "4 loss 148706.22397580525\n",
      "[1.54243366 1.0000831  1.5423676  0.9035523  1.54244137 1.54271703\n",
      " 1.5424124  1.54271916 1.54263144 1.54269755]\n",
      "[[1.66639243 0.81245526 1.55775979 1.10682232 1.65518489 1.59008782\n",
      "  1.7182446  1.57990535 1.6954689  1.61356527]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n",
      "\n",
      "[1.54243366 1.0000831  1.5423676  0.9035523  1.54244137 1.54271703\n",
      " 1.5424124  1.54271916 1.54263144 1.54269755]\n",
      "[[1.66639243 0.81245526 1.55775979 1.10682232 1.65518489 1.59008782\n",
      "  1.7182446  1.57990535 1.6954689  1.61356527]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "acc 0.9012082444918266\n",
      "[[2449  176]\n",
      " [ 102   87]]\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print()\n",
    "    print(\"alpha-mean\",i)\n",
    "    train(0.1/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                          plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha-mean 0.0\n",
      "0 loss 194264.85326121486\n",
      "[ 0.09947401  0.09596     0.09735473  0.09725704  0.09894004 -0.01030508\n",
      "  0.09894431 -0.09624256 -0.09494115 -0.09586474]\n",
      "[[1.01984608 0.71578729 0.91326762 0.90408304 1.00926658 1.07292658\n",
      "  1.07212253 1.12601357 1.24131725 1.16021693]]\n",
      "{0: 2806, 1: 8}\n",
      "acc 0.9342572850035537\n",
      "(0.75, 0.031746031746031744, 0.06091370558375634, None)\n",
      "\n",
      "1 loss 165944.78653442475\n",
      "[ 0.19790907  0.19411453  0.19583783  0.19573171  0.19731637  0.00760686\n",
      "  0.19744465 -0.19395243 -0.1925366  -0.19354266]\n",
      "[[0.92264118 0.61691555 0.81792812 0.8082795  0.9130418  1.0849647\n",
      "  0.97551319 1.22139401 1.33701538 1.25683504]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 145426.3452882983\n",
      "[ 0.29704017  0.29296915  0.29497276  0.29485531  0.29646632  0.0399873\n",
      "  0.29663876 -0.29182634 -0.29029167 -0.29138179]\n",
      "[[0.8261613  0.51767846 0.7251858  0.71477777 0.82094729 1.08603578\n",
      "  0.88155871 1.3152654  1.43122333 1.35249425]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 129826.68522984035\n",
      "[ 0.3965422   0.39207137  0.39443259  0.39429967  0.3960568   0.07599614\n",
      "  0.39621449 -0.38993288 -0.38828145 -0.3894509 ]\n",
      "[[0.73526719 0.41834843 0.63658532 0.62519367 0.74518257 1.08494332\n",
      "  0.79750861 1.40760353 1.52378527 1.44700078]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 117293.74879868481\n",
      "[ 0.49677966  0.49105991  0.49399921  0.49384786  0.49619953  0.11179939\n",
      "  0.49619988 -0.48814211 -0.48638682 -0.48762274]\n",
      "[[0.7522436  0.31907066 0.55577511 0.54350837 0.74399203 1.08535089\n",
      "  0.76963201 1.49848879 1.61471096 1.54024589]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49677966  0.49105991  0.49399921  0.49384786  0.49619953  0.11179939\n",
      "  0.49619988 -0.48814211 -0.48638682 -0.48762274]\n",
      "[[0.7522436  0.31907066 0.55577511 0.54350837 0.74399203 1.08535089\n",
      "  0.76963201 1.49848879 1.61471096 1.54024589]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 185781.95847627256\n",
      "[0.19967327 0.19615971 0.19744814 0.19735001 0.19911576 0.09226008\n",
      " 0.19894121 0.00368871 0.00499454 0.00406713]\n",
      "[[1.02003556 0.7157202  0.91386131 0.90455327 1.00954362 1.07559231\n",
      "  1.07237539 1.12539065 1.24081911 1.15986489]]\n",
      "{0: 2806, 1: 8}\n",
      "acc 0.9342572850035537\n",
      "(0.75, 0.031746031746031744, 0.06091370558375634, None)\n",
      "\n",
      "1 loss 159483.32056801888\n",
      "[ 0.29834619  0.29456714  0.29622298  0.29611599  0.29773821  0.10580634\n",
      "  0.29768761 -0.09462073 -0.09321636 -0.09421548]\n",
      "[[0.92345526 0.61679842 0.81989008 0.80995456 0.91485833 1.09507768\n",
      "  0.97699202 1.22065646 1.33651883 1.25658421]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 139408.32185090086\n",
      "[ 0.3975604   0.39348825  0.39545592  0.39533679  0.39700739  0.13221124\n",
      "  0.39698284 -0.19293461 -0.19142947 -0.1925003 ]\n",
      "[[0.83099436 0.51762236 0.73035262 0.71948807 0.83356164 1.10505495\n",
      "  0.88993698 1.31460596 1.43088955 1.35239227]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 123858.68372792944\n",
      "[ 0.49756632  0.49258738  0.49496802  0.49483458  0.49696945  0.1628117\n",
      "  0.49681511 -0.29131805 -0.28970991 -0.29085113]\n",
      "[[0.83285096 0.41841009 0.64885145 0.63709209 0.82459795 1.11250385\n",
      "  0.85509316 1.40718658 1.5237811  1.4471387 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 113020.3875257964\n",
      "[ 0.50000013  0.59156907  0.5844681   0.59021834  0.5000003   0.19376208\n",
      "  0.51123288 -0.38976341 -0.3880604  -0.38926297]\n",
      "[[0.92591555 0.31930299 0.58000265 0.57207223 0.87728778 1.12105543\n",
      "  0.89176137 1.49844003 1.61517635 1.54073868]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.50000013  0.59156907  0.5844681   0.59021834  0.5000003   0.19376208\n",
      "  0.51123288 -0.38976341 -0.3880604  -0.38926297]\n",
      "[[0.92591555 0.31930299 0.58000265 0.57207223 0.87728778 1.12105543\n",
      "  0.89176137 1.49844003 1.61517635 1.54073868]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.2\n",
      "0 loss 177594.2035698463\n",
      "[0.2998713  0.29635755 0.29753524 0.29743639 0.2992909  0.19452654\n",
      " 0.29888345 0.10360372 0.10490988 0.10398125]\n",
      "[[1.02046742 0.71566814 0.91490631 0.90540562 1.01015783 1.07973837\n",
      "  1.07289938 1.12436596 1.23996459 1.15923948]]\n",
      "{0: 2807, 1: 7}\n",
      "acc 0.9339019189765458\n",
      "(0.7142857142857143, 0.026455026455026454, 0.051020408163265314, None)\n",
      "\n",
      "1 loss 153274.7976608556\n",
      "[0.3987608  0.39498448 0.39659098 0.39648244 0.3981468  0.20352977\n",
      " 0.39785555 0.00476452 0.00615457 0.00516393]\n",
      "[[0.9259043  0.61673024 0.82351894 0.81317403 0.92070084 1.10797379\n",
      "  0.98135213 1.21926386 1.33544443 1.25587701]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 133649.26813170992\n",
      "[ 0.49836711  0.49397731  0.4959534   0.49583306  0.49775627  0.22341711\n",
      "  0.4974006  -0.09395993 -0.09248529 -0.09353668]\n",
      "[[0.90100356 0.5176436  0.74036327 0.72908607 0.89365752 1.12841482\n",
      "  0.93170971 1.31317643 1.42988121 1.35176352]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 120090.01885759828\n",
      "[ 0.50000078  0.59308803  0.5859046   0.59131064  0.50000104  0.24768838\n",
      "  0.51653763 -0.19269018 -0.19113024 -0.19224044]\n",
      "[[0.99217384 0.41859694 0.67015697 0.66244417 0.93906287 1.14633091\n",
      "  0.95828995 1.40607873 1.52320186 1.44684248]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 111705.38536236154\n",
      "[ 0.50000114  0.69205658  0.66524157  0.66324452  0.50000175  0.27312621\n",
      "  0.52859743 -0.29127515 -0.28962538 -0.29079428]\n",
      "[[1.08372211 0.31976297 0.61793727 0.62134597 0.9883906  1.16473381\n",
      "  0.99630666 1.49776328 1.61514372 1.5408448 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.50000114  0.69205658  0.66524157  0.66324452  0.50000175  0.27312621\n",
      "  0.52859743 -0.29127515 -0.28962538 -0.29079428]\n",
      "[[1.08372211 0.31976297 0.61793727 0.62134597 0.9883906  1.16473381\n",
      "  0.99630666 1.49776328 1.61514372 1.5408448 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 169683.52358332893\n",
      "[0.40006244 0.39654585 0.39761115 0.39751119 0.39946103 0.2968958\n",
      " 0.39873967 0.20351808 0.20482092 0.20389316]\n",
      "[[1.02164921 0.71564148 0.9169104  0.9071246  1.01196031 1.08614671\n",
      "  1.07439769 1.12256292 1.23836416 1.15803103]]\n",
      "{0: 2809, 1: 5}\n",
      "acc 0.9331911869225302\n",
      "(0.6, 0.015873015873015872, 0.030927835051546386, None)\n",
      "\n",
      "1 loss 147341.3047459415\n",
      "[0.49927003 0.49536291 0.49695314 0.49684306 0.49865141 0.30143638\n",
      " 0.49798158 0.10420372 0.10557752 0.10459595]\n",
      "[[0.96098571 0.61673248 0.83092475 0.82015039 0.95689325 1.12502221\n",
      "  1.00522847 1.21667679 1.33325105 1.25427689]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 130754.29555342294\n",
      "[0.50000051 0.59445316 0.58784302 0.59255759 0.50000047 0.31379893\n",
      " 0.52728408 0.00498614 0.00642668 0.00539627]\n",
      "[[1.04388695 0.51777637 0.75788739 0.75010021 0.98346727 1.15850694\n",
      "  1.00710826 1.31053049 1.42776614 1.35026805]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 119915.01827076054\n",
      "[ 0.50000205  0.69355416  0.66785191  0.66540137  0.50000267  0.33073439\n",
      "  0.5449851  -0.09395686 -0.09244154 -0.09352388]\n",
      "[[1.131576   0.41900493 0.70354088 0.70594911 1.02190754 1.1893871\n",
      "  1.03480614 1.40369236 1.52145764 1.44561437]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 111929.6503662495\n",
      "[ 0.49999995  0.79251571  0.72138576  0.70825856  0.50000011  0.35003533\n",
      "  0.55367597 -0.19269192 -0.19109407 -0.19223071]\n",
      "[[1.22143754 0.32065982 0.66426053 0.67554094 1.06691918 1.21979513\n",
      "  1.07672563 1.49581689 1.61396201 1.54002997]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49999995  0.79251571  0.72138576  0.70825856  0.50000011  0.35003533\n",
      "  0.55367597 -0.19269192 -0.19109407 -0.19223071]\n",
      "[[1.22143754 0.32065982 0.66426053 0.67554094 1.06691918 1.21979513\n",
      "  1.07672563 1.49581689 1.61396201 1.54002997]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.4\n",
      "0 loss 161998.03791505986\n",
      "[0.50004368 0.49671878 0.4976573  0.49755639 0.4996605  0.39996828\n",
      " 0.49848657 0.30347631 0.30477385 0.30384766]\n",
      "[[1.03043541 0.71565441 0.92121984 0.91115652 1.02617647 1.09669756\n",
      "  1.08433716 1.11916339 1.23507266 1.15545617]]\n",
      "{0: 2811, 1: 3}\n",
      "acc 0.9331911869225302\n",
      "(0.6666666666666666, 0.010582010582010581, 0.020833333333333332, None)\n",
      "\n",
      "1 loss 144794.7257024554\n",
      "[0.5000039  0.59572574 0.58995087 0.59378903 0.50000253 0.39974949\n",
      " 0.54096173 0.20370231 0.20505923 0.20408605]\n",
      "[[1.04276126 0.61683495 0.84408496 0.8362443  1.0170567  1.14981159\n",
      "  1.04887586 1.2118703  1.32878794 1.25081125]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 131998.81618999186\n",
      "[0.49999978 0.69484919 0.67131239 0.66866807 0.50000187 0.40426826\n",
      " 0.5673085  0.10419873 0.10561312 0.10459709]\n",
      "[[1.11295515 0.51813914 0.78585255 0.78676092 1.03153308 1.19926236\n",
      "  1.05092249 1.30523562 1.42297787 1.34652946]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 121756.68062099442\n",
      "[0.50000124 0.79395621 0.72680098 0.71420508 0.49999974 0.41349753\n",
      " 0.57876457 0.00501369 0.00649256 0.0054314 ]\n",
      "[[1.19529865 0.41985641 0.74358907 0.7524142  1.06103448 1.24588008\n",
      "  1.08111453 1.39843059 1.51683113 1.4419827 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 113596.81499379182\n",
      "[ 0.49999942  0.89292764  0.76766756  0.7458067   0.50000148  0.42607836\n",
      "  0.58059854 -0.09390152 -0.09234912 -0.09345881]\n",
      "[[1.2825767  0.32265668 0.70825459 0.72391885 1.10027682 1.29120224\n",
      "  1.12627646 1.49091646 1.60982412 1.53675556]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49999942  0.89292764  0.76766756  0.7458067   0.50000148  0.42607836\n",
      "  0.58059854 -0.09390152 -0.09234912 -0.09345881]\n",
      "[[1.2825767  0.32265668 0.70825459 0.72391885 1.10027682 1.29120224\n",
      "  1.12627646 1.49091646 1.60982412 1.53675556]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.5\n",
      "0 loss 157889.89764038645\n",
      "[0.58517833 0.59686387 0.59179784 0.59418346 0.56453853 0.49954881\n",
      " 0.55875418 0.40426153 0.40557605 0.40463714]\n",
      "[[1.03433954 0.71574596 0.92898791 0.92150586 1.0504195  1.11453611\n",
      "  1.09857672 1.11192803 1.22694152 1.14875655]]\n",
      "{0: 2811, 1: 3}\n",
      "acc 0.9331911869225302\n",
      "(0.6666666666666666, 0.010582010582010581, 0.020833333333333332, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 146478.77296745367\n",
      "[0.53338662 0.69595146 0.67474378 0.67138814 0.56400598 0.49732819\n",
      " 0.59363951 0.30444514 0.30581848 0.30483133]\n",
      "[[1.01621361 0.61717488 0.86621487 0.86592647 1.03540186 1.18550765\n",
      "  1.06752881 1.2011621  1.31727085 1.24125633]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 135427.40164752337\n",
      "[0.50000098 0.79512653 0.73337827 0.72151411 0.53204293 0.49594704\n",
      " 0.61037182 0.20466859 0.20609253 0.20506636]\n",
      "[[1.06801229 0.51895373 0.81971805 0.82609229 1.03869969 1.25376835\n",
      "  1.07146865 1.29299437 1.41013139 1.33585511]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 125405.84016562754\n",
      "[0.50000037 0.89426097 0.77755085 0.75854575 0.50000204 0.49786435\n",
      " 0.61321995 0.10519558 0.10667399 0.10560908]\n",
      "[[1.14167675 0.42182486 0.78115818 0.79334306 1.05738007 1.31948832\n",
      "  1.1008312  1.38573543 1.50370148 1.43105489]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 116605.14990806696\n",
      "[0.5000016  0.99333059 0.81427612 0.78807099 0.50000143 0.49994052\n",
      " 0.6071867  0.00605514 0.00759675 0.00649004]\n",
      "[[1.2250806  0.33255217 0.74747221 0.76514592 1.08892232 1.38322829\n",
      "  1.14569017 1.47835999 1.59697771 1.5260231 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.5000016  0.99333059 0.81427612 0.78807099 0.50000143 0.49994052\n",
      " 0.6071867  0.00605514 0.00759675 0.00649004]\n",
      "[[1.2250806  0.33255217 0.74747221 0.76514592 1.08892232 1.38322829\n",
      "  1.14569017 1.47835999 1.59697771 1.5260231 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 157991.9273150094\n",
      "[0.6795881  0.69694286 0.68036809 0.67494236 0.65479552 0.52810075\n",
      " 0.64552101 0.51358779 0.5116442  0.5146183 ]\n",
      "[[1.04209224 0.71597229 0.94364073 0.9396716  1.06152254 1.11429538\n",
      "  1.09960328 1.09758571 1.20738949 1.13202018]]\n",
      "{0: 2804, 1: 10}\n",
      "acc 0.933546552949538\n",
      "(0.6, 0.031746031746031744, 0.06030150753768844, None)\n",
      "\n",
      "1 loss 149890.4524416201\n",
      "[0.63517439 0.79606018 0.74042151 0.72783358 0.65830195 0.49973105\n",
      " 0.66098025 0.41594672 0.41344938 0.41707058]\n",
      "[[1.0245602  0.61790812 0.89321778 0.89494098 1.0469892  1.18544783\n",
      "  1.07651752 1.17792288 1.28771034 1.21557518]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 140843.32704875\n",
      "[0.55467212 0.89527658 0.78803363 0.76928979 0.64085904 0.49916193\n",
      " 0.66137083 0.31625729 0.31381667 0.31738998]\n",
      "[[1.06092116 0.52085337 0.85143295 0.85802938 1.0445405  1.25504755\n",
      "  1.08379033 1.26536747 1.37633633 1.30636633]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 131295.16355218485\n",
      "[0.5000025  0.99450918 0.82876637 0.80416523 0.60633751 0.49926701\n",
      " 0.65081366 0.21650832 0.21411722 0.21765146]\n",
      "[[1.12035276 0.43212292 0.81520945 0.82614038 1.05175243 1.32277117\n",
      "  1.109827   1.35623743 1.46835251 1.40013485]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 122448.0816656167\n",
      "[0.50000052 1.04166262 0.86270516 0.8344728  0.55329724 0.49993973\n",
      " 0.63411773 0.11704817 0.11471163 0.11820607]\n",
      "[[1.19577783 0.47262262 0.78343188 0.79851332 1.07087894 1.38833399\n",
      "  1.15007873 1.44833139 1.56136341 1.49479543]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.50000052 1.04166262 0.86270516 0.8344728  0.55329724 0.49993973\n",
      " 0.63411773 0.11704817 0.11471163 0.11820607]\n",
      "[[1.19577783 0.47262262 0.78343188 0.79851332 1.07087894 1.38833399\n",
      "  1.15007873 1.44833139 1.56136341 1.49479543]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 158212.8522800911\n",
      "[0.77087208 0.79694338 0.75412759 0.74790735 0.74332603 0.6327147\n",
      " 0.75463405 0.64182257 0.6555505  0.64997963]\n",
      "[[1.05734786 0.71648474 0.95949486 0.95479823 1.07546053 1.10905675\n",
      "  1.09420418 1.06925986 1.17392468 1.08443623]]\n",
      "{0: 2780, 1: 34}\n",
      "acc 0.9292821606254442\n",
      "(0.35294117647058826, 0.06349206349206349, 0.10762331838565022, None)\n",
      "\n",
      "1 loss 154348.3761304055\n",
      "[0.77263302 0.89596836 0.80257895 0.79042664 0.75614468 0.56453736\n",
      " 0.76715262 0.55974273 0.57711215 0.57169421]\n",
      "[[1.02828292 0.61972025 0.91371768 0.91361822 1.05859255 1.17850022\n",
      "  1.0599696  1.12614622 1.21932561 1.13508549]]\n",
      "{0: 2808, 1: 6}\n",
      "acc 0.9328358208955224\n",
      "(0.5, 0.015873015873015872, 0.03076923076923077, None)\n",
      "\n",
      "2 loss 148674.50052367026\n",
      "[0.71298399 0.99519271 0.84536896 0.82868936 0.75261895 0.49992505\n",
      " 0.75771159 0.4676792  0.48250959 0.48073334]\n",
      "[[1.04703092 0.53143197 0.87508763 0.87905982 1.05094218 1.24860456\n",
      "  1.06862649 1.1983685  1.28659245 1.20818878]]\n",
      "{0: 2813, 1: 1}\n",
      "acc 0.9331911869225302\n",
      "(1.0, 0.005291005291005291, 0.010526315789473682, None)\n",
      "\n",
      "3 loss 141690.61760315942\n",
      "[0.6376874  1.03615863 0.88112431 0.86068779 0.73946686 0.49980896\n",
      " 0.7367295  0.36867394 0.38352841 0.38169815]\n",
      "[[1.08401739 0.56628003 0.84135859 0.8493403  1.04859637 1.31761282\n",
      "  1.09512983 1.28119471 1.36890912 1.29368938]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 134060.52406763134\n",
      "[0.55027909 1.14479221 0.91317572 0.887704   0.71555997 0.49982088\n",
      " 0.71102893 0.26895489 0.28383171 0.28196331]\n",
      "[[1.13831214 0.67998815 0.81054042 0.82215634 1.05193462 1.38542238\n",
      "  1.1312991  1.36987315 1.45825034 1.38526294]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.55027909 1.14479221 0.91317572 0.887704   0.71555997 0.49982088\n",
      " 0.71102893 0.26895489 0.28383171 0.28196331]\n",
      "[[1.13831214 0.67998815 0.81054042 0.82215634 1.05193462 1.38542238\n",
      "  1.1312991  1.36987315 1.45825034 1.38526294]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.8\n",
      "0 loss 156888.22334408545\n",
      "[0.85123254 0.89699092 0.82577004 0.82400889 0.82325765 0.73955869\n",
      " 0.86698799 0.78653308 0.79197839 0.81933757]\n",
      "[[1.07921274 0.7175971  1.0012327  0.99298176 1.09320986 1.09959202\n",
      "  1.09771072 1.04887393 1.16077117 1.05241636]]\n",
      "{0: 2523, 1: 291}\n",
      "acc 0.900497512437811\n",
      "(0.3436426116838488, 0.5291005291005291, 0.41666666666666663, None)\n",
      "\n",
      "1 loss 154869.17196782224\n",
      "[0.88113199 0.99595084 0.85332608 0.8488132  0.83906596 0.67486726\n",
      " 0.90783491 0.76021487 0.7730442  0.82764111]\n",
      "[[1.0533548  0.63000863 0.98195173 0.97564956 1.08106245 1.16378688\n",
      "  1.05333171 1.07305276 1.18029171 1.04355757]]\n",
      "{0: 2697, 1: 117}\n",
      "acc 0.9211087420042644\n",
      "(0.358974358974359, 0.2222222222222222, 0.27450980392156865, None)\n",
      "\n",
      "2 loss 153683.83081138183\n",
      "[0.87925825 1.01938122 0.88183616 0.87394576 0.84835123 0.60954498\n",
      " 0.88697858 0.72138928 0.7452723  0.83293699]\n",
      "[[1.04283978 0.6462597  0.95165635 0.94807965 1.07050391 1.22972392\n",
      "  1.04344798 1.10336035 1.2041132  1.03653448]]\n",
      "{0: 2788, 1: 26}\n",
      "acc 0.9321250888415068\n",
      "(0.46153846153846156, 0.06349206349206349, 0.11162790697674418, None)\n",
      "\n",
      "3 loss 153059.99167423995\n",
      "[0.85027622 1.13190199 0.9117698  0.90019485 0.85329039 0.54451263\n",
      " 0.8628413  0.66823563 0.70821727 0.84146342]\n",
      "[[1.04285826 0.76580839 0.91969358 0.91894948 1.06155393 1.29622425\n",
      "  1.04881245 1.14072224 1.23221509 1.03110537]]\n",
      "{0: 2798, 1: 16}\n",
      "acc 0.9299928926794598\n",
      "(0.25, 0.021164021164021163, 0.03902439024390244, None)\n",
      "\n",
      "4 loss 151958.5183988523\n",
      "[0.80827158 1.23714934 0.94081911 0.92669989 0.85593964 0.49995562\n",
      " 0.84428695 0.59469571 0.6572689  0.85025923]\n",
      "[[1.0498893  0.87312588 0.88985932 0.89177947 1.05347871 1.36299581\n",
      "  1.06589468 1.18957504 1.26595552 1.0271375 ]]\n",
      "{0: 2805, 1: 9}\n",
      "acc 0.9324804548685146\n",
      "(0.4444444444444444, 0.021164021164021163, 0.0404040404040404, None)\n",
      "\n",
      "[0.80827158 1.23714934 0.94081911 0.92669989 0.85593964 0.49995562\n",
      " 0.84428695 0.59469571 0.6572689  0.85025923]\n",
      "[[1.0498893  0.87312588 0.88985932 0.89177947 1.05347871 1.36299581\n",
      "  1.06589468 1.18957504 1.26595552 1.0271375 ]]\n",
      "{0: 2805, 1: 9}\n",
      "acc 0.9324804548685146\n",
      "acc 0.9324804548685146\n",
      "[[2620    5]\n",
      " [ 185    4]]\n",
      "(0.4444444444444444, 0.021164021164021163, 0.0404040404040404, None)\n",
      "\n",
      "alpha-mean 0.9\n",
      "0 loss 155264.53954891075\n",
      "[0.92690352 0.9971321  0.89117171 0.89079329 0.90543897 0.98363892\n",
      " 0.9542917  0.89181359 0.8937952  0.91162108]\n",
      "[[1.10009277 0.72704278 1.03085428 1.02047423 1.10633782 0.96621163\n",
      "  1.12864769 1.05197377 1.16535794 1.05758622]]\n",
      "{0: 2491, 1: 323}\n",
      "acc 0.8941009239516702\n",
      "(0.33126934984520123, 0.5661375661375662, 0.41796875, None)\n",
      "\n",
      "1 loss 154352.82584004718\n",
      "[0.94538075 1.00003227 0.88239876 0.88170429 0.90954794 0.99722517\n",
      " 0.98051568 0.88340816 0.88622291 0.92065953]\n",
      "[[1.0884174  0.72649249 1.05094155 1.03924606 1.10629312 0.95459477\n",
      "  1.11214221 1.07165552 1.18340155 1.05207841]]\n",
      "{0: 2493, 1: 321}\n",
      "acc 0.8948116560056859\n",
      "(0.3333333333333333, 0.5661375661375662, 0.41960784313725485, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 154345.657013675\n",
      "[0.95711568 1.00017134 0.87422725 0.87406136 0.91291265 0.99776011\n",
      " 0.99031907 0.87564378 0.87869541 0.92818664]\n",
      "[[1.08146765 0.72632277 1.06995853 1.0570634  1.10656614 0.94945574\n",
      "  1.10669314 1.09036948 1.20057795 1.04758399]]\n",
      "{0: 2487, 1: 327}\n",
      "acc 0.8941009239516702\n",
      "(0.3333333333333333, 0.5767195767195767, 0.42248062015503873, None)\n",
      "\n",
      "3 loss 154341.1192211615\n",
      "[0.96473516 1.00014065 0.87002874 0.86936931 0.91573331 0.99703065\n",
      " 0.99419881 0.87566606 0.87567845 0.93511696]\n",
      "[[1.0772874  0.72628999 1.0882641  1.07415257 1.10708575 0.9450955\n",
      "  1.10472967 1.1084319  1.21700396 1.04402819]]\n",
      "{0: 2459, 1: 355}\n",
      "acc 0.8862828713574982\n",
      "(0.3154929577464789, 0.5925925925925926, 0.411764705882353, None)\n",
      "\n",
      "4 loss 154338.10484061058\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "acc 0.8791755508173419\n",
      "[[2346  279]\n",
      " [  61  128]]\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "alpha-mean 1.0\n",
      "0 loss 154393.62099487986\n",
      "[1.12557558 1.00003874 1.12538632 1.         1.1255733  1.12559693\n",
      " 1.12559615 1.12558608 1.12562009 1.12560506]\n",
      "[[1.2446198  0.8130261  1.13596722 1.00062431 1.23341265 1.16815488\n",
      "  1.29646792 1.15796988 1.27354245 1.19163599]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "1 loss 154240.38810601758\n",
      "[1.23195306 1.00011647 1.23182941 0.97335436 1.23195643 1.23205636\n",
      " 1.23194859 1.232052   1.23202169 1.23205054]\n",
      "[[1.35319708 0.81299169 1.24458075 1.02949871 1.34199253 1.27678313\n",
      "  1.40503345 1.26660157 1.38214293 1.30025738]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "2 loss 153643.17077206614\n",
      "[1.33616409 1.00011389 1.33608252 0.94751831 1.33617116 1.33633815\n",
      " 1.33614353 1.33633812 1.33626476 1.33632289]\n",
      "[[1.45865316 0.81290146 1.35005184 1.05738902 1.44744962 1.38228268\n",
      "  1.51048536 1.37210272 1.48763033 1.40575372]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "3 loss 152087.7456070251\n",
      "[1.43950052 1.00009376 1.43944006 0.92449415 1.43950928 1.43973284\n",
      " 1.43947322 1.43973513 1.43964047 1.43971262]\n",
      "[[1.56283252 0.81272882 1.45422781 1.08297519 1.55162825 1.48649707\n",
      "  1.61466876 1.47631698 1.59184955 1.50996871]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "4 loss 148706.22397580525\n",
      "[1.54243366 1.0000831  1.5423676  0.9035523  1.54244137 1.54271703\n",
      " 1.5424124  1.54271916 1.54263144 1.54269755]\n",
      "[[1.66639243 0.81245526 1.55775979 1.10682232 1.65518489 1.59008782\n",
      "  1.7182446  1.57990535 1.6954689  1.61356527]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n",
      "\n",
      "[1.54243366 1.0000831  1.5423676  0.9035523  1.54244137 1.54271703\n",
      " 1.5424124  1.54271916 1.54263144 1.54269755]\n",
      "[[1.66639243 0.81245526 1.55775979 1.10682232 1.65518489 1.59008782\n",
      "  1.7182446  1.57990535 1.6954689  1.61356527]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "acc 0.9012082444918266\n",
      "[[2449  176]\n",
      " [ 102   87]]\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print()\n",
    "    print(\"alpha-mean\",i)\n",
    "    train(0.1/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                          plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 154423.11505296052\n",
      "[1.12960963 1.00003591 1.12573894 0.98602607 1.12898605 1.12611872\n",
      " 1.1328575  1.12586352 1.13134219 1.12693168]\n",
      "[[1.24184085 0.80167334 1.13637017 1.01583723 1.23121741 1.16866017\n",
      "  1.29117918 1.15852328 1.26928974 1.19147305]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "1 loss 154232.150101072\n",
      "[1.23585489 1.00013351 1.2321689  0.95857505 1.23525663 1.23256117\n",
      " 1.23897777 1.23232052 1.23756257 1.23333406]\n",
      "[[1.35022575 0.80161894 1.24496523 1.04543615 1.33963368 1.27726402\n",
      "  1.39940635 1.26714232 1.3776245  1.30003166]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "2 loss 153619.95126115912\n",
      "[1.34002277 1.00012845 1.3364193  0.93438749 1.33943492 1.33683523\n",
      " 1.34309515 1.33660159 1.34174276 1.33759002]\n",
      "[[1.45561555 0.8014836  1.35043097 1.07191777 1.44503463 1.38275399\n",
      "  1.50474012 1.37263794 1.48301806 1.40550518]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "3 loss 152037.42768775686\n",
      "[1.44333908 1.0001184  1.4397755  0.91269541 1.44275602 1.44022621\n",
      " 1.44638888 1.43999613 1.44508954 1.44097208]\n",
      "[[1.55976218 0.80125261 1.45460391 1.09647828 1.54918546 1.48696416\n",
      "  1.60886566 1.47684993 1.58719229 1.50970955]]\n",
      "{0: 2578, 1: 236}\n",
      "acc 0.9108031272210376\n",
      "(0.3686440677966102, 0.4603174603174603, 0.4094117647058823, None)\n",
      "\n",
      "4 loss 148608.59476388042\n",
      "[1.54626116 1.00010848 1.54270063 0.89252149 1.54567844 1.54321026\n",
      " 1.54931021 1.54298057 1.54806903 1.54395503]\n",
      "[[1.66330304 0.80090514 1.55813235 1.11955594 1.6527256  1.59055467\n",
      "  1.71240982 1.58043904 1.69079034 1.61330252]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n",
      "\n",
      "[1.54626116 1.00010848 1.54270063 0.89252149 1.54567844 1.54321026\n",
      " 1.54931021 1.54298057 1.54806903 1.54395503]\n",
      "[[1.66330304 0.80090514 1.55813235 1.11955594 1.6527256  1.59055467\n",
      "  1.71240982 1.58043904 1.69079034 1.61330252]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "acc 0.9012082444918266\n",
      "[[2449  176]\n",
      " [ 102   87]]\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(0.1/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(1,0.01,seed),\n",
    "                          plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalized model with discrete LFs\n",
    "\n",
    "def train_nl(lr,ep,th):\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "        print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=tf.truncated_normal_initializer(0.3,0.1,seed),\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "        print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "        print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "        print(alphas)\n",
    "        print(s)\n",
    "        print(\"l\",l)\n",
    "        print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "        print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),\\\n",
    "                           -tf.ones_like(v))\n",
    "            print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        ### discrete pout \n",
    "        pout = tf.map_fn(lambda c: iskequalsy(l,c) ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "       \n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,name=\"t_pout\")\n",
    "        print(\"pout\",pout)\n",
    "\n",
    "        print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "        print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "            print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "            print(\"intsy\",out1)\n",
    "            return out1\n",
    "        \n",
    "        zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),np.arange(NoOfClasses,dtype=np.float64))\n",
    "\n",
    "        \n",
    "        print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "        print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "        print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "        \n",
    "        normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "\n",
    "\n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "        print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "        print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "        print(\"predict\",predict)\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "#                 print(a)\n",
    "#                 print(t)\n",
    "\n",
    "#                 unique, counts = np.unique(pl, return_counts=True)\n",
    "#                 print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(true_labels,pl))\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "\n",
    "            # Initialize an iterator over the validation dataset.\n",
    "            sess.run(dev_init_op)\n",
    "            a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "            print(a)\n",
    "            print(t)\n",
    "\n",
    "            unique, counts = np.unique(pl, return_counts=True)\n",
    "            print(dict(zip(unique, counts)))\n",
    "\n",
    "            print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "            predictAndPrint(pl)\n",
    "            print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_element Tensor(\"IteratorGetNext_1:0\", shape=(?, 2, 10), dtype=float64)\n",
      "thetas <tf.Variable 'thetas:0' shape=(1, 10) dtype=float64_ref>\n",
      "k Tensor(\"Const:0\", shape=(10,), dtype=float64)\n",
      "<tf.Variable 'alphas:0' shape=(10,) dtype=float64_ref>\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f32c9926898>\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"pout/while/Select:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"map/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "normloss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "predict Tensor(\"ArgMax:0\", shape=(?, 1), dtype=int64)\n",
      "0 loss 376630.9607297066\n",
      "acc 0.9019189765458422\n",
      "(0.3515358361774744, 0.544973544973545, 0.42738589211618255, None)\n",
      "\n",
      "1 loss 351257.10479729244\n",
      "acc 0.9019189765458422\n",
      "(0.3515358361774744, 0.544973544973545, 0.42738589211618255, None)\n",
      "\n",
      "2 loss 326273.94254572084\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "3 loss 301720.04581946554\n",
      "acc 0.9029850746268657\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n",
      "\n",
      "4 loss 277655.6846060027\n",
      "acc 0.9029850746268657\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n",
      "\n",
      "[0.41754463 0.11421453 0.30955965 0.30062431 0.40637787 0.34133855\n",
      " 0.469206   0.33120785 0.44633471 0.3647233 ]\n",
      "[[0.61831313 0.31635439 0.53769424 0.52325032 0.60957862 1.21725514\n",
      "  0.66965792 0.69257016 0.76519724 0.58094792]]\n",
      "{0: 2526, 1: 288}\n",
      "acc 0.9029850746268657\n",
      "acc 0.9029850746268657\n",
      "[[2439  186]\n",
      " [  87  102]]\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl(0.1/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
