{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from util import load_external_labels\n",
    "\n",
    "# %time load_external_labels(session, Spouse, annotator_name='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "#L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "#L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "\n",
    "# L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "# L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "# gold_labels_dev = [L[0,0] if L[0,0]==1 else -1 for L in L_gold_dev]\n",
    "gold_labels_dev = [L[0,0] for L in L_gold_dev]\n",
    "\n",
    "\n",
    "from snorkel.learning.utils import MentionScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 2625\n",
      "2814\n"
     ]
    }
   ],
   "source": [
    "#gold_labels_dev = [x[0,0] for x in L_gold_dev.todense()]\n",
    "#for i,L in enumerate(gold_labels_dev):\n",
    "#    print(i,gold_labels_dev[i])\n",
    "\n",
    "# gold_labels_dev = []\n",
    "# for i,L in enumerate(L_gold_dev):\n",
    "#     gold_labels_dev.append(L[0,0])\n",
    "    \n",
    "# gold_labels_test = []\n",
    "# for i,L in enumerate(L_gold_test):\n",
    "#     gold_labels_test.append(L[0,0])\n",
    "    \n",
    "# print(len(gold_labels_dev),len(gold_labels_test))\n",
    "# print(gold_labels_dev.count(1),gold_labels_dev.count(-1))\n",
    "# print(len(gold_labels_dev))\n",
    "\n",
    "print(gold_labels_dev.count(1),gold_labels_dev.count(0))\n",
    "print(len(gold_labels_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gensim.matutils as gm\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = KeyedVectors.load_word2vec_format('../../../snorkel/tutorials/glove_w2v.txt', binary=False)  # C binary format\n",
    "\n",
    "\n",
    "wordvec_unavailable= set()\n",
    "def write_to_file(wordvec_unavailable):\n",
    "    with open(\"wordvec_unavailable.txt\",\"w\") as f:\n",
    "        for word in wordvec_unavailable:\n",
    "            f.write(word+\"\\n\")\n",
    "\n",
    "def preprocess(tokens):\n",
    "    btw_words = [word for word in tokens if word not in STOPWORDS]\n",
    "    btw_words = [word for word in btw_words if word.isalpha()]\n",
    "    return btw_words\n",
    "\n",
    "def get_word_vectors(btw_words): # returns vector of embeddings of words\n",
    "    word_vectors= []\n",
    "    for word in btw_words:\n",
    "        try:\n",
    "            word_v = np.array(model[word])\n",
    "            word_v = word_v.reshape(len(word_v),1)\n",
    "            #print(word_v.shape)\n",
    "            word_vectors.append(model[word])\n",
    "        except:\n",
    "            wordvec_unavailable.add(word)\n",
    "    return word_vectors\n",
    "\n",
    "def get_similarity(word_vectors,target_word): # sent(list of word vecs) to word similarity\n",
    "    similarity = 0\n",
    "    target_word_vector = 0\n",
    "    try:\n",
    "        target_word_vector = model[target_word]\n",
    "    except:\n",
    "        wordvec_unavailable.add(target_word+\" t\")\n",
    "        return similarity\n",
    "    target_word_sparse = gm.any2sparse(target_word_vector,eps=1e-09)\n",
    "    for wv in word_vectors:\n",
    "        wv_sparse = gm.any2sparse(wv, eps=1e-09)\n",
    "        similarity = max(similarity,gm.cossim(wv_sparse,target_word_sparse))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Discrete ##########\n",
    "\n",
    "# spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "# family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "#               'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "# family = family | {f + '-in-law' for f in family}\n",
    "# other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# # Helper function to get last name\n",
    "# def last_name(s):\n",
    "#     name_parts = s.split(' ')\n",
    "#     return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "# def LF_husband_wife(c):\n",
    "#     return (1,1) if len(spouses.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "# def LF_husband_wife_left_window(c):\n",
    "#     if len(spouses.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "#         return (1,1)\n",
    "#     elif len(spouses.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "#         return (1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "    \n",
    "# def LF_same_last_name(c):\n",
    "#     p1_last_name = last_name(c.person1.get_span())\n",
    "#     p2_last_name = last_name(c.person2.get_span())\n",
    "#     if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "#         if c.person1.get_span() != c.person2.get_span():\n",
    "#             return (1,1)\n",
    "#     return (0,0)\n",
    "\n",
    "# def LF_no_spouse_in_sentence(c):\n",
    "#     return (-1,1) if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else (0,0)\n",
    "\n",
    "# def LF_and_married(c):\n",
    "#     return (1,1) if 'and' in get_between_tokens(c) and 'married' in get_right_tokens(c) else (0,0)\n",
    "    \n",
    "# def LF_familial_relationship(c):\n",
    "#     return (-1,1) if len(family.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "# def LF_family_left_window(c):\n",
    "#     if len(family.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "#         return (-1,1)\n",
    "#     elif len(family.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "#         return (-1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "\n",
    "# def LF_other_relationship(c):\n",
    "#     return (-1,1) if len(other.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "\n",
    "# import bz2\n",
    "\n",
    "# # Function to remove special characters from text\n",
    "# def strip_special(s):\n",
    "#     return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# # Read in known spouse pairs and save as set of tuples\n",
    "# with bz2.BZ2File('data/spouses_dbpedia.csv.bz2', 'rb') as f:\n",
    "#     known_spouses = set(\n",
    "#         tuple(strip_special(x.decode('utf-8')).strip().split(',')) for x in f.readlines()\n",
    "#     )\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "    \n",
    "# def LF_distant_supervision(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     return (1,1) if (p1, p2) in known_spouses or (p2, p1) in known_spouses else (0,0)\n",
    "\n",
    "# def LF_distant_supervision_last_names(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     p1n, p2n = last_name(p1), last_name(p2)\n",
    "#     return (1,1) if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else (0,0)\n",
    "\n",
    "\n",
    "# LFs = [\n",
    "#     LF_distant_supervision, LF_distant_supervision_last_names, \n",
    "#     LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "#     LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "#     LF_family_left_window, LF_other_relationship\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Continuous ################\n",
    "\n",
    "\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "\n",
    "spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "              'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "family = family | {f + '-in-law' for f in family}\n",
    "other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# Helper function to get last name\n",
    "def last_name(s):\n",
    "    name_parts = s.split(' ')\n",
    "    return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "def LF_husband_wife(c):\n",
    "    global LF_Threshold\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for sw in spouses:\n",
    "        sc=max(sc,get_similarity(word_vectors,sw))\n",
    "    return (1,sc)\n",
    "\n",
    "def LF_husband_wife_left_window(c):\n",
    "    global LF_Threshold\n",
    "    sc_1 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[0])))\n",
    "    for sw in spouses:\n",
    "        sc_1=max(sc_1,get_similarity(word_vectors,sw))\n",
    "        \n",
    "    sc_2 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[1])))\n",
    "    for sw in spouses:\n",
    "        sc_2=max(sc_2,get_similarity(word_vectors,sw))\n",
    "    return(1,max(sc_1,sc_2))\n",
    "    \n",
    "def LF_same_last_name(c):\n",
    "    p1_last_name = last_name(c.person1.get_span())\n",
    "    p2_last_name = last_name(c.person2.get_span())\n",
    "    if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "        if c.person1.get_span() != c.person2.get_span():\n",
    "            return (1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_no_spouse_in_sentence(c):\n",
    "    return (-1,0.75) if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else (0,0)\n",
    "\n",
    "def LF_and_married(c):\n",
    "    global LF_Threshold\n",
    "    word_vectors = get_word_vectors(preprocess(get_right_tokens(c)))\n",
    "    sc = get_similarity(word_vectors,'married')\n",
    "    \n",
    "    if 'and' in get_between_tokens(c):\n",
    "        return (1,sc)\n",
    "    else:\n",
    "        return (0,0)\n",
    "\n",
    "def LF_familial_relationship(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for fw in family:\n",
    "        sc=max(sc,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    return (-1,sc) \n",
    "\n",
    "def LF_family_left_window(c):\n",
    "    sc_1 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[0])))\n",
    "    for fw in family:\n",
    "        sc_1=max(sc_1,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    sc_2 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[1])))\n",
    "    for fw in family:\n",
    "        sc_2=max(sc_2,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    return (-1,max(sc_1,sc_2))\n",
    "\n",
    "def LF_other_relationship(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for ow in other:\n",
    "        sc=max(sc,get_similarity(word_vectors,ow))\n",
    "        \n",
    "    return (-1,sc) \n",
    "\n",
    "# def LF_other_relationship_left_window(c):\n",
    "#     sc = 0\n",
    "#     word_vectors = get_word_vectors(preprocess(get_left_tokens(c)))\n",
    "#     for ow in other:\n",
    "#         sc=max(sc,get_similarity(word_vectors,ow))\n",
    "#     return (-1,sc) \n",
    "\n",
    "import bz2\n",
    "\n",
    "# Function to remove special characters from text\n",
    "def strip_special(s):\n",
    "    return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# # Read in known spouse pairs and save as set of tuples\n",
    "# with bz2.BZ2File('data/spouses_dbpedia.csv.bz2', 'rb') as f:\n",
    "#     known_spouses = set(\n",
    "#         tuple(strip_special(x).strip().split(',')) for x in f.readlines()\n",
    "#     )\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "    \n",
    "def LF_distant_supervision(c):\n",
    "    p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "    return (1,1) if (p1, p2) in known_spouses or (p2, p1) in known_spouses else (0,0)\n",
    "\n",
    "def LF_distant_supervision_last_names(c):\n",
    "    p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "    p1n, p2n = last_name(p1), last_name(p2)\n",
    "    return (1,1) if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else (0,1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# def LF_Three_Lists_Left_Window(c):\n",
    "#     global softmax_Threshold\n",
    "#     c1,s1 = LF_husband_wife_left_window(c)\n",
    "#     c2,s2 = LF_family_left_window(c)\n",
    "#     c3,s3 = LF_other_relationship_left_window(c)\n",
    "#     sc = np.array([s1,s2,s3])\n",
    "#     c = [c1,c2,c3]\n",
    "#     sharp_param = 1.5\n",
    "#     prob_sc = np.exp(sc * sharp_param - np.max(sc))\n",
    "#     prob_sc = prob_sc / np.sum(prob_sc)\n",
    "#     #print 'Left:',s1,s2,s3,prob_sc\n",
    "    \n",
    "#     if s1==s2 or s3==s1:\n",
    "#         return (0,0)\n",
    "#     return c[np.argmax(prob_sc)],1\n",
    "\n",
    "# def LF_Three_Lists_Between_Words(c):\n",
    "#     global softmax_Threshold\n",
    "#     c1,s1 = LF_husband_wife(c)\n",
    "#     c2,s2 = LF_familial_relationship(c)\n",
    "#     c3,s3 = LF_other_relationship(c)\n",
    "#     sc = np.array([s1,s2,s3])\n",
    "#     c = [c1,c2,c3]\n",
    "#     sharp_param = 1.5\n",
    "    \n",
    "#     prob_sc = np.exp(sc * sharp_param - np.max(sc))\n",
    "#     prob_sc = prob_sc / np.sum(prob_sc)\n",
    "#     #print 'BW:',s1,s2,s3,prob_sc\n",
    "#     if s1==s2 or s3==s1:\n",
    "#         return (0,0)\n",
    "#     return c[np.argmax(prob_sc)],1\n",
    "    \n",
    "LFs = [\n",
    "    LF_distant_supervision, LF_distant_supervision_last_names, \n",
    "    LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "    LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "    LF_family_left_window, LF_other_relationship\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' output:\n",
    "\n",
    "    [[[L_x1],[S_x1]],\n",
    "     [[L_x2],[S_x2]],\n",
    "     ......\n",
    "     ......\n",
    "    ]\n",
    "\n",
    "'''\n",
    "def get_L_S_Tensor(cands): \n",
    "    \n",
    "    L_S = []\n",
    "    for i,ci in enumerate(cands):\n",
    "        L_S_ci=[]\n",
    "        L=[]\n",
    "        S=[]\n",
    "        for LF in LFs:\n",
    "            #print LF.__name__\n",
    "            l,s = LF(ci)\n",
    "            L.append(l)\n",
    "            S.append((s+1)/2)  #to scale scores in [0,1] \n",
    "        L_S_ci.append(L)\n",
    "        L_S_ci.append(S)\n",
    "        L_S.append(L_S_ci) \n",
    "        if(i%500==0 and i!=0):\n",
    "            print(str(i)+'data points labelled in',(time.time() - start_time)/60,'mins')\n",
    "    return L_S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "start_time = time.time()\n",
    "\n",
    "lt = time.localtime()\n",
    "\n",
    "print(\"started at: {}-{}-{}, {}:{}:{}\".format(lt.tm_mday,lt.tm_mon,lt.tm_year,lt.tm_hour,lt.tm_min,lt.tm_sec))\n",
    "\n",
    "dev_L_S = get_L_S_Tensor(dev_cands)\n",
    "\n",
    "np.save(\"dev_L_S_smooth\",np.array(dev_L_S))\n",
    "\n",
    "train_L_S = get_L_S_Tensor(train_cands)\n",
    "np.save(\"train_L_S_smooth\",np.array(train_L_S))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# test_L_S = get_L_S_Tensor(test_cands)\n",
    "# pkl.dump(test_L_S,open(\"test_L_S.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2814, 2, 10) (22276, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "LF_l = [\n",
    "    1,1,1,1,1,-1,1,-1,-1,-1\n",
    "]\n",
    "import numpy as np\n",
    "dev_L_S = np.load(\"dev_L_S_smooth.npy\")\n",
    "train_L_S = np.load(\"train_L_S_smooth.npy\")\n",
    "\n",
    "# dev_L_S = np.load(\"dev_L_S_discrete.npy\")\n",
    "# train_L_S = np.load(\"train_L_S_discrete.npy\")\n",
    "\n",
    "test_L_S = dev_L_S\n",
    "true_labels = gold_labels_dev\n",
    "print(dev_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call this only once for a kernel startup\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# BATCH_SIZE = 32\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "NoOfLFs= len(LF_l)\n",
    "NoOfClasses = 2\n",
    "print(len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## normalized model with smooth LFs\n",
    "\n",
    "def train_unl_s(lr,ep,th,af):\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],initializer=af,dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],initializer=th,dtype=tf.float64)\n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "#         print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "#         print(s)\n",
    "#         print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "#         print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),\\\n",
    "                           -tf.ones_like(v))\n",
    "#             print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        ## smooth pout\n",
    "        pout = tf.map_fn(lambda c: iskequalsy(l,c)*s_ ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "       \n",
    "        ## discrete pout\n",
    "#         pout = tf.map_fn(lambda c: iskequalsy(l,c) ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,name=\"t_pout\")\n",
    "#         print(\"pout\",pout)\n",
    "\n",
    "#         print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "#         print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "#             print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "#             print(\"intsy\",out1)\n",
    "            return out1\n",
    "        \n",
    "        ## discrete normalizer\n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),np.arange(NoOfClasses,dtype=np.float64))\n",
    "\n",
    "\n",
    "        ## smooth normalizer\n",
    "        zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),np.array([-1,1],dtype=np.float64),name=\"zy\")\n",
    "    \n",
    "\n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        \n",
    "#         print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "#         print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "#         print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "\n",
    "        normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "        \n",
    "   \n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "#         print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "#         print(\"predict\",predict)\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "\n",
    "\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"macro\"))\n",
    "                print()\n",
    "\n",
    "        return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 190704.48036197305\n",
      "[0.20217393 0.19913547 0.20104263 0.20095318 0.2020543  0.20030376\n",
      " 0.20264392 0.19939658 0.20055018 0.19973241]\n",
      "[[1.11654799 0.8132221  1.00862698 0.99968674 1.10539499 1.04175094\n",
      "  1.16824127 1.03207768 1.14720646 1.06560552]]\n",
      "(0.6494505494505495, 0.5690793650793651, 0.5900021547080372, None)\n",
      "\n",
      "1 loss 190437.1681229399\n",
      "[0.20317241 0.20012884 0.20199151 0.20190196 0.20304489 0.2001942\n",
      " 0.20359697 0.19847852 0.1996344  0.198815  ]\n",
      "[[1.11555139 0.81222961 1.0076926  0.99874784 1.10441194 1.04216402\n",
      "  1.16727546 1.03295038 1.14808062 1.06649125]]\n",
      "(0.6475466914259187, 0.5666243386243386, 0.5871305399632305, None)\n",
      "\n",
      "2 loss 190169.70081555194\n",
      "[0.20417089 0.20112225 0.20294132 0.20285167 0.20403556 0.20008509\n",
      " 0.20455086 0.19755886 0.198717   0.197896  ]\n",
      "[[1.11455479 0.81123706 1.00675736 0.99780807 1.10342872 1.04257697\n",
      "  1.16630898 1.03382496 1.14895673 1.06737886]]\n",
      "(0.6566576698155646, 0.5673862433862433, 0.5891216002380908, None)\n",
      "\n",
      "3 loss 189902.09119194225\n",
      "[0.20516938 0.20211569 0.20389205 0.20380231 0.2050263  0.19997645\n",
      " 0.20550556 0.19663765 0.19779799 0.19697543]\n",
      "[[1.11355819 0.81024447 1.00582128 0.99686746 1.10244534 1.04298977\n",
      "  1.16534183 1.03470137 1.14983476 1.06826831]]\n",
      "(0.6615710660874246, 0.5677671957671958, 0.590135062394675, None)\n",
      "\n",
      "4 loss 189634.34708139126\n",
      "[0.20616786 0.20310916 0.20484368 0.20475385 0.2060171  0.1998683\n",
      " 0.20646107 0.19571491 0.19687741 0.19605331]\n",
      "[[1.11256159 0.80925182 1.00488438 0.99592601 1.1014618  1.0434024\n",
      "  1.16437402 1.03557959 1.15071467 1.06915956]]\n",
      "(0.6641255932822198, 0.567957671957672, 0.5906463968544505, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_unl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                           tf.truncated_normal_initializer(0.2,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-mean 0.0\n",
      "0 loss 209390.4789842156\n",
      "[ 0.01114957  0.00807104  0.00972942  0.00963934  0.01097261 -0.00188373\n",
      "  0.01135486 -0.00910274 -0.00793434 -0.00876264]\n",
      "[[1.10758333 0.80429229 1.00000767 0.9910495  1.09651404 1.04525528\n",
      "  1.15949127 1.0403484  1.15548217 1.07392619]]\n",
      "(0.6769618637705821, 0.557015873015873, 0.5786750050974075, None)\n",
      "\n",
      "1 loss 205842.9393583431\n",
      "[ 0.021122    0.0180006   0.01942907  0.01933837  0.02088492 -0.00397159\n",
      "  0.02107669 -0.01862373 -0.01744067 -0.01827938]\n",
      "[[1.09762426 0.79436676 0.99038834 0.98141001 1.08664188 1.04905637\n",
      "  1.14972266 1.04962248 1.16476291 1.08326669]]\n",
      "(0.6910847132229421, 0.5385185185185185, 0.553250663211796, None)\n",
      "\n",
      "2 loss 202335.09405889295\n",
      "[ 0.03109392  0.02793218  0.02917892  0.02908771  0.03080205 -0.00581486\n",
      "  0.03084618 -0.02822637 -0.02703076 -0.0278784 ]\n",
      "[[1.08766573 0.78443697 0.98072216 0.97172279 1.07676011 1.05271155\n",
      "  1.13991234 1.05899562 1.17414669 1.09270863]]\n",
      "(0.6904676474105969, 0.528888888888889, 0.5378171963537818, None)\n",
      "\n",
      "3 loss 198879.92579298644\n",
      "[ 0.04106549  0.03786617  0.03897121  0.03887956  0.04072432 -0.0073867\n",
      "  0.04065598 -0.03789664 -0.03669022 -0.03754553]\n",
      "[[1.07770754 0.77450258 0.97102144 0.96199947 1.06686893 1.05620089\n",
      "  1.13006863 1.06844633 1.18361208 1.10223175]]\n",
      "(0.7082681964861958, 0.5292698412698413, 0.5385276662443164, None)\n",
      "\n",
      "4 loss 195489.0833074813\n",
      "[ 0.05103689  0.04780295  0.04879901  0.04870699  0.050652   -0.00866442\n",
      "  0.05049936 -0.04762249 -0.04640675 -0.04726868]\n",
      "[[1.06774944 0.76456334 0.96129673 0.95225015 1.05696892 1.05950704\n",
      "  1.12019916 1.0779567  1.19314104 1.11181899]]\n",
      "(0.7181232091690544, 0.527005291005291, 0.5346876211190503, None)\n",
      "\n",
      "alpha-mean 0.1\n",
      "0 loss 199244.30268716748\n",
      "[0.11114956 0.1080678  0.10967509 0.10958489 0.11096696 0.09872762\n",
      " 0.11130431 0.09098263 0.0921535  0.09132344]\n",
      "[[1.10758899 0.80429482 1.00008454 0.99111597 1.09653302 1.04528919\n",
      "  1.15951624 1.04020457 1.15534573 1.07380642]]\n",
      "(0.6667540030845636, 0.5564444444444445, 0.5772197843064336, None)\n",
      "\n",
      "1 loss 196145.38668059962\n",
      "[0.12112243 0.11799515 0.11933156 0.11924067 0.12087503 0.0971845\n",
      " 0.12098402 0.08152855 0.08271604 0.08187415]\n",
      "[[1.09763556 0.79437108 0.99053687 0.98153767 1.08667728 1.04916796\n",
      "  1.14976886 1.04935029 1.16450622 1.08304426]]\n",
      "(0.6814978370583994, 0.5405925925925926, 0.5561769080640034, None)\n",
      "\n",
      "2 loss 193063.27622856438\n",
      "[0.13109522 0.1279255  0.12904726 0.12895579 0.13078927 0.09581247\n",
      " 0.13071928 0.07197781 0.07317938 0.07232748]\n",
      "[[1.08768237 0.78444234 0.98093987 0.97190857 1.07680943 1.05294801\n",
      "  1.13997655 1.05860743 1.17378319 1.09239639]]\n",
      "(0.71875, 0.5368253968253969, 0.5510222688213708, None)\n",
      "\n",
      "3 loss 190008.20155323108\n",
      "[0.14106808 0.1378593  0.13881323 0.13872128 0.14071    0.09463262\n",
      " 0.14050193 0.06234671 0.06356023 0.06269984]\n",
      "[[1.07772917 0.7745083  0.97130753 0.96224198 1.06693004 1.05661284\n",
      "  1.13014855 1.06795262 1.18315305 1.10184058]]\n",
      "(0.7082681964861958, 0.5292698412698413, 0.5385276662443164, None)\n",
      "\n",
      "4 loss 186989.63968789863\n",
      "[0.1510412  0.14779691 0.14862143 0.14852908 0.15063742 0.09366263\n",
      " 0.15032444 0.05264925 0.05387295 0.05300533]\n",
      "[[1.0677757  0.76456876 0.96165196 0.95254955 1.05704033 1.0601483\n",
      "  1.12029352 1.07736638 1.19259598 1.1113581 ]]\n",
      "(0.7060508413891873, 0.5243597883597884, 0.5300849021779255, None)\n",
      "\n",
      "alpha-mean 0.2\n",
      "0 loss 189501.54760205027\n",
      "[0.21114986 0.20806521 0.20960879 0.20951848 0.21096158 0.19933806\n",
      " 0.21124194 0.19107823 0.19225138 0.19141968]\n",
      "[[1.1075981  0.80429673 1.0001941  0.99120959 1.09656165 1.04545815\n",
      "  1.15954164 1.04000171 1.15515164 1.07364118]]\n",
      "(0.6604870956015993, 0.556063492063492, 0.5762648809523809, None)\n",
      "\n",
      "1 loss 186819.23431974082\n",
      "[0.22112348 0.21799102 0.21921337 0.21912229 0.22086576 0.19832294\n",
      " 0.22086984 0.1816969  0.18288835 0.18204362]\n",
      "[[1.09765406 0.79437421 0.99075153 0.98171996 1.08673126 1.04955693\n",
      "  1.1498162  1.04896487 1.16414003 1.08273624]]\n",
      "(0.6714084691154872, 0.5449312169312169, 0.5621479404516421, None)\n",
      "\n",
      "2 loss 184132.73040210412\n",
      "[0.23109738 0.22792082 0.22888842 0.22879671 0.23077748 0.19739353\n",
      " 0.23056298 0.17220115 0.17340789 0.17255229]\n",
      "[[1.08771008 0.78444604 0.98125913 0.9721779  1.07688579 1.05360913\n",
      "  1.14004368 1.05805565 1.173263   1.09196194]]\n",
      "(0.7189072609633358, 0.5392804232804234, 0.554920845861783, None)\n",
      "\n",
      "3 loss 181450.23793493054\n",
      "[0.24107173 0.23785503 0.23862317 0.23853094 0.24069699 0.19656913\n",
      " 0.24031204 0.16261066 0.16383016 0.16296549]\n",
      "[[1.07776586 0.77451197 0.97173355 0.96259948 1.06702672 1.05759962\n",
      "  1.13023517 1.06724802 1.18249376 1.10129319]]\n",
      "(0.6972670250896057, 0.5266243386243387, 0.5340069967357237, None)\n",
      "\n",
      "4 loss 178779.6941968488\n",
      "[0.2510467  0.24779395 0.24840795 0.24831529 0.25062435 0.19586632\n",
      " 0.25010833 0.15294223 0.15417239 0.15330014]\n",
      "[[1.06782112 0.76457185 0.96218919 0.95299872 1.05715678 1.06151545\n",
      "  1.12040142 1.07652046 1.19180997 1.11070894]]\n",
      "(0.7179670722977809, 0.5245502645502645, 0.5304082481363199, None)\n",
      "\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 180120.28513078953\n",
      "[0.31115043 0.30806349 0.30952681 0.3094364  0.31095672 0.29998303\n",
      " 0.31116402 0.29118714 0.29236226 0.29152915]\n",
      "[[1.10761641 0.80429792 1.00036517 0.99135679 1.09661589 1.04585567\n",
      "  1.15956462 1.03968974 1.1548438  1.07338763]]\n",
      "(0.6604870956015993, 0.556063492063492, 0.5762648809523809, None)\n",
      "\n",
      "1 loss 177825.0572664867\n",
      "[0.32112504 0.31798861 0.31906803 0.31897677 0.3208575  0.29951822\n",
      " 0.32072682 0.28188657 0.28308127 0.28223421]\n",
      "[[1.09769196 0.794376   0.99109298 0.98201238 1.08683613 1.0504055\n",
      "  1.1498624  1.0483688  1.16355637 1.08226002]]\n",
      "(0.6942908809093258, 0.553058201058201, 0.5744406853650551, None)\n",
      "\n",
      "2 loss 175508.17793793906\n",
      "[0.33110026 0.3279186  0.3286938  0.32860185 0.33076707 0.29904463\n",
      " 0.33036658 0.2724507  0.27366145 0.27280297]\n",
      "[[1.08776808 0.78444793 0.98177623 0.97261882 1.07703889 1.05496086\n",
      "  1.14011691 1.05719848 1.17243049 1.0912855 ]]\n",
      "(0.6892932712653407, 0.536063492063492, 0.5494107349531036, None)\n",
      "\n",
      "3 loss 173176.14718465414\n",
      "[0.34107624 0.33785381 0.33839063 0.33829812 0.34068558 0.2985828\n",
      " 0.34007254 0.262904   0.2641279  0.26326008]\n",
      "[[1.07784444 0.7745135  0.97243584 0.96319678 1.06722865 1.05950631\n",
      "  1.13034429 1.0661492  1.18143472 1.10043498]]\n",
      "(0.6972670250896057, 0.5266243386243387, 0.5340069967357237, None)\n",
      "\n",
      "4 loss 170835.59544518386\n",
      "[0.35105311 0.34779447 0.34814657 0.34805361 0.35061294 0.29815103\n",
      " 0.34983456 0.253267   0.25450169 0.25362621]\n",
      "[[1.06792079 0.76457266 0.9630899  0.95376431 1.05741315 1.06402856\n",
      "  1.12056141 1.07519677 1.19054318 1.10968436]]\n",
      "(0.7179670722977809, 0.5245502645502645, 0.5304082481363199, None)\n",
      "\n",
      "alpha-mean 0.4\n",
      "0 loss 171025.9978739618\n",
      "[0.41115126 0.40806287 0.40941902 0.4093285  0.41095264 0.40072567\n",
      " 0.41106532 0.39132241 0.39249929 0.39166491]\n",
      "[[1.1076735  0.80429833 1.00066977 0.99163234 1.0967823  1.04671376\n",
      "  1.15959517 1.03915827 1.15428284 1.07293381]]\n",
      "(0.6587154510176605, 0.5605925925925925, 0.581594560651336, None)\n",
      "\n",
      "1 loss 169091.38844153812\n",
      "[0.4211271  0.41798824 0.41887787 0.41878642 0.42085059 0.4008995\n",
      " 0.42054423 0.38212025 0.38331768 0.38246866]\n",
      "[[1.09781533 0.79437645 0.99171389 0.98257291 1.08717766 1.05216419\n",
      "  1.14995483 1.04734775 1.16248804 1.08140029]]\n",
      "(0.6911031582465326, 0.5553227513227513, 0.5773365571180659, None)\n",
      "\n",
      "2 loss 167122.59732545321\n",
      "[0.4311038  0.42791918 0.42843983 0.42834765 0.43075837 0.40096216\n",
      " 0.43011397 0.37275669 0.3739706  0.37310986]\n",
      "[[1.08796607 0.78444811 0.98273489 0.97348313 1.07757649 1.05765903\n",
      "  1.14032498 1.05572482 1.17090234 1.09005636]]\n",
      "(0.6829794890248291, 0.5358730158730158, 0.5490146188008882, None)\n",
      "\n",
      "3 loss 165124.44184369806\n",
      "[0.44108151 0.43785594 0.43808726 0.43799448 0.440676   0.40093695\n",
      " 0.43976222 0.36326322 0.36449036 0.36362023]\n",
      "[[1.07812771 0.77451319 0.97376155 0.96439288 1.06801049 1.06318186\n",
      "  1.13075588 1.06425529 1.17948727 1.09886733]]\n",
      "(0.7185929648241206, 0.5343703703703704, 0.5470517047114302, None)\n",
      "\n",
      "4 loss 163102.17858403202\n",
      "[0.45106033 0.44779864 0.44780495 0.4477117  0.45060328 0.40084549\n",
      " 0.44947728 0.35366547 0.35490329 0.35402558]\n",
      "[[1.06830398 0.76457172 0.96481901 0.95532862 1.05854153 1.06871877\n",
      "  1.12131455 1.07291144 1.18821141 1.10780484]]\n",
      "(0.762119077162506, 0.5251216931216931, 0.5313913470112773, None)\n",
      "\n",
      "alpha-mean 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 162533.8977168874\n",
      "[0.51072572 0.5080634  0.50893824 0.5090677  0.50958497 0.49999427\n",
      " 0.50833638 0.49156155 0.49274657 0.49191861]\n",
      "[[1.10845166 0.80429823 1.00129988 0.99229205 1.0991297  1.04856302\n",
      "  1.16065534 1.03816264 1.15309719 1.07193946]]\n",
      "(0.6632506747638327, 0.5702222222222222, 0.5930534509535157, None)\n",
      "\n",
      "1 loss 161606.99228940535\n",
      "[0.52022548 0.51798953 0.51788975 0.518278   0.51802236 0.4999942\n",
      " 0.5147666  0.48255157 0.48375932 0.48291518]\n",
      "[[1.09942645 0.79437662 0.99300144 0.98394597 1.09192714 1.05581323\n",
      "  1.15230566 1.04541136 1.16019868 1.07948783]]\n",
      "(0.6667540030845636, 0.5564444444444445, 0.5772197843064336, None)\n",
      "\n",
      "2 loss 160639.8308879118\n",
      "[0.52968771 0.52792118 0.52691606 0.52759195 0.52628732 0.49999341\n",
      " 0.52098032 0.47335281 0.4745788  0.4737217 ]\n",
      "[[1.09043075 0.78444902 0.98471248 0.97563661 1.08487009 1.06306787\n",
      "  1.14420381 1.05290436 1.16759186 1.08729251]]\n",
      "(0.6942908809093258, 0.553058201058201, 0.5744406853650551, None)\n",
      "\n",
      "3 loss 159635.0879157345\n",
      "[0.53910901 0.53785845 0.53600143 0.53698225 0.53424085 0.49999368\n",
      " 0.52696393 0.46400307 0.46524382 0.46437627]\n",
      "[[1.08145729 0.77451541 0.97646695 0.96740979 1.07810211 1.0703218\n",
      "  1.13639195 1.060605   1.17523321 1.09531371]]\n",
      "(0.7031025341480949, 0.5364444444444444, 0.5502110135428601, None)\n",
      "\n",
      "4 loss 158595.91192482022\n",
      "[0.54848144 0.54780137 0.54512993 0.54642383 0.54169783 0.49999296\n",
      " 0.53272925 0.45453234 0.45578512 0.45490906]\n",
      "[[1.07250232 0.76457589 0.96829421 0.9593066  1.07178153 1.07757101\n",
      "  1.12890936 1.06848301 1.18308605 1.10351839]]\n",
      "(0.7868422766345402, 0.5355132275132275, 0.5494594426708265, None)\n",
      "\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 161168.46104666786\n",
      "[0.61030481 0.60806392 0.60831035 0.60810879 0.60842354 0.59328544\n",
      " 0.60773074 0.59269788 0.59381298 0.59319917]\n",
      "[[1.10920671 0.80429899 1.00252882 0.99389923 1.10067487 1.04839515\n",
      "  1.16040234 1.03644134 1.15073813 1.06974015]]\n",
      "(0.6226000702808038, 0.5618835978835979, 0.5786042926921472, None)\n",
      "\n",
      "1 loss 160538.6609157963\n",
      "[0.61934017 0.61799027 0.61662987 0.61623686 0.61569949 0.58613908\n",
      " 0.6133857  0.58476328 0.58576247 0.5853875 ]\n",
      "[[1.10098512 0.79437901 0.99550437 0.98725765 1.09497758 1.05549374\n",
      "  1.15179739 1.04203505 1.1555508  1.07523192]]\n",
      "(0.6546044715560904, 0.5556825396825397, 0.5753218324449303, None)\n",
      "\n",
      "2 loss 159878.64705083257\n",
      "[0.62830462 0.62792167 0.62497595 0.6243103  0.62279966 0.57899806\n",
      " 0.61866137 0.57659067 0.57738824 0.57730309]\n",
      "[[1.09281446 0.78445387 0.98855183 0.98075201 1.08936144 1.0626078\n",
      "  1.14345336 1.04794558 1.16074726 1.08111399]]\n",
      "(0.6640096618357488, 0.5492698412698412, 0.5677568004401802, None)\n",
      "\n",
      "3 loss 159190.7208989884\n",
      "[0.63719242 0.63785816 0.63329163 0.63224434 0.62958043 0.57186831\n",
      " 0.62358718 0.56822633 0.56875881 0.56901278]\n",
      "[[1.08468309 0.77452359 0.98172048 0.97442923 1.0839526  1.06972963\n",
      "  1.13545077 1.05413332 1.16629449 1.08733569]]\n",
      "(0.6868638477004272, 0.547957671957672, 0.5670273916937243, None)\n",
      "\n",
      "4 loss 158479.93545878967\n",
      "[0.6459913  0.64779968 0.64149609 0.63994541 0.6358666  0.56475446\n",
      " 0.62813153 0.5597169  0.55992896 0.56056417]\n",
      "[[1.07658364 0.76458832 0.97504397 0.96831383 1.07888686 1.07685329\n",
      "  1.12786573 1.06056232 1.1721583  1.09385015]]\n",
      "(0.7355962643678161, 0.5396613756613757, 0.5557733559237901, None)\n",
      "\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 159692.10369815523\n",
      "[0.70930817 0.7080642  0.70563096 0.70497878 0.70620887 0.69374664\n",
      " 0.7088366  0.69602354 0.69829416 0.6971702 ]\n",
      "[[1.11066337 0.80430172 1.00485537 0.99632926 1.10292997 1.04786954\n",
      "  1.16046855 1.034042   1.14831912 1.06529773]]\n",
      "(0.6728243978243978, 0.7151957671957672, 0.6908899909476942, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print(\"alpha-mean\",i)\n",
    "    predicted_labels=train_nl_s(0.01/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                           tf.truncated_normal_initializer(i,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## normalized model with smooth LFs\n",
    "\n",
    "def train_nl_s(lr,ep,th,af):\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],initializer=af,dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],initializer=th,dtype=tf.float64)\n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "#         print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "#         print(s)\n",
    "#         print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "#         print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),\\\n",
    "                           -tf.ones_like(v))\n",
    "#             print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        ## smooth pout\n",
    "        pout = tf.map_fn(lambda c: iskequalsy(l,c)*s_ ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "       \n",
    "        ## discrete pout\n",
    "#         pout = tf.map_fn(lambda c: iskequalsy(l,c) ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,name=\"t_pout\")\n",
    "#         print(\"pout\",pout)\n",
    "\n",
    "#         print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "#         print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "#             print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "#             print(\"intsy\",out1)\n",
    "            return out1\n",
    "        \n",
    "        ## discrete normalizer\n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),np.arange(NoOfClasses,dtype=np.float64))\n",
    "\n",
    "\n",
    "        ## smooth normalizer\n",
    "        zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),np.array([-1,1],dtype=np.float64),name=\"zy\")\n",
    "    \n",
    "\n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        \n",
    "#         print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "#         print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "#         print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "\n",
    "        normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "        \n",
    "   \n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "#         print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "#         print(\"predict\",predict)\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "\n",
    "\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "\n",
    "        return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_unl_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3ae57c494f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_unl_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_L_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                           \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_unl_s' is not defined"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print(\"alpha-mean\",i)\n",
    "    predicted_labels=train_nl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                           tf.truncated_normal_initializer(i,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 177593.6089042592\n",
      "[0.41854278 0.11520687 0.31047011 0.30153524 0.40736582 0.34136772\n",
      " 0.47013164 0.33035577 0.44548349 0.36387167]\n",
      "[[1.11655652 0.81322315 1.00867167 0.99972798 1.10542697 1.04178828\n",
      "  1.16826229 1.03197667 1.14706397 1.06550782]]\n",
      "acc 0.9068941009239516\n",
      "(0.26143790849673204, 0.21164021164021163, 0.23391812865497075, None)\n",
      "\n",
      "1 loss 177396.56970193452\n",
      "[0.41954094 0.11619926 0.31138325 0.30244885 0.40835387 0.3413951\n",
      " 0.47105875 0.32949968 0.44462813 0.36301599]\n",
      "[[1.11556877 0.8122317  1.00778122 0.99882951 1.10447602 1.04224007\n",
      "  1.16731925 1.0327495  1.14779659 1.06629769]]\n",
      "acc 0.9086709310589908\n",
      "(0.2702702702702703, 0.21164021164021163, 0.2373887240356083, None)\n",
      "\n",
      "2 loss 177199.12666951108\n",
      "[0.42053909 0.11719167 0.3122979  0.30336394 0.409342   0.34142099\n",
      " 0.47198704 0.32864074 0.44376979 0.36215742]\n",
      "[[1.11458114 0.81124022 1.00688941 0.99792959 1.10352504 1.04269297\n",
      "  1.16637726 1.03352561 1.14853279 1.06709081]]\n",
      "acc 0.9136460554371002\n",
      "(0.29850746268656714, 0.21164021164021163, 0.24767801857585137, None)\n",
      "\n",
      "3 loss 177001.28635498337\n",
      "[0.42153725 0.11818411 0.31321404 0.30428052 0.4103302  0.34144541\n",
      " 0.4729165  0.327779   0.44290854 0.36129601]\n",
      "[[1.11359362 0.81024869 1.00599624 0.99702825 1.10257402 1.04314696\n",
      "  1.16543643 1.03430495 1.14927251 1.06788713]]\n",
      "acc 0.9175550817341862\n",
      "(0.31932773109243695, 0.20105820105820105, 0.24675324675324675, None)\n",
      "\n",
      "4 loss 176803.0511289301\n",
      "[0.42253541 0.11917658 0.31413164 0.30519854 0.41131849 0.3414684\n",
      " 0.47384712 0.32691451 0.44204442 0.36043183]\n",
      "[[1.11260622 0.80925713 1.00510178 0.99612552 1.10162297 1.043602\n",
      "  1.16449689 1.03508745 1.15001569 1.06868658]]\n",
      "acc 0.9193319118692252\n",
      "(0.33035714285714285, 0.19576719576719576, 0.24584717607973422, None)\n",
      "\n",
      "[0.42253541 0.11917658 0.31413164 0.30519854 0.41131849 0.3414684\n",
      " 0.47384712 0.32691451 0.44204442 0.36043183]\n",
      "[[1.11260622 0.80925713 1.00510178 0.99612552 1.10162297 1.043602\n",
      "  1.16449689 1.03508745 1.15001569 1.06868658]]\n",
      "{0: 2702, 1: 112}\n",
      "acc 0.9193319118692252\n",
      "acc 0.9193319118692252\n",
      "[[2550   75]\n",
      " [ 152   37]]\n",
      "(0.33035714285714285, 0.19576719576719576, 0.24584717607973422, None)\n"
     ]
    }
   ],
   "source": [
    "# for i in np.linspace(0,1,11):\n",
    "#     print(\"alpha-mean\",i)\n",
    "#     predicted_labels=train_nl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12),\\\n",
    "#                            tf.truncated_normal_initializer(i,0.1,12))\n",
    "    \n",
    "predicted_labels=train_nl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12),\\\n",
    "                           tf.truncated_normal_initializer(0.3,0.1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 155264.53954891075\n",
      "[0.92690352 0.9971321  0.89117171 0.89079329 0.90543897 0.98363892\n",
      " 0.9542917  0.89181359 0.8937952  0.91162108]\n",
      "[[1.10009277 0.72704278 1.03085428 1.02047423 1.10633782 0.96621163\n",
      "  1.12864769 1.05197377 1.16535794 1.05758622]]\n",
      "acc 0.8941009239516702\n",
      "(0.33126934984520123, 0.5661375661375662, 0.41796875, None)\n",
      "\n",
      "1 loss 154352.82584004718\n",
      "[0.94538075 1.00003227 0.88239876 0.88170429 0.90954794 0.99722517\n",
      " 0.98051568 0.88340816 0.88622291 0.92065953]\n",
      "[[1.0884174  0.72649249 1.05094155 1.03924606 1.10629312 0.95459477\n",
      "  1.11214221 1.07165552 1.18340155 1.05207841]]\n",
      "acc 0.8948116560056859\n",
      "(0.3333333333333333, 0.5661375661375662, 0.41960784313725485, None)\n",
      "\n",
      "2 loss 154345.657013675\n",
      "[0.95711568 1.00017134 0.87422725 0.87406136 0.91291265 0.99776011\n",
      " 0.99031907 0.87564378 0.87869541 0.92818664]\n",
      "[[1.08146765 0.72632277 1.06995853 1.0570634  1.10656614 0.94945574\n",
      "  1.10669314 1.09036948 1.20057795 1.04758399]]\n",
      "acc 0.8941009239516702\n",
      "(0.3333333333333333, 0.5767195767195767, 0.42248062015503873, None)\n",
      "\n",
      "3 loss 154341.1192211615\n",
      "[0.96473516 1.00014065 0.87002874 0.86936931 0.91573331 0.99703065\n",
      " 0.99419881 0.87566606 0.87567845 0.93511696]\n",
      "[[1.0772874  0.72628999 1.0882641  1.07415257 1.10708575 0.9450955\n",
      "  1.10472967 1.1084319  1.21700396 1.04402819]]\n",
      "acc 0.8862828713574982\n",
      "(0.3154929577464789, 0.5925925925925926, 0.411764705882353, None)\n",
      "\n",
      "4 loss 154338.10484061058\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "acc 0.8791755508173419\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "acc 0.8791755508173419\n",
      "[[2346  279]\n",
      " [  61  128]]\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl_s(0.1/len(train_L_S),5,\\\n",
    "                            tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            tf.truncated_normal_initializer(0.9,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 155548.10499263214\n",
      "[0.93326346 0.98037827 0.88953763 0.88821575 0.91311962 0.98554735\n",
      " 0.96406621 0.89759127 0.90964637 0.91662847]\n",
      "[[1.1032539  0.72197787 1.03206361 1.02162306 1.10767904 0.96823482\n",
      "  1.13417441 1.05126276 1.16661986 1.05815618]]\n",
      "acc 0.8855721393034826\n",
      "(0.3147632311977716, 0.5978835978835979, 0.41240875912408764, None)\n",
      "\n",
      "1 loss 154383.652287932\n",
      "[0.94953699 1.00003838 0.8767362  0.87537624 0.91583377 0.99209049\n",
      " 0.98585481 0.89384701 0.90618009 0.92479421]\n",
      "[[1.09328744 0.7103856  1.05400886 1.04201962 1.10870954 0.92510664\n",
      "  1.12145815 1.06944685 1.18536492 1.05320904]]\n",
      "acc 0.8855721393034826\n",
      "(0.3147632311977716, 0.5978835978835979, 0.41240875912408764, None)\n",
      "\n",
      "2 loss 154346.07266892138\n",
      "[0.96029182 1.00012677 0.86560251 0.86458486 0.91794999 0.98825132\n",
      " 0.99431731 0.89279564 0.90488922 0.93167133]\n",
      "[[1.08722855 0.71028976 1.07575335 1.06207778 1.11012153 0.84748815\n",
      "  1.11739958 1.08540677 1.20247734 1.04934008]]\n",
      "acc 0.8781094527363185\n",
      "(0.3121951219512195, 0.6772486772486772, 0.42737896494156924, None)\n",
      "\n",
      "3 loss 154338.96566033977\n",
      "[0.96760865 1.00012473 0.85225636 0.85189594 0.9194952  0.98042366\n",
      " 0.99813295 0.89525075 0.90660047 0.93801452]\n",
      "[[1.08354231 0.71012754 1.09771802 1.0821421  1.11199203 0.7512131\n",
      "  1.11605471 1.09861973 1.21776018 1.04669099]]\n",
      "acc 0.8742004264392325\n",
      "(0.3049645390070922, 0.6825396825396826, 0.4215686274509804, None)\n",
      "\n",
      "4 loss 154328.02467496082\n",
      "[0.97290781 1.00012272 0.83648652 0.83773746 0.92044744 0.96624436\n",
      " 0.99960116 0.90305713 0.91281119 0.94217553]\n",
      "[[1.08125315 0.70990132 1.12052711 1.10269218 1.11442038 0.64725766\n",
      "  1.11577799 1.107643   1.23052228 1.04508611]]\n",
      "acc 0.8567874911158493\n",
      "(0.27983539094650206, 0.7195767195767195, 0.40296296296296297, None)\n",
      "\n",
      "[0.97290781 1.00012272 0.83648652 0.83773746 0.92044744 0.96624436\n",
      " 0.99960116 0.90305713 0.91281119 0.94217553]\n",
      "[[1.08125315 0.70990132 1.12052711 1.10269218 1.11442038 0.64725766\n",
      "  1.11577799 1.107643   1.23052228 1.04508611]]\n",
      "{0: 2328, 1: 486}\n",
      "acc 0.8567874911158493\n",
      "acc 0.8567874911158493\n",
      "[[2275  350]\n",
      " [  53  136]]\n",
      "(0.27983539094650206, 0.7195767195767195, 0.40296296296296297, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl_s(0.1/len(train_L_S),5,\\\n",
    "                            tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            tf.truncated_normal_initializer(0.9,0.01,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## normalized model with smooth LFs + penalties\n",
    "\n",
    "def train(lr,ep,th,af,plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=0,p3k=3):\n",
    "    \n",
    "    ## lr : learning rate\n",
    "    ## ep : no of epochs\n",
    "    ## th : thetas initializer\n",
    "    ## af : alphas initializer\n",
    "    ## penalty : {1,2,3} use one of the three penalties, 0: no-penalty\n",
    "    ## p3k : parameter for penalty-3 \n",
    "    ## smooth : flag if smooth lfs are used \n",
    "    ## make sure smooth/discrete LF data is loaded into train_L_S and test_L_S\n",
    "    ## plv : all possible label values = [-1,1] for binary, \n",
    "    ##       np.arange(0,NoOfClasses) for multiclass\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=af,\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "#         print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "#         print(s)\n",
    "#         print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "#         print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),-tf.ones_like(v))\n",
    "#             print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        if(smooth):\n",
    "            pout = tf.map_fn(lambda c: iskequalsy(l,c)*s_ ,plv,name=\"pout\")\n",
    "        else:\n",
    "            pout = tf.map_fn(lambda c: iskequalsy(l,c) ,plv,name=\"pout\")\n",
    "\n",
    "#         print(\"pout\",pout)    \n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,\\\n",
    "                           name=\"t_pout\")\n",
    "    \n",
    "#         print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "#         print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "#             print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "#             print(\"intsy\",out1)\n",
    "            return out1\n",
    "                \n",
    "\n",
    "        if(smooth):\n",
    "            #smooth normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                           plv,name=\"zy\")\n",
    "        else:\n",
    "            #discrete normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                           plv,name=\"zy\")\n",
    "\n",
    "    \n",
    "# \n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        \n",
    "#         print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "#         print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "#         print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "        if(penalty == 1):\n",
    "            normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                      +tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas))\n",
    "        elif(penalty == 2):\n",
    "            normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     -tf.minimum( tf.reduce_min(thetas),0.0)\n",
    "        elif(penalty == 3):\n",
    "             normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     +tf.reduce_sum(tf.log(1+tf.exp(-thetas-pk)))\n",
    "        else:\n",
    "             normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "   \n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "#         print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(true_labels,pl))\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "\n",
    "            # Initialize an iterator over the validation dataset.\n",
    "            sess.run(dev_init_op)\n",
    "            a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "            print(a)\n",
    "            print(t)\n",
    "\n",
    "            unique, counts = np.unique(pl, return_counts=True)\n",
    "            print(dict(zip(unique, counts)))\n",
    "\n",
    "            print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "            predictAndPrint(pl)\n",
    "            print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha-mean 0.0\n",
      "0 loss 194264.85326121486\n",
      "[ 0.09947401  0.09596     0.09735473  0.09725704  0.09894004 -0.01030508\n",
      "  0.09894431 -0.09624256 -0.09494115 -0.09586474]\n",
      "[[1.01984608 0.71578729 0.91326762 0.90408304 1.00926658 1.07292658\n",
      "  1.07212253 1.12601357 1.24131725 1.16021693]]\n",
      "{0: 2806, 1: 8}\n",
      "acc 0.9342572850035537\n",
      "(0.75, 0.031746031746031744, 0.06091370558375634, None)\n",
      "\n",
      "1 loss 165944.78653442475\n",
      "[ 0.19790907  0.19411453  0.19583783  0.19573171  0.19731637  0.00760686\n",
      "  0.19744465 -0.19395243 -0.1925366  -0.19354266]\n",
      "[[0.92264118 0.61691555 0.81792812 0.8082795  0.9130418  1.0849647\n",
      "  0.97551319 1.22139401 1.33701538 1.25683504]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 145426.3452882983\n",
      "[ 0.29704017  0.29296915  0.29497276  0.29485531  0.29646632  0.0399873\n",
      "  0.29663876 -0.29182634 -0.29029167 -0.29138179]\n",
      "[[0.8261613  0.51767846 0.7251858  0.71477777 0.82094729 1.08603578\n",
      "  0.88155871 1.3152654  1.43122333 1.35249425]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 129826.68522984035\n",
      "[ 0.3965422   0.39207137  0.39443259  0.39429967  0.3960568   0.07599614\n",
      "  0.39621449 -0.38993288 -0.38828145 -0.3894509 ]\n",
      "[[0.73526719 0.41834843 0.63658532 0.62519367 0.74518257 1.08494332\n",
      "  0.79750861 1.40760353 1.52378527 1.44700078]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 117293.74879868481\n",
      "[ 0.49677966  0.49105991  0.49399921  0.49384786  0.49619953  0.11179939\n",
      "  0.49619988 -0.48814211 -0.48638682 -0.48762274]\n",
      "[[0.7522436  0.31907066 0.55577511 0.54350837 0.74399203 1.08535089\n",
      "  0.76963201 1.49848879 1.61471096 1.54024589]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49677966  0.49105991  0.49399921  0.49384786  0.49619953  0.11179939\n",
      "  0.49619988 -0.48814211 -0.48638682 -0.48762274]\n",
      "[[0.7522436  0.31907066 0.55577511 0.54350837 0.74399203 1.08535089\n",
      "  0.76963201 1.49848879 1.61471096 1.54024589]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 185781.95847627256\n",
      "[0.19967327 0.19615971 0.19744814 0.19735001 0.19911576 0.09226008\n",
      " 0.19894121 0.00368871 0.00499454 0.00406713]\n",
      "[[1.02003556 0.7157202  0.91386131 0.90455327 1.00954362 1.07559231\n",
      "  1.07237539 1.12539065 1.24081911 1.15986489]]\n",
      "{0: 2806, 1: 8}\n",
      "acc 0.9342572850035537\n",
      "(0.75, 0.031746031746031744, 0.06091370558375634, None)\n",
      "\n",
      "1 loss 159483.32056801888\n",
      "[ 0.29834619  0.29456714  0.29622298  0.29611599  0.29773821  0.10580634\n",
      "  0.29768761 -0.09462073 -0.09321636 -0.09421548]\n",
      "[[0.92345526 0.61679842 0.81989008 0.80995456 0.91485833 1.09507768\n",
      "  0.97699202 1.22065646 1.33651883 1.25658421]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 139408.32185090086\n",
      "[ 0.3975604   0.39348825  0.39545592  0.39533679  0.39700739  0.13221124\n",
      "  0.39698284 -0.19293461 -0.19142947 -0.1925003 ]\n",
      "[[0.83099436 0.51762236 0.73035262 0.71948807 0.83356164 1.10505495\n",
      "  0.88993698 1.31460596 1.43088955 1.35239227]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 123858.68372792944\n",
      "[ 0.49756632  0.49258738  0.49496802  0.49483458  0.49696945  0.1628117\n",
      "  0.49681511 -0.29131805 -0.28970991 -0.29085113]\n",
      "[[0.83285096 0.41841009 0.64885145 0.63709209 0.82459795 1.11250385\n",
      "  0.85509316 1.40718658 1.5237811  1.4471387 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 113020.3875257964\n",
      "[ 0.50000013  0.59156907  0.5844681   0.59021834  0.5000003   0.19376208\n",
      "  0.51123288 -0.38976341 -0.3880604  -0.38926297]\n",
      "[[0.92591555 0.31930299 0.58000265 0.57207223 0.87728778 1.12105543\n",
      "  0.89176137 1.49844003 1.61517635 1.54073868]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.50000013  0.59156907  0.5844681   0.59021834  0.5000003   0.19376208\n",
      "  0.51123288 -0.38976341 -0.3880604  -0.38926297]\n",
      "[[0.92591555 0.31930299 0.58000265 0.57207223 0.87728778 1.12105543\n",
      "  0.89176137 1.49844003 1.61517635 1.54073868]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.2\n",
      "0 loss 177594.2035698463\n",
      "[0.2998713  0.29635755 0.29753524 0.29743639 0.2992909  0.19452654\n",
      " 0.29888345 0.10360372 0.10490988 0.10398125]\n",
      "[[1.02046742 0.71566814 0.91490631 0.90540562 1.01015783 1.07973837\n",
      "  1.07289938 1.12436596 1.23996459 1.15923948]]\n",
      "{0: 2807, 1: 7}\n",
      "acc 0.9339019189765458\n",
      "(0.7142857142857143, 0.026455026455026454, 0.051020408163265314, None)\n",
      "\n",
      "1 loss 153274.7976608556\n",
      "[0.3987608  0.39498448 0.39659098 0.39648244 0.3981468  0.20352977\n",
      " 0.39785555 0.00476452 0.00615457 0.00516393]\n",
      "[[0.9259043  0.61673024 0.82351894 0.81317403 0.92070084 1.10797379\n",
      "  0.98135213 1.21926386 1.33544443 1.25587701]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 133649.26813170992\n",
      "[ 0.49836711  0.49397731  0.4959534   0.49583306  0.49775627  0.22341711\n",
      "  0.4974006  -0.09395993 -0.09248529 -0.09353668]\n",
      "[[0.90100356 0.5176436  0.74036327 0.72908607 0.89365752 1.12841482\n",
      "  0.93170971 1.31317643 1.42988121 1.35176352]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 120090.01885759828\n",
      "[ 0.50000078  0.59308803  0.5859046   0.59131064  0.50000104  0.24768838\n",
      "  0.51653763 -0.19269018 -0.19113024 -0.19224044]\n",
      "[[0.99217384 0.41859694 0.67015697 0.66244417 0.93906287 1.14633091\n",
      "  0.95828995 1.40607873 1.52320186 1.44684248]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 111705.38536236154\n",
      "[ 0.50000114  0.69205658  0.66524157  0.66324452  0.50000175  0.27312621\n",
      "  0.52859743 -0.29127515 -0.28962538 -0.29079428]\n",
      "[[1.08372211 0.31976297 0.61793727 0.62134597 0.9883906  1.16473381\n",
      "  0.99630666 1.49776328 1.61514372 1.5408448 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.50000114  0.69205658  0.66524157  0.66324452  0.50000175  0.27312621\n",
      "  0.52859743 -0.29127515 -0.28962538 -0.29079428]\n",
      "[[1.08372211 0.31976297 0.61793727 0.62134597 0.9883906  1.16473381\n",
      "  0.99630666 1.49776328 1.61514372 1.5408448 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 169683.52358332893\n",
      "[0.40006244 0.39654585 0.39761115 0.39751119 0.39946103 0.2968958\n",
      " 0.39873967 0.20351808 0.20482092 0.20389316]\n",
      "[[1.02164921 0.71564148 0.9169104  0.9071246  1.01196031 1.08614671\n",
      "  1.07439769 1.12256292 1.23836416 1.15803103]]\n",
      "{0: 2809, 1: 5}\n",
      "acc 0.9331911869225302\n",
      "(0.6, 0.015873015873015872, 0.030927835051546386, None)\n",
      "\n",
      "1 loss 147341.3047459415\n",
      "[0.49927003 0.49536291 0.49695314 0.49684306 0.49865141 0.30143638\n",
      " 0.49798158 0.10420372 0.10557752 0.10459595]\n",
      "[[0.96098571 0.61673248 0.83092475 0.82015039 0.95689325 1.12502221\n",
      "  1.00522847 1.21667679 1.33325105 1.25427689]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 130754.29555342294\n",
      "[0.50000051 0.59445316 0.58784302 0.59255759 0.50000047 0.31379893\n",
      " 0.52728408 0.00498614 0.00642668 0.00539627]\n",
      "[[1.04388695 0.51777637 0.75788739 0.75010021 0.98346727 1.15850694\n",
      "  1.00710826 1.31053049 1.42776614 1.35026805]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 119915.01827076054\n",
      "[ 0.50000205  0.69355416  0.66785191  0.66540137  0.50000267  0.33073439\n",
      "  0.5449851  -0.09395686 -0.09244154 -0.09352388]\n",
      "[[1.131576   0.41900493 0.70354088 0.70594911 1.02190754 1.1893871\n",
      "  1.03480614 1.40369236 1.52145764 1.44561437]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 111929.6503662495\n",
      "[ 0.49999995  0.79251571  0.72138576  0.70825856  0.50000011  0.35003533\n",
      "  0.55367597 -0.19269192 -0.19109407 -0.19223071]\n",
      "[[1.22143754 0.32065982 0.66426053 0.67554094 1.06691918 1.21979513\n",
      "  1.07672563 1.49581689 1.61396201 1.54002997]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49999995  0.79251571  0.72138576  0.70825856  0.50000011  0.35003533\n",
      "  0.55367597 -0.19269192 -0.19109407 -0.19223071]\n",
      "[[1.22143754 0.32065982 0.66426053 0.67554094 1.06691918 1.21979513\n",
      "  1.07672563 1.49581689 1.61396201 1.54002997]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.4\n",
      "0 loss 161998.03791505986\n",
      "[0.50004368 0.49671878 0.4976573  0.49755639 0.4996605  0.39996828\n",
      " 0.49848657 0.30347631 0.30477385 0.30384766]\n",
      "[[1.03043541 0.71565441 0.92121984 0.91115652 1.02617647 1.09669756\n",
      "  1.08433716 1.11916339 1.23507266 1.15545617]]\n",
      "{0: 2811, 1: 3}\n",
      "acc 0.9331911869225302\n",
      "(0.6666666666666666, 0.010582010582010581, 0.020833333333333332, None)\n",
      "\n",
      "1 loss 144794.7257024554\n",
      "[0.5000039  0.59572574 0.58995087 0.59378903 0.50000253 0.39974949\n",
      " 0.54096173 0.20370231 0.20505923 0.20408605]\n",
      "[[1.04276126 0.61683495 0.84408496 0.8362443  1.0170567  1.14981159\n",
      "  1.04887586 1.2118703  1.32878794 1.25081125]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 131998.81618999186\n",
      "[0.49999978 0.69484919 0.67131239 0.66866807 0.50000187 0.40426826\n",
      " 0.5673085  0.10419873 0.10561312 0.10459709]\n",
      "[[1.11295515 0.51813914 0.78585255 0.78676092 1.03153308 1.19926236\n",
      "  1.05092249 1.30523562 1.42297787 1.34652946]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 121756.68062099442\n",
      "[0.50000124 0.79395621 0.72680098 0.71420508 0.49999974 0.41349753\n",
      " 0.57876457 0.00501369 0.00649256 0.0054314 ]\n",
      "[[1.19529865 0.41985641 0.74358907 0.7524142  1.06103448 1.24588008\n",
      "  1.08111453 1.39843059 1.51683113 1.4419827 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 113596.81499379182\n",
      "[ 0.49999942  0.89292764  0.76766756  0.7458067   0.50000148  0.42607836\n",
      "  0.58059854 -0.09390152 -0.09234912 -0.09345881]\n",
      "[[1.2825767  0.32265668 0.70825459 0.72391885 1.10027682 1.29120224\n",
      "  1.12627646 1.49091646 1.60982412 1.53675556]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49999942  0.89292764  0.76766756  0.7458067   0.50000148  0.42607836\n",
      "  0.58059854 -0.09390152 -0.09234912 -0.09345881]\n",
      "[[1.2825767  0.32265668 0.70825459 0.72391885 1.10027682 1.29120224\n",
      "  1.12627646 1.49091646 1.60982412 1.53675556]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.5\n",
      "0 loss 157889.89764038645\n",
      "[0.58517833 0.59686387 0.59179784 0.59418346 0.56453853 0.49954881\n",
      " 0.55875418 0.40426153 0.40557605 0.40463714]\n",
      "[[1.03433954 0.71574596 0.92898791 0.92150586 1.0504195  1.11453611\n",
      "  1.09857672 1.11192803 1.22694152 1.14875655]]\n",
      "{0: 2811, 1: 3}\n",
      "acc 0.9331911869225302\n",
      "(0.6666666666666666, 0.010582010582010581, 0.020833333333333332, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 146478.77296745367\n",
      "[0.53338662 0.69595146 0.67474378 0.67138814 0.56400598 0.49732819\n",
      " 0.59363951 0.30444514 0.30581848 0.30483133]\n",
      "[[1.01621361 0.61717488 0.86621487 0.86592647 1.03540186 1.18550765\n",
      "  1.06752881 1.2011621  1.31727085 1.24125633]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 135427.40164752337\n",
      "[0.50000098 0.79512653 0.73337827 0.72151411 0.53204293 0.49594704\n",
      " 0.61037182 0.20466859 0.20609253 0.20506636]\n",
      "[[1.06801229 0.51895373 0.81971805 0.82609229 1.03869969 1.25376835\n",
      "  1.07146865 1.29299437 1.41013139 1.33585511]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 125405.84016562754\n",
      "[0.50000037 0.89426097 0.77755085 0.75854575 0.50000204 0.49786435\n",
      " 0.61321995 0.10519558 0.10667399 0.10560908]\n",
      "[[1.14167675 0.42182486 0.78115818 0.79334306 1.05738007 1.31948832\n",
      "  1.1008312  1.38573543 1.50370148 1.43105489]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 116605.14990806696\n",
      "[0.5000016  0.99333059 0.81427612 0.78807099 0.50000143 0.49994052\n",
      " 0.6071867  0.00605514 0.00759675 0.00649004]\n",
      "[[1.2250806  0.33255217 0.74747221 0.76514592 1.08892232 1.38322829\n",
      "  1.14569017 1.47835999 1.59697771 1.5260231 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.5000016  0.99333059 0.81427612 0.78807099 0.50000143 0.49994052\n",
      " 0.6071867  0.00605514 0.00759675 0.00649004]\n",
      "[[1.2250806  0.33255217 0.74747221 0.76514592 1.08892232 1.38322829\n",
      "  1.14569017 1.47835999 1.59697771 1.5260231 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 157991.9273150094\n",
      "[0.6795881  0.69694286 0.68036809 0.67494236 0.65479552 0.52810075\n",
      " 0.64552101 0.51358779 0.5116442  0.5146183 ]\n",
      "[[1.04209224 0.71597229 0.94364073 0.9396716  1.06152254 1.11429538\n",
      "  1.09960328 1.09758571 1.20738949 1.13202018]]\n",
      "{0: 2804, 1: 10}\n",
      "acc 0.933546552949538\n",
      "(0.6, 0.031746031746031744, 0.06030150753768844, None)\n",
      "\n",
      "1 loss 149890.4524416201\n",
      "[0.63517439 0.79606018 0.74042151 0.72783358 0.65830195 0.49973105\n",
      " 0.66098025 0.41594672 0.41344938 0.41707058]\n",
      "[[1.0245602  0.61790812 0.89321778 0.89494098 1.0469892  1.18544783\n",
      "  1.07651752 1.17792288 1.28771034 1.21557518]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 140843.32704875\n",
      "[0.55467212 0.89527658 0.78803363 0.76928979 0.64085904 0.49916193\n",
      " 0.66137083 0.31625729 0.31381667 0.31738998]\n",
      "[[1.06092116 0.52085337 0.85143295 0.85802938 1.0445405  1.25504755\n",
      "  1.08379033 1.26536747 1.37633633 1.30636633]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 131295.16355218485\n",
      "[0.5000025  0.99450918 0.82876637 0.80416523 0.60633751 0.49926701\n",
      " 0.65081366 0.21650832 0.21411722 0.21765146]\n",
      "[[1.12035276 0.43212292 0.81520945 0.82614038 1.05175243 1.32277117\n",
      "  1.109827   1.35623743 1.46835251 1.40013485]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 122448.0816656167\n",
      "[0.50000052 1.04166262 0.86270516 0.8344728  0.55329724 0.49993973\n",
      " 0.63411773 0.11704817 0.11471163 0.11820607]\n",
      "[[1.19577783 0.47262262 0.78343188 0.79851332 1.07087894 1.38833399\n",
      "  1.15007873 1.44833139 1.56136341 1.49479543]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.50000052 1.04166262 0.86270516 0.8344728  0.55329724 0.49993973\n",
      " 0.63411773 0.11704817 0.11471163 0.11820607]\n",
      "[[1.19577783 0.47262262 0.78343188 0.79851332 1.07087894 1.38833399\n",
      "  1.15007873 1.44833139 1.56136341 1.49479543]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 158212.8522800911\n",
      "[0.77087208 0.79694338 0.75412759 0.74790735 0.74332603 0.6327147\n",
      " 0.75463405 0.64182257 0.6555505  0.64997963]\n",
      "[[1.05734786 0.71648474 0.95949486 0.95479823 1.07546053 1.10905675\n",
      "  1.09420418 1.06925986 1.17392468 1.08443623]]\n",
      "{0: 2780, 1: 34}\n",
      "acc 0.9292821606254442\n",
      "(0.35294117647058826, 0.06349206349206349, 0.10762331838565022, None)\n",
      "\n",
      "1 loss 154348.3761304055\n",
      "[0.77263302 0.89596836 0.80257895 0.79042664 0.75614468 0.56453736\n",
      " 0.76715262 0.55974273 0.57711215 0.57169421]\n",
      "[[1.02828292 0.61972025 0.91371768 0.91361822 1.05859255 1.17850022\n",
      "  1.0599696  1.12614622 1.21932561 1.13508549]]\n",
      "{0: 2808, 1: 6}\n",
      "acc 0.9328358208955224\n",
      "(0.5, 0.015873015873015872, 0.03076923076923077, None)\n",
      "\n",
      "2 loss 148674.50052367026\n",
      "[0.71298399 0.99519271 0.84536896 0.82868936 0.75261895 0.49992505\n",
      " 0.75771159 0.4676792  0.48250959 0.48073334]\n",
      "[[1.04703092 0.53143197 0.87508763 0.87905982 1.05094218 1.24860456\n",
      "  1.06862649 1.1983685  1.28659245 1.20818878]]\n",
      "{0: 2813, 1: 1}\n",
      "acc 0.9331911869225302\n",
      "(1.0, 0.005291005291005291, 0.010526315789473682, None)\n",
      "\n",
      "3 loss 141690.61760315942\n",
      "[0.6376874  1.03615863 0.88112431 0.86068779 0.73946686 0.49980896\n",
      " 0.7367295  0.36867394 0.38352841 0.38169815]\n",
      "[[1.08401739 0.56628003 0.84135859 0.8493403  1.04859637 1.31761282\n",
      "  1.09512983 1.28119471 1.36890912 1.29368938]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 134060.52406763134\n",
      "[0.55027909 1.14479221 0.91317572 0.887704   0.71555997 0.49982088\n",
      " 0.71102893 0.26895489 0.28383171 0.28196331]\n",
      "[[1.13831214 0.67998815 0.81054042 0.82215634 1.05193462 1.38542238\n",
      "  1.1312991  1.36987315 1.45825034 1.38526294]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.55027909 1.14479221 0.91317572 0.887704   0.71555997 0.49982088\n",
      " 0.71102893 0.26895489 0.28383171 0.28196331]\n",
      "[[1.13831214 0.67998815 0.81054042 0.82215634 1.05193462 1.38542238\n",
      "  1.1312991  1.36987315 1.45825034 1.38526294]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.8\n",
      "0 loss 156888.22334408545\n",
      "[0.85123254 0.89699092 0.82577004 0.82400889 0.82325765 0.73955869\n",
      " 0.86698799 0.78653308 0.79197839 0.81933757]\n",
      "[[1.07921274 0.7175971  1.0012327  0.99298176 1.09320986 1.09959202\n",
      "  1.09771072 1.04887393 1.16077117 1.05241636]]\n",
      "{0: 2523, 1: 291}\n",
      "acc 0.900497512437811\n",
      "(0.3436426116838488, 0.5291005291005291, 0.41666666666666663, None)\n",
      "\n",
      "1 loss 154869.17196782224\n",
      "[0.88113199 0.99595084 0.85332608 0.8488132  0.83906596 0.67486726\n",
      " 0.90783491 0.76021487 0.7730442  0.82764111]\n",
      "[[1.0533548  0.63000863 0.98195173 0.97564956 1.08106245 1.16378688\n",
      "  1.05333171 1.07305276 1.18029171 1.04355757]]\n",
      "{0: 2697, 1: 117}\n",
      "acc 0.9211087420042644\n",
      "(0.358974358974359, 0.2222222222222222, 0.27450980392156865, None)\n",
      "\n",
      "2 loss 153683.83081138183\n",
      "[0.87925825 1.01938122 0.88183616 0.87394576 0.84835123 0.60954498\n",
      " 0.88697858 0.72138928 0.7452723  0.83293699]\n",
      "[[1.04283978 0.6462597  0.95165635 0.94807965 1.07050391 1.22972392\n",
      "  1.04344798 1.10336035 1.2041132  1.03653448]]\n",
      "{0: 2788, 1: 26}\n",
      "acc 0.9321250888415068\n",
      "(0.46153846153846156, 0.06349206349206349, 0.11162790697674418, None)\n",
      "\n",
      "3 loss 153059.99167423995\n",
      "[0.85027622 1.13190199 0.9117698  0.90019485 0.85329039 0.54451263\n",
      " 0.8628413  0.66823563 0.70821727 0.84146342]\n",
      "[[1.04285826 0.76580839 0.91969358 0.91894948 1.06155393 1.29622425\n",
      "  1.04881245 1.14072224 1.23221509 1.03110537]]\n",
      "{0: 2798, 1: 16}\n",
      "acc 0.9299928926794598\n",
      "(0.25, 0.021164021164021163, 0.03902439024390244, None)\n",
      "\n",
      "4 loss 151958.5183988523\n",
      "[0.80827158 1.23714934 0.94081911 0.92669989 0.85593964 0.49995562\n",
      " 0.84428695 0.59469571 0.6572689  0.85025923]\n",
      "[[1.0498893  0.87312588 0.88985932 0.89177947 1.05347871 1.36299581\n",
      "  1.06589468 1.18957504 1.26595552 1.0271375 ]]\n",
      "{0: 2805, 1: 9}\n",
      "acc 0.9324804548685146\n",
      "(0.4444444444444444, 0.021164021164021163, 0.0404040404040404, None)\n",
      "\n",
      "[0.80827158 1.23714934 0.94081911 0.92669989 0.85593964 0.49995562\n",
      " 0.84428695 0.59469571 0.6572689  0.85025923]\n",
      "[[1.0498893  0.87312588 0.88985932 0.89177947 1.05347871 1.36299581\n",
      "  1.06589468 1.18957504 1.26595552 1.0271375 ]]\n",
      "{0: 2805, 1: 9}\n",
      "acc 0.9324804548685146\n",
      "acc 0.9324804548685146\n",
      "[[2620    5]\n",
      " [ 185    4]]\n",
      "(0.4444444444444444, 0.021164021164021163, 0.0404040404040404, None)\n",
      "\n",
      "alpha-mean 0.9\n",
      "0 loss 155264.53954891075\n",
      "[0.92690352 0.9971321  0.89117171 0.89079329 0.90543897 0.98363892\n",
      " 0.9542917  0.89181359 0.8937952  0.91162108]\n",
      "[[1.10009277 0.72704278 1.03085428 1.02047423 1.10633782 0.96621163\n",
      "  1.12864769 1.05197377 1.16535794 1.05758622]]\n",
      "{0: 2491, 1: 323}\n",
      "acc 0.8941009239516702\n",
      "(0.33126934984520123, 0.5661375661375662, 0.41796875, None)\n",
      "\n",
      "1 loss 154352.82584004718\n",
      "[0.94538075 1.00003227 0.88239876 0.88170429 0.90954794 0.99722517\n",
      " 0.98051568 0.88340816 0.88622291 0.92065953]\n",
      "[[1.0884174  0.72649249 1.05094155 1.03924606 1.10629312 0.95459477\n",
      "  1.11214221 1.07165552 1.18340155 1.05207841]]\n",
      "{0: 2493, 1: 321}\n",
      "acc 0.8948116560056859\n",
      "(0.3333333333333333, 0.5661375661375662, 0.41960784313725485, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 154345.657013675\n",
      "[0.95711568 1.00017134 0.87422725 0.87406136 0.91291265 0.99776011\n",
      " 0.99031907 0.87564378 0.87869541 0.92818664]\n",
      "[[1.08146765 0.72632277 1.06995853 1.0570634  1.10656614 0.94945574\n",
      "  1.10669314 1.09036948 1.20057795 1.04758399]]\n",
      "{0: 2487, 1: 327}\n",
      "acc 0.8941009239516702\n",
      "(0.3333333333333333, 0.5767195767195767, 0.42248062015503873, None)\n",
      "\n",
      "3 loss 154341.1192211615\n",
      "[0.96473516 1.00014065 0.87002874 0.86936931 0.91573331 0.99703065\n",
      " 0.99419881 0.87566606 0.87567845 0.93511696]\n",
      "[[1.0772874  0.72628999 1.0882641  1.07415257 1.10708575 0.9450955\n",
      "  1.10472967 1.1084319  1.21700396 1.04402819]]\n",
      "{0: 2459, 1: 355}\n",
      "acc 0.8862828713574982\n",
      "(0.3154929577464789, 0.5925925925925926, 0.411764705882353, None)\n",
      "\n",
      "4 loss 154338.10484061058\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "acc 0.8791755508173419\n",
      "[[2346  279]\n",
      " [  61  128]]\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "alpha-mean 1.0\n",
      "0 loss 154393.62099487986\n",
      "[1.12557558 1.00003874 1.12538632 1.         1.1255733  1.12559693\n",
      " 1.12559615 1.12558608 1.12562009 1.12560506]\n",
      "[[1.2446198  0.8130261  1.13596722 1.00062431 1.23341265 1.16815488\n",
      "  1.29646792 1.15796988 1.27354245 1.19163599]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "1 loss 154240.38810601758\n",
      "[1.23195306 1.00011647 1.23182941 0.97335436 1.23195643 1.23205636\n",
      " 1.23194859 1.232052   1.23202169 1.23205054]\n",
      "[[1.35319708 0.81299169 1.24458075 1.02949871 1.34199253 1.27678313\n",
      "  1.40503345 1.26660157 1.38214293 1.30025738]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "2 loss 153643.17077206614\n",
      "[1.33616409 1.00011389 1.33608252 0.94751831 1.33617116 1.33633815\n",
      " 1.33614353 1.33633812 1.33626476 1.33632289]\n",
      "[[1.45865316 0.81290146 1.35005184 1.05738902 1.44744962 1.38228268\n",
      "  1.51048536 1.37210272 1.48763033 1.40575372]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "3 loss 152087.7456070251\n",
      "[1.43950052 1.00009376 1.43944006 0.92449415 1.43950928 1.43973284\n",
      " 1.43947322 1.43973513 1.43964047 1.43971262]\n",
      "[[1.56283252 0.81272882 1.45422781 1.08297519 1.55162825 1.48649707\n",
      "  1.61466876 1.47631698 1.59184955 1.50996871]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "4 loss 148706.22397580525\n",
      "[1.54243366 1.0000831  1.5423676  0.9035523  1.54244137 1.54271703\n",
      " 1.5424124  1.54271916 1.54263144 1.54269755]\n",
      "[[1.66639243 0.81245526 1.55775979 1.10682232 1.65518489 1.59008782\n",
      "  1.7182446  1.57990535 1.6954689  1.61356527]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n",
      "\n",
      "[1.54243366 1.0000831  1.5423676  0.9035523  1.54244137 1.54271703\n",
      " 1.5424124  1.54271916 1.54263144 1.54269755]\n",
      "[[1.66639243 0.81245526 1.55775979 1.10682232 1.65518489 1.59008782\n",
      "  1.7182446  1.57990535 1.6954689  1.61356527]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "acc 0.9012082444918266\n",
      "[[2449  176]\n",
      " [ 102   87]]\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print()\n",
    "    print(\"alpha-mean\",i)\n",
    "    train(0.1/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                          plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha-mean 0.0\n",
      "0 loss 194264.85326121486\n",
      "[ 0.09947401  0.09596     0.09735473  0.09725704  0.09894004 -0.01030508\n",
      "  0.09894431 -0.09624256 -0.09494115 -0.09586474]\n",
      "[[1.01984608 0.71578729 0.91326762 0.90408304 1.00926658 1.07292658\n",
      "  1.07212253 1.12601357 1.24131725 1.16021693]]\n",
      "{0: 2806, 1: 8}\n",
      "acc 0.9342572850035537\n",
      "(0.75, 0.031746031746031744, 0.06091370558375634, None)\n",
      "\n",
      "1 loss 165944.78653442475\n",
      "[ 0.19790907  0.19411453  0.19583783  0.19573171  0.19731637  0.00760686\n",
      "  0.19744465 -0.19395243 -0.1925366  -0.19354266]\n",
      "[[0.92264118 0.61691555 0.81792812 0.8082795  0.9130418  1.0849647\n",
      "  0.97551319 1.22139401 1.33701538 1.25683504]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 145426.3452882983\n",
      "[ 0.29704017  0.29296915  0.29497276  0.29485531  0.29646632  0.0399873\n",
      "  0.29663876 -0.29182634 -0.29029167 -0.29138179]\n",
      "[[0.8261613  0.51767846 0.7251858  0.71477777 0.82094729 1.08603578\n",
      "  0.88155871 1.3152654  1.43122333 1.35249425]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 129826.68522984035\n",
      "[ 0.3965422   0.39207137  0.39443259  0.39429967  0.3960568   0.07599614\n",
      "  0.39621449 -0.38993288 -0.38828145 -0.3894509 ]\n",
      "[[0.73526719 0.41834843 0.63658532 0.62519367 0.74518257 1.08494332\n",
      "  0.79750861 1.40760353 1.52378527 1.44700078]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 117293.74879868481\n",
      "[ 0.49677966  0.49105991  0.49399921  0.49384786  0.49619953  0.11179939\n",
      "  0.49619988 -0.48814211 -0.48638682 -0.48762274]\n",
      "[[0.7522436  0.31907066 0.55577511 0.54350837 0.74399203 1.08535089\n",
      "  0.76963201 1.49848879 1.61471096 1.54024589]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49677966  0.49105991  0.49399921  0.49384786  0.49619953  0.11179939\n",
      "  0.49619988 -0.48814211 -0.48638682 -0.48762274]\n",
      "[[0.7522436  0.31907066 0.55577511 0.54350837 0.74399203 1.08535089\n",
      "  0.76963201 1.49848879 1.61471096 1.54024589]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 185781.95847627256\n",
      "[0.19967327 0.19615971 0.19744814 0.19735001 0.19911576 0.09226008\n",
      " 0.19894121 0.00368871 0.00499454 0.00406713]\n",
      "[[1.02003556 0.7157202  0.91386131 0.90455327 1.00954362 1.07559231\n",
      "  1.07237539 1.12539065 1.24081911 1.15986489]]\n",
      "{0: 2806, 1: 8}\n",
      "acc 0.9342572850035537\n",
      "(0.75, 0.031746031746031744, 0.06091370558375634, None)\n",
      "\n",
      "1 loss 159483.32056801888\n",
      "[ 0.29834619  0.29456714  0.29622298  0.29611599  0.29773821  0.10580634\n",
      "  0.29768761 -0.09462073 -0.09321636 -0.09421548]\n",
      "[[0.92345526 0.61679842 0.81989008 0.80995456 0.91485833 1.09507768\n",
      "  0.97699202 1.22065646 1.33651883 1.25658421]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 139408.32185090086\n",
      "[ 0.3975604   0.39348825  0.39545592  0.39533679  0.39700739  0.13221124\n",
      "  0.39698284 -0.19293461 -0.19142947 -0.1925003 ]\n",
      "[[0.83099436 0.51762236 0.73035262 0.71948807 0.83356164 1.10505495\n",
      "  0.88993698 1.31460596 1.43088955 1.35239227]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 123858.68372792944\n",
      "[ 0.49756632  0.49258738  0.49496802  0.49483458  0.49696945  0.1628117\n",
      "  0.49681511 -0.29131805 -0.28970991 -0.29085113]\n",
      "[[0.83285096 0.41841009 0.64885145 0.63709209 0.82459795 1.11250385\n",
      "  0.85509316 1.40718658 1.5237811  1.4471387 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 113020.3875257964\n",
      "[ 0.50000013  0.59156907  0.5844681   0.59021834  0.5000003   0.19376208\n",
      "  0.51123288 -0.38976341 -0.3880604  -0.38926297]\n",
      "[[0.92591555 0.31930299 0.58000265 0.57207223 0.87728778 1.12105543\n",
      "  0.89176137 1.49844003 1.61517635 1.54073868]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.50000013  0.59156907  0.5844681   0.59021834  0.5000003   0.19376208\n",
      "  0.51123288 -0.38976341 -0.3880604  -0.38926297]\n",
      "[[0.92591555 0.31930299 0.58000265 0.57207223 0.87728778 1.12105543\n",
      "  0.89176137 1.49844003 1.61517635 1.54073868]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.2\n",
      "0 loss 177594.2035698463\n",
      "[0.2998713  0.29635755 0.29753524 0.29743639 0.2992909  0.19452654\n",
      " 0.29888345 0.10360372 0.10490988 0.10398125]\n",
      "[[1.02046742 0.71566814 0.91490631 0.90540562 1.01015783 1.07973837\n",
      "  1.07289938 1.12436596 1.23996459 1.15923948]]\n",
      "{0: 2807, 1: 7}\n",
      "acc 0.9339019189765458\n",
      "(0.7142857142857143, 0.026455026455026454, 0.051020408163265314, None)\n",
      "\n",
      "1 loss 153274.7976608556\n",
      "[0.3987608  0.39498448 0.39659098 0.39648244 0.3981468  0.20352977\n",
      " 0.39785555 0.00476452 0.00615457 0.00516393]\n",
      "[[0.9259043  0.61673024 0.82351894 0.81317403 0.92070084 1.10797379\n",
      "  0.98135213 1.21926386 1.33544443 1.25587701]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 133649.26813170992\n",
      "[ 0.49836711  0.49397731  0.4959534   0.49583306  0.49775627  0.22341711\n",
      "  0.4974006  -0.09395993 -0.09248529 -0.09353668]\n",
      "[[0.90100356 0.5176436  0.74036327 0.72908607 0.89365752 1.12841482\n",
      "  0.93170971 1.31317643 1.42988121 1.35176352]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 120090.01885759828\n",
      "[ 0.50000078  0.59308803  0.5859046   0.59131064  0.50000104  0.24768838\n",
      "  0.51653763 -0.19269018 -0.19113024 -0.19224044]\n",
      "[[0.99217384 0.41859694 0.67015697 0.66244417 0.93906287 1.14633091\n",
      "  0.95828995 1.40607873 1.52320186 1.44684248]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 111705.38536236154\n",
      "[ 0.50000114  0.69205658  0.66524157  0.66324452  0.50000175  0.27312621\n",
      "  0.52859743 -0.29127515 -0.28962538 -0.29079428]\n",
      "[[1.08372211 0.31976297 0.61793727 0.62134597 0.9883906  1.16473381\n",
      "  0.99630666 1.49776328 1.61514372 1.5408448 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.50000114  0.69205658  0.66524157  0.66324452  0.50000175  0.27312621\n",
      "  0.52859743 -0.29127515 -0.28962538 -0.29079428]\n",
      "[[1.08372211 0.31976297 0.61793727 0.62134597 0.9883906  1.16473381\n",
      "  0.99630666 1.49776328 1.61514372 1.5408448 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 169683.52358332893\n",
      "[0.40006244 0.39654585 0.39761115 0.39751119 0.39946103 0.2968958\n",
      " 0.39873967 0.20351808 0.20482092 0.20389316]\n",
      "[[1.02164921 0.71564148 0.9169104  0.9071246  1.01196031 1.08614671\n",
      "  1.07439769 1.12256292 1.23836416 1.15803103]]\n",
      "{0: 2809, 1: 5}\n",
      "acc 0.9331911869225302\n",
      "(0.6, 0.015873015873015872, 0.030927835051546386, None)\n",
      "\n",
      "1 loss 147341.3047459415\n",
      "[0.49927003 0.49536291 0.49695314 0.49684306 0.49865141 0.30143638\n",
      " 0.49798158 0.10420372 0.10557752 0.10459595]\n",
      "[[0.96098571 0.61673248 0.83092475 0.82015039 0.95689325 1.12502221\n",
      "  1.00522847 1.21667679 1.33325105 1.25427689]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 130754.29555342294\n",
      "[0.50000051 0.59445316 0.58784302 0.59255759 0.50000047 0.31379893\n",
      " 0.52728408 0.00498614 0.00642668 0.00539627]\n",
      "[[1.04388695 0.51777637 0.75788739 0.75010021 0.98346727 1.15850694\n",
      "  1.00710826 1.31053049 1.42776614 1.35026805]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 119915.01827076054\n",
      "[ 0.50000205  0.69355416  0.66785191  0.66540137  0.50000267  0.33073439\n",
      "  0.5449851  -0.09395686 -0.09244154 -0.09352388]\n",
      "[[1.131576   0.41900493 0.70354088 0.70594911 1.02190754 1.1893871\n",
      "  1.03480614 1.40369236 1.52145764 1.44561437]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 111929.6503662495\n",
      "[ 0.49999995  0.79251571  0.72138576  0.70825856  0.50000011  0.35003533\n",
      "  0.55367597 -0.19269192 -0.19109407 -0.19223071]\n",
      "[[1.22143754 0.32065982 0.66426053 0.67554094 1.06691918 1.21979513\n",
      "  1.07672563 1.49581689 1.61396201 1.54002997]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49999995  0.79251571  0.72138576  0.70825856  0.50000011  0.35003533\n",
      "  0.55367597 -0.19269192 -0.19109407 -0.19223071]\n",
      "[[1.22143754 0.32065982 0.66426053 0.67554094 1.06691918 1.21979513\n",
      "  1.07672563 1.49581689 1.61396201 1.54002997]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.4\n",
      "0 loss 161998.03791505986\n",
      "[0.50004368 0.49671878 0.4976573  0.49755639 0.4996605  0.39996828\n",
      " 0.49848657 0.30347631 0.30477385 0.30384766]\n",
      "[[1.03043541 0.71565441 0.92121984 0.91115652 1.02617647 1.09669756\n",
      "  1.08433716 1.11916339 1.23507266 1.15545617]]\n",
      "{0: 2811, 1: 3}\n",
      "acc 0.9331911869225302\n",
      "(0.6666666666666666, 0.010582010582010581, 0.020833333333333332, None)\n",
      "\n",
      "1 loss 144794.7257024554\n",
      "[0.5000039  0.59572574 0.58995087 0.59378903 0.50000253 0.39974949\n",
      " 0.54096173 0.20370231 0.20505923 0.20408605]\n",
      "[[1.04276126 0.61683495 0.84408496 0.8362443  1.0170567  1.14981159\n",
      "  1.04887586 1.2118703  1.32878794 1.25081125]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 131998.81618999186\n",
      "[0.49999978 0.69484919 0.67131239 0.66866807 0.50000187 0.40426826\n",
      " 0.5673085  0.10419873 0.10561312 0.10459709]\n",
      "[[1.11295515 0.51813914 0.78585255 0.78676092 1.03153308 1.19926236\n",
      "  1.05092249 1.30523562 1.42297787 1.34652946]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 121756.68062099442\n",
      "[0.50000124 0.79395621 0.72680098 0.71420508 0.49999974 0.41349753\n",
      " 0.57876457 0.00501369 0.00649256 0.0054314 ]\n",
      "[[1.19529865 0.41985641 0.74358907 0.7524142  1.06103448 1.24588008\n",
      "  1.08111453 1.39843059 1.51683113 1.4419827 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 113596.81499379182\n",
      "[ 0.49999942  0.89292764  0.76766756  0.7458067   0.50000148  0.42607836\n",
      "  0.58059854 -0.09390152 -0.09234912 -0.09345881]\n",
      "[[1.2825767  0.32265668 0.70825459 0.72391885 1.10027682 1.29120224\n",
      "  1.12627646 1.49091646 1.60982412 1.53675556]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[ 0.49999942  0.89292764  0.76766756  0.7458067   0.50000148  0.42607836\n",
      "  0.58059854 -0.09390152 -0.09234912 -0.09345881]\n",
      "[[1.2825767  0.32265668 0.70825459 0.72391885 1.10027682 1.29120224\n",
      "  1.12627646 1.49091646 1.60982412 1.53675556]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.5\n",
      "0 loss 157889.89764038645\n",
      "[0.58517833 0.59686387 0.59179784 0.59418346 0.56453853 0.49954881\n",
      " 0.55875418 0.40426153 0.40557605 0.40463714]\n",
      "[[1.03433954 0.71574596 0.92898791 0.92150586 1.0504195  1.11453611\n",
      "  1.09857672 1.11192803 1.22694152 1.14875655]]\n",
      "{0: 2811, 1: 3}\n",
      "acc 0.9331911869225302\n",
      "(0.6666666666666666, 0.010582010582010581, 0.020833333333333332, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 146478.77296745367\n",
      "[0.53338662 0.69595146 0.67474378 0.67138814 0.56400598 0.49732819\n",
      " 0.59363951 0.30444514 0.30581848 0.30483133]\n",
      "[[1.01621361 0.61717488 0.86621487 0.86592647 1.03540186 1.18550765\n",
      "  1.06752881 1.2011621  1.31727085 1.24125633]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 135427.40164752337\n",
      "[0.50000098 0.79512653 0.73337827 0.72151411 0.53204293 0.49594704\n",
      " 0.61037182 0.20466859 0.20609253 0.20506636]\n",
      "[[1.06801229 0.51895373 0.81971805 0.82609229 1.03869969 1.25376835\n",
      "  1.07146865 1.29299437 1.41013139 1.33585511]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 125405.84016562754\n",
      "[0.50000037 0.89426097 0.77755085 0.75854575 0.50000204 0.49786435\n",
      " 0.61321995 0.10519558 0.10667399 0.10560908]\n",
      "[[1.14167675 0.42182486 0.78115818 0.79334306 1.05738007 1.31948832\n",
      "  1.1008312  1.38573543 1.50370148 1.43105489]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 116605.14990806696\n",
      "[0.5000016  0.99333059 0.81427612 0.78807099 0.50000143 0.49994052\n",
      " 0.6071867  0.00605514 0.00759675 0.00649004]\n",
      "[[1.2250806  0.33255217 0.74747221 0.76514592 1.08892232 1.38322829\n",
      "  1.14569017 1.47835999 1.59697771 1.5260231 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.5000016  0.99333059 0.81427612 0.78807099 0.50000143 0.49994052\n",
      " 0.6071867  0.00605514 0.00759675 0.00649004]\n",
      "[[1.2250806  0.33255217 0.74747221 0.76514592 1.08892232 1.38322829\n",
      "  1.14569017 1.47835999 1.59697771 1.5260231 ]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 157991.9273150094\n",
      "[0.6795881  0.69694286 0.68036809 0.67494236 0.65479552 0.52810075\n",
      " 0.64552101 0.51358779 0.5116442  0.5146183 ]\n",
      "[[1.04209224 0.71597229 0.94364073 0.9396716  1.06152254 1.11429538\n",
      "  1.09960328 1.09758571 1.20738949 1.13202018]]\n",
      "{0: 2804, 1: 10}\n",
      "acc 0.933546552949538\n",
      "(0.6, 0.031746031746031744, 0.06030150753768844, None)\n",
      "\n",
      "1 loss 149890.4524416201\n",
      "[0.63517439 0.79606018 0.74042151 0.72783358 0.65830195 0.49973105\n",
      " 0.66098025 0.41594672 0.41344938 0.41707058]\n",
      "[[1.0245602  0.61790812 0.89321778 0.89494098 1.0469892  1.18544783\n",
      "  1.07651752 1.17792288 1.28771034 1.21557518]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "2 loss 140843.32704875\n",
      "[0.55467212 0.89527658 0.78803363 0.76928979 0.64085904 0.49916193\n",
      " 0.66137083 0.31625729 0.31381667 0.31738998]\n",
      "[[1.06092116 0.52085337 0.85143295 0.85802938 1.0445405  1.25504755\n",
      "  1.08379033 1.26536747 1.37633633 1.30636633]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "3 loss 131295.16355218485\n",
      "[0.5000025  0.99450918 0.82876637 0.80416523 0.60633751 0.49926701\n",
      " 0.65081366 0.21650832 0.21411722 0.21765146]\n",
      "[[1.12035276 0.43212292 0.81520945 0.82614038 1.05175243 1.32277117\n",
      "  1.109827   1.35623743 1.46835251 1.40013485]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 122448.0816656167\n",
      "[0.50000052 1.04166262 0.86270516 0.8344728  0.55329724 0.49993973\n",
      " 0.63411773 0.11704817 0.11471163 0.11820607]\n",
      "[[1.19577783 0.47262262 0.78343188 0.79851332 1.07087894 1.38833399\n",
      "  1.15007873 1.44833139 1.56136341 1.49479543]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.50000052 1.04166262 0.86270516 0.8344728  0.55329724 0.49993973\n",
      " 0.63411773 0.11704817 0.11471163 0.11820607]\n",
      "[[1.19577783 0.47262262 0.78343188 0.79851332 1.07087894 1.38833399\n",
      "  1.15007873 1.44833139 1.56136341 1.49479543]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 158212.8522800911\n",
      "[0.77087208 0.79694338 0.75412759 0.74790735 0.74332603 0.6327147\n",
      " 0.75463405 0.64182257 0.6555505  0.64997963]\n",
      "[[1.05734786 0.71648474 0.95949486 0.95479823 1.07546053 1.10905675\n",
      "  1.09420418 1.06925986 1.17392468 1.08443623]]\n",
      "{0: 2780, 1: 34}\n",
      "acc 0.9292821606254442\n",
      "(0.35294117647058826, 0.06349206349206349, 0.10762331838565022, None)\n",
      "\n",
      "1 loss 154348.3761304055\n",
      "[0.77263302 0.89596836 0.80257895 0.79042664 0.75614468 0.56453736\n",
      " 0.76715262 0.55974273 0.57711215 0.57169421]\n",
      "[[1.02828292 0.61972025 0.91371768 0.91361822 1.05859255 1.17850022\n",
      "  1.0599696  1.12614622 1.21932561 1.13508549]]\n",
      "{0: 2808, 1: 6}\n",
      "acc 0.9328358208955224\n",
      "(0.5, 0.015873015873015872, 0.03076923076923077, None)\n",
      "\n",
      "2 loss 148674.50052367026\n",
      "[0.71298399 0.99519271 0.84536896 0.82868936 0.75261895 0.49992505\n",
      " 0.75771159 0.4676792  0.48250959 0.48073334]\n",
      "[[1.04703092 0.53143197 0.87508763 0.87905982 1.05094218 1.24860456\n",
      "  1.06862649 1.1983685  1.28659245 1.20818878]]\n",
      "{0: 2813, 1: 1}\n",
      "acc 0.9331911869225302\n",
      "(1.0, 0.005291005291005291, 0.010526315789473682, None)\n",
      "\n",
      "3 loss 141690.61760315942\n",
      "[0.6376874  1.03615863 0.88112431 0.86068779 0.73946686 0.49980896\n",
      " 0.7367295  0.36867394 0.38352841 0.38169815]\n",
      "[[1.08401739 0.56628003 0.84135859 0.8493403  1.04859637 1.31761282\n",
      "  1.09512983 1.28119471 1.36890912 1.29368938]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "4 loss 134060.52406763134\n",
      "[0.55027909 1.14479221 0.91317572 0.887704   0.71555997 0.49982088\n",
      " 0.71102893 0.26895489 0.28383171 0.28196331]\n",
      "[[1.13831214 0.67998815 0.81054042 0.82215634 1.05193462 1.38542238\n",
      "  1.1312991  1.36987315 1.45825034 1.38526294]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "[0.55027909 1.14479221 0.91317572 0.887704   0.71555997 0.49982088\n",
      " 0.71102893 0.26895489 0.28383171 0.28196331]\n",
      "[[1.13831214 0.67998815 0.81054042 0.82215634 1.05193462 1.38542238\n",
      "  1.1312991  1.36987315 1.45825034 1.38526294]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "acc 0.9328358208955224\n",
      "[[2625    0]\n",
      " [ 189    0]]\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "alpha-mean 0.8\n",
      "0 loss 156888.22334408545\n",
      "[0.85123254 0.89699092 0.82577004 0.82400889 0.82325765 0.73955869\n",
      " 0.86698799 0.78653308 0.79197839 0.81933757]\n",
      "[[1.07921274 0.7175971  1.0012327  0.99298176 1.09320986 1.09959202\n",
      "  1.09771072 1.04887393 1.16077117 1.05241636]]\n",
      "{0: 2523, 1: 291}\n",
      "acc 0.900497512437811\n",
      "(0.3436426116838488, 0.5291005291005291, 0.41666666666666663, None)\n",
      "\n",
      "1 loss 154869.17196782224\n",
      "[0.88113199 0.99595084 0.85332608 0.8488132  0.83906596 0.67486726\n",
      " 0.90783491 0.76021487 0.7730442  0.82764111]\n",
      "[[1.0533548  0.63000863 0.98195173 0.97564956 1.08106245 1.16378688\n",
      "  1.05333171 1.07305276 1.18029171 1.04355757]]\n",
      "{0: 2697, 1: 117}\n",
      "acc 0.9211087420042644\n",
      "(0.358974358974359, 0.2222222222222222, 0.27450980392156865, None)\n",
      "\n",
      "2 loss 153683.83081138183\n",
      "[0.87925825 1.01938122 0.88183616 0.87394576 0.84835123 0.60954498\n",
      " 0.88697858 0.72138928 0.7452723  0.83293699]\n",
      "[[1.04283978 0.6462597  0.95165635 0.94807965 1.07050391 1.22972392\n",
      "  1.04344798 1.10336035 1.2041132  1.03653448]]\n",
      "{0: 2788, 1: 26}\n",
      "acc 0.9321250888415068\n",
      "(0.46153846153846156, 0.06349206349206349, 0.11162790697674418, None)\n",
      "\n",
      "3 loss 153059.99167423995\n",
      "[0.85027622 1.13190199 0.9117698  0.90019485 0.85329039 0.54451263\n",
      " 0.8628413  0.66823563 0.70821727 0.84146342]\n",
      "[[1.04285826 0.76580839 0.91969358 0.91894948 1.06155393 1.29622425\n",
      "  1.04881245 1.14072224 1.23221509 1.03110537]]\n",
      "{0: 2798, 1: 16}\n",
      "acc 0.9299928926794598\n",
      "(0.25, 0.021164021164021163, 0.03902439024390244, None)\n",
      "\n",
      "4 loss 151958.5183988523\n",
      "[0.80827158 1.23714934 0.94081911 0.92669989 0.85593964 0.49995562\n",
      " 0.84428695 0.59469571 0.6572689  0.85025923]\n",
      "[[1.0498893  0.87312588 0.88985932 0.89177947 1.05347871 1.36299581\n",
      "  1.06589468 1.18957504 1.26595552 1.0271375 ]]\n",
      "{0: 2805, 1: 9}\n",
      "acc 0.9324804548685146\n",
      "(0.4444444444444444, 0.021164021164021163, 0.0404040404040404, None)\n",
      "\n",
      "[0.80827158 1.23714934 0.94081911 0.92669989 0.85593964 0.49995562\n",
      " 0.84428695 0.59469571 0.6572689  0.85025923]\n",
      "[[1.0498893  0.87312588 0.88985932 0.89177947 1.05347871 1.36299581\n",
      "  1.06589468 1.18957504 1.26595552 1.0271375 ]]\n",
      "{0: 2805, 1: 9}\n",
      "acc 0.9324804548685146\n",
      "acc 0.9324804548685146\n",
      "[[2620    5]\n",
      " [ 185    4]]\n",
      "(0.4444444444444444, 0.021164021164021163, 0.0404040404040404, None)\n",
      "\n",
      "alpha-mean 0.9\n",
      "0 loss 155264.53954891075\n",
      "[0.92690352 0.9971321  0.89117171 0.89079329 0.90543897 0.98363892\n",
      " 0.9542917  0.89181359 0.8937952  0.91162108]\n",
      "[[1.10009277 0.72704278 1.03085428 1.02047423 1.10633782 0.96621163\n",
      "  1.12864769 1.05197377 1.16535794 1.05758622]]\n",
      "{0: 2491, 1: 323}\n",
      "acc 0.8941009239516702\n",
      "(0.33126934984520123, 0.5661375661375662, 0.41796875, None)\n",
      "\n",
      "1 loss 154352.82584004718\n",
      "[0.94538075 1.00003227 0.88239876 0.88170429 0.90954794 0.99722517\n",
      " 0.98051568 0.88340816 0.88622291 0.92065953]\n",
      "[[1.0884174  0.72649249 1.05094155 1.03924606 1.10629312 0.95459477\n",
      "  1.11214221 1.07165552 1.18340155 1.05207841]]\n",
      "{0: 2493, 1: 321}\n",
      "acc 0.8948116560056859\n",
      "(0.3333333333333333, 0.5661375661375662, 0.41960784313725485, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 154345.657013675\n",
      "[0.95711568 1.00017134 0.87422725 0.87406136 0.91291265 0.99776011\n",
      " 0.99031907 0.87564378 0.87869541 0.92818664]\n",
      "[[1.08146765 0.72632277 1.06995853 1.0570634  1.10656614 0.94945574\n",
      "  1.10669314 1.09036948 1.20057795 1.04758399]]\n",
      "{0: 2487, 1: 327}\n",
      "acc 0.8941009239516702\n",
      "(0.3333333333333333, 0.5767195767195767, 0.42248062015503873, None)\n",
      "\n",
      "3 loss 154341.1192211615\n",
      "[0.96473516 1.00014065 0.87002874 0.86936931 0.91573331 0.99703065\n",
      " 0.99419881 0.87566606 0.87567845 0.93511696]\n",
      "[[1.0772874  0.72628999 1.0882641  1.07415257 1.10708575 0.9450955\n",
      "  1.10472967 1.1084319  1.21700396 1.04402819]]\n",
      "{0: 2459, 1: 355}\n",
      "acc 0.8862828713574982\n",
      "(0.3154929577464789, 0.5925925925925926, 0.411764705882353, None)\n",
      "\n",
      "4 loss 154338.10484061058\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "acc 0.8791755508173419\n",
      "[[2346  279]\n",
      " [  61  128]]\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "alpha-mean 1.0\n",
      "0 loss 154393.62099487986\n",
      "[1.12557558 1.00003874 1.12538632 1.         1.1255733  1.12559693\n",
      " 1.12559615 1.12558608 1.12562009 1.12560506]\n",
      "[[1.2446198  0.8130261  1.13596722 1.00062431 1.23341265 1.16815488\n",
      "  1.29646792 1.15796988 1.27354245 1.19163599]]\n",
      "{0: 2814}\n",
      "acc 0.9328358208955224\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "1 loss 154240.38810601758\n",
      "[1.23195306 1.00011647 1.23182941 0.97335436 1.23195643 1.23205636\n",
      " 1.23194859 1.232052   1.23202169 1.23205054]\n",
      "[[1.35319708 0.81299169 1.24458075 1.02949871 1.34199253 1.27678313\n",
      "  1.40503345 1.26660157 1.38214293 1.30025738]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "2 loss 153643.17077206614\n",
      "[1.33616409 1.00011389 1.33608252 0.94751831 1.33617116 1.33633815\n",
      " 1.33614353 1.33633812 1.33626476 1.33632289]\n",
      "[[1.45865316 0.81290146 1.35005184 1.05738902 1.44744962 1.38228268\n",
      "  1.51048536 1.37210272 1.48763033 1.40575372]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "3 loss 152087.7456070251\n",
      "[1.43950052 1.00009376 1.43944006 0.92449415 1.43950928 1.43973284\n",
      " 1.43947322 1.43973513 1.43964047 1.43971262]\n",
      "[[1.56283252 0.81272882 1.45422781 1.08297519 1.55162825 1.48649707\n",
      "  1.61466876 1.47631698 1.59184955 1.50996871]]\n",
      "{0: 2608, 1: 206}\n",
      "acc 0.9214641080312722\n",
      "(0.4223300970873786, 0.4603174603174603, 0.440506329113924, None)\n",
      "\n",
      "4 loss 148706.22397580525\n",
      "[1.54243366 1.0000831  1.5423676  0.9035523  1.54244137 1.54271703\n",
      " 1.5424124  1.54271916 1.54263144 1.54269755]\n",
      "[[1.66639243 0.81245526 1.55775979 1.10682232 1.65518489 1.59008782\n",
      "  1.7182446  1.57990535 1.6954689  1.61356527]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n",
      "\n",
      "[1.54243366 1.0000831  1.5423676  0.9035523  1.54244137 1.54271703\n",
      " 1.5424124  1.54271916 1.54263144 1.54269755]\n",
      "[[1.66639243 0.81245526 1.55775979 1.10682232 1.65518489 1.59008782\n",
      "  1.7182446  1.57990535 1.6954689  1.61356527]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9012082444918266\n",
      "acc 0.9012082444918266\n",
      "[[2449  176]\n",
      " [ 102   87]]\n",
      "(0.33079847908745247, 0.4603174603174603, 0.38495575221238937, None)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print()\n",
    "    print(\"alpha-mean\",i)\n",
    "    train(0.1/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                          plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalized model with discrete LFs\n",
    "\n",
    "def train_nl(lr,ep,th):\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "        print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=tf.truncated_normal_initializer(0.3,0.1,seed),\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "        print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "        print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "        print(alphas)\n",
    "        print(s)\n",
    "        print(\"l\",l)\n",
    "        print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "        print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),\\\n",
    "                           -tf.ones_like(v))\n",
    "            print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        ### discrete pout \n",
    "        pout = tf.map_fn(lambda c: iskequalsy(l,c) ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "       \n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,name=\"t_pout\")\n",
    "        print(\"pout\",pout)\n",
    "\n",
    "        print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "        print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "            print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "            print(\"intsy\",out1)\n",
    "            return out1\n",
    "        \n",
    "        zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),np.arange(NoOfClasses,dtype=np.float64))\n",
    "\n",
    "        \n",
    "        print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "        print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "        print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "        \n",
    "        normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "\n",
    "\n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "        print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "        print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "        print(\"predict\",predict)\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_element Tensor(\"IteratorGetNext_1:0\", shape=(?, 2, 10), dtype=float64)\n",
      "thetas <tf.Variable 'thetas:0' shape=(1, 10) dtype=float64_ref>\n",
      "k Tensor(\"Const:0\", shape=(10,), dtype=float64)\n",
      "<tf.Variable 'alphas:0' shape=(10,) dtype=float64_ref>\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f32c9926898>\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"pout/while/Select:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"map/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "normloss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "predict Tensor(\"ArgMax:0\", shape=(?, 1), dtype=int64)\n",
      "0 loss 376630.9607297066\n",
      "acc 0.9019189765458422\n",
      "(0.3515358361774744, 0.544973544973545, 0.42738589211618255, None)\n",
      "\n",
      "1 loss 351257.10479729244\n",
      "acc 0.9019189765458422\n",
      "(0.3515358361774744, 0.544973544973545, 0.42738589211618255, None)\n",
      "\n",
      "2 loss 326273.94254572084\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "3 loss 301720.04581946554\n",
      "acc 0.9029850746268657\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n",
      "\n",
      "4 loss 277655.6846060027\n",
      "acc 0.9029850746268657\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n",
      "\n",
      "[0.41754463 0.11421453 0.30955965 0.30062431 0.40637787 0.34133855\n",
      " 0.469206   0.33120785 0.44633471 0.3647233 ]\n",
      "[[0.61831313 0.31635439 0.53769424 0.52325032 0.60957862 1.21725514\n",
      "  0.66965792 0.69257016 0.76519724 0.58094792]]\n",
      "{0: 2526, 1: 288}\n",
      "acc 0.9029850746268657\n",
      "acc 0.9029850746268657\n",
      "[[2439  186]\n",
      " [  87  102]]\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl(0.1/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
