{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import load_external_labels\n",
    "\n",
    "# %time load_external_labels(session, Spouse, annotator_name='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "\n",
    "session = SnorkelSession()\n",
    "dev_cands = session.query(Spouse).filter(Spouse.split == 1).all()\n",
    "test_cands = session.query(Spouse).filter(Spouse.split == 2).all()\n",
    "\n",
    "#L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "#L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "\n",
    "# L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "# gold_labels_dev = [L[0,0] if L[0,0]==1 else -1 for L in L_gold_dev]\n",
    "gold_labels_dev = [L[0,0] for L in L_gold_dev]\n",
    "gold_labels_test = [L[0,0] for L in L_gold_test]\n",
    "\n",
    "from snorkel.learning.utils import MentionScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2625, 1: 189}\n",
      "{0: 2484, 1: 218}\n",
      "2814 2702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(gold_labels_dev, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "\n",
    "unique, counts = np.unique(gold_labels_test, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print(len(gold_labels_dev),len(gold_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gensim.matutils as gm\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = KeyedVectors.load_word2vec_format('../../../snorkel/tutorials/glove_w2v.txt', binary=False)  # C binary format\n",
    "\n",
    "\n",
    "wordvec_unavailable= set()\n",
    "def write_to_file(wordvec_unavailable):\n",
    "    with open(\"wordvec_unavailable.txt\",\"w\") as f:\n",
    "        for word in wordvec_unavailable:\n",
    "            f.write(word+\"\\n\")\n",
    "\n",
    "def preprocess(tokens):\n",
    "    btw_words = [word for word in tokens if word not in STOPWORDS]\n",
    "    btw_words = [word for word in btw_words if word.isalpha()]\n",
    "    return btw_words\n",
    "\n",
    "def get_word_vectors(btw_words): # returns vector of embeddings of words\n",
    "    word_vectors= []\n",
    "    for word in btw_words:\n",
    "        try:\n",
    "            word_v = np.array(model[word])\n",
    "            word_v = word_v.reshape(len(word_v),1)\n",
    "            #print(word_v.shape)\n",
    "            word_vectors.append(model[word])\n",
    "        except:\n",
    "            wordvec_unavailable.add(word)\n",
    "    return word_vectors\n",
    "\n",
    "def get_similarity(word_vectors,target_word): # sent(list of word vecs) to word similarity\n",
    "    similarity = 0\n",
    "    target_word_vector = 0\n",
    "    try:\n",
    "        target_word_vector = model[target_word]\n",
    "    except:\n",
    "        wordvec_unavailable.add(target_word+\" t\")\n",
    "        return similarity\n",
    "    target_word_sparse = gm.any2sparse(target_word_vector,eps=1e-09)\n",
    "    for wv in word_vectors:\n",
    "        wv_sparse = gm.any2sparse(wv, eps=1e-09)\n",
    "        similarity = max(similarity,gm.cossim(wv_sparse,target_word_sparse))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Discrete ##########\n",
    "\n",
    "# import re\n",
    "# from snorkel.lf_helpers import (\n",
    "#     get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "#     get_text_between, get_tagged_text,\n",
    "# )\n",
    "\n",
    "# spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "# family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "#               'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "# family = family | {f + '-in-law' for f in family}\n",
    "# other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# # Helper function to get last name\n",
    "# def last_name(s):\n",
    "#     name_parts = s.split(' ')\n",
    "#     return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "# def LF_husband_wife(c):\n",
    "#     return (1,1) if len(spouses.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "# def LF_husband_wife_left_window(c):\n",
    "#     if len(spouses.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "#         return (1,1)\n",
    "#     elif len(spouses.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "#         return (1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "    \n",
    "# def LF_same_last_name(c):\n",
    "#     p1_last_name = last_name(c.person1.get_span())\n",
    "#     p2_last_name = last_name(c.person2.get_span())\n",
    "#     if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "#         if c.person1.get_span() != c.person2.get_span():\n",
    "#             return (1,1)\n",
    "#     return (0,0)\n",
    "\n",
    "# def LF_no_spouse_in_sentence(c):\n",
    "#     return (-1,1) if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else (0,0)\n",
    "\n",
    "# def LF_and_married(c):\n",
    "#     return (1,1) if 'and' in get_between_tokens(c) and 'married' in get_right_tokens(c) else (0,0)\n",
    "    \n",
    "# def LF_familial_relationship(c):\n",
    "#     return (-1,1) if len(family.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "# def LF_family_left_window(c):\n",
    "#     if len(family.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "#         return (-1,1)\n",
    "#     elif len(family.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "#         return (-1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "\n",
    "# def LF_other_relationship(c):\n",
    "#     return (-1,1) if len(other.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "\n",
    "# import bz2\n",
    "\n",
    "# # Function to remove special characters from text\n",
    "# def strip_special(s):\n",
    "#     return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# # Read in known spouse pairs and save as set of tuples\n",
    "# with bz2.BZ2File('data/spouses_dbpedia.csv.bz2', 'rb') as f:\n",
    "#     known_spouses = set(\n",
    "#         tuple(strip_special(x.decode('utf-8')).strip().split(',')) for x in f.readlines()\n",
    "#     )\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "    \n",
    "# def LF_distant_supervision(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     return (1,1) if (p1, p2) in known_spouses or (p2, p1) in known_spouses else (0,0)\n",
    "\n",
    "# def LF_distant_supervision_last_names(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     p1n, p2n = last_name(p1), last_name(p2)\n",
    "#     return (1,1) if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else (0,0)\n",
    "\n",
    "\n",
    "# LFs = [\n",
    "#     LF_distant_supervision, LF_distant_supervision_last_names, \n",
    "#     LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "#     LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "#     LF_family_left_window, LF_other_relationship\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Continuous ################\n",
    "\n",
    "\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "\n",
    "spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "              'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "family = family | {f + '-in-law' for f in family}\n",
    "other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# Helper function to get last name\n",
    "def last_name(s):\n",
    "    name_parts = s.split(' ')\n",
    "    return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "def LF_husband_wife(c):\n",
    "    global LF_Threshold\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for sw in spouses:\n",
    "        sc=max(sc,get_similarity(word_vectors,sw))\n",
    "    return (1,sc)\n",
    "\n",
    "def LF_husband_wife_left_window(c):\n",
    "    global LF_Threshold\n",
    "    sc_1 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[0])))\n",
    "    for sw in spouses:\n",
    "        sc_1=max(sc_1,get_similarity(word_vectors,sw))\n",
    "        \n",
    "    sc_2 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[1])))\n",
    "    for sw in spouses:\n",
    "        sc_2=max(sc_2,get_similarity(word_vectors,sw))\n",
    "    return(1,max(sc_1,sc_2))\n",
    "    \n",
    "def LF_same_last_name(c):\n",
    "    p1_last_name = last_name(c.person1.get_span())\n",
    "    p2_last_name = last_name(c.person2.get_span())\n",
    "    if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "        if c.person1.get_span() != c.person2.get_span():\n",
    "            return (1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_no_spouse_in_sentence(c):\n",
    "    return (-1,0.75) if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else (0,0)\n",
    "\n",
    "def LF_and_married(c):\n",
    "    global LF_Threshold\n",
    "    word_vectors = get_word_vectors(preprocess(get_right_tokens(c)))\n",
    "    sc = get_similarity(word_vectors,'married')\n",
    "    \n",
    "    if 'and' in get_between_tokens(c):\n",
    "        return (1,sc)\n",
    "    else:\n",
    "        return (0,0)\n",
    "\n",
    "def LF_familial_relationship(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for fw in family:\n",
    "        sc=max(sc,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    return (-1,sc) \n",
    "\n",
    "def LF_family_left_window(c):\n",
    "    sc_1 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[0])))\n",
    "    for fw in family:\n",
    "        sc_1=max(sc_1,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    sc_2 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[1])))\n",
    "    for fw in family:\n",
    "        sc_2=max(sc_2,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    return (-1,max(sc_1,sc_2))\n",
    "\n",
    "def LF_other_relationship(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for ow in other:\n",
    "        sc=max(sc,get_similarity(word_vectors,ow))\n",
    "        \n",
    "    return (-1,sc) \n",
    "\n",
    "# def LF_other_relationship_left_window(c):\n",
    "#     sc = 0\n",
    "#     word_vectors = get_word_vectors(preprocess(get_left_tokens(c)))\n",
    "#     for ow in other:\n",
    "#         sc=max(sc,get_similarity(word_vectors,ow))\n",
    "#     return (-1,sc) \n",
    "\n",
    "import bz2\n",
    "\n",
    "# Function to remove special characters from text\n",
    "def strip_special(s):\n",
    "    s = s.decode(\"utf-8\") \n",
    "    return ''.join(c for c in s if (ord(c) < 128))\n",
    "\n",
    "\n",
    "# Read in known spouse pairs and save as set of tuples\n",
    "with bz2.BZ2File('data/spouses_dbpedia.csv.bz2', 'r') as f:\n",
    "    known_spouses = set(\n",
    "        tuple(strip_special(x).strip().split(',')) for x in f.readlines()\n",
    "    )\n",
    "# Last name pairs for known spouses\n",
    "last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "    \n",
    "def LF_distant_supervision(c):\n",
    "    p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "    return (1,1) if (p1, p2) in known_spouses or (p2, p1) in known_spouses else (0,0)\n",
    "\n",
    "def LF_distant_supervision_last_names(c):\n",
    "    p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "    p1n, p2n = last_name(p1), last_name(p2)\n",
    "    return (1,1) if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else (0,1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# def LF_Three_Lists_Left_Window(c):\n",
    "#     global softmax_Threshold\n",
    "#     c1,s1 = LF_husband_wife_left_window(c)\n",
    "#     c2,s2 = LF_family_left_window(c)\n",
    "#     c3,s3 = LF_other_relationship_left_window(c)\n",
    "#     sc = np.array([s1,s2,s3])\n",
    "#     c = [c1,c2,c3]\n",
    "#     sharp_param = 1.5\n",
    "#     prob_sc = np.exp(sc * sharp_param - np.max(sc))\n",
    "#     prob_sc = prob_sc / np.sum(prob_sc)\n",
    "#     #print 'Left:',s1,s2,s3,prob_sc\n",
    "    \n",
    "#     if s1==s2 or s3==s1:\n",
    "#         return (0,0)\n",
    "#     return c[np.argmax(prob_sc)],1\n",
    "\n",
    "# def LF_Three_Lists_Between_Words(c):\n",
    "#     global softmax_Threshold\n",
    "#     c1,s1 = LF_husband_wife(c)\n",
    "#     c2,s2 = LF_familial_relationship(c)\n",
    "#     c3,s3 = LF_other_relationship(c)\n",
    "#     sc = np.array([s1,s2,s3])\n",
    "#     c = [c1,c2,c3]\n",
    "#     sharp_param = 1.5\n",
    "    \n",
    "#     prob_sc = np.exp(sc * sharp_param - np.max(sc))\n",
    "#     prob_sc = prob_sc / np.sum(prob_sc)\n",
    "#     #print 'BW:',s1,s2,s3,prob_sc\n",
    "#     if s1==s2 or s3==s1:\n",
    "#         return (0,0)\n",
    "#     return c[np.argmax(prob_sc)],1\n",
    "    \n",
    "LFs = [\n",
    "    LF_distant_supervision, LF_distant_supervision_last_names, \n",
    "    LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "    LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "    LF_family_left_window, LF_other_relationship\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' output:\n",
    "\n",
    "    [[[L_x1],[S_x1]],\n",
    "     [[L_x2],[S_x2]],\n",
    "     ......\n",
    "     ......\n",
    "    ]\n",
    "    \n",
    "output shape : [NoOfDataPoints,2,NoOfLFs]\n",
    "\n",
    "'''\n",
    "def get_L_S_Tensor(cands): \n",
    "    \n",
    "    L_S = []\n",
    "    for i,ci in enumerate(cands):\n",
    "        L_S_ci=[]\n",
    "        L=[]\n",
    "        S=[]\n",
    "        for LF in LFs:\n",
    "            #print LF.__name__\n",
    "            l,s = LF(ci)\n",
    "            L.append(l)\n",
    "            S.append((s+1)/2)  #to scale scores in [0,1] \n",
    "        L_S_ci.append(L)\n",
    "        L_S_ci.append(S)\n",
    "        L_S.append(L_S_ci) \n",
    "        if(i%500==0 and i!=0):\n",
    "            print(str(i)+'data points labelled in',(time.time() - start_time)/60,'mins')\n",
    "    return L_S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at: 16-6-2018, 12:11:51\n",
      "500data points labelled in 0.5303041696548462 mins\n",
      "1000data points labelled in 1.0592769702275595 mins\n",
      "1500data points labelled in 1.6191872398058573 mins\n",
      "2000data points labelled in 2.2701824069023133 mins\n",
      "2500data points labelled in 2.8335480292638144 mins\n",
      "--- 187.22964453697205 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "start_time = time.time()\n",
    "\n",
    "lt = time.localtime()\n",
    "\n",
    "print(\"started at: {}-{}-{}, {}:{}:{}\".format(lt.tm_mday,lt.tm_mon,lt.tm_year,lt.tm_hour,lt.tm_min,lt.tm_sec))\n",
    "\n",
    "# dev_L_S = get_L_S_Tensor(dev_cands)\n",
    "\n",
    "# np.save(\"dev_L_S_smooth\",np.array(dev_L_S))\n",
    "\n",
    "# train_L_S = get_L_S_Tensor(train_cands)\n",
    "# np.save(\"train_L_S_smooth\",np.array(train_L_S))\n",
    "\n",
    "\n",
    "test_L_S = get_L_S_Tensor(test_cands)\n",
    "np.save(\"test_L_S_smooth\",np.array(test_L_S))\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def draw2DArray(a):\n",
    "    fig = plt.figure(figsize=(6, 3.2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('colorMap')\n",
    "    plt.imshow(np.array(a))\n",
    "    ax.set_aspect('equal')\n",
    "    cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
    "    cax.get_xaxis().set_visible(False)\n",
    "    cax.get_yaxis().set_visible(False)\n",
    "    cax.patch.set_alpha(0)\n",
    "    cax.set_frame_on(False)\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.show()\n",
    "    \n",
    "      \n",
    "def report2dict(cr):\n",
    "    # Parse rows\n",
    "    tmp = list()\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0:\n",
    "            tmp.append(parsed_row)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    measures = tmp[0]\n",
    "\n",
    "    D_class_data = defaultdict(dict)\n",
    "    for row in tmp[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return pd.DataFrame(D_class_data).T\n",
    "\n",
    "def predictAndPrint(pl):\n",
    "    print(\"acc\",accuracy_score(gold_labels_dev,pl))\n",
    "    print(precision_recall_fscore_support(gold_labels_test,pl,average='binary'))\n",
    "    print(confusion_matrix(gold_labels_dev,pl))\n",
    "#     draw2DArray(confusion_matrix(gold_labels_dev,pl))\n",
    "#     return report2dict(classification_report(gold_labels_dev, pl))# target_names=class_names))\n",
    "    \n",
    "\n",
    "\n",
    "def drawPRcurve(y_test,y_score,it_no):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    splt = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score,pos_label=1)\n",
    "\n",
    "    splt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    splt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.title('{0:d} Precision-Recall curve: AP={1:0.2f}'.format(it_no,\n",
    "              average_precision))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2814 2702\n",
      "(2702, 2, 10) (2814, 2, 10) (22276, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "LF_l = [\n",
    "    1,1,1,1,1,-1,1,-1,-1,-1\n",
    "]\n",
    "import numpy as np\n",
    "dev_L_S = np.load(\"dev_L_S_smooth.npy\")\n",
    "test_L_S = np.load(\"test_L_S_smooth.npy\")\n",
    "train_L_S = np.load(\"train_L_S_smooth.npy\")\n",
    "\n",
    "# dev_L_S = np.load(\"dev_L_S_discrete.npy\")\n",
    "# train_L_S = np.load(\"train_L_S_discrete.npy\")\n",
    "# true_labels = gold_labels_test\n",
    "print(len(gold_labels_dev),len(gold_labels_test))\n",
    "print(test_L_S.shape,dev_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_L_S = np.load(\"dev_L_S_discrete.npy\")\n",
    "test_L_S = np.load(\"test_L_S_discrete.npy\")\n",
    "train_L_S = np.load(\"train_L_S_discrete.npy\")\n",
    "print(test_L_S.shape,dev_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call this only once for a kernel startup\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# BATCH_SIZE = 32\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(2814, 2, 20) (22276, 2, 20)\n"
     ]
    }
   ],
   "source": [
    "LF_l = [\n",
    "    1,1,1,1,1,-1,1,-1,-1,-1\n",
    "]\n",
    "\n",
    "def merge(a,b):\n",
    "    c = []\n",
    "    for i in range(len(a)):\n",
    "        ci = []\n",
    "        ci_l = a[i,0,:].tolist()+b[i,0,:].tolist()\n",
    "        ci_s = a[i,1,:].tolist()+b[i,1,:].tolist()\n",
    "        ci.append(ci_l)\n",
    "        ci.append(ci_s)\n",
    "        c.append(ci)\n",
    "    return c\n",
    "import numpy as np\n",
    "dev_L_S_s = np.load(\"dev_L_S_smooth.npy\")\n",
    "train_L_S_s = np.load(\"train_L_S_smooth.npy\")\n",
    "\n",
    "dev_L_S_d = np.load(\"dev_L_S_discrete.npy\")\n",
    "train_L_S_d = np.load(\"train_L_S_discrete.npy\")\n",
    "\n",
    "dev_L_S = np.array(merge(dev_L_S_d,dev_L_S_s))\n",
    "train_L_S = np.array(merge(train_L_S_d,train_L_S_s))\n",
    "\n",
    "LF_l = LF_l + LF_l\n",
    "print(len(LF_l))\n",
    "\n",
    "\n",
    "print(dev_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "NoOfLFs= len(LF_l)\n",
    "NoOfClasses = 2\n",
    "print(len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(lr,ep,th,af,batch_size=32,LF_acc=None,pcl=np.array([-1,1],dtype=np.float64),norm=True,\\\n",
    "          smooth=True,penalty=0,p3k=3,alp=1,Gamma=1.0,debug=True):\n",
    "    \n",
    "    ## lr : learning rate\n",
    "    ## ep : no of epochs\n",
    "    ## th : thetas initializer\n",
    "    ## af : alphas initializer\n",
    "    ## penalty : {1,2,3} use one of the three penalties, 0: no-penalty\n",
    "    ## p3k : parameter for penalty-3 \n",
    "    ## smooth : flag if smooth lfs are used \n",
    "    ## make sure smooth/discrete LF data is loaded into train_L_S and test_L_S\n",
    "    ## pcl : all possible class labels  = [-1,1] for binary, \n",
    "    ##       np.arange(0,NoOfClasses) for multiclass\n",
    "    ## alp : alpha parameter (to set a max value for alpha)\n",
    "    ## norm : use normalization or not\n",
    "    ## Gamma : penalty tuning parameter\n",
    "    \n",
    "    BATCH_SIZE = batch_size\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(dev_L_S).batch(len(dev_L_S))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "        test_init_op = iterator.make_initializer(test_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=af,\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "        \n",
    "        \n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "    \n",
    "        g = tf.convert_to_tensor(Gamma, dtype=tf.float64)\n",
    "        \n",
    "        LF_a = tf.convert_to_tensor(LF_acc, dtype=tf.float64)\n",
    "        \n",
    "        if(debug):\n",
    "            print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "        if(debug):\n",
    "            print(\"s\",s)\n",
    "            print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "        if(smooth):\n",
    "            s_ = tf.maximum(tf.subtract(s,tf.minimum(alphas,alp)), 0)\n",
    "        if(debug):\n",
    "            print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),-tf.ones_like(v))\n",
    "            if(debug):\n",
    "                print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        if(smooth):\n",
    "            pout = tf.map_fn(lambda c: l*c*s_ ,pcl,name=\"pout\")\n",
    "        else:\n",
    "            pout = tf.map_fn(lambda c: l*c ,pcl,name=\"pout\")\n",
    "\n",
    "        if(debug):\n",
    "            print(\"pout\",pout)    \n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,\\\n",
    "                           name=\"t_pout\")\n",
    "    \n",
    "        if(debug):\n",
    "            print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "        if(debug):\n",
    "            print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "            if(debug):\n",
    "                print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "            if(debug):\n",
    "                print(\"intsy\",out1)\n",
    "            return out1\n",
    "                \n",
    "\n",
    "        if(smooth):\n",
    "            #smooth normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                           pcl,name=\"zy\")\n",
    "        else:\n",
    "            #discrete normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                           pcl,name=\"zy\")\n",
    "            \n",
    "        ### for precision penalty\n",
    "        def softplus(j):\n",
    "            Lj = tf.map_fn(lambda li : tf.gather(li,j),l)\n",
    "            if(debug):\n",
    "                print(\"sft Lj\",Lj)\n",
    "            kj = tf.gather(k,j)\n",
    "            if(debug):\n",
    "                print(\"sft kj\",kj)\n",
    "            aj = tf.gather(LF_a,j)\n",
    "            if(debug):\n",
    "                print(\"sft aj\",aj)\n",
    "            indices = tf.where(tf.equal(Lj,kj))\n",
    "            if(debug):\n",
    "                print(\"sft indices\",indices)\n",
    "            li_lij_eq_kj = tf.gather(l,tf.squeeze(indices,1))\n",
    "            if(smooth):\n",
    "                si_lij_eq_kj = tf.gather(s_,tf.squeeze(indices,1))\n",
    "            if(debug):\n",
    "                print(\"sft l_ij_eq_kj\",li_lij_eq_kj)\n",
    "            if(smooth):\n",
    "                prec_z = tf.reduce_sum(tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                           pcl,name=\"prec_zy\"))\n",
    "            else:\n",
    "                prec_z = tf.reduce_sum(tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                           pcl,name=\"prec_zy\"))\n",
    "            if(debug):\n",
    "                print(\"prec_z\",prec_z)\n",
    "            if(smooth):\n",
    "                prec_t_pout = (tf.matmul(li_lij_eq_kj*si_lij_eq_kj*kj, thetas,transpose_b=True))/prec_z\n",
    "            else:\n",
    "                prec_t_pout = (tf.matmul(li_lij_eq_kj*kj, thetas,transpose_b=True))/prec_z\n",
    "            if(debug):\n",
    "                print(\"prec_t_pout\",prec_t_pout)\n",
    "            f =  tf.reduce_sum(aj - prec_t_pout)\n",
    "            if(debug):\n",
    "                print(\"f\",f)\n",
    "            sft = tf.nn.softplus(f,name=\"sft\")\n",
    "            if(debug):\n",
    "                print(\"sft\",sft)\n",
    "            return sft\n",
    "        \n",
    "#         logsft = tf.map_fn(lambda j: tf.log(softplus(j)),np.arange(NoOfLFs),\\\n",
    "#                                              dtype=tf.float64)\n",
    "#         sft  =  tf.map_fn(lambda j: softplus(j),np.arange(NoOfLFs),\\\n",
    "#                                              dtype=tf.float64)\n",
    "        \n",
    "# \n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        if(debug):\n",
    "            print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        if(debug):\n",
    "            print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "        if(debug):\n",
    "            print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "        \n",
    "        if(not norm):\n",
    "            print(\"unnormlized loss\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  ))\n",
    "        elif(penalty == 1):\n",
    "            print(\"penalty1\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                      +(g*tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas)))\n",
    "        elif(penalty == 2):\n",
    "            print(\"penalty2\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     -(g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "        elif(penalty == 3):\n",
    "            print(\"penalty3\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     +(g*tf.reduce_sum(tf.log(1+tf.exp(-thetas-pk))))\n",
    "        elif(penalty == 4):\n",
    "            print(\"precision penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "        elif(penalty == 5):\n",
    "            print(\"precision log(softplus) penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: tf.log(softplus(j)),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "  \n",
    "        else:\n",
    "            print(\"normalized loss\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "       \n",
    "        if(debug):\n",
    "            print(\"loss\",loss)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "        if(debug):\n",
    "            print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(loss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,loss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "                print(\"dev set\")\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(gold_labels_dev,pl))\n",
    "                print(precision_recall_fscore_support(np.array(gold_labels_dev),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "                print(\"test set\")\n",
    "                sess.run(test_init_op)\n",
    "                a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(gold_labels_test,pl))\n",
    "                print(precision_recall_fscore_support(np.array(gold_labels_test),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "                \n",
    "#             # Initialize an iterator over the validation dataset.\n",
    "#             sess.run(dev_init_op)\n",
    "#             a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "#             print(a)\n",
    "#             print(t)\n",
    "\n",
    "#             unique, counts = np.unique(pl, return_counts=True)\n",
    "#             print(dict(zip(unique, counts)))\n",
    "\n",
    "#             print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "# #             predictAndPrint(pl)\n",
    "#             print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.empty([len(LF_l)],dtype=np.float64)\n",
    "a.fill(0.5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 189, -1: 2625}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.10732054e-04, 2.48756219e-03, 3.30490405e-02, 2.87846482e-02,\n",
       "       6.75195451e-03, 5.99502488e-01, 3.55366027e-04, 1.12651031e-01,\n",
       "       7.46268657e-02, 7.46268657e-03])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "def get_LF_acc(L_S,true_labels):\n",
    "    #L_S : a numpy array of [NoOfDataPoints,2,NoOfLFs] \n",
    "    #true_labels : numpy array [NoOfDataPoints]\n",
    "    \n",
    "    tl = [-1 if x==0 else x for x in true_labels]\n",
    "    unique, counts = np.unique(tl, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "\n",
    "    # take only labels \n",
    "    L_S = L_S[:,0,:]\n",
    "    #L_S shape [NoOfDataPoints,NoOfLFs]\n",
    "    LF_acc = []\n",
    "    for i in range(L_S.shape[1]):\n",
    "#         print(accuracy_score(L_S[:,i],tl,normalize=False),accuracy_score(L_S[:,i],tl))\n",
    "        LF_acc.append(accuracy_score(L_S[:,i],tl))\n",
    "#         unique, counts = np.unique(L_S[:,i], return_counts=True)\n",
    "#         print(i,dict(zip(unique, counts)))\n",
    "#         print(precision_score(L_S[:,i],tl,labels=[LF_l[i]],average='macro'))\n",
    "#         LF_acc.append(precision_score(L_S[:,i],tl,labels=[LF_l[i]],average='macro'))\n",
    "    return np.array(LF_acc)\n",
    "                      \n",
    "get_LF_acc(dev_L_S,gold_labels_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 512 alpha-init: 0.0\n",
      "precision penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 170217.75416025025\n",
      "dev set\n",
      "[ 0.00137266 -0.00166069  0.00029264  0.00020329  0.00126115  0.00021667\n",
      "  0.0018891   0.00011512  0.00126639  0.00045027]\n",
      "[[1.11734745 0.81401745 1.00936248 1.0004271  1.10618046 1.04153514\n",
      "  1.16900881 1.03140499 1.14653194 1.06492007]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "1 loss 170166.99521960263\n",
      "dev set\n",
      "[ 1.56889740e-03 -1.46446395e-03  4.89001812e-04  3.99647685e-04\n",
      "  1.45749166e-03  2.04943991e-05  2.08545759e-03 -8.12470987e-05\n",
      "  1.07003415e-03  2.53911117e-04]\n",
      "[[1.11715121 0.8138212  1.00916604 1.00023069 1.10598405 1.04173127\n",
      "  1.16881242 1.03160143 1.14672836 1.0651164 ]]\n",
      "{0: 2733, 1: 81}\n",
      "acc 0.9246624022743426\n",
      "(0.35802469135802467, 0.15343915343915343, 0.2148148148148148, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "2 loss 170116.1942630439\n",
      "dev set\n",
      "[ 1.76512834e-03 -1.26826725e-03  6.85583494e-04  5.96228982e-04\n",
      "  1.65379509e-03 -1.75891875e-04  2.28196055e-03 -2.77897842e-04\n",
      "  8.73390062e-04  5.72624068e-05]\n",
      "[[1.11695494 0.81362496 1.0089694  1.00003407 1.10578768 1.04192766\n",
      "  1.16861591 1.03179816 1.14692506 1.06531307]]\n",
      "{0: 2734, 1: 80}\n",
      "acc 0.9250177683013504\n",
      "(0.3625, 0.15343915343915343, 0.21561338289962823, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "3 loss 170065.36368929662\n",
      "dev set\n",
      "[ 0.00196125 -0.00107221  0.00088226  0.00079291  0.00184998 -0.00037236\n",
      "  0.00247851 -0.0004747   0.00067659 -0.00013954]\n",
      "[[1.11675877 0.81342881 1.00877266 0.99983735 1.10559141 1.04212417\n",
      "  1.16841936 1.03199507 1.14712193 1.06550993]]\n",
      "{0: 2734, 1: 80}\n",
      "acc 0.9250177683013504\n",
      "(0.3625, 0.15343915343915343, 0.21561338289962823, None)\n",
      "\n",
      "test set\n",
      "{0: 2632, 1: 70}\n",
      "acc 0.9119170984455959\n",
      "(0.35714285714285715, 0.11467889908256881, 0.1736111111111111, None)\n",
      "\n",
      "4 loss 170014.52612109846\n",
      "dev set\n",
      "[ 0.00215722 -0.00087632  0.00107899  0.00098964  0.002046   -0.00056885\n",
      "  0.00267505 -0.00067161  0.0004797  -0.00033644]\n",
      "[[1.11656271 0.81323282 1.00857586 0.99964057 1.10539527 1.04232074\n",
      "  1.16822282 1.03219209 1.14731892 1.06570692]]\n",
      "{0: 2735, 1: 79}\n",
      "acc 0.9253731343283582\n",
      "(0.3670886075949367, 0.15343915343915343, 0.21641791044776118, None)\n",
      "\n",
      "test set\n",
      "{0: 2634, 1: 68}\n",
      "acc 0.9119170984455959\n",
      "(0.35294117647058826, 0.11009174311926606, 0.16783216783216784, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.1\n",
      "precision penalty\n",
      "0 loss 169008.73985670632\n",
      "dev set\n",
      "[0.10137264 0.09833928 0.10029261 0.10020325 0.10126115 0.10021673\n",
      " 0.10188905 0.10011516 0.10126644 0.10045032]\n",
      "[[1.11734748 0.8140175  1.00936249 1.0004271  1.10618046 1.0415351\n",
      "  1.16900881 1.03140499 1.14653196 1.06491999]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "1 loss 168966.15059282907\n",
      "dev set\n",
      "[0.10156886 0.09853548 0.10048897 0.10039961 0.10145749 0.10002058\n",
      " 0.10208539 0.0999188  0.10107008 0.10025396]\n",
      "[[1.11715126 0.81382128 1.00916604 1.00023068 1.10598406 1.04173123\n",
      "  1.16881244 1.03160145 1.14672838 1.06511631]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9235963041933192\n",
      "(0.34523809523809523, 0.15343915343915343, 0.21245421245421245, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "2 loss 168923.51358903683\n",
      "dev set\n",
      "[0.10176505 0.09873164 0.10068557 0.10059622 0.10165377 0.09982419\n",
      " 0.10228189 0.09972212 0.10087341 0.10005728]\n",
      "[[1.11695503 0.81362507 1.00896938 1.00003405 1.1057877  1.04192764\n",
      "  1.16861594 1.03179821 1.14692511 1.065313  ]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "3 loss 168880.84036261885\n",
      "dev set\n",
      "[0.10196113 0.09892765 0.1008823  0.10079294 0.10184991 0.0996277\n",
      " 0.10247845 0.09952527 0.10067656 0.09986043]\n",
      "[[1.1167589  0.81342899 1.00877261 0.99983731 1.10559147 1.04212419\n",
      "  1.16841941 1.03199517 1.14712203 1.06550991]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "4 loss 168838.1502246615\n",
      "dev set\n",
      "[0.10215704 0.09912346 0.10107909 0.10098973 0.10204589 0.09943116\n",
      " 0.10267503 0.09932828 0.10047959 0.09966345]\n",
      "[[1.11656291 0.81323306 1.00857577 0.9996405  1.10539538 1.04232083\n",
      "  1.16822288 1.03219227 1.1473191  1.06570698]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "test set\n",
      "{0: 2632, 1: 70}\n",
      "acc 0.9119170984455959\n",
      "(0.35714285714285715, 0.11467889908256881, 0.1736111111111111, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.2\n",
      "precision penalty\n",
      "0 loss 168219.7729574007\n",
      "dev set\n",
      "[0.20137262 0.19833923 0.20029257 0.20020321 0.20126114 0.20021679\n",
      " 0.20188899 0.20011522 0.2012665  0.20045038]\n",
      "[[1.11734751 0.81401757 1.00936248 1.00042709 1.10618047 1.04153507\n",
      "  1.1690088  1.031405   1.146532   1.06491988]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "1 loss 168184.734763607\n",
      "dev set\n",
      "[0.20156881 0.19853542 0.20048893 0.20039958 0.20145748 0.20002065\n",
      " 0.2020853  0.19991885 0.20107013 0.20025401]\n",
      "[[1.11715133 0.81382138 1.00916603 1.00023067 1.10598407 1.0417312\n",
      "  1.16881245 1.03160147 1.14672842 1.06511618]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "2 loss 168149.6425938574\n",
      "dev set\n",
      "[0.20176497 0.19873154 0.20068557 0.20059622 0.20165374 0.19982424\n",
      " 0.20228181 0.19972213 0.20087342 0.20005729]\n",
      "[[1.11695514 0.81362522 1.00896934 1.00003402 1.10578773 1.04192765\n",
      "  1.16861596 1.03179828 1.14692517 1.0653129 ]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "3 loss 168114.506925969\n",
      "dev set\n",
      "[0.201961   0.19892749 0.20088236 0.200793   0.20184986 0.1996277\n",
      " 0.2024784  0.1995252  0.20067649 0.19986036]\n",
      "[[1.11675906 0.81342919 1.00877254 0.99983725 1.10559153 1.04212427\n",
      "  1.16841945 1.0319953  1.14712215 1.06550988]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "4 loss 168079.34396089753\n",
      "dev set\n",
      "[0.20215686 0.19912324 0.20107924 0.20098988 0.20204579 0.19943108\n",
      " 0.20267503 0.19932811 0.20047941 0.19966327]\n",
      "[[1.11656312 0.81323333 1.00857565 0.9996404  1.10539547 1.04232101\n",
      "  1.16822294 1.03219251 1.14731932 1.06570706]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9243070362473348\n",
      "(0.35714285714285715, 0.15873015873015872, 0.21978021978021978, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.30000000000000004\n",
      "precision penalty\n",
      "0 loss 167808.3954374097\n",
      "dev set\n",
      "[0.30137259 0.29833918 0.30029252 0.30020316 0.30126113 0.30021685\n",
      " 0.30188891 0.30011528 0.30126656 0.30045044]\n",
      "[[1.11734756 0.81401767 1.00936247 1.00042707 1.10618051 1.04153503\n",
      "  1.16900877 1.03140503 1.14653206 1.06491972]]\n",
      "{0: 2722, 1: 92}\n",
      "acc 0.9235963041933192\n",
      "(0.358695652173913, 0.1746031746031746, 0.23487544483985762, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "1 loss 167780.31607997065\n",
      "dev set\n",
      "[0.30156875 0.29853533 0.30048889 0.30039954 0.30145747 0.3000207\n",
      " 0.3020852  0.2999189  0.30107019 0.30025406]\n",
      "[[1.11715141 0.81382153 1.009166   1.00023065 1.10598411 1.04173118\n",
      "  1.16881244 1.03160151 1.14672847 1.06511599]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9243070362473348\n",
      "(0.36666666666666664, 0.1746031746031746, 0.2365591397849462, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 167752.1774122239\n",
      "dev set\n",
      "[0.30176488 0.29873142 0.30068558 0.30059623 0.30165372 0.29982425\n",
      " 0.30228172 0.29972212 0.30087341 0.30005728]\n",
      "[[1.11695526 0.81362542 1.00896929 1.00003398 1.10578779 1.04192769\n",
      "  1.16861598 1.03179836 1.14692524 1.06531275]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "3 loss 167723.98865562686\n",
      "dev set\n",
      "[0.30196087 0.29892732 0.30088246 0.3007931  0.30184981 0.29962762\n",
      " 0.30247834 0.29952509 0.30067638 0.29986025]\n",
      "[[1.11675923 0.81342945 1.00877244 0.99983718 1.10559161 1.04212441\n",
      "  1.1684195  1.03199546 1.14712228 1.06550981]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "4 loss 167695.7630659566\n",
      "dev set\n",
      "[0.30215667 0.299123   0.30107945 0.3009901  0.30204571 0.29943089\n",
      " 0.30267505 0.29932785 0.30047916 0.29966302]\n",
      "[[1.11656336 0.81323367 1.0085755  0.99964028 1.1053956  1.0423213\n",
      "  1.16822303 1.03219279 1.14731954 1.06570712]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.4\n",
      "precision penalty\n",
      "0 loss 167699.1389585775\n",
      "dev set\n",
      "[0.40137255 0.39833908 0.40029245 0.4002031  0.40126109 0.4002169\n",
      " 0.40188882 0.40011536 0.40126664 0.40045052]\n",
      "[[1.11734763 0.81401784 1.00936244 1.00042702 1.1061806  1.041535\n",
      "  1.16900867 1.0314051  1.14653216 1.06491945]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "1 loss 167677.47906421585\n",
      "dev set\n",
      "[0.40156868 0.39853521 0.40048885 0.40039949 0.40145743 0.40002074\n",
      " 0.40208507 0.39991896 0.40107025 0.40025412]\n",
      "[[1.11715153 0.81382176 1.00916595 1.00023061 1.10598421 1.04173118\n",
      "  1.16881239 1.03160156 1.14672849 1.06511565]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2617, 1: 85}\n",
      "acc 0.9115470022205774\n",
      "(0.3764705882352941, 0.14678899082568808, 0.21122112211221122, None)\n",
      "\n",
      "2 loss 167655.75670974192\n",
      "dev set\n",
      "[0.40176477 0.39873125 0.40068561 0.40059625 0.40165368 0.39982421\n",
      " 0.4022816  0.3997221  0.40087339 0.40005726]\n",
      "[[1.11695543 0.81362572 1.00896922 1.00003395 1.10578791 1.04192778\n",
      "  1.16861601 1.03179842 1.14692522 1.06531241]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2618, 1: 84}\n",
      "acc 0.9119170984455959\n",
      "(0.38095238095238093, 0.14678899082568808, 0.2119205298013245, None)\n",
      "\n",
      "3 loss 167633.97958408005\n",
      "dev set\n",
      "[0.40196071 0.39892709 0.4008826  0.40079324 0.40184974 0.39962746\n",
      " 0.40247828 0.39952493 0.40067622 0.39986009]\n",
      "[[1.11675946 0.81342985 1.00877234 0.99983714 1.10559178 1.04212465\n",
      "  1.16841963 1.03199559 1.14712227 1.06550956]]\n",
      "{0: 2718, 1: 96}\n",
      "acc 0.9228855721393034\n",
      "(0.3541666666666667, 0.17989417989417988, 0.2385964912280702, None)\n",
      "\n",
      "test set\n",
      "{0: 2619, 1: 83}\n",
      "acc 0.9122871946706144\n",
      "(0.3855421686746988, 0.14678899082568808, 0.21262458471760798, None)\n",
      "\n",
      "4 loss 167612.1581188096\n",
      "dev set\n",
      "[0.40215646 0.3991227  0.40107976 0.4009904  0.40204561 0.39943055\n",
      " 0.40267508 0.3993275  0.4004788  0.39966267]\n",
      "[[1.11656367 0.81323417 1.00857534 0.99964022 1.10539582 1.04232173\n",
      "  1.16822327 1.03219304 1.1473196  1.06570703]]\n",
      "{0: 2720, 1: 94}\n",
      "acc 0.9235963041933192\n",
      "(0.3617021276595745, 0.17989417989417988, 0.24028268551236745, None)\n",
      "\n",
      "test set\n",
      "{0: 2619, 1: 83}\n",
      "acc 0.9122871946706144\n",
      "(0.3855421686746988, 0.14678899082568808, 0.21262458471760798, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.5\n",
      "precision penalty\n",
      "0 loss 167788.29849754192\n",
      "dev set\n",
      "[0.50137248 0.49833893 0.50029227 0.50020279 0.50126099 0.50021695\n",
      " 0.5018893  0.50011562 0.50126705 0.50045079]\n",
      "[[1.11734774 0.81401814 1.00936235 1.00042692 1.10618082 1.04153496\n",
      "  1.16900841 1.0314052  1.14653226 1.06491886]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "1 loss 167773.35207766123\n",
      "dev set\n",
      "[0.50156857 0.498535   0.50048862 0.50039908 0.50145733 0.50002078\n",
      " 0.50208559 0.49991662 0.5010708  0.50025447]\n",
      "[[1.11715171 0.81382219 1.00916588 1.00023062 1.10598449 1.04173117\n",
      "  1.16881224 1.03160151 1.14672818 1.06511476]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "2 loss 167758.19867163672\n",
      "dev set\n",
      "[0.50176461 0.49873097 0.5006854  0.50059583 0.50165354 0.49982417\n",
      " 0.50228206 0.49971039 0.50087398 0.5000576 ]\n",
      "[[1.11695569 0.81362629 1.00896919 1.0000341  1.10578828 1.04192786\n",
      "  1.16861606 1.03179823 1.14692451 1.06531136]]\n",
      "{0: 2704, 1: 110}\n",
      "acc 0.9193319118692252\n",
      "(0.32727272727272727, 0.19047619047619047, 0.24080267558528426, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "3 loss 167742.91363691984\n",
      "dev set\n",
      "[0.5019605  0.49892673 0.50088245 0.50079286 0.50184957 0.49962729\n",
      " 0.50247862 0.4995064  0.50067676 0.49985326]\n",
      "[[1.1167598  0.81343057 1.00877234 0.99983743 1.10559225 1.04212489\n",
      "  1.16841995 1.03199533 1.14712121 1.06550845]]\n",
      "{0: 2705, 1: 109}\n",
      "acc 0.9196872778962332\n",
      "(0.3302752293577982, 0.19047619047619047, 0.24161073825503354, None)\n",
      "\n",
      "test set\n",
      "{0: 2605, 1: 97}\n",
      "acc 0.9085862324204294\n",
      "(0.35051546391752575, 0.1559633027522936, 0.21587301587301586, None)\n",
      "\n",
      "4 loss 167727.4312354944\n",
      "dev set\n",
      "[0.50215618 0.49912224 0.50107971 0.50099014 0.50204539 0.49943017\n",
      " 0.50267522 0.49930377 0.5004792  0.49964463]\n",
      "[[1.11656411 0.81323507 1.00857536 0.99964063 1.10539641 1.0423222\n",
      "  1.16822394 1.03219277 1.14731828 1.06570598]]\n",
      "{0: 2706, 1: 108}\n",
      "acc 0.920042643923241\n",
      "(0.3333333333333333, 0.19047619047619047, 0.24242424242424246, None)\n",
      "\n",
      "test set\n",
      "{0: 2605, 1: 97}\n",
      "acc 0.9085862324204294\n",
      "(0.35051546391752575, 0.1559633027522936, 0.21587301587301586, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6000000000000001\n",
      "precision penalty\n",
      "0 loss 168080.89278663715\n",
      "dev set\n",
      "[0.60137236 0.5983386  0.6002922  0.60020261 0.60126078 0.60021681\n",
      " 0.60189077 0.60011583 0.6012671  0.60045123]\n",
      "[[1.11734794 0.81401883 1.00936203 1.00042663 1.10618135 1.04153511\n",
      "  1.16900829 1.03140535 1.14653174 1.06491681]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "1 loss 168072.17822356996\n",
      "dev set\n",
      "[0.60156836 0.59853452 0.60048851 0.60039869 0.60145707 0.60002058\n",
      " 0.60208663 0.59991958 0.60107099 0.60025511]\n",
      "[[1.11715205 0.81382327 1.0091658  1.00023086 1.10598525 1.04173139\n",
      "  1.16881221 1.03160074 1.14672509 1.065111  ]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2563, 1: 139}\n",
      "acc 0.8952627683197631\n",
      "(0.26618705035971224, 0.16972477064220184, 0.20728291316526612, None)\n",
      "\n",
      "2 loss 168063.42066776686\n",
      "dev set\n",
      "[0.60176433 0.59873034 0.60068533 0.60059527 0.6016532  0.59982386\n",
      " 0.60228241 0.59972262 0.60087413 0.60005825]\n",
      "[[1.11695616 0.81362776 1.0089694  1.00003495 1.10578933 1.04192823\n",
      "  1.1686162  1.03179652 1.14691876 1.06530623]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2565, 1: 137}\n",
      "acc 0.8960029607698001\n",
      "(0.27007299270072993, 0.16972477064220184, 0.20845070422535214, None)\n",
      "\n",
      "3 loss 168054.62271920976\n",
      "dev set\n",
      "[0.60196013 0.59892593 0.60088246 0.60079215 0.60184912 0.59962681\n",
      " 0.60247817 0.59952513 0.60067671 0.59986085]\n",
      "[[1.11676042 0.81343244 1.00877285 0.99983893 1.10559361 1.04212547\n",
      "  1.16842036 1.03199274 1.14711289 1.06550222]]\n",
      "{0: 2678, 1: 136}\n",
      "acc 0.9093816631130064\n",
      "(0.25735294117647056, 0.18518518518518517, 0.21538461538461537, None)\n",
      "\n",
      "test set\n",
      "{0: 2566, 1: 136}\n",
      "acc 0.8963730569948186\n",
      "(0.27205882352941174, 0.16972477064220184, 0.20903954802259883, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 168045.79094114547\n",
      "dev set\n",
      "[0.60215571 0.59912124 0.60107983 0.60098922 0.60204481 0.59942947\n",
      " 0.60267385 0.5993272  0.60047888 0.599663  ]\n",
      "[[1.11656489 0.81323737 1.00857616 0.99964281 1.1053981  1.04232307\n",
      "  1.1682247  1.0321894  1.14730748 1.06569887]]\n",
      "{0: 2680, 1: 134}\n",
      "acc 0.910092395167022\n",
      "(0.26119402985074625, 0.18518518518518517, 0.21671826625386997, None)\n",
      "\n",
      "test set\n",
      "{0: 2572, 1: 130}\n",
      "acc 0.8985936343449297\n",
      "(0.2846153846153846, 0.16972477064220184, 0.21264367816091956, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7000000000000001\n",
      "precision penalty\n",
      "0 loss 168266.52989743015\n",
      "dev set\n",
      "[0.7013721  0.69833762 0.70029272 0.70020336 0.70126016 0.70021629\n",
      " 0.70188902 0.70011522 0.70126896 0.7004537 ]\n",
      "[[1.11734838 0.81402122 1.00936226 1.00042787 1.1061834  1.04153564\n",
      "  1.16900887 1.03140258 1.14651948 1.06484031]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "1 loss 168263.66524053298\n",
      "dev set\n",
      "[0.70156793 0.69853298 0.70048755 0.70039743 0.70145609 0.70002009\n",
      " 0.70208453 0.69992152 0.70107888 0.70026122]\n",
      "[[1.11715282 0.81382731 1.00916779 1.0002348  1.1059887  1.04173191\n",
      "  1.16881295 1.03159165 1.1466966  1.06494754]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2377, 1: 325}\n",
      "acc 0.8945225758697262\n",
      "(0.39692307692307693, 0.591743119266055, 0.47513812154696133, None)\n",
      "\n",
      "2 loss 168260.79005360784\n",
      "dev set\n",
      "[0.70176373 0.69872821 0.70068194 0.70059113 0.70165175 0.6998235\n",
      " 0.70228006 0.69972738 0.70088802 0.70006687]\n",
      "[[1.11695724 0.81363347 1.00897321 1.00004162 1.10579432 1.04192866\n",
      "  1.16861711 1.03178094 1.14687384 1.06505742]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2382, 1: 320}\n",
      "acc 0.8963730569948186\n",
      "(0.403125, 0.591743119266055, 0.4795539033457249, None)\n",
      "\n",
      "3 loss 168257.90452972383\n",
      "dev set\n",
      "[0.70195935 0.69892318 0.70087681 0.70078491 0.70184713 0.69962663\n",
      " 0.70247548 0.69953233 0.70069678 0.69987234]\n",
      "[[1.11676183 0.81343986 1.00877842 0.99984825 1.10560024 1.04212581\n",
      "  1.16842146 1.03197072 1.14705157 1.06516975]]\n",
      "{0: 2556, 1: 258}\n",
      "acc 0.9086709310589908\n",
      "(0.3682170542635659, 0.5026455026455027, 0.4250559284116331, None)\n",
      "\n",
      "test set\n",
      "{0: 2385, 1: 317}\n",
      "acc 0.8974833456698742\n",
      "(0.4069400630914827, 0.591743119266055, 0.4822429906542056, None)\n",
      "\n",
      "4 loss 168255.00709427692\n",
      "dev set\n",
      "[0.70215474 0.69911784 0.70107186 0.70097883 0.70204223 0.6994295\n",
      " 0.70267073 0.69933675 0.70050537 0.69967727]\n",
      "[[1.11656665 0.81324655 1.00858343 0.99965469 1.10540643 1.04232331\n",
      "  1.16822605 1.03216105 1.14722988 1.06528444]]\n",
      "{0: 2557, 1: 257}\n",
      "acc 0.9090262970859986\n",
      "(0.36964980544747084, 0.5026455026455027, 0.4260089686098655, None)\n",
      "\n",
      "test set\n",
      "{0: 2385, 1: 317}\n",
      "acc 0.8974833456698742\n",
      "(0.4069400630914827, 0.591743119266055, 0.4822429906542056, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "precision penalty\n",
      "0 loss 168229.80077076046\n",
      "dev set\n",
      "[0.80137128 0.79833292 0.8002889  0.80019645 0.80125549 0.80021561\n",
      " 0.80188943 0.80015659 0.80136038 0.80083836]\n",
      "[[1.11734988 0.81403506 1.00943698 1.00050127 1.10620185 1.04153631\n",
      "  1.16900898 1.03138985 1.14650122 1.06455854]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "1 loss 168229.0422712362\n",
      "dev set\n",
      "[0.80156656 0.79852478 0.80047389 0.80037904 0.80144797 0.80001949\n",
      " 0.80208527 0.80002004 0.80126716 0.80102328]\n",
      "[[1.11715548 0.81385308 1.00933784 1.0004009  1.10602158 1.04173245\n",
      "  1.16881324 1.03156008 1.14665837 1.06439353]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "2 loss 168228.28653826597\n",
      "dev set\n",
      "[0.80176191 0.79871661 0.80065862 0.80056145 0.80164001 0.7998231\n",
      " 0.80228094 0.79988339 0.80117294 0.8012067 ]\n",
      "[[1.11696094 0.81367102 1.00923865 1.0003002  1.10584169 1.0419291\n",
      "  1.16861763 1.03173007 1.14681546 1.06423018]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "3 loss 168227.52912191206\n",
      "dev set\n",
      "[0.80195712 0.79890819 0.80084347 0.800744   0.80183167 0.79962643\n",
      " 0.80247638 0.79974592 0.80107747 0.80138933]\n",
      "[[1.11676656 0.8134892  1.00913873 1.00019874 1.10566218 1.04212629\n",
      "  1.16842227 1.03190038 1.14697294 1.06406782]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "4 loss 168226.76971251288\n",
      "dev set\n",
      "[0.8021521  0.79909947 0.80102857 0.80092677 0.80202298 0.79942948\n",
      " 0.80267157 0.79960744 0.80098069 0.80157141]\n",
      "[[1.11657243 0.81330769 1.00903786 1.0000964  1.10548304 1.04232401\n",
      "  1.1682272  1.03207116 1.1471309  1.06390623]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "precision penalty\n",
      "0 loss 168212.76493292765\n",
      "dev set\n",
      "[0.90136673 0.89826664 0.89993531 0.89983816 0.90113263 0.90061063\n",
      " 0.90188867 0.90014681 0.90131549 0.90077591]\n",
      "[[1.11735949 0.8141998  1.00975306 1.00081992 1.10643097 1.04114134\n",
      "  1.16900998 1.03140029 1.14652305 1.06464043]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "1 loss 168212.63866632752\n",
      "dev set\n",
      "[0.90155795 0.89839155 0.89978594 0.89968145 0.90121057 0.90080669\n",
      " 0.90208379 0.9        0.90118074 0.90091582]\n",
      "[[1.11717466 0.81419538 1.00994299 1.0010098  1.10649258 1.04094548\n",
      "  1.16881598 1.0315847  1.14670355 1.06454284]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "2 loss 168212.51451524431\n",
      "dev set\n",
      "[0.90174949 0.8985165  0.89963823 0.899527   0.90128883 0.90100254\n",
      " 0.90227881 0.89985433 0.90104664 0.90105512]\n",
      "[[1.11698948 0.81419163 1.01013207 1.00119833 1.10655577 1.04075\n",
      "  1.16862221 1.03176865 1.14688356 1.06444574]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "3 loss 168212.3909055865\n",
      "dev set\n",
      "[0.90194091 0.89864115 0.89949119 0.89937346 0.90136699 0.90119808\n",
      " 0.90247356 0.89970901 0.90091271 0.90119395]\n",
      "[[1.11680452 0.81418844 1.01032086 1.00138636 1.10661975 1.040555\n",
      "  1.16842886 1.03195251 1.14706346 1.06434912]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "4 loss 168212.26763912497\n",
      "dev set\n",
      "[0.90213208 0.89876541 0.89934449 0.89922041 0.90144492 0.9013933\n",
      " 0.902668   0.89956383 0.90077882 0.90133236]\n",
      "[[1.11661995 0.81418574 1.01050952 1.00157417 1.10668423 1.0403605\n",
      "  1.168236   1.03213639 1.14724337 1.06425294]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "precision penalty\n",
      "0 loss 168252.31303285924\n",
      "dev set\n",
      "[1.00137947 0.9979753  1.00032022 1.00003599 1.00126843 1.00062655\n",
      " 1.00189418 1.00052849 1.00166616 1.00085578]\n",
      "[[1.11768804 0.81438464 1.00956152 1.00062431 1.10650897 1.04136608\n",
      "  1.1693828  1.03122316 1.14650066 1.06478942]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "1 loss 168252.3129793366\n",
      "dev set\n",
      "[1.00160806 0.99779847 1.00064107 1.00035681 1.00149996 1.00089523\n",
      " 1.00211373 1.00080981 1.00188902 1.00110501]\n",
      "[[1.11789563 0.8145699  1.0095938  1.00062663 1.10671107 1.04146895\n",
      "  1.16959972 1.03130097 1.14671564 1.06494417]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "2 loss 168252.31291064713\n",
      "dev set\n",
      "[1.00186456 0.99761507 1.00101191 1.0007827  1.00176163 1.00121337\n",
      " 1.00235391 1.00114316 1.00213527 1.00139575]\n",
      "[[1.11815338 0.81476864 1.00974216 1.00068924 1.10696905 1.04168395\n",
      "  1.16985043 1.03149743 1.14697013 1.06518809]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "3 loss 168252.31282018663\n",
      "dev set\n",
      "[1.00214642 0.99742564 1.00140502 1.00122058 1.00205021 1.00156449\n",
      " 1.00261366 1.00150768 1.0024034  1.00171911]\n",
      "[[1.1184534  0.81497978 1.01003541 1.00092664 1.10727332 1.0419975\n",
      "  1.17013157 1.03180686 1.14725931 1.06550387]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "4 loss 168252.31270075188\n",
      "dev set\n",
      "[1.00245012 0.99723079 1.00180801 1.00165687 1.0023614  1.0019359\n",
      " 1.00289139 1.00188974 1.00269122 1.00206601]\n",
      "[[1.11878773 0.81520207 1.01041809 1.00130273 1.10761417 1.04237379\n",
      "  1.17043955 1.03218641 1.14757822 1.06586928]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.0\n",
      "precision penalty\n",
      "0 loss 170168.2294004203\n",
      "dev set\n",
      "[ 0.0012741  -0.00175922  0.0001942   0.00010484  0.00116248  0.00031488\n",
      "  0.00179065  0.0002135   0.00136477  0.00054866]\n",
      "[[1.11744599 0.81411592 1.00946101 1.00052565 1.10627915 1.04143702\n",
      "  1.16910737 1.03130648 1.14643338 1.06482181]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "1 loss 170142.7857301925\n",
      "dev set\n",
      "[ 0.00137244 -0.00166087  0.00029253  0.00020318  0.00126086  0.0002166\n",
      "  0.00188898  0.00011517  0.00126645  0.00045033]\n",
      "[[1.11734765 0.81401757 1.00936264 1.00042729 1.10618075 1.04153528\n",
      "  1.16900901 1.03140485 1.14653174 1.06492013]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "2 loss 170117.34131480963\n",
      "dev set\n",
      "[ 1.47079980e-03 -1.56251173e-03  3.90954679e-04  3.01600931e-04\n",
      "  1.35926040e-03  1.18237874e-04  1.98737908e-03  1.67446871e-05\n",
      "  1.16801851e-03  3.51900701e-04]\n",
      "[[1.11724929 0.8139192  1.00926419 1.00032885 1.10608233 1.04163364\n",
      "  1.16891061 1.03150331 1.14663019 1.06501855]]\n",
      "{0: 2733, 1: 81}\n",
      "acc 0.9246624022743426\n",
      "(0.35802469135802467, 0.15343915343915343, 0.2148148148148148, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "3 loss 170091.88172201402\n",
      "dev set\n",
      "[ 1.56915906e-03 -1.46416018e-03  4.89426891e-04  4.00073022e-04\n",
      "  1.45764640e-03  1.98298470e-05  2.08580564e-03 -8.17514587e-05\n",
      "  1.06952437e-03  2.53405171e-04]\n",
      "[[1.11715091 0.81382083 1.00916569 1.00023035 1.10598392 1.04173205\n",
      "  1.16881218 1.03160184 1.14672872 1.06511705]]\n",
      "{0: 2733, 1: 81}\n",
      "acc 0.9246624022743426\n",
      "(0.35802469135802467, 0.15343915343915343, 0.2148148148148148, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "4 loss 170066.41436290758\n",
      "dev set\n",
      "[ 1.66749590e-03 -1.36583762e-03  5.87929860e-04  4.98575843e-04\n",
      "  1.55600666e-03 -7.86032391e-05  2.18424726e-03 -1.80292572e-04\n",
      "  9.70985649e-04  1.54864793e-04]\n",
      "[[1.11705256 0.81372248 1.00906717 1.00013183 1.10588553 1.0418305\n",
      "  1.16871373 1.03170042 1.14682729 1.06521561]]\n",
      "{0: 2733, 1: 81}\n",
      "acc 0.9246624022743426\n",
      "(0.35802469135802467, 0.15343915343915343, 0.2148148148148148, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.1\n",
      "precision penalty\n",
      "0 loss 168957.1822292648\n",
      "dev set\n",
      "[0.1012741  0.09824078 0.10019419 0.10010483 0.10116248 0.1003149\n",
      " 0.10179063 0.10021352 0.10136479 0.10054867]\n",
      "[[1.11744599 0.81411593 1.00946101 1.00052565 1.10627915 1.04143701\n",
      "  1.16910737 1.03130649 1.14643339 1.06482179]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "1 loss 168935.8351773551\n",
      "dev set\n",
      "[0.10137243 0.09833911 0.10029252 0.10020317 0.10126087 0.10021663\n",
      " 0.10188896 0.10011519 0.10126647 0.10045035]\n",
      "[[1.11734767 0.81401759 1.00936264 1.00042729 1.10618074 1.04153527\n",
      "  1.16900902 1.03140486 1.14653175 1.06492009]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "2 loss 168914.48449100804\n",
      "dev set\n",
      "[0.10147078 0.09843747 0.10039094 0.10030159 0.10135926 0.10011827\n",
      " 0.10198735 0.10001676 0.10116804 0.10035192]\n",
      "[[1.11724931 0.81391923 1.00926419 1.00032884 1.10608233 1.04163362\n",
      "  1.16891062 1.03150332 1.14663021 1.06501852]]\n",
      "{0: 2729, 1: 85}\n",
      "acc 0.923951670220327\n",
      "(0.35294117647058826, 0.15873015873015872, 0.21897810218978106, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "3 loss 168893.1181526793\n",
      "dev set\n",
      "[0.10156913 0.09853581 0.10048942 0.10040007 0.10145764 0.10001986\n",
      " 0.10208577 0.09991826 0.10106953 0.10025342]\n",
      "[[1.11715095 0.81382087 1.00916568 1.00023034 1.10598392 1.04173204\n",
      "  1.1688122  1.03160187 1.14672875 1.06511703]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9235963041933192\n",
      "(0.34523809523809523, 0.15343915343915343, 0.21245421245421245, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "4 loss 168871.74245794865\n",
      "dev set\n",
      "[0.10166745 0.09863412 0.10058794 0.10049858 0.10155599 0.09992142\n",
      " 0.10218421 0.0998197  0.10097098 0.10015486]\n",
      "[[1.11705261 0.81372253 1.00906714 1.00013181 1.10588554 1.0418305\n",
      "  1.16871376 1.03170046 1.14682733 1.0652156 ]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9235963041933192\n",
      "(0.34523809523809523, 0.15343915343915343, 0.21245421245421245, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.2\n",
      "precision penalty\n",
      "0 loss 168166.3419300304\n",
      "dev set\n",
      "[0.20127409 0.19824077 0.20019417 0.20010482 0.20116248 0.20031491\n",
      " 0.20179061 0.20021354 0.20136481 0.20054869]\n",
      "[[1.117446   0.81411595 1.00946101 1.00052565 1.10627916 1.041437\n",
      "  1.16910736 1.03130649 1.1464334  1.06482175]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "1 loss 168148.7816987941\n",
      "dev set\n",
      "[0.20137242 0.1983391  0.2002925  0.20020315 0.20126087 0.20021665\n",
      " 0.20188893 0.20011522 0.20126649 0.20045037]\n",
      "[[1.11734768 0.81401762 1.00936263 1.00042728 1.10618074 1.04153525\n",
      "  1.16900902 1.03140487 1.14653177 1.06492004]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 168131.2149498341\n",
      "dev set\n",
      "[0.20147076 0.19843745 0.20039093 0.20030157 0.20135926 0.20011829\n",
      " 0.20198731 0.20001678 0.20116806 0.20035194]\n",
      "[[1.11724934 0.81391926 1.00926417 1.00032883 1.10608232 1.04163362\n",
      "  1.16891063 1.03150335 1.14663024 1.06501847]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "3 loss 168113.63183869992\n",
      "dev set\n",
      "[0.2015691  0.19853578 0.20048942 0.20040006 0.20145764 0.20001987\n",
      " 0.20208573 0.19991826 0.20106954 0.20025342]\n",
      "[[1.11715099 0.81382091 1.00916566 1.00023033 1.10598392 1.04173205\n",
      "  1.16881221 1.03160191 1.14672879 1.06511699]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "4 loss 168096.03760508666\n",
      "dev set\n",
      "[0.20166741 0.19863407 0.20058795 0.2004986  0.20155598 0.19992142\n",
      " 0.20218418 0.19981969 0.20097097 0.20015484]\n",
      "[[1.11705266 0.81372259 1.00906711 1.00013179 1.10588554 1.04183053\n",
      "  1.16871378 1.03170053 1.1468274  1.06521558]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.30000000000000004\n",
      "precision penalty\n",
      "0 loss 167753.24469196697\n",
      "dev set\n",
      "[0.30127408 0.29824075 0.30019416 0.3001048  0.30116248 0.30031493\n",
      " 0.30179059 0.30021356 0.30136483 0.30054871]\n",
      "[[1.11744601 0.81411598 1.00946101 1.00052564 1.10627917 1.04143699\n",
      "  1.16910735 1.03130651 1.14643343 1.06482171]]\n",
      "{0: 2719, 1: 95}\n",
      "acc 0.9225302061122956\n",
      "(0.3473684210526316, 0.1746031746031746, 0.2323943661971831, None)\n",
      "\n",
      "test set\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9104367135455218\n",
      "(0.34615384615384615, 0.12385321100917432, 0.18243243243243243, None)\n",
      "\n",
      "1 loss 167739.17439320934\n",
      "dev set\n",
      "[0.3013724  0.29833908 0.30029248 0.30020313 0.30126087 0.30021667\n",
      " 0.30188888 0.30011524 0.30126652 0.3004504 ]\n",
      "[[1.11734771 0.81401766 1.00936262 1.00042727 1.10618074 1.04153524\n",
      "  1.16900902 1.03140489 1.1465318  1.06491998]]\n",
      "{0: 2722, 1: 92}\n",
      "acc 0.9235963041933192\n",
      "(0.358695652173913, 0.1746031746031746, 0.23487544483985762, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "2 loss 167725.09503883403\n",
      "dev set\n",
      "[0.30147074 0.29843742 0.30039091 0.30030156 0.30135927 0.30011831\n",
      " 0.30198726 0.3000168  0.30116808 0.30035196]\n",
      "[[1.11724937 0.81391931 1.00926415 1.00032881 1.10608232 1.04163361\n",
      "  1.16891064 1.03150339 1.14663028 1.0650184 ]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9243070362473348\n",
      "(0.36666666666666664, 0.1746031746031746, 0.2365591397849462, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "3 loss 167710.99872463016\n",
      "dev set\n",
      "[0.30156907 0.29853574 0.30048942 0.30040006 0.30145764 0.30001987\n",
      " 0.30208568 0.29991827 0.30106954 0.30025342]\n",
      "[[1.11715103 0.81382097 1.00916562 1.0002303  1.10598392 1.04173207\n",
      "  1.16881223 1.03160197 1.14672884 1.06511694]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9243070362473348\n",
      "(0.36666666666666664, 0.1746031746031746, 0.2365591397849462, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "4 loss 167696.88968731585\n",
      "dev set\n",
      "[0.30166736 0.29863402 0.30058798 0.30049862 0.30155598 0.29992139\n",
      " 0.30218414 0.29981966 0.30097094 0.30015482]\n",
      "[[1.11705272 0.81372267 1.00906706 1.00013175 1.10588554 1.04183058\n",
      "  1.16871381 1.03170062 1.14682748 1.06521555]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9243070362473348\n",
      "(0.36666666666666664, 0.1746031746031746, 0.2365591397849462, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.4\n",
      "precision penalty\n",
      "0 loss 167642.40905862302\n",
      "dev set\n",
      "[0.40127407 0.39824072 0.40019413 0.40010478 0.40116246 0.40031494\n",
      " 0.40179056 0.40021358 0.40136486 0.40054874]\n",
      "[[1.11744603 0.81411602 1.00946099 1.00052562 1.10627919 1.04143698\n",
      "  1.16910731 1.03130654 1.14643348 1.06482163]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "1 loss 167631.55798046166\n",
      "dev set\n",
      "[0.40137238 0.39833905 0.40029245 0.4002031  0.40126087 0.40021669\n",
      " 0.40188883 0.40011528 0.40126655 0.40045043]\n",
      "[[1.11734774 0.81401772 1.00936259 1.00042724 1.10618076 1.04153524\n",
      "  1.16900899 1.03140494 1.14653185 1.06491986]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "2 loss 167620.69595785564\n",
      "dev set\n",
      "[0.40147071 0.39843738 0.4003909  0.40030154 0.40135927 0.40011831\n",
      " 0.4019872  0.40001683 0.4011681  0.40035198]\n",
      "[[1.11724942 0.81391939 1.00926411 1.00032878 1.10608233 1.04163362\n",
      "  1.16891064 1.03150345 1.14663033 1.06501828]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2616, 1: 86}\n",
      "acc 0.9111769059955589\n",
      "(0.37209302325581395, 0.14678899082568808, 0.2105263157894737, None)\n",
      "\n",
      "3 loss 167609.8168081001\n",
      "dev set\n",
      "[0.40156903 0.39853569 0.40048942 0.40040007 0.40145765 0.40001985\n",
      " 0.40208562 0.39991826 0.40106954 0.40025342]\n",
      "[[1.1171511  0.81382107 1.00916557 1.00023026 1.10598393 1.04173211\n",
      "  1.16881226 1.03160206 1.14672891 1.06511682]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2617, 1: 85}\n",
      "acc 0.9115470022205774\n",
      "(0.3764705882352941, 0.14678899082568808, 0.21122112211221122, None)\n",
      "\n",
      "4 loss 167598.92380854013\n",
      "dev set\n",
      "[0.40166731 0.39863395 0.40058801 0.40049866 0.40155598 0.39992133\n",
      " 0.40218409 0.39981962 0.4009709  0.40015477]\n",
      "[[1.1170528  0.81372279 1.00906698 1.0001317  1.10588556 1.04183067\n",
      "  1.16871387 1.03170075 1.14682757 1.06521547]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2617, 1: 85}\n",
      "acc 0.9115470022205774\n",
      "(0.3764705882352941, 0.14678899082568808, 0.21122112211221122, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.5\n",
      "precision penalty\n",
      "0 loss 167729.9195722991\n",
      "dev set\n",
      "[0.50127406 0.49824068 0.50019408 0.50010469 0.50116244 0.50031496\n",
      " 0.50179067 0.50021366 0.50136498 0.50054882]\n",
      "[[1.11744606 0.81411611 1.00946095 1.00052557 1.10627925 1.04143697\n",
      "  1.16910722 1.03130662 1.14643358 1.06482146]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2603, 1: 99}\n",
      "acc 0.9078460399703923\n",
      "(0.3434343434343434, 0.1559633027522936, 0.21451104100946375, None)\n",
      "\n",
      "1 loss 167722.43826539785\n",
      "dev set\n",
      "[0.50137235 0.49833899 0.50029238 0.50020296 0.50126085 0.5002167\n",
      " 0.50188897 0.50011539 0.50126673 0.50045055]\n",
      "[[1.11734779 0.81401783 1.00936253 1.0004272  1.10618082 1.04153523\n",
      "  1.16900892 1.03140502 1.1465319  1.0649196 ]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "2 loss 167714.94680718114\n",
      "dev set\n",
      "[0.50147067 0.49843731 0.50039081 0.50030138 0.50135926 0.50011832\n",
      " 0.5019873  0.50001695 0.50116831 0.50035211]\n",
      "[[1.11724948 0.81391953 1.00926403 1.00032876 1.1060824  1.04163363\n",
      "  1.16891061 1.03150353 1.14663031 1.06501795]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "3 loss 167707.41280987547\n",
      "dev set\n",
      "[0.50156897 0.4985356  0.50048935 0.5003999  0.50145763 0.50001983\n",
      " 0.50208567 0.49991536 0.50106976 0.50025355]\n",
      "[[1.11715119 0.81382125 1.00916548 1.00023026 1.10598401 1.04173214\n",
      "  1.16881229 1.03160214 1.14672883 1.06511647]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 167699.79320817365\n",
      "dev set\n",
      "[0.50166724 0.49863385 0.50058796 0.5004985  0.50155596 0.49992127\n",
      " 0.50218407 0.49981175 0.5009711  0.50015488]\n",
      "[[1.11705292 0.81372301 1.00906689 1.00013172 1.10588566 1.04183075\n",
      "  1.16871399 1.03170085 1.14682744 1.06521511]]\n",
      "{0: 2703, 1: 111}\n",
      "acc 0.9189765458422174\n",
      "(0.32432432432432434, 0.19047619047619047, 0.24, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6000000000000001\n",
      "precision penalty\n",
      "0 loss 168020.99829953653\n",
      "dev set\n",
      "[0.60127403 0.59824059 0.60019407 0.60010466 0.60116238 0.60031491\n",
      " 0.60179122 0.60021371 0.60136497 0.60054893]\n",
      "[[1.11744611 0.81411629 1.0094608  1.00052541 1.10627939 1.04143702\n",
      "  1.16910718 1.03130682 1.14643372 1.06482091]]\n",
      "{0: 2674, 1: 140}\n",
      "acc 0.9079601990049752\n",
      "(0.25, 0.18518518518518517, 0.2127659574468085, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "1 loss 168016.63201251198\n",
      "dev set\n",
      "[0.60137229 0.59833887 0.60029237 0.60020288 0.60126081 0.60021663\n",
      " 0.60188949 0.60011547 0.60126678 0.60045073]\n",
      "[[1.11734788 0.81401811 1.00936238 1.00042711 1.10618097 1.0415353\n",
      "  1.16900889 1.03140511 1.14653158 1.06491855]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "2 loss 168012.25741739568\n",
      "dev set\n",
      "[0.60147059 0.59843715 0.60039081 0.60030126 0.60135922 0.60011822\n",
      " 0.60198773 0.60001704 0.60116838 0.60035231]\n",
      "[[1.11724961 0.81391992 1.00926391 1.00032879 1.10608259 1.04163374\n",
      "  1.1689106  1.03150347 1.14662946 1.06501651]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2563, 1: 139}\n",
      "acc 0.8952627683197631\n",
      "(0.26618705035971224, 0.16972477064220184, 0.20728291316526612, None)\n",
      "\n",
      "3 loss 168007.8712097473\n",
      "dev set\n",
      "[0.60156887 0.59853541 0.60048938 0.60039977 0.60145758 0.6000197\n",
      " 0.60208597 0.59991844 0.6010698  0.60025371]\n",
      "[[1.11715135 0.81382174 1.0091654  1.00023042 1.10598425 1.0417323\n",
      "  1.16881233 1.03160195 1.14672744 1.06511472]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2563, 1: 139}\n",
      "acc 0.8952627683197631\n",
      "(0.26618705035971224, 0.16972477064220184, 0.20728291316526612, None)\n",
      "\n",
      "4 loss 168003.47461723277\n",
      "dev set\n",
      "[0.60166711 0.5986336  0.60058805 0.60049836 0.6015559  0.59992108\n",
      " 0.60218421 0.59981969 0.60097107 0.60015497]\n",
      "[[1.11705312 0.81372361 1.00906684 1.00013201 1.10588595 1.04183098\n",
      "  1.16871409 1.03170054 1.14682553 1.06521313]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2564, 1: 138}\n",
      "acc 0.8956328645447816\n",
      "(0.26811594202898553, 0.16972477064220184, 0.20786516853932585, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7000000000000001\n",
      "precision penalty\n",
      "0 loss 168205.21760700786\n",
      "dev set\n",
      "[0.70127396 0.69824035 0.70019441 0.70010517 0.70116224 0.70031472\n",
      " 0.70179066 0.70021325 0.70136462 0.70054911]\n",
      "[[1.11744622 0.81411689 1.0094607  1.00052561 1.10627988 1.04143722\n",
      "  1.16910737 1.03130663 1.14643139 1.06479204]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2374, 1: 328}\n",
      "acc 0.8934122871946706\n",
      "(0.3932926829268293, 0.591743119266055, 0.4725274725274725, None)\n",
      "\n",
      "1 loss 168203.77447619135\n",
      "dev set\n",
      "[0.70137217 0.69833848 0.70029247 0.70020312 0.70126066 0.7002164\n",
      " 0.70188874 0.70011541 0.70126784 0.70045162]\n",
      "[[1.11734809 0.81401915 1.00936262 1.00042797 1.10618169 1.04153555\n",
      "  1.16900913 1.0314037  1.14652551 1.06485727]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "2 loss 168202.33044171633\n",
      "dev set\n",
      "[0.70147042 0.69843662 0.70039062 0.70030109 0.70135901 0.70011798\n",
      " 0.70198685 0.70001748 0.70117042 0.70035398]\n",
      "[[1.11724991 0.81392141 1.00926454 1.00033033 1.10608359 1.041634\n",
      "  1.16891089 1.03150073 1.14661947 1.06492355]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "3 loss 168200.88046231394\n",
      "dev set\n",
      "[0.70156866 0.69853471 0.70048871 0.70039914 0.70145729 0.70001947\n",
      " 0.70208496 0.69991943 0.70107261 0.70025533]\n",
      "[[1.11715173 0.8138237  1.0091664  1.00023265 1.10598557 1.04173257\n",
      "  1.16881267 1.03159784 1.14671348 1.06499079]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2377, 1: 325}\n",
      "acc 0.8945225758697262\n",
      "(0.39692307692307693, 0.591743119266055, 0.47513812154696133, None)\n",
      "\n",
      "4 loss 168199.42719540026\n",
      "dev set\n",
      "[0.70166685 0.69863275 0.7005866  0.70049711 0.70155551 0.69992088\n",
      " 0.70218306 0.69982124 0.70097469 0.70015628]\n",
      "[[1.11705359 0.81372604 1.00906821 1.00013492 1.10588764 1.04183125\n",
      "  1.16871449 1.03169509 1.1468076  1.06505888]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2379, 1: 323}\n",
      "acc 0.8952627683197631\n",
      "(0.3993808049535604, 0.591743119266055, 0.47689463955637706, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "precision penalty\n",
      "0 loss 168167.97927660777\n",
      "dev set\n",
      "[0.80127375 0.79823913 0.8001934  0.80010373 0.80116105 0.80031448\n",
      " 0.80179077 0.80022537 0.80139755 0.80074442]\n",
      "[[1.11744659 0.81412059 1.00948767 1.00054981 1.10628505 1.04143747\n",
      "  1.16910738 1.0313033  1.1464263  1.06463302]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "1 loss 168167.58930639667\n",
      "dev set\n",
      "[0.80137179 0.79833623 0.80028877 0.8001987  0.80125874 0.8002161\n",
      " 0.80188902 0.80014517 0.80133571 0.80084065]\n",
      "[[1.11734881 0.81402654 1.00942511 1.00048687 1.10619059 1.04153586\n",
      "  1.16900919 1.03139497 1.1465145  1.06454427]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "2 loss 168167.2010913949\n",
      "dev set\n",
      "[0.8014699  0.79843334 0.80038398 0.8002935  0.80135629 0.80011766\n",
      " 0.80198724 0.80006528 0.80127391 0.80093642]\n",
      "[[1.11725092 0.81393249 1.00936281 1.00042422 1.10609631 1.04163435\n",
      "  1.168911   1.03148642 1.14660245 1.06445597]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "3 loss 168166.81252252427\n",
      "dev set\n",
      "[0.80156801 0.79853041 0.80047919 0.80038831 0.8014537  0.80001915\n",
      " 0.80208542 0.79998526 0.80121182 0.80103191]\n",
      "[[1.11715302 0.81383849 1.00930031 1.00036132 1.10600221 1.04173299\n",
      "  1.16881285 1.03157788 1.14669041 1.06436801]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "4 loss 168166.42339329582\n",
      "dev set\n",
      "[0.8016661  0.79862742 0.80057446 0.80048317 0.80155101 0.79992057\n",
      " 0.80218354 0.799905   0.80114936 0.80112721]\n",
      "[[1.11705515 0.81374457 1.00923749 1.00029812 1.10590827 1.04183176\n",
      "  1.16871475 1.03166943 1.14677845 1.06428031]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "precision penalty\n",
      "0 loss 168150.79488031872\n",
      "dev set\n",
      "[0.90127262 0.89821813 0.90000936 0.89991548 0.90110615 0.90051205\n",
      " 0.90179057 0.90021932 0.90137487 0.9007092 ]\n",
      "[[1.117449   0.81420281 1.00965721 1.00072301 1.10641781 1.04123989\n",
      "  1.16910764 1.03130589 1.1464323  1.06468297]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "1 loss 168150.72579593296\n",
      "dev set\n",
      "[0.90136949 0.89829089 0.89992546 0.89982806 0.90115729 0.90061037\n",
      " 0.90188854 0.90013334 0.90129193 0.90078802]\n",
      "[[1.11735391 0.81419962 1.00975426 1.00082061 1.10645957 1.04114161\n",
      "  1.16901    1.03140165 1.14652744 1.06462482]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "2 loss 168150.65754467665\n",
      "dev set\n",
      "[0.90146656 0.89836335 0.89984216 0.89974157 0.90120881 0.90070866\n",
      " 0.90198653 0.90004793 0.90120951 0.90086667]\n",
      "[[1.11725855 0.81419686 1.00985103 1.00091772 1.10650159 1.04104339\n",
      "  1.16891235 1.03149719 1.14662233 1.06456665]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "3 loss 168150.58952665527\n",
      "dev set\n",
      "[0.90156368 0.8984356  0.89975918 0.89965557 0.90126023 0.9008069\n",
      " 0.9020845  0.89996272 0.90112727 0.90094512]\n",
      "[[1.11716312 0.81419435 1.00994765 1.00101458 1.10654392 1.04094527\n",
      "  1.16881477 1.03159269 1.14671713 1.06450868]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "4 loss 168150.5216439297\n",
      "dev set\n",
      "[0.90166079 0.89850768 0.89967637 0.89956985 0.90131151 0.90090507\n",
      " 0.9021824  0.8998776  0.9010451  0.9010234 ]\n",
      "[[1.11706771 0.81419205 1.0100442  1.00111132 1.10658646 1.04084727\n",
      "  1.16871727 1.03168818 1.14681191 1.06445088]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "precision penalty\n",
      "0 loss 168190.31197863782\n",
      "dev set\n",
      "[1.00127511 0.99804745 1.00019692 1.00001631 1.00116353 1.00051438\n",
      " 1.00179144 1.00041353 1.00156283 1.00074755]\n",
      "[[1.11761975 0.81430907 1.00956007 1.00062431 1.10644725 1.04135243\n",
      "  1.16929564 1.03121487 1.1464198  1.06475909]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "1 loss 168190.31195325285\n",
      "dev set\n",
      "[1.00137928 0.99795513 1.00032438 1.00010262 1.00126825 1.00062672\n",
      " 1.00189395 1.00052892 1.00166595 1.00085572]\n",
      "[[1.11771273 0.81440306 1.00956348 1.00062433 1.10653701 1.04138636\n",
      "  1.16939507 1.03123598 1.14651751 1.06482196]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "2 loss 168190.31192512304\n",
      "dev set\n",
      "[1.00149025 0.99786119 1.00047616 1.00026473 1.00138039 1.00075417\n",
      " 1.00200137 1.00066194 1.00177467 1.00097499]\n",
      "[[1.11781883 0.81450061 1.00957877 1.00062559 1.10664159 1.04144674\n",
      "  1.16950292 1.03128109 1.14662524 1.06490889]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "3 loss 168190.31189335097\n",
      "dev set\n",
      "[1.00160838 0.99776539 1.0006456  1.00045421 1.00150031 1.00089603\n",
      " 1.002114   1.00081091 1.00188932 1.00110552]\n",
      "[[1.11793724 0.814602   1.00962244 1.00063762 1.10675991 1.04153782\n",
      "  1.16961908 1.03135893 1.14674267 1.06501884]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "4 loss 168190.31185717267\n",
      "dev set\n",
      "[1.00173353 0.99766775 1.00082698 1.00065622 1.0016278  1.0010503\n",
      " 1.0022318  1.00097284 1.00200984 1.00124651]\n",
      "[[1.11806717 0.81470715 1.00970867 1.00068354 1.10689096 1.04165901\n",
      "  1.16974329 1.0314718  1.14686937 1.06514968]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.0\n",
      "precision penalty\n",
      "0 loss 170144.18004523465\n",
      "dev set\n",
      "[ 1.22478621e-03 -1.80851707e-03  1.44922145e-04  5.55686472e-05\n",
      "  1.11313238e-03  3.64088939e-04  1.74138171e-03  2.62759761e-04\n",
      "  1.41402889e-03  5.97914381e-04]\n",
      "[[1.11749529 0.8141652  1.00951032 1.00057497 1.10632851 1.04138784\n",
      "  1.16915666 1.03125718 1.14638406 1.0647726 ]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "1 loss 170131.43500749994\n",
      "dev set\n",
      "[ 0.00127404 -0.00175926  0.00019417  0.00010481  0.0011624   0.00031486\n",
      "  0.00179063  0.00021352  0.00136479  0.00054867]\n",
      "[[1.11744604 0.81411594 1.00946106 1.00052571 1.10627923 1.04143705\n",
      "  1.16910741 1.03130644 1.14643331 1.06482183]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "2 loss 170118.69442447432\n",
      "dev set\n",
      "[ 0.0013233  -0.00171     0.00024343  0.00015407  0.00121168  0.00026563\n",
      "  0.00183989  0.00016426  0.00131553  0.00049942]\n",
      "[[1.11739679 0.81406668 1.00941179 1.00047644 1.10622996 1.04148629\n",
      "  1.16905814 1.0313557  1.14648257 1.06487108]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "3 loss 170105.95088647254\n",
      "dev set\n",
      "[ 0.00137256 -0.00166074  0.0002927   0.00020335  0.00126095  0.00021637\n",
      "  0.00188915  0.00011499  0.00126626  0.00045014]\n",
      "[[1.11734752 0.81401741 1.00936251 1.00042716 1.10618068 1.04153554\n",
      "  1.16900887 1.03140499 1.14653185 1.06492035]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "4 loss 170093.2046433462\n",
      "dev set\n",
      "[ 1.42181593e-03 -1.61147853e-03  3.41983824e-04  2.52630199e-04\n",
      "  1.31021804e-03  1.67110313e-04  1.93842683e-03  6.56996802e-05\n",
      "  1.21697110e-03  4.00854982e-04]\n",
      "[[1.11729826 0.81396815 1.00931321 1.00037787 1.1061314  1.0415848\n",
      "  1.1689596  1.03145429 1.14658114 1.06496964]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.1\n",
      "precision penalty\n",
      "0 loss 168932.12357237877\n",
      "dev set\n",
      "[0.10122478 0.09819148 0.10014492 0.10005557 0.10111313 0.10036409\n",
      " 0.10174138 0.10026276 0.10141403 0.10059792]\n",
      "[[1.11749529 0.8141652  1.00951032 1.00057497 1.10632851 1.04138783\n",
      "  1.16915666 1.03125718 1.14638406 1.06477259]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "1 loss 168921.4308713697\n",
      "dev set\n",
      "[0.10127404 0.09824074 0.10019416 0.10010481 0.10116241 0.10031487\n",
      " 0.10179062 0.10021353 0.1013648  0.10054868]\n",
      "[[1.11744605 0.81411595 1.00946106 1.00052571 1.10627923 1.04143705\n",
      "  1.16910741 1.03130644 1.14643331 1.06482182]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 168910.74129737393\n",
      "dev set\n",
      "[0.10132329 0.09829    0.10024342 0.10015406 0.10121168 0.10026564\n",
      " 0.10183988 0.10016427 0.10131554 0.10049943]\n",
      "[[1.11739679 0.81406669 1.00941179 1.00047645 1.10622995 1.04148628\n",
      "  1.16905815 1.0313557  1.14648257 1.06487106]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "3 loss 168900.04857026113\n",
      "dev set\n",
      "[0.10137255 0.09833926 0.10029269 0.10020334 0.10126095 0.10021639\n",
      " 0.10188914 0.100115   0.10126627 0.10045015]\n",
      "[[1.11734753 0.81401742 1.0093625  1.00042717 1.10618067 1.04153553\n",
      "  1.16900888 1.03140499 1.14653185 1.06492034]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "4 loss 168889.35287844122\n",
      "dev set\n",
      "[0.10142181 0.09838851 0.10034198 0.10025262 0.10131022 0.10016712\n",
      " 0.10193841 0.10006571 0.10121698 0.10040086]\n",
      "[[1.11729828 0.81396816 1.00931321 1.00037787 1.1061314  1.04158479\n",
      "  1.16895961 1.0314543  1.14658114 1.06496963]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.2\n",
      "precision penalty\n",
      "0 loss 168140.3482500112\n",
      "dev set\n",
      "[0.20122478 0.19819148 0.20014491 0.20005556 0.20111313 0.2003641\n",
      " 0.20174137 0.20026277 0.20141404 0.20059792]\n",
      "[[1.1174953  0.81416521 1.00951032 1.00057496 1.10632851 1.04138783\n",
      "  1.16915666 1.03125718 1.14638406 1.06477258]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "1 loss 168131.55279701998\n",
      "dev set\n",
      "[0.20127403 0.19824074 0.20019415 0.2001048  0.20116241 0.20031488\n",
      " 0.20179061 0.20021354 0.20136481 0.20054869]\n",
      "[[1.11744605 0.81411595 1.00946106 1.00052571 1.10627923 1.04143704\n",
      "  1.16910741 1.03130644 1.14643331 1.0648218 ]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "2 loss 168122.75918578822\n",
      "dev set\n",
      "[0.20132329 0.19828999 0.20024341 0.20015406 0.20121168 0.20026565\n",
      " 0.20183986 0.20016429 0.20131556 0.20049944]\n",
      "[[1.1173968  0.81406669 1.00941179 1.00047645 1.10622995 1.04148627\n",
      "  1.16905815 1.03135571 1.14648257 1.06487104]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "3 loss 168113.96217453713\n",
      "dev set\n",
      "[0.20137254 0.19833925 0.20029268 0.20020333 0.20126095 0.2002164\n",
      " 0.20188912 0.20011501 0.20126628 0.20045017]\n",
      "[[1.11734755 0.81401743 1.0093625  1.00042716 1.10618067 1.04153552\n",
      "  1.16900889 1.031405   1.14653185 1.06492031]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "4 loss 168105.16188877236\n",
      "dev set\n",
      "[0.20142179 0.1983885  0.20034197 0.20025262 0.20131022 0.20016713\n",
      " 0.20193839 0.20006572 0.20121699 0.20040087]\n",
      "[[1.11729829 0.81396817 1.0093132  1.00037787 1.10613139 1.04158479\n",
      "  1.16895962 1.03145431 1.14658115 1.06496961]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.30000000000000004\n",
      "precision penalty\n",
      "0 loss 167726.38641651874\n",
      "dev set\n",
      "[0.30122478 0.29819147 0.30014491 0.30005556 0.30111313 0.3003641\n",
      " 0.30174136 0.30026278 0.30141405 0.30059793]\n",
      "[[1.1174953  0.81416521 1.00951032 1.00057496 1.10632852 1.04138783\n",
      "  1.16915666 1.03125719 1.14638407 1.06477256]]\n",
      "{0: 2719, 1: 95}\n",
      "acc 0.9225302061122956\n",
      "(0.3473684210526316, 0.1746031746031746, 0.2323943661971831, None)\n",
      "\n",
      "test set\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9104367135455218\n",
      "(0.34615384615384615, 0.12385321100917432, 0.18243243243243243, None)\n",
      "\n",
      "1 loss 167719.33952726304\n",
      "dev set\n",
      "[0.30127403 0.29824073 0.30019415 0.30010479 0.30116241 0.30031489\n",
      " 0.3017906  0.30021355 0.30136482 0.3005487 ]\n",
      "[[1.11744606 0.81411596 1.00946106 1.00052571 1.10627923 1.04143704\n",
      "  1.16910741 1.03130644 1.14643331 1.06482178]]\n",
      "{0: 2719, 1: 95}\n",
      "acc 0.9225302061122956\n",
      "(0.3473684210526316, 0.1746031746031746, 0.2323943661971831, None)\n",
      "\n",
      "test set\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9104367135455218\n",
      "(0.34615384615384615, 0.12385321100917432, 0.18243243243243243, None)\n",
      "\n",
      "2 loss 167712.29331027795\n",
      "dev set\n",
      "[0.30132328 0.29828999 0.3002434  0.30015405 0.30121168 0.30026566\n",
      " 0.30183984 0.3001643  0.30131557 0.30049945]\n",
      "[[1.11739681 0.8140667  1.00941178 1.00047644 1.10622995 1.04148627\n",
      "  1.16905815 1.03135571 1.14648257 1.06487101]]\n",
      "{0: 2721, 1: 93}\n",
      "acc 0.9232409381663113\n",
      "(0.3548387096774194, 0.1746031746031746, 0.2340425531914894, None)\n",
      "\n",
      "test set\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9104367135455218\n",
      "(0.34615384615384615, 0.12385321100917432, 0.18243243243243243, None)\n",
      "\n",
      "3 loss 167705.24347925742\n",
      "dev set\n",
      "[0.30137253 0.29833924 0.30029267 0.30020332 0.30126096 0.30021641\n",
      " 0.30188909 0.30011502 0.3012663  0.30045018]\n",
      "[[1.11734756 0.81401744 1.00936249 1.00042716 1.10618067 1.04153552\n",
      "  1.16900889 1.03140501 1.14653185 1.06492028]]\n",
      "{0: 2722, 1: 92}\n",
      "acc 0.9235963041933192\n",
      "(0.358695652173913, 0.1746031746031746, 0.23487544483985762, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "4 loss 167698.1900979086\n",
      "dev set\n",
      "[0.30142178 0.29838849 0.30034196 0.30025261 0.30131022 0.30016714\n",
      " 0.30193836 0.30006573 0.301217   0.30040088]\n",
      "[[1.11729831 0.81396819 1.00931319 1.00037787 1.10613139 1.04158479\n",
      "  1.16895962 1.03145432 1.14658115 1.06496957]]\n",
      "{0: 2723, 1: 91}\n",
      "acc 0.923951670220327\n",
      "(0.3626373626373626, 0.1746031746031746, 0.23571428571428568, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.4\n",
      "precision penalty\n",
      "0 loss 167614.74992965953\n",
      "dev set\n",
      "[0.40122478 0.39819147 0.4001449  0.40005555 0.40111313 0.40036411\n",
      " 0.40174136 0.40026279 0.40141406 0.40059794]\n",
      "[[1.11749531 0.81416522 1.00951031 1.00057496 1.10632853 1.04138782\n",
      "  1.16915665 1.0312572  1.14638408 1.06477254]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "1 loss 167609.31596602066\n",
      "dev set\n",
      "[0.40127402 0.39824072 0.40019413 0.40010478 0.40116241 0.4003149\n",
      " 0.40179058 0.40021356 0.40136483 0.40054872]\n",
      "[[1.11744607 0.81411597 1.00946105 1.0005257  1.10627924 1.04143703\n",
      "  1.1691074  1.03130646 1.14643332 1.06482173]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "2 loss 167603.88168583863\n",
      "dev set\n",
      "[0.40132327 0.39828998 0.40024339 0.40015403 0.40121168 0.40026567\n",
      " 0.40183981 0.40016432 0.40131559 0.40049947]\n",
      "[[1.11739683 0.81406672 1.00941177 1.00047644 1.10622995 1.04148626\n",
      "  1.16905815 1.03135573 1.14648258 1.06487096]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "3 loss 167598.44368507157\n",
      "dev set\n",
      "[0.40137252 0.39833923 0.40029266 0.40020331 0.40126096 0.40021642\n",
      " 0.40188906 0.40011504 0.40126631 0.4004502 ]\n",
      "[[1.11734758 0.81401746 1.00936247 1.00042716 1.10618067 1.04153551\n",
      "  1.16900889 1.03140503 1.14653185 1.06492023]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 167593.00196878647\n",
      "dev set\n",
      "[0.40142176 0.39838848 0.40034195 0.4002526  0.40131023 0.40016715\n",
      " 0.40193833 0.40006574 0.40121701 0.4004009 ]\n",
      "[[1.11729834 0.81396821 1.00931317 1.00037786 1.10613139 1.04158479\n",
      "  1.16895963 1.03145435 1.14658115 1.06496952]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2616, 1: 86}\n",
      "acc 0.9111769059955589\n",
      "(0.37209302325581395, 0.14678899082568808, 0.2105263157894737, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.5\n",
      "precision penalty\n",
      "0 loss 167701.4192528906\n",
      "dev set\n",
      "[0.50122477 0.49819146 0.50014488 0.50005552 0.50111312 0.50036412\n",
      " 0.50174139 0.50026281 0.50141409 0.50059797]\n",
      "[[1.11749531 0.81416524 1.0095103  1.00057494 1.10632855 1.04138782\n",
      "  1.16915662 1.03125722 1.14638411 1.06477249]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2603, 1: 99}\n",
      "acc 0.9078460399703923\n",
      "(0.3434343434343434, 0.1559633027522936, 0.21451104100946375, None)\n",
      "\n",
      "1 loss 167697.67293330657\n",
      "dev set\n",
      "[0.50127401 0.49824071 0.5001941  0.50010473 0.5011624  0.50031491\n",
      " 0.50179065 0.5002136  0.5013649  0.50054876]\n",
      "[[1.11744609 0.814116   1.00946103 1.00052569 1.10627926 1.04143702\n",
      "  1.16910737 1.03130648 1.14643333 1.06482165]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2603, 1: 99}\n",
      "acc 0.9078460399703923\n",
      "(0.3434343434343434, 0.1559633027522936, 0.21451104100946375, None)\n",
      "\n",
      "2 loss 167693.92581552887\n",
      "dev set\n",
      "[0.50132325 0.49828997 0.50024335 0.50015396 0.50121168 0.50026568\n",
      " 0.5018399  0.50016437 0.50131568 0.50049952]\n",
      "[[1.11739685 0.81406674 1.00941174 1.00047643 1.10622997 1.04148625\n",
      "  1.16905813 1.03135576 1.14648256 1.06487085]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "3 loss 167690.1755632214\n",
      "dev set\n",
      "[0.5013725  0.49833922 0.50029262 0.50020322 0.50126096 0.50021643\n",
      " 0.50188917 0.5001151  0.50126642 0.50045026]\n",
      "[[1.11734761 0.81401749 1.00936244 1.00042716 1.10618069 1.0415355\n",
      "  1.16900888 1.03140506 1.1465318  1.06492009]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "4 loss 167686.4221828155\n",
      "dev set\n",
      "[0.50142174 0.49838846 0.50034191 0.5002525  0.50131023 0.50016716\n",
      " 0.50193843 0.5000658  0.50121714 0.50040096]\n",
      "[[1.11729838 0.81396825 1.00931313 1.00037787 1.10613142 1.04158479\n",
      "  1.16895963 1.03145438 1.14658108 1.06496937]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6000000000000001\n",
      "precision penalty\n",
      "0 loss 167991.70885266067\n",
      "dev set\n",
      "[0.60122476 0.59819144 0.60014488 0.60005552 0.6011131  0.60036411\n",
      " 0.60174153 0.60026283 0.60141409 0.60059801]\n",
      "[[1.11749533 0.81416528 1.00951026 1.00057489 1.10632859 1.04138783\n",
      "  1.16915661 1.03125729 1.14638415 1.06477232]]\n",
      "{0: 2673, 1: 141}\n",
      "acc 0.9076048329779673\n",
      "(0.24822695035460993, 0.18518518518518517, 0.21212121212121213, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "1 loss 167989.522680473\n",
      "dev set\n",
      "[0.60127399 0.59824069 0.60019409 0.6001047  0.60116239 0.6003149\n",
      " 0.60179077 0.60021365 0.60136492 0.60054883]\n",
      "[[1.11744612 0.81411605 1.00946097 1.00052565 1.10627931 1.04143703\n",
      "  1.16910736 1.03130654 1.14643322 1.06482133]]\n",
      "{0: 2674, 1: 140}\n",
      "acc 0.9079601990049752\n",
      "(0.25, 0.18518518518518517, 0.2127659574468085, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "2 loss 167987.33577237983\n",
      "dev set\n",
      "[0.60132323 0.59828994 0.60024333 0.60015392 0.60121167 0.60026567\n",
      " 0.60184    0.60016443 0.60131572 0.60049962]\n",
      "[[1.1173969  0.81406681 1.00941168 1.00047642 1.10623003 1.04148626\n",
      "  1.16905812 1.03135578 1.14648227 1.0648704 ]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "3 loss 167985.14632074776\n",
      "dev set\n",
      "[0.60137246 0.59833918 0.6002926  0.60020316 0.60126095 0.60021641\n",
      " 0.60188921 0.60011517 0.60126648 0.60045037]\n",
      "[[1.11734767 0.81401757 1.00936238 1.00042719 1.10618076 1.04153553\n",
      "  1.16900889 1.03140505 1.14653133 1.06491953]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "4 loss 167982.95416371527\n",
      "dev set\n",
      "[0.60142169 0.59838842 0.6003419  0.60025244 0.60131022 0.60016713\n",
      " 0.60193843 0.60006588 0.6012172  0.60040107]\n",
      "[[1.11729845 0.81396834 1.00931307 1.00037794 1.1061315  1.04158482\n",
      "  1.16895965 1.03145434 1.14658042 1.06496872]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7000000000000001\n",
      "precision penalty\n",
      "0 loss 168175.18416819462\n",
      "dev set\n",
      "[0.70122474 0.69819139 0.70014498 0.70005564 0.70111306 0.70036405\n",
      " 0.70174139 0.70026269 0.70141406 0.70059803]\n",
      "[[1.11749536 0.8141654  1.00951024 1.00057499 1.10632876 1.04138788\n",
      "  1.16915666 1.03125725 1.14638327 1.06476129]]\n",
      "{0: 2549, 1: 265}\n",
      "acc 0.9068941009239516\n",
      "(0.3622641509433962, 0.5079365079365079, 0.42290748898678415, None)\n",
      "\n",
      "test set\n",
      "{0: 2374, 1: 328}\n",
      "acc 0.8934122871946706\n",
      "(0.3932926829268293, 0.591743119266055, 0.4725274725274725, None)\n",
      "\n",
      "1 loss 168174.4610433744\n",
      "dev set\n",
      "[0.70127395 0.69824062 0.70019414 0.70010472 0.70116234 0.70031483\n",
      " 0.70179057 0.7002136  0.70136545 0.70054902]\n",
      "[[1.11744618 0.81411623 1.00946107 1.000526   1.10627954 1.0414371\n",
      "  1.16910743 1.03130614 1.14643101 1.06479866]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2374, 1: 328}\n",
      "acc 0.8934122871946706\n",
      "(0.3932926829268293, 0.591743119266055, 0.4725274725274725, None)\n",
      "\n",
      "2 loss 168173.7386709735\n",
      "dev set\n",
      "[0.70132317 0.69828985 0.7002433  0.70015378 0.70121162 0.7002656\n",
      " 0.70183975 0.70016451 0.70131687 0.70049998]\n",
      "[[1.11739699 0.81406705 1.00941191 1.00047703 1.10623034 1.04148634\n",
      "  1.16905821 1.03135499 1.14647866 1.06483637]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2374, 1: 328}\n",
      "acc 0.8934122871946706\n",
      "(0.3932926829268293, 0.591743119266055, 0.4725274725274725, None)\n",
      "\n",
      "3 loss 168173.01528516246\n",
      "dev set\n",
      "[0.70137239 0.69833908 0.70029248 0.70020285 0.70126088 0.70021634\n",
      " 0.70188893 0.7001154  0.70126814 0.70045092]\n",
      "[[1.1173478  0.81401788 1.00936274 1.00042806 1.10618115 1.0415356\n",
      "  1.16900898 1.03140385 1.14652629 1.06487441]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "4 loss 168172.29086658318\n",
      "dev set\n",
      "[0.7014216  0.69838829 0.70034169 0.70025193 0.70131013 0.70016707\n",
      " 0.70193812 0.70006626 0.70121924 0.70040182]\n",
      "[[1.1172986  0.81396872 1.00931357 1.00037908 1.10613199 1.04158489\n",
      "  1.16895976 1.03145272 1.14657392 1.06491274]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "precision penalty\n",
      "0 loss 168137.668346464\n",
      "dev set\n",
      "[0.80122469 0.79819114 0.8001446  0.80005501 0.80111263 0.800364\n",
      " 0.80174142 0.80026794 0.80142879 0.80069582]\n",
      "[[1.11749546 0.81416617 1.00952209 1.00058532 1.1063307  1.04138794\n",
      "  1.16915667 1.03125625 1.14638132 1.06467714]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "1 loss 168137.47156549103\n",
      "dev set\n",
      "[0.80127384 0.79824018 0.80019294 0.80010301 0.80116171 0.80031476\n",
      " 0.80179067 0.80022528 0.80139495 0.80074444]\n",
      "[[1.11744639 0.81411768 1.00948721 1.00055072 1.10628263 1.04143717\n",
      "  1.16910745 1.03130351 1.14642696 1.06463056]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "2 loss 168137.27545221482\n",
      "dev set\n",
      "[0.801323   0.79828923 0.80024121 0.80015093 0.80121078 0.80026552\n",
      " 0.80183992 0.80018278 0.80136125 0.800793  ]\n",
      "[[1.1173973  0.81406917 1.00945259 1.00051653 1.10623454 1.0414864\n",
      "  1.16905824 1.03135067 1.14647248 1.06458394]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "3 loss 168137.07933502828\n",
      "dev set\n",
      "[0.80137217 0.79833828 0.80028946 0.80019882 0.80125981 0.80021627\n",
      " 0.80188917 0.8001403  0.80132752 0.8008415 ]\n",
      "[[1.11734819 0.81402066 1.00941797 1.00048237 1.10618649 1.04153566\n",
      "  1.16900904 1.03139779 1.14651796 1.06453736]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "4 loss 168136.88310901567\n",
      "dev set\n",
      "[0.80142135 0.79838732 0.80033771 0.80024671 0.8013088  0.800167\n",
      " 0.8019384  0.80009778 0.80129373 0.80088993]\n",
      "[[1.11729908 0.81397216 1.00938329 1.00044815 1.10613849 1.04158496\n",
      "  1.16895984 1.03144491 1.14656344 1.06449084]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "precision penalty\n",
      "0 loss 168120.39592469335\n",
      "dev set\n",
      "[0.90122439 0.89818544 0.90005029 0.89995983 0.90108747 0.90046273\n",
      " 0.90174136 0.90026489 0.90141812 0.90068014]\n",
      "[[1.11749606 0.81420736 1.00960863 1.0006736  1.10640017 1.0412892\n",
      "  1.16915673 1.03125717 1.14638373 1.06469971]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "1 loss 168120.3601968693\n",
      "dev set\n",
      "[0.90127321 0.89822825 0.90000592 0.89991424 0.90111777 0.90051199\n",
      " 0.9017905  0.90021967 0.90137447 0.9007233 ]\n",
      "[[1.1174477  0.81420483 1.0096576  1.00072276 1.10642633 1.04123995\n",
      "  1.16910769 1.03130584 1.14643201 1.06466456]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "2 loss 168120.3246906157\n",
      "dev set\n",
      "[0.90132207 0.89827103 0.89996169 0.89986884 0.90114894 0.90056123\n",
      " 0.90183964 0.90017466 0.901331   0.90076677]\n",
      "[[1.11739928 0.81420256 1.00970653 1.00077182 1.10645256 1.04119072\n",
      "  1.16905866 1.03135442 1.14648019 1.0646287 ]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "3 loss 168120.2892498996\n",
      "dev set\n",
      "[0.90137095 0.8983138  0.89991757 0.89982358 0.90118031 0.90061048\n",
      " 0.90188877 0.90012974 0.90128762 0.9008103 ]\n",
      "[[1.11735083 0.81420041 1.00975542 1.00082081 1.10647896 1.0411415\n",
      "  1.16900963 1.03140296 1.14652832 1.06459268]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "4 loss 168120.25385313618\n",
      "dev set\n",
      "[0.90141985 0.89835653 0.89987352 0.89977842 0.90121173 0.9006597\n",
      " 0.90193789 0.90008486 0.90124428 0.90085383]\n",
      "[[1.11730235 0.81419836 1.00980429 1.00086975 1.10650553 1.0410923\n",
      "  1.16896062 1.03145149 1.14657644 1.06455663]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n",
      "precision penalty\n",
      "0 loss 168159.89635316163\n",
      "dev set\n",
      "[1.00122492 0.99809377 1.00014453 1.00001149 1.00111327 1.00046302\n",
      " 1.0017415  1.00036175 1.0015128  1.00069679]\n",
      "[[1.11758478 0.8142628  1.00955983 1.00062431 1.10641555 1.04134694\n",
      "  1.16925195 1.03121199 1.14637892 1.06474444]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "1 loss 168159.8963405288\n",
      "dev set\n",
      "[1.00127506 0.9980458  1.00019867 1.00003549 1.00116349 1.00051445\n",
      " 1.00179138 1.00041369 1.00156278 1.00074755]\n",
      "[[1.11763009 0.81431101 1.00956051 1.00062431 1.10645938 1.04136256\n",
      "  1.16930029 1.03122081 1.14642641 1.06477528]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "2 loss 168159.8963273029\n",
      "dev set\n",
      "[1.00132645 0.99799748 1.00025932 1.00008802 1.00121508 1.0005689\n",
      " 1.00184216 1.00046933 1.00161378 1.00080042]\n",
      "[[1.11767841 0.81435998 1.00956248 1.00062433 1.10650672 1.04138509\n",
      "  1.16935037 1.03123522 1.14647606 1.06481261]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "3 loss 168159.89631334838\n",
      "dev set\n",
      "[1.00137941 0.99794869 1.00032661 1.00015666 1.00126838 1.00062699\n",
      " 1.00189407 1.00052931 1.00166607 1.00085589]\n",
      "[[1.11772968 0.8144099  1.00956727 1.00062457 1.10655741 1.0414151\n",
      "  1.16940234 1.03125665 1.14652796 1.06485592]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "4 loss 168159.89629856654\n",
      "dev set\n",
      "[1.00143408 0.99789938 1.00039997 1.00023544 1.00132356 1.00068891\n",
      " 1.00194721 1.00059376 1.00171977 1.00091418]\n",
      "[[1.11778389 0.81446087 1.00957725 1.00062587 1.1066114  1.04145307\n",
      "  1.16945629 1.03128639 1.14658216 1.06490499]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = np.array([7.10732054e-04, 2.48756219e-03, 3.30490405e-02, 2.87846482e-02,\\\n",
    "       6.75195451e-03, 5.99502488e-01, 3.55366027e-04, 1.12651031e-01,\\\n",
    "       7.46268657e-02, 7.46268657e-03])\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [512,1024,2048]:\n",
    "    for i in np.linspace(0,1,11):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = acc ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=4,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 512 alpha-init: 0.0\n",
      "precision penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 223671.90833237345\n",
      "dev set\n",
      "[ 0.00137266 -0.00166069  0.00029264  0.00020329  0.00126115  0.00021667\n",
      "  0.0018891   0.00011512  0.00126639  0.00045027]\n",
      "[[1.11734745 0.81401745 1.00936248 1.0004271  1.10618046 1.04153514\n",
      "  1.16900881 1.03140499 1.14653194 1.06492007]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "1 loss 223621.1521673154\n",
      "dev set\n",
      "[ 1.56889742e-03 -1.46446394e-03  4.89001811e-04  3.99647684e-04\n",
      "  1.45749178e-03  2.04943532e-05  2.08545761e-03 -8.12470719e-05\n",
      "  1.07003418e-03  2.53911144e-04]\n",
      "[[1.11715121 0.8138212  1.00916604 1.00023069 1.10598405 1.04173127\n",
      "  1.16881242 1.03160143 1.14672836 1.0651164 ]]\n",
      "{0: 2733, 1: 81}\n",
      "acc 0.9246624022743426\n",
      "(0.35802469135802467, 0.15343915343915343, 0.2148148148148148, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "2 loss 223570.35398952325\n",
      "dev set\n",
      "[ 1.76512837e-03 -1.26826723e-03  6.85583509e-04  5.96228997e-04\n",
      "  1.65379524e-03 -1.75891946e-04  2.28196059e-03 -2.77897831e-04\n",
      "  8.73390077e-04  5.72624195e-05]\n",
      "[[1.11695494 0.81362496 1.0089694  1.00003407 1.10578768 1.04192766\n",
      "  1.16861591 1.03179816 1.14692506 1.06531307]]\n",
      "{0: 2734, 1: 80}\n",
      "acc 0.9250177683013504\n",
      "(0.3625, 0.15343915343915343, 0.21561338289962823, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "3 loss 223519.52620022013\n",
      "dev set\n",
      "[ 0.00196125 -0.00107221  0.00088226  0.00079291  0.00184998 -0.00037236\n",
      "  0.00247851 -0.0004747   0.00067659 -0.00013954]\n",
      "[[1.11675877 0.81342881 1.00877266 0.99983735 1.10559141 1.04212417\n",
      "  1.16841936 1.03199507 1.14712193 1.06550993]]\n",
      "{0: 2734, 1: 80}\n",
      "acc 0.9250177683013504\n",
      "(0.3625, 0.15343915343915343, 0.21561338289962823, None)\n",
      "\n",
      "test set\n",
      "{0: 2632, 1: 70}\n",
      "acc 0.9119170984455959\n",
      "(0.35714285714285715, 0.11467889908256881, 0.1736111111111111, None)\n",
      "\n",
      "4 loss 223468.6914210273\n",
      "dev set\n",
      "[ 0.00215722 -0.00087632  0.00107899  0.00098964  0.002046   -0.00056885\n",
      "  0.00267505 -0.00067161  0.0004797  -0.00033644]\n",
      "[[1.11656271 0.81323282 1.00857586 0.99964057 1.10539527 1.04232074\n",
      "  1.16822282 1.03219209 1.14731892 1.06570692]]\n",
      "{0: 2735, 1: 79}\n",
      "acc 0.9253731343283582\n",
      "(0.3670886075949367, 0.15343915343915343, 0.21641791044776118, None)\n",
      "\n",
      "test set\n",
      "{0: 2634, 1: 68}\n",
      "acc 0.9119170984455959\n",
      "(0.35294117647058826, 0.11009174311926606, 0.16783216783216784, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.1\n",
      "precision penalty\n",
      "0 loss 222462.94321285764\n",
      "dev set\n",
      "[0.10137264 0.09833928 0.10029261 0.10020325 0.10126115 0.10021673\n",
      " 0.10188905 0.10011516 0.10126644 0.10045032]\n",
      "[[1.11734748 0.8140175  1.00936249 1.0004271  1.10618046 1.0415351\n",
      "  1.16900881 1.03140499 1.14653196 1.06491999]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "1 loss 222420.3568966333\n",
      "dev set\n",
      "[0.10156886 0.09853548 0.10048897 0.10039961 0.10145749 0.10002058\n",
      " 0.10208539 0.0999188  0.10107008 0.10025396]\n",
      "[[1.11715126 0.81382128 1.00916604 1.00023068 1.10598406 1.04173123\n",
      "  1.16881244 1.03160145 1.14672838 1.06511631]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9235963041933192\n",
      "(0.34523809523809523, 0.15343915343915343, 0.21245421245421245, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "2 loss 222377.72284243148\n",
      "dev set\n",
      "[0.10176505 0.09873164 0.10068557 0.10059622 0.10165377 0.09982419\n",
      " 0.10228189 0.09972212 0.10087341 0.10005728]\n",
      "[[1.11695503 0.81362507 1.00896938 1.00003405 1.1057877  1.04192764\n",
      "  1.16861594 1.03179821 1.14692511 1.065313  ]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "3 loss 222335.05257025946\n",
      "dev set\n",
      "[0.10196113 0.09892765 0.1008823  0.10079294 0.10184991 0.0996277\n",
      " 0.10247845 0.09952527 0.10067656 0.09986043]\n",
      "[[1.1167589  0.81342899 1.00877261 0.99983731 1.10559147 1.04212419\n",
      "  1.16841941 1.03199517 1.14712203 1.06550991]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "4 loss 222292.36539006958\n",
      "dev set\n",
      "[0.10215704 0.09912346 0.10107909 0.10098973 0.10204589 0.09943116\n",
      " 0.10267503 0.09932828 0.10047959 0.09966345]\n",
      "[[1.11656291 0.81323306 1.00857577 0.9996405  1.10539537 1.04232083\n",
      "  1.16822288 1.03219227 1.1473191  1.06570698]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "test set\n",
      "{0: 2632, 1: 70}\n",
      "acc 0.9119170984455959\n",
      "(0.35714285714285715, 0.11467889908256881, 0.1736111111111111, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.2\n",
      "precision penalty\n",
      "0 loss 221674.00764695022\n",
      "dev set\n",
      "[0.20137262 0.19833923 0.20029257 0.20020321 0.20126114 0.20021679\n",
      " 0.20188899 0.20011522 0.2012665  0.20045038]\n",
      "[[1.11734751 0.81401757 1.00936248 1.00042709 1.10618047 1.04153507\n",
      "  1.1690088  1.031405   1.146532   1.06491988]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "1 loss 221638.97252301723\n",
      "dev set\n",
      "[0.20156881 0.19853542 0.20048893 0.20039958 0.20145748 0.20002065\n",
      " 0.2020853  0.19991885 0.20107013 0.20025401]\n",
      "[[1.11715133 0.81382138 1.00916603 1.00023067 1.10598407 1.0417312\n",
      "  1.16881245 1.03160147 1.14672842 1.06511618]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "2 loss 221603.88342394534\n",
      "dev set\n",
      "[0.20176497 0.19873154 0.20068557 0.20059622 0.20165375 0.19982424\n",
      " 0.20228181 0.19972213 0.20087342 0.20005729]\n",
      "[[1.11695514 0.81362522 1.00896934 1.00003402 1.10578773 1.04192765\n",
      "  1.16861596 1.03179828 1.14692517 1.0653129 ]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "3 loss 221568.7508304472\n",
      "dev set\n",
      "[0.201961   0.19892749 0.20088236 0.200793   0.20184986 0.1996277\n",
      " 0.2024784  0.1995252  0.20067649 0.19986036]\n",
      "[[1.11675906 0.81342919 1.00877254 0.99983725 1.10559153 1.04212427\n",
      "  1.16841945 1.0319953  1.14712215 1.06550988]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "4 loss 221533.59094234658\n",
      "dev set\n",
      "[0.20215686 0.19912324 0.20107924 0.20098988 0.2020458  0.19943108\n",
      " 0.20267503 0.19932811 0.20047941 0.19966327]\n",
      "[[1.11656312 0.81323333 1.00857565 0.9996404  1.10539547 1.04232101\n",
      "  1.16822294 1.03219251 1.14731932 1.06570706]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9243070362473348\n",
      "(0.35714285714285715, 0.15873015873015872, 0.21978021978021978, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.30000000000000004\n",
      "precision penalty\n",
      "0 loss 221262.6394444194\n",
      "dev set\n",
      "[0.30137259 0.29833918 0.30029252 0.30020316 0.30126113 0.30021685\n",
      " 0.30188891 0.30011528 0.30126656 0.30045044]\n",
      "[[1.11734756 0.81401767 1.00936247 1.00042707 1.10618051 1.04153503\n",
      "  1.16900877 1.03140503 1.14653206 1.06491972]]\n",
      "{0: 2722, 1: 92}\n",
      "acc 0.9235963041933192\n",
      "(0.358695652173913, 0.1746031746031746, 0.23487544483985762, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "1 loss 221234.56322233772\n",
      "dev set\n",
      "[0.30156875 0.29853533 0.30048889 0.30039954 0.30145747 0.3000207\n",
      " 0.3020852  0.2999189  0.30107019 0.30025406]\n",
      "[[1.11715141 0.81382153 1.009166   1.00023065 1.10598411 1.04173118\n",
      "  1.16881244 1.03160151 1.14672847 1.06511599]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9243070362473348\n",
      "(0.36666666666666664, 0.1746031746031746, 0.2365591397849462, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 221206.4276898442\n",
      "dev set\n",
      "[0.30176488 0.29873142 0.30068558 0.30059623 0.30165372 0.29982425\n",
      " 0.30228172 0.29972212 0.30087341 0.30005728]\n",
      "[[1.11695526 0.81362542 1.00896929 1.00003398 1.10578779 1.04192769\n",
      "  1.16861598 1.03179836 1.14692524 1.06531275]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "3 loss 221178.24207141812\n",
      "dev set\n",
      "[0.30196087 0.29892732 0.30088246 0.3007931  0.30184981 0.29962762\n",
      " 0.30247834 0.29952509 0.30067638 0.29986025]\n",
      "[[1.11675923 0.81342945 1.00877244 0.99983718 1.10559161 1.04212441\n",
      "  1.1684195  1.03199546 1.14712228 1.06550981]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "4 loss 221150.01962172159\n",
      "dev set\n",
      "[0.30215667 0.299123   0.30107945 0.3009901  0.30204571 0.29943089\n",
      " 0.30267505 0.29932785 0.30047916 0.29966302]\n",
      "[[1.11656336 0.81323367 1.0085755  0.99964028 1.1053956  1.0423213\n",
      "  1.16822303 1.03219279 1.14731954 1.06570712]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.4\n",
      "precision penalty\n",
      "0 loss 221153.36816617587\n",
      "dev set\n",
      "[0.40137255 0.39833908 0.40029245 0.4002031  0.40126109 0.4002169\n",
      " 0.40188882 0.40011536 0.40126664 0.40045052]\n",
      "[[1.11734763 0.81401784 1.00936244 1.00042702 1.1061806  1.041535\n",
      "  1.16900867 1.0314051  1.14653216 1.06491945]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "1 loss 221131.71141184086\n",
      "dev set\n",
      "[0.40156868 0.39853521 0.40048885 0.40039949 0.40145743 0.40002074\n",
      " 0.40208507 0.39991896 0.40107025 0.40025412]\n",
      "[[1.11715153 0.81382176 1.00916595 1.00023061 1.10598421 1.04173118\n",
      "  1.16881239 1.03160156 1.14672849 1.06511565]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2617, 1: 85}\n",
      "acc 0.9115470022205774\n",
      "(0.3764705882352941, 0.14678899082568808, 0.21122112211221122, None)\n",
      "\n",
      "2 loss 221109.99219660525\n",
      "dev set\n",
      "[0.40176477 0.39873125 0.40068561 0.40059625 0.40165368 0.39982421\n",
      " 0.4022816  0.3997221  0.40087339 0.40005726]\n",
      "[[1.11695543 0.81362572 1.00896922 1.00003395 1.10578791 1.04192778\n",
      "  1.16861601 1.03179842 1.14692522 1.06531241]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2618, 1: 84}\n",
      "acc 0.9119170984455959\n",
      "(0.38095238095238093, 0.14678899082568808, 0.2119205298013245, None)\n",
      "\n",
      "3 loss 221088.21821247967\n",
      "dev set\n",
      "[0.40196071 0.39892709 0.4008826  0.40079324 0.40184974 0.39962746\n",
      " 0.40247828 0.39952493 0.40067622 0.39986009]\n",
      "[[1.11675946 0.81342985 1.00877234 0.99983714 1.10559178 1.04212465\n",
      "  1.16841963 1.03199559 1.14712227 1.06550956]]\n",
      "{0: 2718, 1: 96}\n",
      "acc 0.9228855721393034\n",
      "(0.3541666666666667, 0.17989417989417988, 0.2385964912280702, None)\n",
      "\n",
      "test set\n",
      "{0: 2619, 1: 83}\n",
      "acc 0.9122871946706144\n",
      "(0.3855421686746988, 0.14678899082568808, 0.21262458471760798, None)\n",
      "\n",
      "4 loss 221066.39988995882\n",
      "dev set\n",
      "[0.40215646 0.3991227  0.40107976 0.4009904  0.40204561 0.39943055\n",
      " 0.40267508 0.3993275  0.4004788  0.39966267]\n",
      "[[1.11656367 0.81323417 1.00857534 0.99964022 1.10539582 1.04232173\n",
      "  1.16822327 1.03219304 1.1473196  1.06570703]]\n",
      "{0: 2720, 1: 94}\n",
      "acc 0.9235963041933192\n",
      "(0.3617021276595745, 0.17989417989417988, 0.24028268551236745, None)\n",
      "\n",
      "test set\n",
      "{0: 2619, 1: 83}\n",
      "acc 0.9122871946706144\n",
      "(0.3855421686746988, 0.14678899082568808, 0.21262458471760798, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.5\n",
      "precision penalty\n",
      "0 loss 221242.48779989989\n",
      "dev set\n",
      "[0.50137248 0.49833893 0.50029227 0.50020279 0.50126099 0.50021695\n",
      " 0.5018893  0.50011562 0.50126705 0.50045079]\n",
      "[[1.11734774 0.81401814 1.00936235 1.00042692 1.10618082 1.04153496\n",
      "  1.16900841 1.0314052  1.14653226 1.06491886]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "1 loss 221227.5441364839\n",
      "dev set\n",
      "[0.50156857 0.498535   0.50048862 0.50039908 0.50145733 0.50002078\n",
      " 0.50208559 0.49991662 0.5010708  0.50025447]\n",
      "[[1.11715171 0.81382219 1.00916588 1.00023062 1.10598449 1.04173117\n",
      "  1.16881224 1.03160151 1.14672818 1.06511476]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "2 loss 221212.3935483633\n",
      "dev set\n",
      "[0.50176461 0.49873097 0.5006854  0.50059583 0.50165354 0.49982417\n",
      " 0.50228206 0.49971039 0.50087398 0.5000576 ]\n",
      "[[1.11695569 0.8136263  1.00896919 1.0000341  1.10578828 1.04192786\n",
      "  1.16861606 1.03179823 1.14692451 1.06531136]]\n",
      "{0: 2704, 1: 110}\n",
      "acc 0.9193319118692252\n",
      "(0.32727272727272727, 0.19047619047619047, 0.24080267558528426, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "3 loss 221197.11136548073\n",
      "dev set\n",
      "[0.5019605  0.49892673 0.50088245 0.50079286 0.50184957 0.49962729\n",
      " 0.50247862 0.49950641 0.50067676 0.49985326]\n",
      "[[1.1167598  0.81343057 1.00877234 0.99983743 1.10559225 1.04212489\n",
      "  1.16841995 1.03199533 1.14712121 1.06550845]]\n",
      "{0: 2705, 1: 109}\n",
      "acc 0.9196872778962332\n",
      "(0.3302752293577982, 0.19047619047619047, 0.24161073825503354, None)\n",
      "\n",
      "test set\n",
      "{0: 2605, 1: 97}\n",
      "acc 0.9085862324204294\n",
      "(0.35051546391752575, 0.1559633027522936, 0.21587301587301586, None)\n",
      "\n",
      "4 loss 221181.63187866253\n",
      "dev set\n",
      "[0.50215617 0.49912224 0.50107971 0.50099014 0.50204539 0.49943017\n",
      " 0.50267522 0.49930377 0.5004792  0.49964463]\n",
      "[[1.11656411 0.81323507 1.00857536 0.99964063 1.10539641 1.0423222\n",
      "  1.16822394 1.03219277 1.14731828 1.06570598]]\n",
      "{0: 2706, 1: 108}\n",
      "acc 0.920042643923241\n",
      "(0.3333333333333333, 0.19047619047619047, 0.24242424242424246, None)\n",
      "\n",
      "test set\n",
      "{0: 2605, 1: 97}\n",
      "acc 0.9085862324204294\n",
      "(0.35051546391752575, 0.1559633027522936, 0.21587301587301586, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6000000000000001\n",
      "precision penalty\n",
      "0 loss 221534.92701884656\n",
      "dev set\n",
      "[0.60137236 0.5983386  0.6002922  0.60020261 0.60126078 0.60021681\n",
      " 0.60189077 0.60011583 0.6012671  0.60045123]\n",
      "[[1.11734794 0.81401883 1.00936203 1.00042663 1.10618135 1.04153511\n",
      "  1.16900829 1.03140535 1.14653174 1.0649168 ]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "1 loss 221526.21482552562\n",
      "dev set\n",
      "[0.60156836 0.59853452 0.60048851 0.60039869 0.60145707 0.60002058\n",
      " 0.60208662 0.59991958 0.60107099 0.60025511]\n",
      "[[1.11715205 0.81382327 1.0091658  1.00023086 1.10598525 1.04173139\n",
      "  1.16881221 1.03160074 1.14672509 1.06511099]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2563, 1: 139}\n",
      "acc 0.8952627683197631\n",
      "(0.26618705035971224, 0.16972477064220184, 0.20728291316526612, None)\n",
      "\n",
      "2 loss 221517.4596391372\n",
      "dev set\n",
      "[0.60176433 0.59873034 0.60068533 0.60059527 0.6016532  0.59982386\n",
      " 0.60228241 0.59972262 0.60087413 0.60005825]\n",
      "[[1.11695616 0.81362776 1.0089694  1.00003495 1.10578933 1.04192823\n",
      "  1.1686162  1.03179652 1.14691876 1.06530623]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2565, 1: 137}\n",
      "acc 0.8960029607698001\n",
      "(0.27007299270072993, 0.16972477064220184, 0.20845070422535214, None)\n",
      "\n",
      "3 loss 221508.66406178032\n",
      "dev set\n",
      "[0.60196013 0.59892592 0.60088246 0.60079215 0.60184912 0.59962681\n",
      " 0.60247817 0.59952513 0.60067671 0.59986085]\n",
      "[[1.11676042 0.81343245 1.00877285 0.99983893 1.10559361 1.04212547\n",
      "  1.16842036 1.03199274 1.14711288 1.06550222]]\n",
      "{0: 2678, 1: 136}\n",
      "acc 0.9093816631130064\n",
      "(0.25735294117647056, 0.18518518518518517, 0.21538461538461537, None)\n",
      "\n",
      "test set\n",
      "{0: 2566, 1: 136}\n",
      "acc 0.8963730569948186\n",
      "(0.27205882352941174, 0.16972477064220184, 0.20903954802259883, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 221499.83465498377\n",
      "dev set\n",
      "[0.60215571 0.59912124 0.60107983 0.60098922 0.60204481 0.59942947\n",
      " 0.60267385 0.5993272  0.60047888 0.599663  ]\n",
      "[[1.11656489 0.81323738 1.00857616 0.99964281 1.1053981  1.04232307\n",
      "  1.1682247  1.0321894  1.14730747 1.06569887]]\n",
      "{0: 2680, 1: 134}\n",
      "acc 0.910092395167022\n",
      "(0.26119402985074625, 0.18518518518518517, 0.21671826625386997, None)\n",
      "\n",
      "test set\n",
      "{0: 2572, 1: 130}\n",
      "acc 0.8985936343449297\n",
      "(0.2846153846153846, 0.16972477064220184, 0.21264367816091956, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7000000000000001\n",
      "precision penalty\n",
      "0 loss 221720.33448239003\n",
      "dev set\n",
      "[0.7013721  0.69833762 0.70029272 0.70020336 0.70126016 0.70021629\n",
      " 0.70188902 0.70011522 0.70126896 0.7004537 ]\n",
      "[[1.11734839 0.81402123 1.00936226 1.00042787 1.1061834  1.04153564\n",
      "  1.16900887 1.03140257 1.14651946 1.0648401 ]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "1 loss 221717.471235495\n",
      "dev set\n",
      "[0.70156793 0.69853298 0.70048755 0.70039742 0.70145608 0.70002008\n",
      " 0.70208453 0.69992153 0.7010789  0.70026123]\n",
      "[[1.11715283 0.81382732 1.00916779 1.00023481 1.10598871 1.04173191\n",
      "  1.16881295 1.03159164 1.14669657 1.06494711]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2377, 1: 325}\n",
      "acc 0.8945225758697262\n",
      "(0.39692307692307693, 0.591743119266055, 0.47513812154696133, None)\n",
      "\n",
      "2 loss 221714.59746259724\n",
      "dev set\n",
      "[0.70176373 0.69872821 0.70068194 0.70059112 0.70165174 0.6998235\n",
      " 0.70228006 0.69972739 0.70088804 0.70006689]\n",
      "[[1.11695725 0.81363349 1.00897321 1.00004163 1.10579434 1.04192866\n",
      "  1.16861711 1.03178092 1.14687379 1.06505675]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2382, 1: 320}\n",
      "acc 0.8963730569948186\n",
      "(0.403125, 0.591743119266055, 0.4795539033457249, None)\n",
      "\n",
      "3 loss 221711.7133537887\n",
      "dev set\n",
      "[0.70195935 0.69892317 0.70087681 0.7007849  0.70184712 0.69962663\n",
      " 0.70247548 0.69953234 0.70069681 0.69987236]\n",
      "[[1.11676183 0.81343989 1.00877843 0.99984826 1.10560026 1.04212581\n",
      "  1.16842146 1.03197069 1.1470515  1.06516885]]\n",
      "{0: 2556, 1: 258}\n",
      "acc 0.9086709310589908\n",
      "(0.3682170542635659, 0.5026455026455027, 0.4250559284116331, None)\n",
      "\n",
      "test set\n",
      "{0: 2385, 1: 317}\n",
      "acc 0.8974833456698742\n",
      "(0.4069400630914827, 0.591743119266055, 0.4822429906542056, None)\n",
      "\n",
      "4 loss 221708.81733391085\n",
      "dev set\n",
      "[0.70215473 0.69911783 0.70107186 0.70097882 0.70204222 0.6994295\n",
      " 0.70267073 0.69933676 0.70050541 0.6996773 ]\n",
      "[[1.11656665 0.81324659 1.00858344 0.9996547  1.10540646 1.04232332\n",
      "  1.16822606 1.03216102 1.14722979 1.0652833 ]]\n",
      "{0: 2557, 1: 257}\n",
      "acc 0.9090262970859986\n",
      "(0.36964980544747084, 0.5026455026455027, 0.4260089686098655, None)\n",
      "\n",
      "test set\n",
      "{0: 2385, 1: 317}\n",
      "acc 0.8974833456698742\n",
      "(0.4069400630914827, 0.591743119266055, 0.4822429906542056, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "precision penalty\n",
      "0 loss 221683.43412491662\n",
      "dev set\n",
      "[0.80137128 0.7983329  0.80028888 0.80019644 0.80125547 0.80021561\n",
      " 0.80188943 0.80015682 0.80136065 0.80083837]\n",
      "[[1.11734989 0.81403513 1.00943746 1.00050156 1.10620195 1.04153631\n",
      "  1.16900899 1.03138981 1.14650117 1.06455847]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "1 loss 221682.67639519373\n",
      "dev set\n",
      "[0.80156656 0.79852474 0.80047385 0.80037901 0.80144793 0.80001949\n",
      " 0.80208526 0.80002052 0.8012677  0.8010233 ]\n",
      "[[1.11715548 0.81385321 1.00933882 1.00040153 1.10602177 1.04173245\n",
      "  1.16881325 1.03155998 1.14665826 1.06439341]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "2 loss 221681.92143193792\n",
      "dev set\n",
      "[0.80176191 0.79871655 0.80065856 0.8005614  0.80163995 0.7998231\n",
      " 0.80228093 0.79988412 0.80117375 0.80120673]\n",
      "[[1.11696095 0.81367121 1.00924013 1.00030117 1.10584196 1.0419291\n",
      "  1.16861763 1.03172991 1.1468153  1.06423001]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "3 loss 221681.16478982466\n",
      "dev set\n",
      "[0.80195711 0.79890812 0.80084339 0.80074393 0.8018316  0.79962642\n",
      " 0.80247637 0.7997469  0.80107855 0.80138938]\n",
      "[[1.11676657 0.81348945 1.0091407  1.00020005 1.10566254 1.04212629\n",
      "  1.16842227 1.03190017 1.14697272 1.06406759]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "4 loss 221680.40615921092\n",
      "dev set\n",
      "[0.80215209 0.79909939 0.80102846 0.80092669 0.80202289 0.79942948\n",
      " 0.80267156 0.79960866 0.80098203 0.80157147]\n",
      "[[1.11657244 0.81330801 1.00904034 1.00009805 1.10548348 1.04232401\n",
      "  1.16822721 1.0320709  1.14713063 1.06390596]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "precision penalty\n",
      "0 loss 221666.3091570935\n",
      "dev set\n",
      "[0.90136672 0.89826614 0.89993511 0.89983803 0.90113174 0.90061063\n",
      " 0.90188867 0.900147   0.90131566 0.90077608]\n",
      "[[1.11735952 0.81420056 1.00975307 1.00081993 1.10643167 1.04114134\n",
      "  1.16900998 1.03140028 1.14652304 1.06464022]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "1 loss 221666.18293275643\n",
      "dev set\n",
      "[0.90155792 0.89839053 0.89978551 0.8996812  0.90120873 0.90080669\n",
      " 0.90208378 0.90000041 0.90118108 0.90091614]\n",
      "[[1.11717473 0.81419694 1.009943   1.00100981 1.10649404 1.04094548\n",
      "  1.16881598 1.03158468 1.14670353 1.06454241]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "2 loss 221666.0588251987\n",
      "dev set\n",
      "[0.90174945 0.89851496 0.89963756 0.89952661 0.90128604 0.90100254\n",
      " 0.9022788  0.89985497 0.90104715 0.90105559]\n",
      "[[1.11698958 0.81419401 1.01013209 1.00119835 1.10655799 1.04075\n",
      "  1.16862222 1.03176861 1.14688353 1.0644451 ]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "3 loss 221665.93525951492\n",
      "dev set\n",
      "[0.90194086 0.89863909 0.89949029 0.89937294 0.90136324 0.90119808\n",
      " 0.90247356 0.89970988 0.90091339 0.90119456]\n",
      "[[1.11680465 0.81419162 1.01032089 1.00138639 1.10662274 1.040555\n",
      "  1.16842888 1.03195245 1.14706343 1.06434827]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "4 loss 221665.81203712535\n",
      "dev set\n",
      "[0.90213202 0.89876282 0.89934336 0.89921974 0.90144022 0.90139329\n",
      " 0.90266799 0.89956493 0.90077968 0.90133312]\n",
      "[[1.11662011 0.81418972 1.01050956 1.0015742  1.10668799 1.0403605\n",
      "  1.16823602 1.03213631 1.14724333 1.06425187]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "precision penalty\n",
      "0 loss 221705.87912346402\n",
      "dev set\n",
      "[1.00137947 0.99797592 1.00032022 1.00003599 1.00126843 1.00062655\n",
      " 1.00189418 1.00052849 1.00166616 1.00085578]\n",
      "[[1.11768804 0.81438409 1.00956152 1.00062431 1.10650897 1.04136608\n",
      "  1.1693828  1.03122316 1.14650066 1.06478942]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "1 loss 221705.87905793366\n",
      "dev set\n",
      "[1.00160806 0.99780124 1.00064107 1.00035681 1.00149996 1.00089523\n",
      " 1.00211373 1.00080981 1.00188902 1.00110501]\n",
      "[[1.11789563 0.81456703 1.0095938  1.00062663 1.10671107 1.04146895\n",
      "  1.16959972 1.03130097 1.14671564 1.06494417]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "2 loss 221705.87897734268\n",
      "dev set\n",
      "[1.00186456 0.99762157 1.00101191 1.0007827  1.00176164 1.00121337\n",
      " 1.00235391 1.00114316 1.00213527 1.00139575]\n",
      "[[1.11815338 0.81476171 1.00974216 1.00068924 1.10696905 1.04168395\n",
      "  1.16985043 1.03149743 1.14697013 1.06518808]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "3 loss 221705.87887511213\n",
      "dev set\n",
      "[1.00214643 0.99743726 1.00140502 1.00122058 1.00205021 1.00156449\n",
      " 1.00261366 1.00150768 1.0024034  1.00171911]\n",
      "[[1.1184534  0.81496725 1.01003541 1.00092664 1.10727332 1.0419975\n",
      "  1.17013157 1.03180685 1.14725931 1.06550386]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "4 loss 221705.87874409673\n",
      "dev set\n",
      "[1.00245012 0.99724868 1.00180801 1.00165687 1.00236141 1.0019359\n",
      " 1.00289139 1.00188974 1.00269122 1.00206601]\n",
      "[[1.11878773 0.81518266 1.01041809 1.00130273 1.10761417 1.04237379\n",
      "  1.17043955 1.03218641 1.14757822 1.06586928]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.0\n",
      "precision penalty\n",
      "0 loss 223660.9535263723\n",
      "dev set\n",
      "[ 0.0012741  -0.00175922  0.0001942   0.00010484  0.00116248  0.00031488\n",
      "  0.00179065  0.0002135   0.00136477  0.00054866]\n",
      "[[1.11744599 0.81411592 1.00946101 1.00052565 1.10627915 1.04143702\n",
      "  1.16910737 1.03130648 1.14643338 1.06482181]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "1 loss 223635.51137023428\n",
      "dev set\n",
      "[ 0.00137244 -0.00166087  0.00029253  0.00020318  0.00126086  0.0002166\n",
      "  0.00188898  0.00011517  0.00126645  0.00045033]\n",
      "[[1.11734765 0.81401757 1.00936264 1.00042729 1.10618075 1.04153528\n",
      "  1.16900901 1.03140485 1.14653174 1.06492013]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "2 loss 223610.0684690985\n",
      "dev set\n",
      "[ 1.47079979e-03 -1.56251174e-03  3.90954659e-04  3.01600911e-04\n",
      "  1.35926045e-03  1.18237870e-04  1.98737906e-03  1.67447174e-05\n",
      "  1.16801854e-03  3.51900731e-04]\n",
      "[[1.11724929 0.8139192  1.00926419 1.00032885 1.10608233 1.04163364\n",
      "  1.16891061 1.03150331 1.14663019 1.06501855]]\n",
      "{0: 2733, 1: 81}\n",
      "acc 0.9246624022743426\n",
      "(0.35802469135802467, 0.15343915343915343, 0.2148148148148148, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "3 loss 223584.61039200143\n",
      "dev set\n",
      "[ 1.56915904e-03 -1.46416020e-03  4.89426865e-04  4.00072996e-04\n",
      "  1.45764645e-03  1.98298438e-05  2.08580561e-03 -8.17514224e-05\n",
      "  1.06952441e-03  2.53405208e-04]\n",
      "[[1.11715091 0.81382083 1.00916569 1.00023035 1.10598392 1.04173205\n",
      "  1.16881218 1.03160184 1.14672872 1.06511705]]\n",
      "{0: 2733, 1: 81}\n",
      "acc 0.9246624022743426\n",
      "(0.35802469135802467, 0.15343915343915343, 0.2148148148148148, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "4 loss 223559.14454985998\n",
      "dev set\n",
      "[ 1.66749586e-03 -1.36583765e-03  5.87929828e-04  4.98575811e-04\n",
      "  1.55600671e-03 -7.86032408e-05  2.18424722e-03 -1.80292531e-04\n",
      "  9.70985691e-04  1.54864835e-04]\n",
      "[[1.11705256 0.81372248 1.00906717 1.00013183 1.10588553 1.0418305\n",
      "  1.16871373 1.03170042 1.14682729 1.06521561]]\n",
      "{0: 2733, 1: 81}\n",
      "acc 0.9246624022743426\n",
      "(0.35802469135802467, 0.15343915343915343, 0.2148148148148148, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.1\n",
      "precision penalty\n",
      "0 loss 222449.95776622498\n",
      "dev set\n",
      "[0.1012741  0.09824078 0.10019419 0.10010483 0.10116248 0.1003149\n",
      " 0.10179063 0.10021352 0.10136479 0.10054867]\n",
      "[[1.11744599 0.81411593 1.00946101 1.00052565 1.10627915 1.04143701\n",
      "  1.16910737 1.03130649 1.14643339 1.06482179]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "1 loss 222428.61231222245\n",
      "dev set\n",
      "[0.10137243 0.09833911 0.10029252 0.10020317 0.10126087 0.10021663\n",
      " 0.10188896 0.10011519 0.10126647 0.10045035]\n",
      "[[1.11734767 0.81401759 1.00936264 1.00042729 1.10618074 1.04153527\n",
      "  1.16900902 1.03140486 1.14653175 1.06492009]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "2 loss 222407.26322355418\n",
      "dev set\n",
      "[0.10147078 0.09843747 0.10039094 0.10030159 0.10135926 0.10011827\n",
      " 0.10198735 0.10001676 0.10116804 0.10035192]\n",
      "[[1.11724931 0.81391923 1.00926419 1.00032884 1.10608233 1.04163362\n",
      "  1.16891062 1.03150332 1.14663021 1.06501852]]\n",
      "{0: 2729, 1: 85}\n",
      "acc 0.923951670220327\n",
      "(0.35294117647058826, 0.15873015873015872, 0.21897810218978106, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "3 loss 222385.89848407143\n",
      "dev set\n",
      "[0.10156913 0.09853581 0.10048942 0.10040007 0.10145764 0.10001986\n",
      " 0.10208577 0.09991826 0.10106953 0.10025342]\n",
      "[[1.11715095 0.81382087 1.00916568 1.00023034 1.10598392 1.04173204\n",
      "  1.1688122  1.03160187 1.14672875 1.06511703]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9235963041933192\n",
      "(0.34523809523809523, 0.15343915343915343, 0.21245421245421245, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "4 loss 222364.52438916845\n",
      "dev set\n",
      "[0.10166745 0.09863412 0.10058794 0.10049858 0.10155599 0.09992142\n",
      " 0.10218421 0.0998197  0.10097098 0.10015486]\n",
      "[[1.11705261 0.81372253 1.00906714 1.00013181 1.10588554 1.0418305\n",
      "  1.16871376 1.03170046 1.14682733 1.0652156 ]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9235963041933192\n",
      "(0.34523809523809523, 0.15343915343915343, 0.21245421245421245, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.2\n",
      "precision penalty\n",
      "0 loss 221659.14569241792\n",
      "dev set\n",
      "[0.20127409 0.19824077 0.20019417 0.20010482 0.20116248 0.20031491\n",
      " 0.20179061 0.20021354 0.20136481 0.20054869]\n",
      "[[1.117446   0.81411595 1.00946101 1.00052565 1.10627916 1.041437\n",
      "  1.16910736 1.03130649 1.1464334  1.06482175]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "1 loss 221641.58711624192\n",
      "dev set\n",
      "[0.20137242 0.1983391  0.2002925  0.20020315 0.20126087 0.20021665\n",
      " 0.20188893 0.20011522 0.20126649 0.20045037]\n",
      "[[1.11734768 0.81401762 1.00936263 1.00042728 1.10618074 1.04153525\n",
      "  1.16900902 1.03140487 1.14653177 1.06492004]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 221624.02202177737\n",
      "dev set\n",
      "[0.20147076 0.19843745 0.20039093 0.20030157 0.20135926 0.20011829\n",
      " 0.20198731 0.20001678 0.20116806 0.20035194]\n",
      "[[1.11724934 0.81391926 1.00926417 1.00032883 1.10608232 1.04163362\n",
      "  1.16891063 1.03150335 1.14663024 1.06501847]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "3 loss 221606.4405660494\n",
      "dev set\n",
      "[0.2015691  0.19853578 0.20048942 0.20040006 0.20145764 0.20001987\n",
      " 0.20208573 0.19991826 0.20106954 0.20025342]\n",
      "[[1.11715099 0.81382091 1.00916566 1.00023033 1.10598392 1.04173205\n",
      "  1.16881221 1.03160191 1.14672879 1.06511699]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "4 loss 221588.84798857087\n",
      "dev set\n",
      "[0.20166741 0.19863407 0.20058795 0.2004986  0.20155598 0.19992142\n",
      " 0.20218418 0.19981969 0.20097097 0.20015484]\n",
      "[[1.11705266 0.81372259 1.00906711 1.00013179 1.10588554 1.04183053\n",
      "  1.16871378 1.03170053 1.1468274  1.06521558]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.30000000000000004\n",
      "precision penalty\n",
      "0 loss 221246.0488553142\n",
      "dev set\n",
      "[0.30127408 0.29824075 0.30019416 0.3001048  0.30116248 0.30031493\n",
      " 0.30179059 0.30021356 0.30136483 0.30054871]\n",
      "[[1.11744601 0.81411598 1.00946101 1.00052564 1.10627917 1.04143699\n",
      "  1.16910735 1.03130651 1.14643343 1.06482171]]\n",
      "{0: 2719, 1: 95}\n",
      "acc 0.9225302061122956\n",
      "(0.3473684210526316, 0.1746031746031746, 0.2323943661971831, None)\n",
      "\n",
      "test set\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9104367135455218\n",
      "(0.34615384615384615, 0.12385321100917432, 0.18243243243243243, None)\n",
      "\n",
      "1 loss 221231.98023941033\n",
      "dev set\n",
      "[0.3013724  0.29833908 0.30029248 0.30020313 0.30126087 0.30021667\n",
      " 0.30188888 0.30011524 0.30126652 0.3004504 ]\n",
      "[[1.11734771 0.81401766 1.00936262 1.00042727 1.10618074 1.04153524\n",
      "  1.16900902 1.03140489 1.1465318  1.06491998]]\n",
      "{0: 2722, 1: 92}\n",
      "acc 0.9235963041933192\n",
      "(0.358695652173913, 0.1746031746031746, 0.23487544483985762, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "2 loss 221217.9025670601\n",
      "dev set\n",
      "[0.30147074 0.29843742 0.30039091 0.30030156 0.30135927 0.30011831\n",
      " 0.30198726 0.3000168  0.30116808 0.30035196]\n",
      "[[1.11724937 0.81391931 1.00926415 1.00032881 1.10608232 1.04163361\n",
      "  1.16891064 1.03150339 1.14663028 1.0650184 ]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9243070362473348\n",
      "(0.36666666666666664, 0.1746031746031746, 0.2365591397849462, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "3 loss 221203.8079355814\n",
      "dev set\n",
      "[0.30156907 0.29853574 0.30048942 0.30040006 0.30145764 0.30001987\n",
      " 0.30208568 0.29991827 0.30106954 0.30025342]\n",
      "[[1.11715103 0.81382097 1.00916562 1.0002303  1.10598392 1.04173207\n",
      "  1.16881223 1.03160197 1.14672884 1.06511693]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9243070362473348\n",
      "(0.36666666666666664, 0.1746031746031746, 0.2365591397849462, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "4 loss 221189.70058151564\n",
      "dev set\n",
      "[0.30166736 0.29863402 0.30058798 0.30049862 0.30155598 0.29992139\n",
      " 0.30218414 0.29981966 0.30097094 0.30015482]\n",
      "[[1.11705272 0.81372267 1.00906706 1.00013175 1.10588554 1.04183058\n",
      "  1.16871382 1.03170062 1.14682748 1.06521555]]\n",
      "{0: 2724, 1: 90}\n",
      "acc 0.9243070362473348\n",
      "(0.36666666666666664, 0.1746031746031746, 0.2365591397849462, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.4\n",
      "precision penalty\n",
      "0 loss 221135.18393946817\n",
      "dev set\n",
      "[0.40127407 0.39824072 0.40019413 0.40010478 0.40116246 0.40031494\n",
      " 0.40179056 0.40021358 0.40136486 0.40054874]\n",
      "[[1.11744603 0.81411603 1.00946099 1.00052562 1.10627919 1.04143698\n",
      "  1.16910731 1.03130654 1.14643348 1.06482163]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "1 loss 221124.33454101798\n",
      "dev set\n",
      "[0.40137238 0.39833905 0.40029245 0.4002031  0.40126087 0.40021669\n",
      " 0.40188883 0.40011528 0.40126655 0.40045043]\n",
      "[[1.11734774 0.81401772 1.00936259 1.00042724 1.10618076 1.04153524\n",
      "  1.16900899 1.03140494 1.14653185 1.06491986]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "2 loss 221113.47419711537\n",
      "dev set\n",
      "[0.40147071 0.39843738 0.40039089 0.40030154 0.40135927 0.40011831\n",
      " 0.4019872  0.40001683 0.4011681  0.40035198]\n",
      "[[1.11724942 0.81391939 1.00926411 1.00032878 1.10608233 1.04163362\n",
      "  1.16891064 1.03150345 1.14663033 1.06501828]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2616, 1: 86}\n",
      "acc 0.9111769059955589\n",
      "(0.37209302325581395, 0.14678899082568808, 0.2105263157894737, None)\n",
      "\n",
      "3 loss 221102.59672660506\n",
      "dev set\n",
      "[0.40156903 0.39853569 0.40048942 0.40040007 0.40145765 0.40001985\n",
      " 0.40208562 0.39991826 0.40106954 0.40025342]\n",
      "[[1.1171511  0.81382107 1.00916557 1.00023026 1.10598393 1.04173211\n",
      "  1.16881226 1.03160206 1.14672891 1.06511682]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2617, 1: 85}\n",
      "acc 0.9115470022205774\n",
      "(0.3764705882352941, 0.14678899082568808, 0.21122112211221122, None)\n",
      "\n",
      "4 loss 221091.70540666213\n",
      "dev set\n",
      "[0.40166731 0.39863395 0.40058801 0.40049866 0.40155598 0.39992133\n",
      " 0.40218409 0.39981962 0.4009709  0.40015477]\n",
      "[[1.1170528  0.81372279 1.00906698 1.0001317  1.10588556 1.04183067\n",
      "  1.16871387 1.03170075 1.14682757 1.06521547]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2617, 1: 85}\n",
      "acc 0.9115470022205774\n",
      "(0.3764705882352941, 0.14678899082568808, 0.21122112211221122, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.5\n",
      "precision penalty\n",
      "0 loss 221222.63549468206\n",
      "dev set\n",
      "[0.50127406 0.49824068 0.50019408 0.50010469 0.50116244 0.50031496\n",
      " 0.50179067 0.50021366 0.50136498 0.50054882]\n",
      "[[1.11744606 0.81411611 1.00946095 1.00052557 1.10627925 1.04143697\n",
      "  1.16910722 1.03130662 1.14643358 1.06482146]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2603, 1: 99}\n",
      "acc 0.9078460399703923\n",
      "(0.3434343434343434, 0.1559633027522936, 0.21451104100946375, None)\n",
      "\n",
      "1 loss 221215.15566263156\n",
      "dev set\n",
      "[0.50137235 0.49833899 0.50029238 0.50020296 0.50126085 0.5002167\n",
      " 0.50188897 0.50011539 0.50126673 0.50045055]\n",
      "[[1.11734779 0.81401783 1.00936253 1.0004272  1.10618082 1.04153523\n",
      "  1.16900892 1.03140502 1.1465319  1.0649196 ]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "2 loss 221207.6656782996\n",
      "dev set\n",
      "[0.50147067 0.49843731 0.50039081 0.50030138 0.50135926 0.50011832\n",
      " 0.5019873  0.50001695 0.50116831 0.50035211]\n",
      "[[1.11724948 0.81391953 1.00926403 1.00032876 1.1060824  1.04163363\n",
      "  1.16891061 1.03150353 1.14663031 1.06501795]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "3 loss 221200.13316751932\n",
      "dev set\n",
      "[0.50156897 0.4985356  0.50048935 0.5003999  0.50145763 0.50001983\n",
      " 0.50208567 0.49991536 0.50106976 0.50025355]\n",
      "[[1.11715119 0.81382125 1.00916548 1.00023026 1.10598401 1.04173214\n",
      "  1.16881229 1.03160214 1.14672883 1.06511647]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 221192.5150835845\n",
      "dev set\n",
      "[0.50166724 0.49863385 0.50058796 0.5004985  0.50155596 0.49992127\n",
      " 0.50218407 0.49981175 0.5009711  0.50015488]\n",
      "[[1.11705292 0.81372301 1.00906689 1.00013172 1.10588566 1.04183075\n",
      "  1.16871399 1.03170085 1.14682744 1.06521511]]\n",
      "{0: 2703, 1: 111}\n",
      "acc 0.9189765458422174\n",
      "(0.32432432432432434, 0.19047619047619047, 0.24, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6000000000000001\n",
      "precision penalty\n",
      "0 loss 221513.53870640005\n",
      "dev set\n",
      "[0.60127403 0.59824059 0.60019407 0.60010466 0.60116238 0.60031491\n",
      " 0.60179122 0.60021371 0.60136497 0.60054893]\n",
      "[[1.11744611 0.81411629 1.0094608  1.00052541 1.10627939 1.04143702\n",
      "  1.16910718 1.03130682 1.14643372 1.06482091]]\n",
      "{0: 2674, 1: 140}\n",
      "acc 0.9079601990049752\n",
      "(0.25, 0.18518518518518517, 0.2127659574468085, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "1 loss 221509.17369255278\n",
      "dev set\n",
      "[0.60137229 0.59833887 0.60029237 0.60020288 0.60126081 0.60021663\n",
      " 0.60188949 0.60011547 0.60126678 0.60045073]\n",
      "[[1.11734788 0.81401811 1.00936238 1.00042711 1.10618097 1.0415353\n",
      "  1.16900889 1.03140511 1.14653158 1.06491855]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "2 loss 221504.80036991107\n",
      "dev set\n",
      "[0.60147059 0.59843715 0.60039081 0.60030126 0.60135922 0.60011822\n",
      " 0.60198773 0.60001704 0.60116838 0.60035231]\n",
      "[[1.11724961 0.81391992 1.00926391 1.00032879 1.10608259 1.04163374\n",
      "  1.1689106  1.03150347 1.14662946 1.06501651]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2563, 1: 139}\n",
      "acc 0.8952627683197631\n",
      "(0.26618705035971224, 0.16972477064220184, 0.20728291316526612, None)\n",
      "\n",
      "3 loss 221500.4154352891\n",
      "dev set\n",
      "[0.60156887 0.5985354  0.60048938 0.60039977 0.60145758 0.6000197\n",
      " 0.60208597 0.59991844 0.6010698  0.60025371]\n",
      "[[1.11715135 0.81382174 1.0091654  1.00023042 1.10598425 1.0417323\n",
      "  1.16881233 1.03160195 1.14672744 1.06511472]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2563, 1: 139}\n",
      "acc 0.8952627683197631\n",
      "(0.26618705035971224, 0.16972477064220184, 0.20728291316526612, None)\n",
      "\n",
      "4 loss 221496.02011630303\n",
      "dev set\n",
      "[0.60166711 0.5986336  0.60058805 0.60049836 0.6015559  0.59992108\n",
      " 0.60218421 0.59981969 0.60097107 0.60015497]\n",
      "[[1.11705312 0.81372361 1.00906684 1.00013201 1.10588595 1.04183098\n",
      "  1.1687141  1.03170054 1.14682553 1.06521313]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2564, 1: 138}\n",
      "acc 0.8956328645447816\n",
      "(0.26811594202898553, 0.16972477064220184, 0.20786516853932585, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7000000000000001\n",
      "precision penalty\n",
      "0 loss 221697.5093926553\n",
      "dev set\n",
      "[0.70127396 0.69824035 0.70019441 0.70010517 0.70116224 0.70031472\n",
      " 0.70179066 0.70021325 0.70136462 0.70054911]\n",
      "[[1.11744622 0.81411689 1.0094607  1.00052561 1.10627988 1.04143722\n",
      "  1.16910737 1.03130663 1.14643138 1.06479194]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2374, 1: 328}\n",
      "acc 0.8934122871946706\n",
      "(0.3932926829268293, 0.591743119266055, 0.4725274725274725, None)\n",
      "\n",
      "1 loss 221696.06701288896\n",
      "dev set\n",
      "[0.70137217 0.69833848 0.70029247 0.70020312 0.70126066 0.7002164\n",
      " 0.70188874 0.70011541 0.70126785 0.70045162]\n",
      "[[1.11734809 0.81401916 1.00936262 1.00042797 1.10618169 1.04153555\n",
      "  1.16900913 1.0314037  1.1465255  1.06485705]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "2 loss 221694.62372977557\n",
      "dev set\n",
      "[0.70147042 0.69843662 0.70039061 0.70030109 0.70135901 0.70011798\n",
      " 0.70198685 0.70001749 0.70117043 0.70035398]\n",
      "[[1.11724991 0.81392141 1.00926454 1.00033033 1.10608359 1.041634\n",
      "  1.16891089 1.03150072 1.14661946 1.0649232 ]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "3 loss 221693.174504215\n",
      "dev set\n",
      "[0.70156866 0.69853471 0.70048871 0.70039914 0.70145729 0.70001947\n",
      " 0.70208496 0.69991943 0.70107262 0.70025534]\n",
      "[[1.11715173 0.8138237  1.0091664  1.00023265 1.10598558 1.04173257\n",
      "  1.16881267 1.03159784 1.14671347 1.06499033]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2377, 1: 325}\n",
      "acc 0.8945225758697262\n",
      "(0.39692307692307693, 0.591743119266055, 0.47513812154696133, None)\n",
      "\n",
      "4 loss 221691.72199220894\n",
      "dev set\n",
      "[0.70166685 0.69863274 0.70058659 0.7004971  0.70155551 0.69992088\n",
      " 0.70218305 0.69982124 0.7009747  0.70015628]\n",
      "[[1.11705359 0.81372605 1.00906822 1.00013492 1.10588765 1.04183125\n",
      "  1.16871449 1.03169508 1.14680758 1.0650583 ]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2379, 1: 323}\n",
      "acc 0.8952627683197631\n",
      "(0.3993808049535604, 0.591743119266055, 0.47689463955637706, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "precision penalty\n",
      "0 loss 221660.08706321448\n",
      "dev set\n",
      "[0.80127375 0.79823913 0.8001934  0.80010373 0.80116104 0.80031448\n",
      " 0.80179077 0.80022546 0.8013977  0.80074442]\n",
      "[[1.1174466  0.81412061 1.00948791 1.00054994 1.10628508 1.04143747\n",
      "  1.16910738 1.03130329 1.14642628 1.06463299]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "1 loss 221659.6975146294\n",
      "dev set\n",
      "[0.80137179 0.79833622 0.80028876 0.80019869 0.80125873 0.8002161\n",
      " 0.80188901 0.80014537 0.80133601 0.80084065]\n",
      "[[1.11734881 0.81402658 1.00942562 1.00048718 1.10619064 1.04153586\n",
      "  1.16900919 1.03139494 1.14651446 1.06454422]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "2 loss 221659.3097211618\n",
      "dev set\n",
      "[0.8014699  0.79843333 0.80038396 0.80029349 0.80135627 0.80011766\n",
      " 0.80198723 0.80006557 0.80127436 0.80093643]\n",
      "[[1.11725093 0.81393255 1.0093636  1.0004247  1.10609639 1.04163436\n",
      "  1.168911   1.03148637 1.1466024  1.0644559 ]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "3 loss 221658.92157497292\n",
      "dev set\n",
      "[0.80156801 0.7985304  0.80047917 0.80038829 0.80145369 0.80001915\n",
      " 0.80208541 0.79998566 0.80121242 0.80103192]\n",
      "[[1.11715303 0.81383857 1.00930136 1.00036199 1.10600232 1.04173299\n",
      "  1.16881285 1.03157781 1.14669034 1.06436792]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "4 loss 221658.5328696103\n",
      "dev set\n",
      "[0.8016661  0.7986274  0.80057442 0.80048315 0.80155099 0.79992056\n",
      " 0.80218354 0.7999055  0.80115011 0.80112722]\n",
      "[[1.11705515 0.81374467 1.00923881 1.00029897 1.10590839 1.04183176\n",
      "  1.16871475 1.03166935 1.14677836 1.0642802 ]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "precision penalty\n",
      "0 loss 221642.80624076756\n",
      "dev set\n",
      "[0.90127262 0.89821791 0.90000928 0.89991544 0.90110554 0.90051205\n",
      " 0.90179057 0.90021937 0.90137492 0.90070929]\n",
      "[[1.11744901 0.81420342 1.00965721 1.00072301 1.10641823 1.04123989\n",
      "  1.16910764 1.03130589 1.1464323  1.06468285]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "1 loss 221642.73718323125\n",
      "dev set\n",
      "[0.90136948 0.89829043 0.89992529 0.89982796 0.9011561  0.90061037\n",
      " 0.90188854 0.90013346 0.90129204 0.90078818]\n",
      "[[1.11735393 0.81420082 1.00975427 1.00082061 1.10646047 1.04114161\n",
      "  1.16901    1.03140164 1.14652744 1.06462458]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "2 loss 221642.66895963394\n",
      "dev set\n",
      "[0.90146655 0.89836264 0.8998419  0.89974143 0.90120704 0.90070866\n",
      " 0.90198653 0.90004812 0.90120967 0.90086689]\n",
      "[[1.11725858 0.81419865 1.00985103 1.00091773 1.10650298 1.04104339\n",
      "  1.16891236 1.03149718 1.14662233 1.06456629]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "3 loss 221642.6009694791\n",
      "dev set\n",
      "[0.90156367 0.89843465 0.89975882 0.89965538 0.90125788 0.9008069\n",
      " 0.90208449 0.89996299 0.90112749 0.90094541]\n",
      "[[1.11716316 0.81419672 1.00994766 1.00101459 1.1065458  1.04094527\n",
      "  1.16881477 1.03159267 1.14671713 1.0645082 ]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "4 loss 221642.53311468204\n",
      "dev set\n",
      "[0.90166077 0.89850648 0.89967593 0.8995696  0.90130859 0.90090507\n",
      " 0.9021824  0.89987795 0.90104539 0.90102376]\n",
      "[[1.11706777 0.81419499 1.01004421 1.00111133 1.10658883 1.04084727\n",
      "  1.16871728 1.03168816 1.14681191 1.06445029]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "precision penalty\n",
      "0 loss 221682.3466959367\n",
      "dev set\n",
      "[1.00127511 0.99804726 1.00019692 1.00001631 1.00116353 1.00051438\n",
      " 1.00179144 1.00041353 1.00156283 1.00074755]\n",
      "[[1.11761975 0.81430937 1.00956007 1.00062431 1.10644725 1.04135243\n",
      "  1.16929564 1.03121487 1.1464198  1.06475909]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "1 loss 221682.3466632612\n",
      "dev set\n",
      "[1.00137928 0.99795499 1.00032438 1.00010262 1.00126825 1.00062672\n",
      " 1.00189395 1.00052892 1.00166595 1.00085572]\n",
      "[[1.11771273 0.8144033  1.00956348 1.00062433 1.10653701 1.04138636\n",
      "  1.16939507 1.03123598 1.14651751 1.06482196]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "2 loss 221682.3466279094\n",
      "dev set\n",
      "[1.00149025 0.99786159 1.00047616 1.00026473 1.00138039 1.00075417\n",
      " 1.00200137 1.00066194 1.00177467 1.00097499]\n",
      "[[1.11781883 0.81450027 1.00957877 1.00062559 1.10664159 1.04144674\n",
      "  1.16950292 1.03128109 1.14662524 1.06490889]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "3 loss 221682.34658893064\n",
      "dev set\n",
      "[1.00160838 0.99776684 1.0006456  1.00045421 1.00150031 1.00089603\n",
      " 1.002114   1.00081091 1.00188932 1.00110552]\n",
      "[[1.11793724 0.81460056 1.00962244 1.00063762 1.10675992 1.04153782\n",
      "  1.16961908 1.03135893 1.14674267 1.06501884]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "4 loss 221682.34654556817\n",
      "dev set\n",
      "[1.00173353 0.99767074 1.00082698 1.00065621 1.0016278  1.0010503\n",
      " 1.0022318  1.00097284 1.00200984 1.00124651]\n",
      "[[1.11806717 0.8147041  1.00970867 1.00068354 1.10689096 1.04165901\n",
      "  1.16974329 1.0314718  1.14686937 1.06514968]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.0\n",
      "precision penalty\n",
      "0 loss 223659.642874426\n",
      "dev set\n",
      "[ 1.22478621e-03 -1.80851708e-03  1.44922144e-04  5.55686456e-05\n",
      "  1.11313239e-03  3.64088937e-04  1.74138171e-03  2.62759764e-04\n",
      "  1.41402890e-03  5.97914384e-04]\n",
      "[[1.11749529 0.8141652  1.00951032 1.00057497 1.10632851 1.04138784\n",
      "  1.16915666 1.03125718 1.14638406 1.0647726 ]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "1 loss 223646.89850961952\n",
      "dev set\n",
      "[ 0.00127404 -0.00175926  0.00019417  0.00010481  0.0011624   0.00031486\n",
      "  0.00179063  0.00021352  0.00136479  0.00054867]\n",
      "[[1.11744604 0.81411594 1.00946106 1.00052571 1.10627923 1.04143705\n",
      "  1.16910741 1.03130644 1.14643331 1.06482183]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "2 loss 223634.15859946463\n",
      "dev set\n",
      "[ 0.0013233  -0.00171     0.00024343  0.00015407  0.00121168  0.00026563\n",
      "  0.00183989  0.00016426  0.00131553  0.00049942]\n",
      "[[1.11739679 0.81406668 1.00941179 1.00047644 1.10622996 1.04148629\n",
      "  1.16905814 1.0313557  1.14648257 1.06487108]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "3 loss 223621.41573455112\n",
      "dev set\n",
      "[ 0.00137256 -0.00166074  0.0002927   0.00020335  0.00126095  0.00021637\n",
      "  0.00188915  0.00011499  0.00126626  0.00045014]\n",
      "[[1.11734752 0.81401741 1.00936251 1.00042716 1.10618068 1.04153554\n",
      "  1.16900887 1.03140499 1.14653185 1.06492035]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "4 loss 223608.67016474574\n",
      "dev set\n",
      "[ 1.42181592e-03 -1.61147853e-03  3.41983809e-04  2.52630185e-04\n",
      "  1.31021806e-03  1.67110315e-04  1.93842681e-03  6.56996997e-05\n",
      "  1.21697112e-03  4.00855002e-04]\n",
      "[[1.11729826 0.81396815 1.00931321 1.00037787 1.1061314  1.0415848\n",
      "  1.1689596  1.03145429 1.14658114 1.06496964]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "test set\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.1\n",
      "precision penalty\n",
      "0 loss 222447.6311719718\n",
      "dev set\n",
      "[0.10122478 0.09819148 0.10014492 0.10005557 0.10111313 0.10036409\n",
      " 0.10174138 0.10026276 0.10141403 0.10059792]\n",
      "[[1.11749529 0.8141652  1.00951032 1.00057497 1.10632851 1.04138783\n",
      "  1.16915666 1.03125718 1.14638406 1.06477259]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "1 loss 222436.93917916977\n",
      "dev set\n",
      "[0.10127404 0.09824074 0.10019416 0.10010481 0.10116241 0.10031487\n",
      " 0.10179062 0.10021353 0.1013648  0.10054868]\n",
      "[[1.11744605 0.81411595 1.00946106 1.00052571 1.10627923 1.04143705\n",
      "  1.16910741 1.03130644 1.14643331 1.06482182]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 222426.25031324377\n",
      "dev set\n",
      "[0.10132329 0.09829    0.10024342 0.10015406 0.10121168 0.10026564\n",
      " 0.10183988 0.10016427 0.10131554 0.10049943]\n",
      "[[1.11739679 0.81406669 1.00941179 1.00047645 1.10622995 1.04148628\n",
      "  1.16905815 1.0313557  1.14648257 1.06487106]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "3 loss 222415.55829435174\n",
      "dev set\n",
      "[0.10137255 0.09833926 0.10029269 0.10020334 0.10126095 0.10021639\n",
      " 0.10188914 0.100115   0.10126627 0.10045016]\n",
      "[[1.11734753 0.81401742 1.0093625  1.00042717 1.10618067 1.04153553\n",
      "  1.16900888 1.03140499 1.14653185 1.06492034]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2629, 1: 73}\n",
      "acc 0.9108068097705403\n",
      "(0.3424657534246575, 0.11467889908256881, 0.1718213058419244, None)\n",
      "\n",
      "4 loss 222404.86331091792\n",
      "dev set\n",
      "[0.10142181 0.09838851 0.10034198 0.10025262 0.10131022 0.10016712\n",
      " 0.10193841 0.10006571 0.10121698 0.10040086]\n",
      "[[1.11729828 0.81396816 1.00931321 1.00037787 1.1061314  1.04158479\n",
      "  1.16895961 1.0314543  1.14658114 1.06496963]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2630, 1: 72}\n",
      "acc 0.9111769059955589\n",
      "(0.3472222222222222, 0.11467889908256881, 0.1724137931034483, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.2\n",
      "precision penalty\n",
      "0 loss 221655.88016202\n",
      "dev set\n",
      "[0.20122478 0.19819148 0.20014491 0.20005556 0.20111313 0.2003641\n",
      " 0.20174137 0.20026277 0.20141404 0.20059792]\n",
      "[[1.1174953  0.81416521 1.00951032 1.00057496 1.10632851 1.04138783\n",
      "  1.16915666 1.03125718 1.14638406 1.06477258]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "1 loss 221647.0854415831\n",
      "dev set\n",
      "[0.20127403 0.19824074 0.20019415 0.2001048  0.20116241 0.20031488\n",
      " 0.20179061 0.20021354 0.20136481 0.20054869]\n",
      "[[1.11744605 0.81411595 1.00946106 1.00052571 1.10627923 1.04143704\n",
      "  1.16910741 1.03130644 1.14643331 1.0648218 ]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "2 loss 221638.2925626996\n",
      "dev set\n",
      "[0.20132329 0.19828999 0.20024341 0.20015406 0.20121168 0.20026565\n",
      " 0.20183986 0.20016429 0.20131556 0.20049944]\n",
      "[[1.1173968  0.81406669 1.00941179 1.00047645 1.10622995 1.04148627\n",
      "  1.16905815 1.03135571 1.14648257 1.06487104]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "3 loss 221629.49628388943\n",
      "dev set\n",
      "[0.20137254 0.19833925 0.20029268 0.20020333 0.20126095 0.2002164\n",
      " 0.20188912 0.20011501 0.20126628 0.20045017]\n",
      "[[1.11734755 0.81401743 1.0093625  1.00042716 1.10618067 1.04153552\n",
      "  1.16900889 1.031405   1.14653185 1.06492031]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "4 loss 221620.69673067218\n",
      "dev set\n",
      "[0.20142179 0.1983885  0.20034197 0.20025262 0.20131022 0.20016713\n",
      " 0.20193839 0.20006572 0.20121699 0.20040087]\n",
      "[[1.11729829 0.81396817 1.0093132  1.00037787 1.10613139 1.04158479\n",
      "  1.16895962 1.03145431 1.14658115 1.06496961]]\n",
      "{0: 2727, 1: 87}\n",
      "acc 0.9246624022743426\n",
      "(0.367816091954023, 0.1693121693121693, 0.2318840579710145, None)\n",
      "\n",
      "test set\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9104367135455218\n",
      "(0.33783783783783783, 0.11467889908256881, 0.17123287671232879, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.30000000000000004\n",
      "precision penalty\n",
      "0 loss 221241.91828165122\n",
      "dev set\n",
      "[0.30122478 0.29819147 0.30014491 0.30005556 0.30111313 0.3003641\n",
      " 0.30174136 0.30026278 0.30141405 0.30059793]\n",
      "[[1.1174953  0.81416521 1.00951032 1.00057496 1.10632852 1.04138783\n",
      "  1.16915666 1.03125719 1.14638407 1.06477256]]\n",
      "{0: 2719, 1: 95}\n",
      "acc 0.9225302061122956\n",
      "(0.3473684210526316, 0.1746031746031746, 0.2323943661971831, None)\n",
      "\n",
      "test set\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9104367135455218\n",
      "(0.34615384615384615, 0.12385321100917432, 0.18243243243243243, None)\n",
      "\n",
      "1 loss 221234.8721375328\n",
      "dev set\n",
      "[0.30127403 0.29824073 0.30019415 0.30010479 0.30116241 0.30031489\n",
      " 0.3017906  0.30021355 0.30136482 0.3005487 ]\n",
      "[[1.11744606 0.81411596 1.00946106 1.00052571 1.10627923 1.04143704\n",
      "  1.16910741 1.03130644 1.14643331 1.06482177]]\n",
      "{0: 2719, 1: 95}\n",
      "acc 0.9225302061122956\n",
      "(0.3473684210526316, 0.1746031746031746, 0.2323943661971831, None)\n",
      "\n",
      "test set\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9104367135455218\n",
      "(0.34615384615384615, 0.12385321100917432, 0.18243243243243243, None)\n",
      "\n",
      "2 loss 221227.8266654245\n",
      "dev set\n",
      "[0.30132328 0.29828999 0.3002434  0.30015405 0.30121168 0.30026566\n",
      " 0.30183984 0.3001643  0.30131557 0.30049945]\n",
      "[[1.11739681 0.8140667  1.00941178 1.00047644 1.10622995 1.04148627\n",
      "  1.16905815 1.03135571 1.14648257 1.06487101]]\n",
      "{0: 2721, 1: 93}\n",
      "acc 0.9232409381663113\n",
      "(0.3548387096774194, 0.1746031746031746, 0.2340425531914894, None)\n",
      "\n",
      "test set\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9104367135455218\n",
      "(0.34615384615384615, 0.12385321100917432, 0.18243243243243243, None)\n",
      "\n",
      "3 loss 221220.77757932738\n",
      "dev set\n",
      "[0.30137253 0.29833924 0.30029267 0.30020332 0.30126096 0.30021641\n",
      " 0.30188909 0.30011502 0.3012663  0.30045018]\n",
      "[[1.11734756 0.81401744 1.00936249 1.00042716 1.10618067 1.04153552\n",
      "  1.16900889 1.03140501 1.14653185 1.06492028]]\n",
      "{0: 2722, 1: 92}\n",
      "acc 0.9235963041933192\n",
      "(0.358695652173913, 0.1746031746031746, 0.23487544483985762, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "4 loss 221213.72494296217\n",
      "dev set\n",
      "[0.30142178 0.29838849 0.30034196 0.30025261 0.30131022 0.30016714\n",
      " 0.30193836 0.30006573 0.301217   0.30040088]\n",
      "[[1.11729831 0.81396819 1.00931319 1.00037787 1.10613139 1.04158479\n",
      "  1.16895962 1.03145432 1.14658115 1.06496957]]\n",
      "{0: 2723, 1: 91}\n",
      "acc 0.923951670220327\n",
      "(0.3626373626373626, 0.1746031746031746, 0.23571428571428568, None)\n",
      "\n",
      "test set\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9111769059955589\n",
      "(0.35526315789473684, 0.12385321100917432, 0.1836734693877551, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.4\n",
      "precision penalty\n",
      "0 loss 221130.25579687025\n",
      "dev set\n",
      "[0.40122478 0.39819147 0.4001449  0.40005555 0.40111313 0.40036411\n",
      " 0.40174136 0.40026279 0.40141406 0.40059794]\n",
      "[[1.11749531 0.81416523 1.00951031 1.00057496 1.10632853 1.04138782\n",
      "  1.16915665 1.0312572  1.14638408 1.06477254]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "1 loss 221124.8225786091\n",
      "dev set\n",
      "[0.40127402 0.39824072 0.40019413 0.40010478 0.40116241 0.4003149\n",
      " 0.40179058 0.40021356 0.40136483 0.40054872]\n",
      "[[1.11744607 0.81411597 1.00946105 1.0005257  1.10627924 1.04143703\n",
      "  1.1691074  1.03130646 1.14643332 1.06482173]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "2 loss 221119.38904350653\n",
      "dev set\n",
      "[0.40132327 0.39828998 0.40024339 0.40015403 0.40121168 0.40026567\n",
      " 0.40183981 0.40016432 0.40131559 0.40049947]\n",
      "[[1.11739683 0.81406672 1.00941177 1.00047644 1.10622995 1.04148626\n",
      "  1.16905815 1.03135573 1.14648258 1.06487096]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n",
      "3 loss 221113.95178783292\n",
      "dev set\n",
      "[0.40137252 0.39833923 0.40029266 0.40020331 0.40126096 0.40021642\n",
      " 0.40188906 0.40011504 0.40126631 0.4004502 ]\n",
      "[[1.11734758 0.81401746 1.00936247 1.00042716 1.10618067 1.04153551\n",
      "  1.16900889 1.03140503 1.14653185 1.06492023]]\n",
      "{0: 2716, 1: 98}\n",
      "acc 0.9228855721393034\n",
      "(0.35714285714285715, 0.18518518518518517, 0.24390243902439024, None)\n",
      "\n",
      "test set\n",
      "{0: 2615, 1: 87}\n",
      "acc 0.9108068097705403\n",
      "(0.367816091954023, 0.14678899082568808, 0.2098360655737705, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 221108.51081666892\n",
      "dev set\n",
      "[0.40142176 0.39838848 0.40034195 0.4002526  0.40131023 0.40016715\n",
      " 0.40193833 0.40006574 0.40121701 0.4004009 ]\n",
      "[[1.11729834 0.81396821 1.00931317 1.00037786 1.10613139 1.04158479\n",
      "  1.16895963 1.03145435 1.14658115 1.06496952]]\n",
      "{0: 2717, 1: 97}\n",
      "acc 0.9225302061122956\n",
      "(0.35051546391752575, 0.17989417989417988, 0.23776223776223773, None)\n",
      "\n",
      "test set\n",
      "{0: 2616, 1: 86}\n",
      "acc 0.9111769059955589\n",
      "(0.37209302325581395, 0.14678899082568808, 0.2105263157894737, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.5\n",
      "precision penalty\n",
      "0 loss 221216.8730794584\n",
      "dev set\n",
      "[0.50122477 0.49819146 0.50014488 0.50005552 0.50111312 0.50036412\n",
      " 0.50174139 0.50026281 0.50141409 0.50059797]\n",
      "[[1.11749531 0.81416524 1.0095103  1.00057494 1.10632855 1.04138782\n",
      "  1.16915662 1.03125722 1.14638411 1.06477249]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2603, 1: 99}\n",
      "acc 0.9078460399703923\n",
      "(0.3434343434343434, 0.1559633027522936, 0.21451104100946375, None)\n",
      "\n",
      "1 loss 221213.1274174122\n",
      "dev set\n",
      "[0.50127401 0.49824071 0.5001941  0.50010473 0.5011624  0.50031491\n",
      " 0.50179065 0.5002136  0.5013649  0.50054876]\n",
      "[[1.11744609 0.814116   1.00946103 1.00052569 1.10627926 1.04143702\n",
      "  1.16910737 1.03130648 1.14643333 1.06482165]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2603, 1: 99}\n",
      "acc 0.9078460399703923\n",
      "(0.3434343434343434, 0.1559633027522936, 0.21451104100946375, None)\n",
      "\n",
      "2 loss 221209.38095690703\n",
      "dev set\n",
      "[0.50132325 0.49828997 0.50024335 0.50015396 0.50121168 0.50026568\n",
      " 0.5018399  0.50016437 0.50131568 0.50049952]\n",
      "[[1.11739685 0.81406674 1.00941174 1.00047643 1.10622997 1.04148625\n",
      "  1.16905813 1.03135576 1.14648256 1.06487085]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "3 loss 221205.63136186745\n",
      "dev set\n",
      "[0.5013725  0.49833922 0.50029262 0.50020322 0.50126096 0.50021643\n",
      " 0.50188916 0.5001151  0.50126642 0.50045026]\n",
      "[[1.11734761 0.81401749 1.00936244 1.00042716 1.10618069 1.0415355\n",
      "  1.16900888 1.03140506 1.1465318  1.06492009]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "4 loss 221201.87863872398\n",
      "dev set\n",
      "[0.50142174 0.49838846 0.50034191 0.5002525  0.50131023 0.50016716\n",
      " 0.50193843 0.5000658  0.50121714 0.50040096]\n",
      "[[1.11729838 0.81396825 1.00931313 1.00037787 1.10613142 1.04158479\n",
      "  1.16895963 1.03145438 1.14658108 1.06496937]]\n",
      "{0: 2701, 1: 113}\n",
      "acc 0.9189765458422174\n",
      "(0.3274336283185841, 0.19576719576719576, 0.24503311258278143, None)\n",
      "\n",
      "test set\n",
      "{0: 2604, 1: 98}\n",
      "acc 0.9082161361954109\n",
      "(0.3469387755102041, 0.1559633027522936, 0.21518987341772153, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6000000000000001\n",
      "precision penalty\n",
      "0 loss 221507.00692091972\n",
      "dev set\n",
      "[0.60122476 0.59819144 0.60014488 0.60005552 0.6011131  0.60036411\n",
      " 0.60174153 0.60026283 0.60141409 0.60059801]\n",
      "[[1.11749533 0.81416528 1.00951026 1.00057489 1.10632859 1.04138783\n",
      "  1.16915661 1.03125729 1.14638415 1.06477232]]\n",
      "{0: 2673, 1: 141}\n",
      "acc 0.9076048329779673\n",
      "(0.24822695035460993, 0.18518518518518517, 0.21212121212121213, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "1 loss 221504.82132273528\n",
      "dev set\n",
      "[0.60127399 0.59824069 0.60019409 0.6001047  0.60116239 0.6003149\n",
      " 0.60179077 0.60021365 0.60136492 0.60054883]\n",
      "[[1.11744612 0.81411605 1.00946097 1.00052565 1.10627931 1.04143703\n",
      "  1.16910736 1.03130654 1.14643322 1.06482133]]\n",
      "{0: 2674, 1: 140}\n",
      "acc 0.9079601990049752\n",
      "(0.25, 0.18518518518518517, 0.2127659574468085, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "2 loss 221502.63498841628\n",
      "dev set\n",
      "[0.60132323 0.59828994 0.60024333 0.60015392 0.60121167 0.60026567\n",
      " 0.60183999 0.60016443 0.60131572 0.60049962]\n",
      "[[1.1173969  0.81406681 1.00941168 1.00047642 1.10623003 1.04148626\n",
      "  1.16905812 1.03135578 1.14648227 1.0648704 ]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "3 loss 221500.44611057732\n",
      "dev set\n",
      "[0.60137246 0.59833918 0.6002926  0.60020316 0.60126095 0.60021641\n",
      " 0.60188921 0.60011517 0.60126648 0.60045037]\n",
      "[[1.11734767 0.81401757 1.00936238 1.00042719 1.10618076 1.04153553\n",
      "  1.16900889 1.03140505 1.14653133 1.06491953]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "4 loss 221498.25452738302\n",
      "dev set\n",
      "[0.60142169 0.59838842 0.6003419  0.60025244 0.60131022 0.60016713\n",
      " 0.60193843 0.60006588 0.6012172  0.60040107]\n",
      "[[1.11729845 0.81396834 1.00931307 1.00037794 1.1061315  1.04158482\n",
      "  1.16895965 1.03145434 1.14658042 1.06496872]]\n",
      "{0: 2676, 1: 138}\n",
      "acc 0.9086709310589908\n",
      "(0.2536231884057971, 0.18518518518518517, 0.21406727828746178, None)\n",
      "\n",
      "test set\n",
      "{0: 2561, 1: 141}\n",
      "acc 0.8945225758697262\n",
      "(0.2624113475177305, 0.16972477064220184, 0.20612813370473534, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7000000000000001\n",
      "precision penalty\n",
      "0 loss 221690.25883782518\n",
      "dev set\n",
      "[0.70122474 0.69819139 0.70014498 0.70005564 0.70111306 0.70036405\n",
      " 0.70174139 0.70026269 0.70141406 0.70059803]\n",
      "[[1.11749536 0.8141654  1.00951024 1.00057499 1.10632876 1.04138788\n",
      "  1.16915666 1.03125725 1.14638327 1.06476125]]\n",
      "{0: 2549, 1: 265}\n",
      "acc 0.9068941009239516\n",
      "(0.3622641509433962, 0.5079365079365079, 0.42290748898678415, None)\n",
      "\n",
      "test set\n",
      "{0: 2374, 1: 328}\n",
      "acc 0.8934122871946706\n",
      "(0.3932926829268293, 0.591743119266055, 0.4725274725274725, None)\n",
      "\n",
      "1 loss 221689.536057113\n",
      "dev set\n",
      "[0.70127395 0.69824062 0.70019414 0.70010472 0.70116234 0.70031483\n",
      " 0.70179057 0.7002136  0.70136545 0.70054902]\n",
      "[[1.11744618 0.81411623 1.00946107 1.000526   1.10627954 1.0414371\n",
      "  1.16910743 1.03130614 1.146431   1.06479857]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2374, 1: 328}\n",
      "acc 0.8934122871946706\n",
      "(0.3932926829268293, 0.591743119266055, 0.4725274725274725, None)\n",
      "\n",
      "2 loss 221688.8140286324\n",
      "dev set\n",
      "[0.70132317 0.69828985 0.7002433  0.70015378 0.70121162 0.7002656\n",
      " 0.70183975 0.70016451 0.70131687 0.70049999]\n",
      "[[1.11739699 0.81406706 1.00941191 1.00047703 1.10623034 1.04148634\n",
      "  1.16905821 1.03135499 1.14647865 1.06483623]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2374, 1: 328}\n",
      "acc 0.8934122871946706\n",
      "(0.3932926829268293, 0.591743119266055, 0.4725274725274725, None)\n",
      "\n",
      "3 loss 221688.09098692765\n",
      "dev set\n",
      "[0.70137239 0.69833908 0.70029248 0.70020285 0.70126088 0.70021634\n",
      " 0.70188893 0.7001154  0.70126814 0.70045092]\n",
      "[[1.1173478  0.81401788 1.00936274 1.00042806 1.10618115 1.0415356\n",
      "  1.16900898 1.03140384 1.14652628 1.06487422]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "4 loss 221687.36691267366\n",
      "dev set\n",
      "[0.7014216  0.69838829 0.70034169 0.70025193 0.70131013 0.70016707\n",
      " 0.70193812 0.70006626 0.70121925 0.70040182]\n",
      "[[1.1172986  0.81396872 1.00931357 1.00037909 1.10613199 1.04158489\n",
      "  1.16895976 1.03145272 1.14657391 1.06491251]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "test set\n",
      "{0: 2375, 1: 327}\n",
      "acc 0.8937823834196891\n",
      "(0.3944954128440367, 0.591743119266055, 0.4733944954128441, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "precision penalty\n",
      "0 loss 221652.57591238953\n",
      "dev set\n",
      "[0.80122469 0.79819113 0.8001446  0.80005501 0.80111263 0.800364\n",
      " 0.80174141 0.80026798 0.80142886 0.80069582]\n",
      "[[1.11749546 0.81416617 1.0095222  1.00058537 1.10633071 1.04138794\n",
      "  1.16915667 1.03125624 1.14638132 1.06467713]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 221652.37932760434\n",
      "dev set\n",
      "[0.80127384 0.79824018 0.80019294 0.80010301 0.80116171 0.80031476\n",
      " 0.80179067 0.80022536 0.80139509 0.80074444]\n",
      "[[1.11744639 0.81411769 1.00948744 1.00055085 1.10628265 1.04143717\n",
      "  1.16910745 1.03130351 1.14642695 1.06463055]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "2 loss 221652.18341036356\n",
      "dev set\n",
      "[0.801323   0.79828923 0.8002412  0.80015092 0.80121077 0.80026552\n",
      " 0.80183992 0.8001829  0.80136145 0.800793  ]\n",
      "[[1.1173973  0.81406918 1.00945293 1.00051674 1.10623457 1.0414864\n",
      "  1.16905824 1.03135065 1.14647246 1.06458392]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "3 loss 221651.98748936565\n",
      "dev set\n",
      "[0.80137217 0.79833828 0.80028945 0.80019881 0.8012598  0.80021627\n",
      " 0.80188916 0.80014046 0.8013278  0.8008415 ]\n",
      "[[1.11734819 0.81402067 1.00941843 1.00048266 1.10618652 1.04153566\n",
      "  1.16900904 1.03139777 1.14651794 1.06453733]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "4 loss 221651.79145974616\n",
      "dev set\n",
      "[0.80142134 0.79838732 0.8003377  0.8002467  0.8013088  0.800167\n",
      " 0.8019384  0.80009797 0.80129407 0.80088994]\n",
      "[[1.11729908 0.81397218 1.00938387 1.00044852 1.10613852 1.04158496\n",
      "  1.16895984 1.03144489 1.1465634  1.06449081]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "test set\n",
      "{0: 2289, 1: 413}\n",
      "acc 0.8782383419689119\n",
      "(0.36561743341404357, 0.6926605504587156, 0.47860538827258314, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "precision penalty\n",
      "0 loss 221635.21589764164\n",
      "dev set\n",
      "[0.90122439 0.89818537 0.90005027 0.89995981 0.90108716 0.90046273\n",
      " 0.90174136 0.9002649  0.90141814 0.90068017]\n",
      "[[1.11749606 0.81420781 1.00960863 1.0006736  1.10640035 1.0412892\n",
      "  1.16915673 1.03125717 1.14638373 1.06469966]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "1 loss 221635.18018387386\n",
      "dev set\n",
      "[0.90127321 0.8982281  0.90000586 0.89991421 0.90111718 0.90051199\n",
      " 0.9017905  0.90021971 0.90137451 0.90072336]\n",
      "[[1.11744771 0.81420575 1.0096576  1.00072276 1.10642677 1.04123995\n",
      "  1.16910769 1.03130583 1.14643201 1.06466445]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "2 loss 221635.14469178597\n",
      "dev set\n",
      "[0.90132207 0.89827081 0.89996161 0.89986879 0.90114807 0.90056123\n",
      " 0.90183963 0.90017472 0.90133107 0.90076685]\n",
      "[[1.11739929 0.81420395 1.00970653 1.00077182 1.10645326 1.04119072\n",
      "  1.16905866 1.03135441 1.14648019 1.06462854]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "3 loss 221635.10926524567\n",
      "dev set\n",
      "[0.90137095 0.8983135  0.89991745 0.89982351 0.90117917 0.90061047\n",
      " 0.90188877 0.90012983 0.9012877  0.9008104 ]\n",
      "[[1.11735084 0.81420227 1.00975542 1.00082081 1.10647992 1.0411415\n",
      "  1.16900963 1.03140296 1.14652832 1.06459247]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "4 loss 221635.07388264703\n",
      "dev set\n",
      "[0.90141985 0.89835616 0.89987337 0.89977833 0.90121032 0.9006597\n",
      " 0.90193789 0.90008497 0.90124438 0.90085395]\n",
      "[[1.11730237 0.81420069 1.00980429 1.00086976 1.10650675 1.0410923\n",
      "  1.16896062 1.03145149 1.14657644 1.06455637]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "test set\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n",
      "precision penalty\n",
      "0 loss 221674.73949734212\n",
      "dev set\n",
      "[1.00122492 0.99809362 1.00014453 1.00001149 1.00111327 1.00046302\n",
      " 1.0017415  1.00036175 1.0015128  1.00069679]\n",
      "[[1.11758478 0.81426298 1.00955983 1.00062431 1.10641555 1.04134694\n",
      "  1.16925195 1.03121199 1.14637892 1.06474444]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "1 loss 221674.73948091897\n",
      "dev set\n",
      "[1.00127506 0.99804557 1.00019867 1.00003549 1.00116349 1.00051445\n",
      " 1.00179138 1.00041369 1.00156278 1.00074755]\n",
      "[[1.11763009 0.81431128 1.00956051 1.00062431 1.10645938 1.04136256\n",
      "  1.16930029 1.03122081 1.14642641 1.06477528]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "2 loss 221674.73946391902\n",
      "dev set\n",
      "[1.00132645 0.99799728 1.00025932 1.00008802 1.00121508 1.0005689\n",
      " 1.00184216 1.00046933 1.00161378 1.00080042]\n",
      "[[1.11767841 0.81436021 1.00956248 1.00062433 1.10650672 1.04138509\n",
      "  1.16935037 1.03123522 1.14647606 1.06481261]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "3 loss 221674.7394461914\n",
      "dev set\n",
      "[1.00137941 0.99794866 1.00032661 1.00015666 1.00126838 1.00062699\n",
      " 1.00189407 1.00052931 1.00166607 1.00085589]\n",
      "[[1.11772968 0.81440997 1.00956727 1.00062457 1.10655741 1.0414151\n",
      "  1.16940234 1.03125665 1.14652796 1.06485592]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n",
      "4 loss 221674.7394276397\n",
      "dev set\n",
      "[1.00143408 0.99789965 1.00039997 1.00023544 1.00132356 1.00068891\n",
      " 1.00194721 1.00059376 1.00171977 1.00091418]\n",
      "[[1.11778389 0.81446063 1.00957725 1.00062587 1.1066114  1.04145307\n",
      "  1.16945629 1.03128639 1.14658216 1.06490499]]\n",
      "{0: 2796, 1: 18}\n",
      "acc 0.9314143567874911\n",
      "(0.3888888888888889, 0.037037037037037035, 0.06763285024154589, None)\n",
      "\n",
      "test set\n",
      "{0: 2681, 1: 21}\n",
      "acc 0.9174685418208735\n",
      "(0.38095238095238093, 0.03669724770642202, 0.06694560669456068, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.empty([len(LF_l)],dtype=np.float64)\n",
    "a.fill(0.5)\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [512,1024,2048]:\n",
    "    for i in np.linspace(0,1,11):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = a ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=4,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 32\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 194076.24123840564\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11442187 0.81109423 1.00647734 0.997539   1.10325496 1.04438816\n",
      "  1.16608175 1.03416844 1.14927513 1.06772651]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 193759.15882109336\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11130766 0.80798234 1.00339696 0.99444883 1.10014142 1.0474505\n",
      "  1.162967   1.03706816 1.15213361 1.07073351]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 193445.46587211205\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10819913 0.80487696 1.0003221  0.99136355 1.09703392 1.0505097\n",
      "  1.1598579  1.03994505 1.15496302 1.07371192]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 193135.18637982037\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10509494 0.80177655 0.99725208 0.98828281 1.09393089 1.05356539\n",
      "  1.15675309 1.04280333 1.15776828 1.07666524]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 192828.22070732564\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10199396 0.79867981 0.99418591 0.98520571 1.09083114 1.05661803\n",
      "  1.15365142 1.0456455  1.16055212 1.07959694]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "batch-size: 64\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 191999.31001340266\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.1159801  0.81265088 1.00800679 0.99907298 1.10481282 1.04287834\n",
      "  1.16764077 1.0327388  1.14786413 1.06624863]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 191839.00941115766\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11441939 0.81109077 1.00645563 0.99751955 1.10325205 1.04442399\n",
      "  1.16607985 1.03424399 1.14935938 1.06778015]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 191679.5074135533\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11286034 0.80953258 1.00490582 0.99596708 1.10169313 1.04596944\n",
      "  1.1645206  1.03574241 1.15084612 1.06930392]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 191520.89846795175\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11130289 0.80797625 1.00335763 0.9944161  1.10013589 1.04751395\n",
      "  1.16296294 1.03723516 1.15232572 1.07081975]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 191363.18029488987\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10974689 0.80642157 1.00181101 0.99286659 1.09858015 1.04905743\n",
      "  1.16140671 1.03872288 1.15379895 1.0723282 ]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "batch-size: 128\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190980.42345982065\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11676001 0.81343022 1.00877836 0.99984457 1.10559288 1.04211494\n",
      "  1.16842106 1.03198565 1.14711717 1.06549532]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 190899.76370408904\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11597806 0.81264841 1.00799918 0.99906518 1.10481079 1.04289234\n",
      "  1.16763902 1.03275308 1.14788269 1.06626904]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 190819.24683499002\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11519636 0.81186694 1.00722001 0.99828562 1.10402907 1.04367018\n",
      "  1.16685726 1.03351878 1.14864566 1.06704109]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 190738.9414213494\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11441507 0.81108594 1.00644118 0.99750632 1.10324779 1.04444796\n",
      "  1.1660759  1.03428293 1.14940654 1.06781103]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 190658.86168740023\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11363421 0.81030543 1.00566278 0.99672741 1.10246695 1.04522553\n",
      "  1.16529496 1.03504562 1.15016552 1.0685788 ]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "batch-size: 512\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190279.63633535107\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11734734 0.81401729 1.00936257 1.00042755 1.10618052 1.04153501\n",
      "  1.16900867 1.03140532 1.14653287 1.0649193 ]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 190259.2954241623\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11715091 0.81382086 1.00916647 1.00023154 1.10598402 1.04173089\n",
      "  1.16881221 1.0316007  1.14672802 1.065115  ]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 190238.94957893435\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11695432 0.81362427 1.00897015 1.00003526 1.10578739 1.04192708\n",
      "  1.16861561 1.03179604 1.14692298 1.06531087]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 190218.60140712632\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11675768 0.81342764 1.00877374 0.99983887 1.10559071 1.04212341\n",
      "  1.16841896 1.0319913  1.14711781 1.06550672]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 190198.26027300398\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11656102 0.813231   1.00857731 0.99964245 1.10539403 1.04231979\n",
      "  1.1682223  1.03218648 1.1473125  1.06570248]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "batch-size: 1024\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190186.96118412152\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11744596 0.81411588 1.00946103 1.00052579 1.10627918 1.04143697\n",
      "  1.16910731 1.03130665 1.1464338  1.06482156]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 190176.75938143133\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11734758 0.8140175  1.0093628  1.00042761 1.10618078 1.04153509\n",
      "  1.16900893 1.03140483 1.14653195 1.06491966]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 190166.56134357644\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11724915 0.81391906 1.00926448 1.00032933 1.10608232 1.04163334\n",
      "  1.16891049 1.03150299 1.14663004 1.06501786]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 190156.3595801088\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11715067 0.81382058 1.00916611 1.00023098 1.10598383 1.04173165\n",
      "  1.16881201 1.03160116 1.14672809 1.06511609]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 190146.1571273422\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11705218 0.81372209 1.00906771 1.00013261 1.10588532 1.04183\n",
      "  1.16871352 1.03169931 1.14682611 1.06521431]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "batch-size: 2048\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190148.2683951757\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11749529 0.81416519 1.00951032 1.00057501 1.10632852 1.04138781\n",
      "  1.16915665 1.03125726 1.14638418 1.06477252]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 190143.1565284531\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11744602 0.81411593 1.00946111 1.00052581 1.10627925 1.04143698\n",
      "  1.16910739 1.0313065  1.14643341 1.06482169]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 190138.047743283\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11739675 0.81406665 1.00941189 1.0004766  1.10622997 1.04148616\n",
      "  1.16905811 1.03135573 1.1464826  1.06487087]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 190132.93840468605\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11734747 0.81401737 1.00936266 1.00042738 1.10618068 1.04153537\n",
      "  1.16900883 1.03140496 1.14653179 1.06492006]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 190127.8285770832\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11729818 0.81396808 1.00931341 1.00037814 1.10613138 1.04158458\n",
      "  1.16895954 1.03145418 1.14658096 1.06496927]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in [32,64,128,512,1024,2048]:\n",
    "    print(\"batch-size:\",b)\n",
    "    train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(0,0.001,seed),\\\n",
    "                                LF_acc = get_LF_acc(dev_L_S,gold_labels_dev) ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                norm=True,smooth=False,penalty=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 32\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 191004.97299376698\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.05046739 0.74753509 0.94381144 0.93478734 1.03929744 1.10701521\n",
      "  1.10204145 1.08907541 1.20153912 1.11674167]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "1 loss 185851.3357691606\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[0.989175   0.68753803 0.88489167 0.87550729 0.97804014 1.16788496\n",
      "  1.04054882 1.12098156 1.22092219 1.10928555]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "2 loss 182156.79791380258\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[0.93212529 0.63277197 0.83153932 0.8216209  0.92105164 1.22506825\n",
      "  0.98316046 1.11924539 1.19400962 1.03269697]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "3 loss 179133.15308558205\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[0.87727238 0.58112036 0.78167621 0.7710377  0.86626633 1.28056282\n",
      "  0.92784622 1.08552717 1.13591773 0.9439649 ]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "4 loss 176477.80983678324\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[0.82391423 0.53197891 0.73478342 0.72319797 0.81297609 1.33505686\n",
      "  0.8738989  1.03145839 1.06695089 0.85910137]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "batch-size: 64\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190372.69727217496\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.08326091 0.7800262  0.97562564 0.96672174 1.07208203 1.0751333\n",
      "  1.13489453 1.0636114  1.17828451 1.09574942]]\n",
      "{0: 2515, 1: 299}\n",
      "acc 0.900497512437811\n",
      "(0.34782608695652173, 0.5502645502645502, 0.4262295081967213, None)\n",
      "\n",
      "test set\n",
      "{0: 2334, 1: 368}\n",
      "acc 0.8926720947446336\n",
      "(0.40217391304347827, 0.6788990825688074, 0.5051194539249146, None)\n",
      "\n",
      "1 loss 187293.52151850145\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.05043632 0.74748445 0.9433447  0.93436749 1.03925815 1.10783073\n",
      "  1.10202368 1.09075346 1.20333657 1.11785309]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "2 loss 184729.33969632062\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.01911884 0.71668899 0.91286358 0.9037764  1.00795142 1.13919716\n",
      "  1.07062574 1.11142712 1.21932428 1.12446288]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "3 loss 182606.69042783175\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[0.98918175 0.68753185 0.88409298 0.87485839 0.97803304 1.16934824\n",
      "  1.0405712  1.12402813 1.22321346 1.10854156]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "4 loss 180787.06206774316\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[0.96028087 0.65965734 0.85667682 0.84725822 0.94915569 1.19863041\n",
      "  1.01151813 1.12741864 1.21327464 1.07259371]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "batch-size: 128\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190146.08489934003\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10019132 0.79688462 0.99229921 0.98339829 1.08901607 1.05852355\n",
      "  1.15184303 1.04817553 1.16332452 1.08130898]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 188469.08664866403\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.08321859 0.77997465 0.9754585  0.96654926 1.07204042 1.07544932\n",
      "  1.13485901 1.06392956 1.17869108 1.0962146 ]]\n",
      "{0: 2515, 1: 299}\n",
      "acc 0.900497512437811\n",
      "(0.34782608695652173, 0.5502645502645502, 0.4262295081967213, None)\n",
      "\n",
      "test set\n",
      "{0: 2334, 1: 368}\n",
      "acc 0.8926720947446336\n",
      "(0.40217391304347827, 0.6788990825688074, 0.5051194539249146, None)\n",
      "\n",
      "2 loss 186923.59539151718\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.06660095 0.76347058 0.95902728 0.95010105 1.05542284 1.09207458\n",
      "  1.11822306 1.07847531 1.1924716  1.10883295]]\n",
      "{0: 2517, 1: 297}\n",
      "acc 0.900497512437811\n",
      "(0.3468013468013468, 0.544973544973545, 0.4238683127572016, None)\n",
      "\n",
      "test set\n",
      "{0: 2335, 1: 367}\n",
      "acc 0.8930421909696521\n",
      "(0.4032697547683924, 0.6788990825688074, 0.505982905982906, None)\n",
      "\n",
      "3 loss 185511.86991136323\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.05035964 0.74739885 0.94303886 0.93408827 1.0391837  1.10836928\n",
      "  1.10195531 1.09161209 1.2043412  1.11845168]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "4 loss 184230.11968958564\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.03450252 0.73177198 0.92750954 0.91852692 1.02333076 1.12432312\n",
      "  1.08606291 1.10311869 1.21390727 1.12414477]]\n",
      "{0: 2522, 1: 292}\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.8915618060695781\n",
      "(0.39669421487603307, 0.6605504587155964, 0.49569707401032703, None)\n",
      "\n",
      "batch-size: 512\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190070.44850940816\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11315418 0.80982564 1.00517418 0.9962463  1.10198603 1.04571119\n",
      "  1.16481441 1.03559505 1.15073478 1.06906923]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 189623.9927740934\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10879929 0.80547346 1.00082993 0.99190382 1.09762966 1.05005652\n",
      "  1.16045869 1.03988815 1.15500875 1.07333001]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 189185.14832040507\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10446047 0.80114007 0.99650318 0.98757763 1.09328986 1.05439209\n",
      "  1.15611881 1.0441236  1.15920788 1.07749902]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 188754.19211160485\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10014063 0.79682845 0.99219785 0.98327227 1.08896926 1.05871299\n",
      "  1.15179753 1.0482981  1.16332926 1.08156515]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 188331.4252256391\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.09584107 0.79254002 0.98791575 0.97898971 1.08466911 1.0630172\n",
      "  1.14749614 1.05240869 1.16736916 1.08552011]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "batch-size: 1024\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190084.50226686918\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11534728 0.81201759 1.00736348 0.99843053 1.10418014 1.04353035\n",
      "  1.16700834 1.03340718 1.14853992 1.06690917]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 189858.75514250092\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11315953 0.80983025 1.00517941 0.99624764 1.10199172 1.04571306\n",
      "  1.16482036 1.03558387 1.15071385 1.06907757]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 189634.90520075132\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11097479 0.80764652 1.00299849 0.99406748 1.09980649 1.04789462\n",
      "  1.16263536 1.0377479  1.15287076 1.0712272 ]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 189412.90728015162\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10879401 0.80546743 1.00082192 0.99189145 1.09762534 1.0500736\n",
      "  1.16045426 1.03989812 1.15500982 1.07335454]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 189192.86654528618\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.10661774 0.80329352 0.99865041 0.98972034 1.09544875 1.05224919\n",
      "  1.15827758 1.04203387 1.15713046 1.07545783]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "batch-size: 2048\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190099.40944124435\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11644554 0.81311549 1.00846079 0.99952619 1.10527864 1.04243593\n",
      "  1.16810682 1.03230828 1.14743646 1.06581937]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 189985.87889610248\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11534873 0.81201871 1.00736522 0.99843098 1.10418159 1.04353065\n",
      "  1.16700993 1.03340366 1.14853112 1.06691208]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 189872.82387557707\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11425249 0.81092261 1.00627032 0.99733631 1.10308516 1.04462511\n",
      "  1.16591362 1.0344966  1.14962242 1.06800153]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 189760.202788305\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.113157   0.80982739 1.00517625 0.99624239 1.1019895  1.04571916\n",
      "  1.16481804 1.03558668 1.15070998 1.06908662]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 189648.04097859588\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11206243 0.80873326 1.0040832  0.99514943 1.1008948  1.0468126\n",
      "  1.16372337 1.03667358 1.15179343 1.0701666 ]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "batch-size: 4096\n",
      "{1: 189, -1: 2625}\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision constraints penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 190109.96797280968\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11695004 0.81361994 1.00896526 1.00003012 1.10578317 1.04193265\n",
      "  1.16861139 1.03180258 1.1469298  1.06531725]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "1 loss 190049.06125400894\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11636737 0.81303723 1.00838361 0.99944854 1.10520035 1.04251389\n",
      "  1.1680287  1.03238393 1.1475105  1.06589852]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "2 loss 189988.89682882637\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11578611 0.81245595 1.00780352 0.99886848 1.10461894 1.04309359\n",
      "  1.16744742 1.03296336 1.14808899 1.06647778]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "3 loss 189928.93411281198\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.1152052  0.81187504 1.00722385 0.99828881 1.10403789 1.04367294\n",
      "  1.16686649 1.03354196 1.14866642 1.06705595]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n",
      "4 loss 189869.0994157487\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04\n",
      "  1.46334713e-03  6.47232968e-04]\n",
      "[[1.11462437 0.81129424 1.00664431 0.99770927 1.10345692 1.04425223\n",
      "  1.16628565 1.03411995 1.14924303 1.06763314]]\n",
      "{0: 2498, 1: 316}\n",
      "acc 0.8958777540867093\n",
      "(0.33544303797468356, 0.5608465608465608, 0.41980198019801984, None)\n",
      "\n",
      "test set\n",
      "{0: 2321, 1: 381}\n",
      "acc 0.8886010362694301\n",
      "(0.3910761154855643, 0.6834862385321101, 0.4974958263772954, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in [32,64,128,512,1024,2048,4096]:\n",
    "    print(\"batch-size:\",b)\n",
    "    train(0.0001,5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(0,0.001,seed),\\\n",
    "                                LF_acc = get_LF_acc(dev_L_S,gold_labels_dev) ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                norm=True,smooth=False,penalty=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(2, 4), dtype=int32)\n",
      "L_a Tensor(\"Const_3:0\", shape=(2,), dtype=int32)\n",
      "2\n",
      "<dtype: 'int32'>\n",
      "<dtype: 'int32'>\n",
      "<dtype: 'int32'>\n",
      "<dtype: 'int32'>\n",
      "Tensor(\"gather_cols/Reshape_3:0\", shape=(?, ?), dtype=int32)\n",
      "Tensor(\"gather_cols_1/Reshape_3:0\", shape=(?, ?), dtype=int32)\n",
      "Tensor(\"Squeeze:0\", shape=(?,), dtype=bool)\n",
      "Tensor(\"Const_2:0\", shape=(2, 4), dtype=int32)\n",
      "Tensor(\"boolean_mask/Gather:0\", shape=(?, 4), dtype=int32)\n",
      "Tensor(\"MatMul:0\", shape=(?, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 2\n",
    "k = tf.constant([[1,2,3,4]])\n",
    "thetas = tf.constant([[1,2,3,4]])\n",
    "l =  tf.constant([[1, 2, 3, 4],[3, 3, 3, 4]])\n",
    "L_a = tf.constant([1,2])\n",
    "print(l)\n",
    "print(\"L_a\",L_a)\n",
    "print(l.shape[0])\n",
    "# print(c)\n",
    "# print(s)\n",
    "# gc = tf.squeeze(gather_cols(s,[3]))\n",
    "# print(gc)\n",
    "# wh = tf.where(tf.equal(gc,2),tf.constant(True),tf.constant(False))\n",
    "# w,g = tf.Session().run([wh,gc])\n",
    "# print(w,g)\n",
    "# m = tf.fill(\n",
    "#     [1,7],\n",
    "#     True,\n",
    "#     name=None\n",
    "# )\n",
    "# tf.Session().run(m)\n",
    "BATCH_SIZE = 2\n",
    "Lj = gather_cols(l,[j])\n",
    "kj = gather_cols(k,[j])\n",
    "print(Lj)\n",
    "print(kj)\n",
    "mask = tf.squeeze(tf.equal(Lj,kj),[1])\n",
    "\n",
    "print(mask)\n",
    "print(l)\n",
    "L_ij_equals_kj = tf.boolean_mask(l,mask)\n",
    "print(L_ij_equals_kj)\n",
    "prec_t_pout = tf.matmul(L_ij_equals_kj*kj, thetas,transpose_b=True)\n",
    "print(prec_t_pout)\n",
    "f = tf.reduce_sum(tf.expand_dims(L_a,1) - prec_t_pout)\n",
    "sft = tf.nn.softplus(f,name=\"sft\")\n",
    "tf.Session().run([prec_t_pout,f,sft])\n",
    "np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_107:0\", shape=(2, 4), dtype=int32)\n",
      "Tensor(\"Const_108:0\", shape=(2,), dtype=bool)\n",
      "Tensor(\"boolean_mask_9/Gather:0\", shape=(?, 4), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l =  tf.constant([[1, 2, 3, 4],[3,4,5,6]])\n",
    "mask = tf.constant([True,False])\n",
    "print(l)\n",
    "print(mask)\n",
    "L_ij_equals_kj = tf.boolean_mask(l,mask)\n",
    "print(L_ij_equals_kj)\n",
    "tf.Session().run(L_ij_equals_kj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 2, 3, 4]], dtype=int32), 2]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 1\n",
    "\n",
    "l =  tf.constant([[1, 2, 3, 4],[1, 3, 3, 4]])\n",
    "k = tf.constant([1,2,3,4])\n",
    "kj = tf.gather(k,j)\n",
    "col = tf.map_fn(lambda li : tf.gather(li,j),l)\n",
    "eq = tf.where(tf.equal(col,kj))\n",
    "leqk = tf.gather(l,tf.squeeze(eq,1))\n",
    "tf.Session().run([leqk,kj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_cols(params, indices, name=None):\n",
    "    \"\"\"Gather columns of a 2D tensor.\n",
    "\n",
    "    Args:\n",
    "        params: A 2D tensor.\n",
    "        indices: A 1D tensor. Must be one of the following types: ``int32``, ``int64``.\n",
    "        name: A name for the operation (optional).\n",
    "\n",
    "    Returns:\n",
    "        A 2D Tensor. Has the same type as ``params``.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, \"gather_cols\",[params, indices]) as scope:\n",
    "        # Check input\n",
    "        params = tf.convert_to_tensor(params, name=\"params\")\n",
    "        indices = tf.convert_to_tensor(indices, name=\"indices\")\n",
    "        try:\n",
    "            params.get_shape().assert_has_rank(2)\n",
    "            print(params.dtype)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 2D.')\n",
    "        try:\n",
    "            indices.get_shape().assert_has_rank(1)\n",
    "            print(indices.dtype)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'indices\\' must be 1D.')\n",
    "\n",
    "        # Define op\n",
    "        p_shape = tf.shape(params)\n",
    "        p_flat = tf.reshape(params, [-1])\n",
    "        i_flat = tf.reshape(tf.reshape(tf.range(0, p_shape[0]) * p_shape[1],\n",
    "                                       [-1, 1]) + indices, [-1])\n",
    "        return tf.reshape(tf.gather(p_flat, i_flat),\n",
    "                          [p_shape[0], -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-mean 0.0\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -28920.421611836453\n",
      "[ 0.00114834 -0.00192877  0.00101388  0.00092453  0.00101542 -0.00034952\n",
      "  0.00222818 -0.00060628  0.000545   -0.00027112]\n",
      "[[1.11757173 0.81428545 1.00865285 0.99971416 1.10642623 1.04210146\n",
      "  1.16867488 1.03211011 1.14724064 1.06563276]]\n",
      "{0: 2734, 1: 80}\n",
      "acc 0.9250177683013504\n",
      "(0.3625, 0.15343915343915343, 0.21561338289962823, None)\n",
      "\n",
      "1 loss -29068.159556315197\n",
      "[ 0.00112236 -0.00199761  0.00193483  0.00184548  0.00096838 -0.00111373\n",
      "  0.00276806 -0.00152729 -0.00037602 -0.00119214]\n",
      "[[1.11759771 0.81435429 1.0077435  0.99880186 1.10647327 1.04286568\n",
      "  1.16814008 1.03301515 1.14814892 1.06654532]]\n",
      "{0: 2737, 1: 77}\n",
      "acc 0.9260838663823738\n",
      "(0.37662337662337664, 0.15343915343915343, 0.21804511278195485, None)\n",
      "\n",
      "2 loss -29216.976923887432\n",
      "[ 0.00109648 -0.00206599  0.00285757  0.00276821  0.00092267 -0.00187817\n",
      "  0.00331057 -0.0024501  -0.00129883 -0.00211495]\n",
      "[[1.11762359 0.81442267 1.00683235 0.99788778 1.10651898 1.04363011\n",
      "  1.16760252 1.03392203 1.14905904 1.06745972]]\n",
      "{0: 2738, 1: 76}\n",
      "acc 0.9264392324093816\n",
      "(0.3815789473684211, 0.15343915343915343, 0.21886792452830187, None)\n",
      "\n",
      "3 loss -29366.85959159653\n",
      "[ 0.00107071 -0.00213389  0.00378206  0.0036927   0.00087831 -0.00264281\n",
      "  0.00385564 -0.00337467 -0.00222339 -0.00303951]\n",
      "[[1.11764937 0.81449057 1.00591945 0.99697195 1.10656334 1.04439476\n",
      "  1.16706228 1.03483072 1.14997097 1.06837591]]\n",
      "{0: 2741, 1: 73}\n",
      "acc 0.9260838663823738\n",
      "(0.3698630136986301, 0.14285714285714285, 0.20610687022900764, None)\n",
      "\n",
      "4 loss -29517.799453741798\n",
      "[ 0.00104503 -0.00220131  0.00470827  0.00461891  0.0008353  -0.00340766\n",
      "  0.00440321 -0.00430096 -0.00314967 -0.0039658 ]\n",
      "[[1.11767504 0.81455799 1.00500485 0.99605442 1.10660635 1.04515962\n",
      "  1.16651942 1.03574119 1.15088466 1.06929386]]\n",
      "{0: 2743, 1: 71}\n",
      "acc 0.9267945984363894\n",
      "(0.38028169014084506, 0.14285714285714285, 0.20769230769230768, None)\n",
      "\n",
      "[ 0.00104503 -0.00220131  0.00470827  0.00461891  0.0008353  -0.00340766\n",
      "  0.00440321 -0.00430096 -0.00314967 -0.0039658 ]\n",
      "[[1.11767504 0.81455799 1.00500485 0.99605442 1.10660635 1.04515962\n",
      "  1.16651942 1.03574119 1.15088466 1.06929386]]\n",
      "{0: 2743, 1: 71}\n",
      "acc 0.9267945984363894\n",
      "(0.38028169014084506, 0.14285714285714285, 0.20769230769230768, None)\n",
      "alpha-mean 0.1\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -26376.542659086077\n",
      "[0.1011481  0.09807046 0.10101001 0.10092066 0.1010124  0.09965156\n",
      " 0.10222852 0.09939759 0.10054887 0.09973275]\n",
      "[[1.11757197 0.81428622 1.00866116 0.99972124 1.10642925 1.04210038\n",
      "  1.16867635 1.03209996 1.14723158 1.06562513]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "1 loss -26508.10269444301\n",
      "[0.10112173 0.09800077 0.10192723 0.10183788 0.10096238 0.09888839\n",
      " 0.1027687  0.09848031 0.09963158 0.09881546]\n",
      "[[1.11759834 0.81435591 1.00775998 0.99881594 1.10647926 1.04286356\n",
      "  1.16814307 1.03299499 1.14813091 1.06653031]]\n",
      "{0: 2735, 1: 79}\n",
      "acc 0.9253731343283582\n",
      "(0.3670886075949367, 0.15343915343915343, 0.21641791044776118, None)\n",
      "\n",
      "2 loss -26640.724963430916\n",
      "[0.10109545 0.09793153 0.10284631 0.10275696 0.10091376 0.09812497\n",
      " 0.10331147 0.09756115 0.09871243 0.09789631]\n",
      "[[1.11762462 0.81442515 1.00685696 0.99790879 1.10652789 1.04362699\n",
      "  1.16760705 1.03389197 1.14903219 1.06743742]]\n",
      "{0: 2737, 1: 77}\n",
      "acc 0.9260838663823738\n",
      "(0.37662337662337664, 0.15343915343915343, 0.21804511278195485, None)\n",
      "\n",
      "3 loss -26774.39647947106\n",
      "[0.10106927 0.09786275 0.10376722 0.10367787 0.10086653 0.09736131\n",
      " 0.10385678 0.09664017 0.09779145 0.09697533]\n",
      "[[1.11765081 0.81449393 1.00595214 0.99699985 1.10657512 1.04439065\n",
      "  1.16706836 1.03479085 1.14993537 1.06834641]]\n",
      "{0: 2739, 1: 75}\n",
      "acc 0.9267945984363894\n",
      "(0.38666666666666666, 0.15343915343915343, 0.2196969696969697, None)\n",
      "\n",
      "4 loss -26909.11001536762\n",
      "[0.10104318 0.09779444 0.10468992 0.10460057 0.10082071 0.09659742\n",
      " 0.10440455 0.0957174  0.09686868 0.09605255]\n",
      "[[1.11767689 0.81456224 1.00504557 0.99608914 1.10662094 1.04515456\n",
      "  1.16652705 1.0356916  1.15084041 1.06925724]]\n",
      "{0: 2741, 1: 73}\n",
      "acc 0.9260838663823738\n",
      "(0.3698630136986301, 0.14285714285714285, 0.20610687022900764, None)\n",
      "\n",
      "[0.10104318 0.09779444 0.10468992 0.10460057 0.10082071 0.09659742\n",
      " 0.10440455 0.0957174  0.09686868 0.09605255]\n",
      "[[1.11767689 0.81456224 1.00504557 0.99608914 1.10662094 1.04515456\n",
      "  1.16652705 1.0356916  1.15084041 1.06925724]]\n",
      "{0: 2741, 1: 73}\n",
      "acc 0.9260838663823738\n",
      "(0.3698630136986301, 0.14285714285714285, 0.20610687022900764, None)\n",
      "alpha-mean 0.2\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -23978.195802911952\n",
      "[0.20114783 0.19806984 0.20100479 0.20091544 0.20100884 0.19965289\n",
      " 0.20222902 0.19940282 0.20055409 0.19973797]\n",
      "[[1.11757224 0.81428684 1.00867396 0.99973235 1.10643281 1.04209906\n",
      "  1.16867932 1.03208431 1.1472173  1.06561345]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "1 loss -24092.581597054635\n",
      "[0.20112105 0.19799941 0.20191697 0.20182761 0.20095531 0.19889102\n",
      " 0.20276967 0.19849057 0.19964185 0.19882573]\n",
      "[[1.11759903 0.81435727 1.00778543 0.99883806 1.10648634 1.04286094\n",
      "  1.16814908 1.03296389 1.1481025  1.0665073 ]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "2 loss -24208.008864761687\n",
      "[0.20109435 0.19792942 0.20283112 0.20274177 0.20090322 0.19812886\n",
      " 0.20331289 0.19757635 0.19872762 0.1979115 ]\n",
      "[[1.11762573 0.81442726 1.006895   0.99794184 1.10653842 1.04362312\n",
      "  1.16761607 1.03384557 1.1489898  1.06740321]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss -24324.46604019108\n",
      "[0.20106773 0.19785987 0.20374722 0.20365786 0.20085259 0.19736642\n",
      " 0.20385861 0.19666018 0.19781146 0.19699534]\n",
      "[[1.11765234 0.8144968  1.00600269 0.99704372 1.10658905 1.04438557\n",
      "  1.16708036 1.0347293  1.14987918 1.06830114]]\n",
      "{0: 2737, 1: 77}\n",
      "acc 0.9260838663823738\n",
      "(0.37662337662337664, 0.15343915343915343, 0.21804511278195485, None)\n",
      "\n",
      "4 loss -24441.946989478885\n",
      "[0.20104121 0.19779079 0.2046652  0.20457585 0.20080344 0.19660371\n",
      " 0.20440678 0.19574212 0.19689341 0.19607728]\n",
      "[[1.11767887 0.81456588 1.00510857 0.99614376 1.10663821 1.04514829\n",
      "  1.16654204 1.03561505 1.15077058 1.06920105]]\n",
      "{0: 2739, 1: 75}\n",
      "acc 0.9267945984363894\n",
      "(0.38666666666666666, 0.15343915343915343, 0.2196969696969697, None)\n",
      "\n",
      "[0.20104121 0.19779079 0.2046652  0.20457585 0.20080344 0.19660371\n",
      " 0.20440678 0.19574212 0.19689341 0.19607728]\n",
      "[[1.11767887 0.81456588 1.00510857 0.99614376 1.10663821 1.04514829\n",
      "  1.16654204 1.03561505 1.15077058 1.06920105]]\n",
      "{0: 2739, 1: 75}\n",
      "acc 0.9267945984363894\n",
      "(0.38666666666666666, 0.15343915343915343, 0.2196969696969697, None)\n",
      "alpha-mean 0.30000000000000004\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -21771.88549894075\n",
      "[0.30114754 0.29806944 0.3009976  0.30090825 0.30100469 0.29965459\n",
      " 0.30222956 0.29941001 0.30056128 0.29974516]\n",
      "[[1.11757254 0.81428723 1.0086952  0.99975145 1.10643696 1.04209736\n",
      "  1.16868692 1.03205867 1.14719295 1.06559418]]\n",
      "{0: 2728, 1: 86}\n",
      "acc 0.9250177683013504\n",
      "(0.37209302325581395, 0.1693121693121693, 0.23272727272727273, None)\n",
      "\n",
      "1 loss -21868.036640468956\n",
      "[0.3011203  0.29799842 0.30190284 0.30181349 0.30094706 0.29889435\n",
      " 0.30277073 0.2985047  0.29965598 0.29883986]\n",
      "[[1.11759977 0.81435825 1.00782777 0.99887619 1.10649459 1.04285762\n",
      "  1.16816438 1.03291284 1.14805399 1.06646926]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9243070362473348\n",
      "(0.35714285714285715, 0.15873015873015872, 0.21978021978021978, None)\n",
      "\n",
      "2 loss -21965.19919353428\n",
      "[0.30109314 0.29792783 0.30281023 0.30272087 0.30089092 0.29813379\n",
      " 0.30331447 0.29759725 0.29874853 0.2979324 ]\n",
      "[[1.11762694 0.81442885 1.00695834 0.99799886 1.10655073 1.0436182\n",
      "  1.167639   1.03376936 1.14891742 1.06734663]]\n",
      "{0: 2731, 1: 83}\n",
      "acc 0.923951670220327\n",
      "(0.3493975903614458, 0.15343915343915343, 0.21323529411764708, None)\n",
      "\n",
      "3 loss -22063.36337855594\n",
      "[0.30106606 0.29785767 0.30371971 0.30363035 0.30083629 0.29737291\n",
      " 0.3038607  0.2966877  0.29783898 0.29702285]\n",
      "[[1.11765402 0.81449901 1.00608697 0.99711952 1.10660536 1.04437911\n",
      "  1.16711087 1.03462818 1.14978322 1.06822623]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9243070362473348\n",
      "(0.35365853658536583, 0.15343915343915343, 0.21402214022140223, None)\n",
      "\n",
      "4 loss -22162.52442607711\n",
      "[0.30103905 0.29778796 0.30463124 0.30454189 0.3007832  0.29661171\n",
      " 0.30440937 0.2957761  0.29692738 0.29611125]\n",
      "[[1.11768102 0.81456871 1.00521371 0.99623822 1.10665845 1.04514032\n",
      "  1.16658007 1.03548925 1.15065131 1.06910802]]\n",
      "{0: 2736, 1: 78}\n",
      "acc 0.925728500355366\n",
      "(0.3717948717948718, 0.15343915343915343, 0.21722846441947563, None)\n",
      "\n",
      "[0.30103905 0.29778796 0.30463124 0.30454189 0.3007832  0.29661171\n",
      " 0.30440937 0.2957761  0.29692738 0.29611125]\n",
      "[[1.11768102 0.81456871 1.00521371 0.99623822 1.10665845 1.04514032\n",
      "  1.16658007 1.03548925 1.15065131 1.06910802]]\n",
      "{0: 2736, 1: 78}\n",
      "acc 0.925728500355366\n",
      "(0.3717948717948718, 0.15343915343915343, 0.21722846441947563, None)\n",
      "alpha-mean 0.4\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -19816.827407460372\n",
      "[0.4011472  0.39806937 0.40098685 0.4008975  0.401      0.39965723\n",
      " 0.40222984 0.39942076 0.40057204 0.39975592]\n",
      "[[1.11757288 0.81428731 1.00873435 0.99978939 1.10644164 1.04209474\n",
      "  1.16871387 1.03201314 1.14714658 1.06555838]]\n",
      "{0: 2718, 1: 96}\n",
      "acc 0.9228855721393034\n",
      "(0.3541666666666667, 0.17989417989417988, 0.2385964912280702, None)\n",
      "\n",
      "1 loss -19893.71048147337\n",
      "[0.40111946 0.39799797 0.40188171 0.40179236 0.4009377  0.39889953\n",
      " 0.4027713  0.39852584 0.39967711 0.39886099]\n",
      "[[1.11760062 0.8143587  1.00790599 0.99895207 1.10650394 1.04285246\n",
      "  1.16821856 1.0328221  1.14796154 1.06639843]]\n",
      "{0: 2725, 1: 89}\n",
      "acc 0.9246624022743426\n",
      "(0.3707865168539326, 0.1746031746031746, 0.237410071942446, None)\n",
      "\n",
      "2 loss -19971.557436599855\n",
      "[0.40109178 0.39792699 0.40277899 0.40268963 0.40087693 0.39814145\n",
      " 0.40331534 0.3976285  0.39877978 0.39796365]\n",
      "[[1.11762829 0.81442969 1.00707556 0.9981125  1.10656472 1.04361057\n",
      "  1.16772034 1.03363383 1.14877945 1.06724116]]\n",
      "{0: 2729, 1: 85}\n",
      "acc 0.9246624022743426\n",
      "(0.36470588235294116, 0.164021164021164, 0.2262773722627737, None)\n",
      "\n",
      "3 loss -20050.3607289453\n",
      "[0.40106417 0.39785644 0.40367863 0.40358927 0.4008177  0.39738298\n",
      " 0.4038619  0.3967288  0.39788008 0.39706395]\n",
      "[[1.1176559  0.81450024 1.00624312 0.99727077 1.10662395 1.04436907\n",
      "  1.16721931 1.03444826 1.14960025 1.06808652]]\n",
      "{0: 2730, 1: 84}\n",
      "acc 0.9243070362473348\n",
      "(0.35714285714285715, 0.15873015873015872, 0.21978021978021978, None)\n",
      "\n",
      "4 loss -20130.11727634784\n",
      "[0.40103664 0.39778633 0.40458057 0.40449121 0.40076006 0.39662414\n",
      " 0.40441091 0.39582679 0.39697808 0.39616195]\n",
      "[[1.11768344 0.81457035 1.00540875 0.99642694 1.10668159 1.04512794\n",
      "  1.16671557 1.03526535 1.15042388 1.06893444]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9250177683013504\n",
      "(0.36585365853658536, 0.15873015873015872, 0.22140221402214022, None)\n",
      "\n",
      "[0.40103664 0.39778633 0.40458057 0.40449121 0.40076006 0.39662414\n",
      " 0.40441091 0.39582679 0.39697808 0.39616195]\n",
      "[[1.11768344 0.81457035 1.00540875 0.99642694 1.10668159 1.04512794\n",
      "  1.16671557 1.03526535 1.15042388 1.06893444]]\n",
      "{0: 2732, 1: 82}\n",
      "acc 0.9250177683013504\n",
      "(0.36585365853658536, 0.15873015873015872, 0.22140221402214022, None)\n",
      "alpha-mean 0.5\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -18180.099362868117\n",
      "[0.5011468  0.49806971 0.50092861 0.50086756 0.50099493 0.49966343\n",
      " 0.50209671 0.49945431 0.50060183 0.49980488]\n",
      "[[1.11757328 0.81428697 1.00881581 0.99988076 1.10644672 1.04208854\n",
      "  1.16889122 1.03192609 1.14704683 1.06547996]]\n",
      "{0: 2704, 1: 110}\n",
      "acc 0.9193319118692252\n",
      "(0.32727272727272727, 0.19047619047619047, 0.24080267558528426, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss -18233.865538499387\n",
      "[0.50111848 0.49799827 0.50176535 0.50173301 0.50092744 0.49891183\n",
      " 0.50250389 0.49857901 0.49973255 0.49892957]\n",
      "[[1.1176016  0.81435841 1.00806904 0.99913532 1.1065142  1.04284018\n",
      "  1.16857396 1.03264821 1.14776227 1.06624262]]\n",
      "{0: 2707, 1: 107}\n",
      "acc 0.9196872778962332\n",
      "(0.32710280373831774, 0.18518518518518517, 0.23648648648648646, None)\n",
      "\n",
      "2 loss -18288.958569170187\n",
      "[0.5010902  0.49792721 0.50260451 0.50260117 0.50086141 0.49815974\n",
      " 0.50291333 0.49770095 0.49885449 0.49805151]\n",
      "[[1.11762987 0.81442947 1.00732011 0.99838763 1.10658024 1.04359232\n",
      "  1.16825364 1.03337367 1.14848153 1.06700864]]\n",
      "{0: 2712, 1: 102}\n",
      "acc 0.9207533759772566\n",
      "(0.3333333333333333, 0.17989417989417988, 0.23367697594501716, None)\n",
      "\n",
      "3 loss -18344.90822574766\n",
      "[0.50106198 0.49785655 0.50344601 0.50347196 0.50079687 0.49740717\n",
      " 0.50332508 0.49682019 0.49797374 0.49717075]\n",
      "[[1.11765809 0.81450013 1.00656911 0.99763778 1.10664478 1.04434493\n",
      "  1.16793036 1.03410242 1.14920458 1.06777795]]\n",
      "{0: 2714, 1: 100}\n",
      "acc 0.9214641080312722\n",
      "(0.34, 0.17989417989417988, 0.23529411764705885, None)\n",
      "\n",
      "4 loss -18401.65147234292\n",
      "[0.50103382 0.4977863  0.50428979 0.50434523 0.50073384 0.49665414\n",
      " 0.5037389  0.4959368  0.49709035 0.49628736]\n",
      "[[1.11768626 0.81457038 1.00581612 0.99688588 1.10670781 1.045098\n",
      "  1.16760423 1.03483441 1.14993133 1.06855049]]\n",
      "{0: 2723, 1: 91}\n",
      "acc 0.9232409381663113\n",
      "(0.3516483516483517, 0.1693121693121693, 0.22857142857142856, None)\n",
      "\n",
      "[0.50103382 0.4977863  0.50428979 0.50434523 0.50073384 0.49665414\n",
      " 0.5037389  0.4959368  0.49709035 0.49628736]\n",
      "[[1.11768626 0.81457038 1.00581612 0.99688588 1.10670781 1.045098\n",
      "  1.16760423 1.03483441 1.14993133 1.06855049]]\n",
      "{0: 2723, 1: 91}\n",
      "acc 0.9232409381663113\n",
      "(0.3516483516483517, 0.1693121693121693, 0.22857142857142856, None)\n",
      "alpha-mean 0.6000000000000001\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -16806.520172371387\n",
      "[0.60114655 0.59806937 0.60085401 0.60075575 0.60098396 0.59967532\n",
      " 0.6019192  0.59954531 0.60069308 0.59989646]\n",
      "[[1.11757353 0.8142873  1.00897583 1.00010148 1.10645769 1.04207667\n",
      "  1.16910063 1.03177288 1.14684298 1.0653119 ]]\n",
      "{0: 2677, 1: 137}\n",
      "acc 0.9090262970859986\n",
      "(0.25547445255474455, 0.18518518518518517, 0.2147239263803681, None)\n",
      "\n",
      "1 loss -16834.969129938607\n",
      "[0.60111779 0.59799725 0.60161612 0.60150814 0.60090507 0.59893557\n",
      " 0.60214952 0.59877341 0.59991728 0.59914021]\n",
      "[[1.11760228 0.81435943 1.00838922 0.99957757 1.10653658 1.04281649\n",
      "  1.16899514 1.03234171 1.14735463 1.06590849]]\n",
      "{0: 2682, 1: 132}\n",
      "acc 0.9108031272210376\n",
      "(0.26515151515151514, 0.18518518518518517, 0.21806853582554514, None)\n",
      "\n",
      "2 loss -16863.93191422365\n",
      "[0.60108908 0.59792541 0.60238124 0.60226231 0.60082727 0.59819527\n",
      " 0.60238183 0.59799803 0.59913688 0.59837933]\n",
      "[[1.117631   0.81443126 1.00780006 0.99905128 1.10661438 1.04355686\n",
      "  1.16888713 1.03291454 1.14787073 1.06650962]]\n",
      "{0: 2688, 1: 126}\n",
      "acc 0.912224591329069\n",
      "(0.2698412698412698, 0.17989417989417988, 0.21587301587301586, None)\n",
      "\n",
      "3 loss -16893.4300570551\n",
      "[0.6010604  0.59785388 0.60314897 0.60301863 0.60075059 0.59745444\n",
      " 0.60261602 0.59721916 0.59835081 0.59761454]\n",
      "[[1.11765968 0.8145028  1.00720846 0.99852275 1.10669106 1.04429775\n",
      "  1.16877666 1.03349131 1.14839127 1.06711522]]\n",
      "{0: 2691, 1: 123}\n",
      "acc 0.9125799573560768\n",
      "(0.2682926829268293, 0.1746031746031746, 0.21153846153846154, None)\n",
      "\n",
      "4 loss -16923.450744822967\n",
      "[0.60103175 0.59778266 0.60391909 0.60377566 0.60067507 0.59671309\n",
      " 0.60285175 0.59643683 0.59756051 0.59684557]\n",
      "[[1.11768832 0.81457402 1.00661452 0.99799209 1.10676658 1.04503917\n",
      "  1.16866376 1.03407198 1.1489162  1.06772525]]\n",
      "{0: 2700, 1: 114}\n",
      "acc 0.9150675195451314\n",
      "(0.2807017543859649, 0.1693121693121693, 0.21122112211221122, None)\n",
      "\n",
      "[0.60103175 0.59778266 0.60391909 0.60377566 0.60067507 0.59671309\n",
      " 0.60285175 0.59643683 0.59756051 0.59684557]\n",
      "[[1.11768832 0.81457402 1.00661452 0.99799209 1.10676658 1.04503917\n",
      "  1.16866376 1.03407198 1.1489162  1.06772525]]\n",
      "{0: 2700, 1: 114}\n",
      "acc 0.9150675195451314\n",
      "(0.2807017543859649, 0.1693121693121693, 0.21122112211221122, None)\n",
      "alpha-mean 0.7000000000000001\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -15939.431711918833\n",
      "[0.70114658 0.6980671  0.7005352  0.70036628 0.70097048 0.69970941\n",
      " 0.70172842 0.69983442 0.70106882 0.70023938]\n",
      "[[1.1175735  0.81428958 1.00926217 1.00040094 1.10647117 1.04204262\n",
      "  1.16921675 1.03155796 1.14662476 1.06497891]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "1 loss -15945.547968058825\n",
      "[0.70111772 0.69799241 0.7009752  0.70072644 0.70087748 0.69900428\n",
      " 0.70176563 0.69935282 0.70067024 0.69982519]\n",
      "[[1.11760236 0.81436427 1.00896215 1.0001753  1.10656417 1.04274786\n",
      "  1.16922713 1.03190938 1.14691616 1.06524055]]\n",
      "{0: 2556, 1: 258}\n",
      "acc 0.9086709310589908\n",
      "(0.3682170542635659, 0.5026455026455027, 0.4250559284116331, None)\n",
      "\n",
      "2 loss -15951.757772791365\n",
      "[0.70108887 0.69791784 0.70141635 0.7010881  0.70078491 0.69829879\n",
      " 0.7018038  0.69886784 0.70026877 0.69940672]\n",
      "[[1.1176312  0.81443884 1.0086587  0.9999462  1.10665674 1.04345345\n",
      "  1.16923675 1.03226318 1.14720957 1.06550534]]\n",
      "{0: 2561, 1: 253}\n",
      "acc 0.9104477611940298\n",
      "(0.37549407114624506, 0.5026455026455027, 0.4298642533936652, None)\n",
      "\n",
      "3 loss -15958.059847491313\n",
      "[0.70106004 0.69784341 0.70185925 0.70145038 0.70069277 0.69759296\n",
      " 0.70184291 0.69838007 0.69986473 0.69898245]\n",
      "[[1.11766004 0.81451327 1.00835185 0.99971367 1.10674889 1.04415938\n",
      "  1.16924559 1.03261936 1.14750498 1.06577329]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "4 loss -15964.453597918462\n",
      "[0.70103121 0.69776911 0.70230358 0.70181466 0.70060106 0.69688679\n",
      " 0.70188297 0.69788888 0.69945783 0.6985552 ]\n",
      "[[1.11768886 0.81458757 1.00804164 0.99947771 1.1068406  1.04486566\n",
      "  1.16925366 1.03297791 1.14780238 1.06604442]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "[0.70103121 0.69776911 0.70230358 0.70181466 0.70060106 0.69688679\n",
      " 0.70188297 0.69788888 0.69945783 0.6985552 ]\n",
      "[[1.11768886 0.81458757 1.00804164 0.99947771 1.1068406  1.04486566\n",
      "  1.16925366 1.03297791 1.14780238 1.06604442]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "alpha-mean 0.8\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss -15617.795835581157\n",
      "[0.80114662 0.79806672 0.80022123 0.80011771 0.8009654  0.79980673\n",
      " 0.80167435 0.80015961 0.8013301  0.80070702]\n",
      "[[1.11757345 0.81428996 1.00963296 1.0007069  1.10647625 1.04194538\n",
      "  1.16922697 1.03140962 1.146522   1.06480009]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "1 loss -15618.934387292413\n",
      "[0.80111784 0.7979916  0.80034773 0.80022991 0.80086708 0.79919892\n",
      " 0.80165777 0.8000064  0.80119611 0.80076598]\n",
      "[[1.11760223 0.81436508 1.0097051  1.00078839 1.10657457 1.0425534\n",
      "  1.16924785 1.03161153 1.14670955 1.06488057]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "2 loss -15620.086200054015\n",
      "[0.80108907 0.79791653 0.80047546 0.80034316 0.8007689  0.79858972\n",
      " 0.80164134 0.79985185 0.801061   0.80082423]\n",
      "[[1.11763101 0.81444015 1.00977615 1.00086895 1.10667275 1.0431628\n",
      "  1.16926864 1.03181417 1.14689767 1.06496137]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "3 loss -15621.251340857134\n",
      "[0.8010603  0.79784152 0.80060444 0.80045749 0.80067087 0.79797914\n",
      " 0.80162507 0.79969593 0.80092475 0.80088176]\n",
      "[[1.11765978 0.81451516 1.00984612 1.00094859 1.10677078 1.04377358\n",
      "  1.16928933 1.03201753 1.14708635 1.06504247]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "4 loss -15622.429921608207\n",
      "[0.80103154 0.79776656 0.80073466 0.8005729  0.80057298 0.79736721\n",
      " 0.80160897 0.79953865 0.80078737 0.80093857]\n",
      "[[1.11768854 0.81459012 1.00991499 1.00102729 1.10686867 1.04438571\n",
      "  1.16930993 1.03222161 1.14727559 1.06512388]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "\n",
      "[0.80103154 0.79776656 0.80073466 0.8005729  0.80057298 0.79736721\n",
      " 0.80160897 0.79953865 0.80078737 0.80093857]\n",
      "[[1.11768854 0.81459012 1.00991499 1.00102729 1.10686867 1.04438571\n",
      "  1.16930993 1.03222161 1.14727559 1.06512388]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8923240938166311\n",
      "(0.3323529411764706, 0.5978835978835979, 0.42722117202268434, None)\n",
      "alpha-mean 0.9\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -15499.709186025439\n",
      "[0.90114659 0.89806781 0.89995791 0.89986302 0.90096542 0.90041339\n",
      " 0.90167754 0.90018924 0.90134299 0.90055397]\n",
      "[[1.11757348 0.81428887 1.00981192 1.00086355 1.10647623 1.04133855\n",
      "  1.16922052 1.03144909 1.14656283 1.06480805]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "1 loss -15499.832108050312\n",
      "[0.90111784 0.89799378 0.89982084 0.89972035 0.90086712 0.90041339\n",
      " 0.90166262 0.90006677 0.90122299 0.90045888]\n",
      "[[1.11760224 0.8143629  1.01006265 1.00110126 1.10657454 1.04133855\n",
      "  1.16923543 1.03168954 1.14679027 1.06489547]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "2 loss -15499.955271220799\n",
      "[0.90108909 0.89791976 0.89968367 0.89957759 0.90076881 0.90041339\n",
      " 0.90164771 0.89994425 0.90110293 0.90036378]\n",
      "[[1.11763099 0.81443692 1.01031325 1.00133885 1.10667285 1.04133855\n",
      "  1.16925034 1.03192984 1.14701758 1.06498291]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "3 loss -15500.07868474255\n",
      "[0.90106033 0.89784574 0.89954639 0.89943474 0.9006705  0.90041339\n",
      " 0.90163281 0.89982165 0.9009828  0.90026865]\n",
      "[[1.11765974 0.81451095 1.01056371 1.00157633 1.10677116 1.04133855\n",
      "  1.16926525 1.03217    1.14724478 1.06507038]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "4 loss -15500.202348950163\n",
      "[0.90103158 0.89777172 0.89940901 0.8992918  0.90057219 0.90041339\n",
      " 0.9016179  0.899699   0.9008626  0.90017349]\n",
      "[[1.11768849 0.81458497 1.01081404 1.00181369 1.10686947 1.04133855\n",
      "  1.16928015 1.03241001 1.14747185 1.06515788]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "\n",
      "[0.90103158 0.89777172 0.89940901 0.8992918  0.90057219 0.90041339\n",
      " 0.9016179  0.899699   0.9008626  0.90017349]\n",
      "[[1.11768849 0.81458497 1.01081404 1.00181369 1.10686947 1.04133855\n",
      "  1.16928015 1.03241001 1.14747185 1.06515788]]\n",
      "{0: 2489, 1: 325}\n",
      "acc 0.8933901918976546\n",
      "(0.3292307692307692, 0.5661375661375662, 0.41634241245136183, None)\n",
      "alpha-mean 1.0\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -15441.244159159418\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11757313 0.8142873  1.00983121 1.00087959 1.10647382 1.04133855\n",
      "  1.1692205  1.03147985 1.1465891  1.06479855]]\n",
      "{0: 2490, 1: 324}\n",
      "acc 0.8937455579246624\n",
      "(0.33024691358024694, 0.5661375661375662, 0.41715399610136455, None)\n",
      "\n",
      "1 loss -15441.24448844349\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11760143 0.81435963 1.01010119 1.00113339 1.10656974 1.04133855\n",
      "  1.16923539 1.03175107 1.14684279 1.06487669]]\n",
      "{0: 2490, 1: 324}\n",
      "acc 0.8937455579246624\n",
      "(0.33024691358024694, 0.5661375661375662, 0.41715399610136455, None)\n",
      "\n",
      "2 loss -15441.244817769148\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11762974 0.81443195 1.01037117 1.00138719 1.10666564 1.04133855\n",
      "  1.16925027 1.03202229 1.14709649 1.06495483]]\n",
      "{0: 2490, 1: 324}\n",
      "acc 0.8937455579246624\n",
      "(0.33024691358024694, 0.5661375661375662, 0.41715399610136455, None)\n",
      "\n",
      "3 loss -15441.24514717711\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11765804 0.81450427 1.01064116 1.00164099 1.10676155 1.04133855\n",
      "  1.16926516 1.03229352 1.14735018 1.06503296]]\n",
      "{0: 2490, 1: 324}\n",
      "acc 0.8937455579246624\n",
      "(0.33024691358024694, 0.5661375661375662, 0.41715399610136455, None)\n",
      "\n",
      "4 loss -15441.24547666745\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11768635 0.81457658 1.01091115 1.00189479 1.10685745 1.04133855\n",
      "  1.16928004 1.03256474 1.14760388 1.0651111 ]]\n",
      "{0: 2490, 1: 324}\n",
      "acc 0.8937455579246624\n",
      "(0.33024691358024694, 0.5661375661375662, 0.41715399610136455, None)\n",
      "\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11768635 0.81457658 1.01091115 1.00189479 1.10685745 1.04133855\n",
      "  1.16928004 1.03256474 1.14760388 1.0651111 ]]\n",
      "{0: 2490, 1: 324}\n",
      "acc 0.8937455579246624\n",
      "(0.33024691358024694, 0.5661375661375662, 0.41715399610136455, None)\n"
     ]
    }
   ],
   "source": [
    "# dev data\n",
    "for i in np.linspace(0,1,11):\n",
    "    print(\"alpha-mean\",i)\n",
    "    R=train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                              pcl=np.array([-1,1],dtype=np.float64),norm=False,smooth=True,penalty=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-mean 0.0\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 156285.81383787203\n",
      "[ 0.0021718  -0.00087335  0.00105642  0.00096699  0.0020438  -0.00040336\n",
      "  0.00255586 -0.00062411  0.00052896 -0.00028843]\n",
      "[[1.11655268 0.81325392 1.00860748 0.9996698  1.10542435 1.04211087\n",
      "  1.16832359 1.03211472 1.14724213 1.06563647]]\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9115470022205774\n",
      "(0.352112676056338, 0.11467889908256881, 0.17301038062283738, None)\n",
      "\n",
      "1 loss 156046.28300800116\n",
      "[ 0.00316804  0.00011092  0.00201864  0.00192914  0.00302363 -0.00121978\n",
      "  0.00341954 -0.00156223 -0.0004074  -0.00122604]\n",
      "[[1.11556102 0.81229386 1.00765389 0.99871416 1.10447113 1.0428832\n",
      "  1.1674412  1.03302393 1.14815153 1.06655231]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "2 loss 155806.89443674905\n",
      "[ 0.00416424  0.00109507  0.00298152  0.00289194  0.00400323 -0.00203497\n",
      "  0.00428202 -0.00250145 -0.00134488 -0.00216476]\n",
      "[[1.11456944 0.811334   1.00669958 0.9977578  1.10351829 1.04365465\n",
      "  1.16655973 1.0339346  1.14906241 1.06746959]]\n",
      "{0: 2635, 1: 67}\n",
      "acc 0.9122871946706144\n",
      "(0.3582089552238806, 0.11009174311926606, 0.16842105263157894, None)\n",
      "\n",
      "3 loss 155567.671954637\n",
      "[ 0.00516039  0.0020791   0.00394503  0.00385539  0.00498259 -0.00284892\n",
      "  0.00514331 -0.00344176 -0.00228348 -0.00310457]\n",
      "[[1.11357793 0.81037435 1.00574457 0.99680074 1.10256585 1.04442521\n",
      "  1.16567921 1.03484668 1.14997474 1.06838827]]\n",
      "{0: 2638, 1: 64}\n",
      "acc 0.9126572908956329\n",
      "(0.359375, 0.10550458715596331, 0.1631205673758865, None)\n",
      "\n",
      "4 loss 155328.63184077415\n",
      "[ 0.0061565   0.00306299  0.00490918  0.00481947  0.0059617  -0.00366161\n",
      "  0.00600336 -0.00438313 -0.00322316 -0.00404546]\n",
      "[[1.11258651 0.80941491 1.00478887 0.995843   1.10161384 1.04519487\n",
      "  1.16479966 1.03576014 1.15088849 1.06930835]]\n",
      "{0: 2640, 1: 62}\n",
      "acc 0.9133974833456698\n",
      "(0.3709677419354839, 0.10550458715596331, 0.16428571428571426, None)\n",
      "\n",
      "[ 0.0061565   0.00306299  0.00490918  0.00481947  0.0059617  -0.00366161\n",
      "  0.00600336 -0.00438313 -0.00322316 -0.00404546]\n",
      "[[1.11258651 0.80941491 1.00478887 0.995843   1.10161384 1.04519487\n",
      "  1.16479966 1.03576014 1.15088849 1.06930835]]\n",
      "{0: 2640, 1: 62}\n",
      "acc 0.9133974833456698\n",
      "(0.3709677419354839, 0.10550458715596331, 0.16428571428571426, None)\n",
      "alpha-mean 0.1\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 155093.63879449212\n",
      "[0.10217031 0.09911982 0.10105024 0.1009608  0.10203688 0.09961726\n",
      " 0.10253281 0.09938558 0.10053891 0.09972133]\n",
      "[[1.11655622 0.81327059 1.00861558 0.99967688 1.10543999 1.0420983\n",
      "  1.16833355 1.03209931 1.14722737 1.06562343]]\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9104367135455218\n",
      "(0.34210526315789475, 0.11926605504587157, 0.17687074829931976, None)\n",
      "\n",
      "1 loss 154894.88241384583\n",
      "[0.10316499 0.10009714 0.10200646 0.10191693 0.10300974 0.09882144\n",
      " 0.10337332 0.09845688 0.09961225 0.09879322]\n",
      "[[1.11556825 0.81232747 1.00766996 0.99872823 1.10450245 1.04285861\n",
      "  1.16746124 1.03299333 1.14812218 1.06652657]]\n",
      "{0: 2632, 1: 70}\n",
      "acc 0.9119170984455959\n",
      "(0.35714285714285715, 0.11467889908256881, 0.1736111111111111, None)\n",
      "\n",
      "2 loss 154696.06582623755\n",
      "[0.1041596  0.10107429 0.10296344 0.10287383 0.1039823  0.09802679\n",
      " 0.10421251 0.09752689 0.09868426 0.09786381]\n",
      "[[1.1145804  0.8113846  1.00672357 0.99777882 1.10356538 1.04361816\n",
      "  1.16659    1.03388896 1.14901864 1.06743131]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "3 loss 154497.2083249658\n",
      "[0.10515416 0.10205126 0.10392116 0.10383147 0.10495455 0.09723335\n",
      " 0.10505037 0.09659563 0.09775497 0.09693312]\n",
      "[[1.11359266 0.81044201 1.00577642 0.99682864 1.10262881 1.04437695\n",
      "  1.16571982 1.03478617 1.14991674 1.06833763]]\n",
      "{0: 2635, 1: 67}\n",
      "acc 0.9122871946706144\n",
      "(0.3582089552238806, 0.11009174311926606, 0.16842105263157894, None)\n",
      "\n",
      "4 loss 154298.32221186275\n",
      "[0.10614865 0.10302804 0.10487962 0.10478985 0.10592647 0.09644112\n",
      " 0.10588687 0.09566313 0.09682441 0.09600118]\n",
      "[[1.11260503 0.8094997  1.00482853 0.99587772 1.10169277 1.04513495\n",
      "  1.16485074 1.03568492 1.15081643 1.06924549]]\n",
      "{0: 2638, 1: 64}\n",
      "acc 0.9126572908956329\n",
      "(0.359375, 0.10550458715596331, 0.1631205673758865, None)\n",
      "\n",
      "[0.10614865 0.10302804 0.10487962 0.10478985 0.10592647 0.09644112\n",
      " 0.10588687 0.09566313 0.09682441 0.09600118]\n",
      "[[1.11260503 0.8094997  1.00482853 0.99587772 1.10169277 1.04513495\n",
      "  1.16485074 1.03568492 1.15081643 1.06924549]]\n",
      "{0: 2638, 1: 64}\n",
      "acc 0.9126572908956329\n",
      "(0.359375, 0.10550458715596331, 0.1631205673758865, None)\n",
      "alpha-mean 0.2\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 154319.67251902487\n",
      "[0.20216776 0.19910833 0.20104261 0.20095316 0.20202603 0.19963648\n",
      " 0.20250567 0.19939661 0.2005502  0.19973243]\n",
      "[[1.11656218 0.81329727 1.00862699 0.99968675 1.10546357 1.04208761\n",
      "  1.16834215 1.03207767 1.14720645 1.0656055 ]]\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9096965210954848\n",
      "(0.3333333333333333, 0.11926605504587157, 0.17567567567567569, None)\n",
      "\n",
      "1 loss 154158.34580408173\n",
      "[0.20315979 0.20007397 0.20199144 0.20190189 0.20298801 0.19885975\n",
      " 0.20331899 0.19847861 0.1996345  0.1988151 ]\n",
      "[[1.11558044 0.81238125 1.00769265 0.9987479  1.10454962 1.04283739\n",
      "  1.16747858 1.03295031 1.14808054 1.06649117]]\n",
      "{0: 2627, 1: 75}\n",
      "acc 0.9108068097705403\n",
      "(0.3466666666666667, 0.11926605504587157, 0.17747440273037546, None)\n",
      "\n",
      "2 loss 153996.7584819073\n",
      "[0.20415173 0.20103937 0.20294116 0.20285152 0.20394962 0.19808406\n",
      " 0.20413093 0.19755909 0.19871723 0.19789623]\n",
      "[[1.11459886 0.81146556 1.00675748 0.9978082  1.10363621 1.04358659\n",
      "  1.16661618 1.03382479 1.14895655 1.06737866]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "3 loss 153834.92614261247\n",
      "[0.20514357 0.2020045  0.20389177 0.20380203 0.20491082 0.19730942\n",
      " 0.20494148 0.19663806 0.19779841 0.19697584]\n",
      "[[1.11361744 0.8105502  1.0058215  0.99686768 1.10272338 1.04433519\n",
      "  1.16575496 1.03470106 1.14983444 1.06826794]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 153672.85800301103\n",
      "[0.20613531 0.20296937 0.20484324 0.20475341 0.20587159 0.19653585\n",
      " 0.20575062 0.19571555 0.19687807 0.19605396]\n",
      "[[1.11263618 0.80963519 1.00488472 0.99592636 1.10181117 1.04508319\n",
      "  1.16489494 1.0355791  1.15071416 1.06915899]]\n",
      "{0: 2635, 1: 67}\n",
      "acc 0.9122871946706144\n",
      "(0.3582089552238806, 0.11009174311926606, 0.16842105263157894, None)\n",
      "\n",
      "[0.20613531 0.20296937 0.20484324 0.20475341 0.20587159 0.19653585\n",
      " 0.20575062 0.19571555 0.19687807 0.19605396]\n",
      "[[1.11263618 0.80963519 1.00488472 0.99592636 1.10181117 1.04508319\n",
      "  1.16489494 1.0355791  1.15071416 1.06915899]]\n",
      "{0: 2635, 1: 67}\n",
      "acc 0.9122871946706144\n",
      "(0.3582089552238806, 0.11009174311926606, 0.16842105263157894, None)\n",
      "alpha-mean 0.30000000000000004\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 153921.43746778983\n",
      "[0.30216319 0.29908825 0.30103311 0.30094364 0.3020083  0.29965335\n",
      " 0.30247457 0.29940936 0.3005632  0.29974525]\n",
      "[[1.11657269 0.8133405  1.00864449 0.99970197 1.10549999 1.04207844\n",
      "  1.16834673 1.03204466 1.14717354 1.06557826]]\n",
      "{0: 2620, 1: 82}\n",
      "acc 0.9089563286454478\n",
      "(0.32926829268292684, 0.12385321100917432, 0.18000000000000005, None)\n",
      "\n",
      "1 loss 153794.30637188465\n",
      "[0.30315045 0.30003348 0.30197272 0.30188314 0.30295254 0.29889325\n",
      " 0.30325683 0.29850372 0.29966008 0.29884034]\n",
      "[[1.1156019  0.81246838 1.00772754 0.99877829 1.10462242 1.04281927\n",
      "  1.1674879  1.03288461 1.14801499 1.0664373 ]]\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9096965210954848\n",
      "(0.3333333333333333, 0.11926605504587157, 0.17567567567567569, None)\n",
      "\n",
      "2 loss 153666.73960411156\n",
      "[0.30413757 0.30097835 0.30291341 0.30282373 0.3038963  0.29813397\n",
      " 0.30403777 0.29759624 0.29875507 0.29793357]\n",
      "[[1.11463134 0.81159662 1.00680972 0.99785372 1.10374538 1.04355973\n",
      "  1.16663033 1.03372671 1.14885874 1.06729848]]\n",
      "{0: 2627, 1: 75}\n",
      "acc 0.9108068097705403\n",
      "(0.3466666666666667, 0.11926605504587157, 0.17747440273037546, None)\n",
      "\n",
      "3 loss 153538.74957231988\n",
      "[0.30512455 0.30192286 0.30385517 0.30376538 0.30483958 0.29737552\n",
      " 0.30481737 0.29668695 0.2978482  0.29702498]\n",
      "[[1.113661   0.81072524 1.00589105 0.99692826 1.10286894 1.0442998\n",
      "  1.16577403 1.03457093 1.14970474 1.06816177]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "4 loss 153410.34300114552\n",
      "[0.30611139 0.30286699 0.30479798 0.30470809 0.30578232 0.2966179\n",
      " 0.30559563 0.29577587 0.2969395  0.2961146 ]\n",
      "[[1.11269089 0.80985425 1.00497157 0.99600195 1.10199313 1.04503947\n",
      "  1.16491903 1.03541721 1.15055295 1.06902712]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "[0.30611139 0.30286699 0.30479798 0.30470809 0.30578232 0.2966179\n",
      " 0.30559563 0.29577587 0.2969395  0.2961146 ]\n",
      "[[1.11269089 0.80985425 1.00497157 0.99600195 1.10199313 1.04503947\n",
      "  1.16491903 1.03541721 1.15055295 1.06902712]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "alpha-mean 0.4\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 153823.57264339356\n",
      "[0.40215443 0.39905182 0.40102054 0.40093106 0.40197768 0.39966838\n",
      " 0.4024398  0.39942535 0.40057942 0.39976131]\n",
      "[[1.11659206 0.81341018 1.00867497 0.99972974 1.10555764 1.04206997\n",
      "  1.16834298 1.031989   1.14711422 1.06553015]]\n",
      "{0: 2616, 1: 86}\n",
      "acc 0.9104367135455218\n",
      "(0.36046511627906974, 0.14220183486238533, 0.20394736842105263, None)\n",
      "\n",
      "1 loss 153727.6811843583\n",
      "[0.40313259 0.39996004 0.40194797 0.40185837 0.40289132 0.39892255\n",
      " 0.40318747 0.39853518 0.39969197 0.39887193]\n",
      "[[1.11564139 0.81260884 1.0077885  0.99883395 1.10473757 1.04280262\n",
      "  1.16748065 1.03277365 1.14789669 1.06634197]]\n",
      "{0: 2619, 1: 83}\n",
      "acc 0.9100666173205033\n",
      "(0.3493975903614458, 0.13302752293577982, 0.19269102990033224, None)\n",
      "\n",
      "2 loss 153631.22417633925\n",
      "[0.40411053 0.40086778 0.40287675 0.40278703 0.40380444 0.39817723\n",
      " 0.40393402 0.39764272 0.3988022  0.39798024]\n",
      "[[1.11469104 0.81180781 1.00690121 0.99793725 1.10391787 1.04353513\n",
      "  1.16661968 1.03356094 1.14868213 1.06715644]]\n",
      "{0: 2621, 1: 81}\n",
      "acc 0.9100666173205033\n",
      "(0.345679012345679, 0.12844036697247707, 0.18729096989966554, None)\n",
      "\n",
      "3 loss 153534.211006496\n",
      "[0.40508826 0.40177501 0.40380686 0.40371703 0.404717   0.39743243\n",
      " 0.40467945 0.39674804 0.39791013 0.39708632]\n",
      "[[1.11374101 0.81100712 1.00601313 0.99703968 1.1030986  1.04426751\n",
      "  1.16576012 1.03435084 1.14947047 1.0679735 ]]\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9111769059955589\n",
      "(0.358974358974359, 0.12844036697247707, 0.1891891891891892, None)\n",
      "\n",
      "4 loss 153436.64616782684\n",
      "[0.40606576 0.40268174 0.40473828 0.40464834 0.40562897 0.39668816\n",
      " 0.40542375 0.39585117 0.39701582 0.39619019]\n",
      "[[1.11279129 0.81020676 1.0051243  0.99614128 1.10227984 1.04499975\n",
      "  1.16490198 1.03514327 1.15026164 1.06879312]]\n",
      "{0: 2627, 1: 75}\n",
      "acc 0.9108068097705403\n",
      "(0.3466666666666667, 0.11926605504587157, 0.17747440273037546, None)\n",
      "\n",
      "[0.40606576 0.40268174 0.40473828 0.40464834 0.40562897 0.39668816\n",
      " 0.40542375 0.39585117 0.39701582 0.39619019]\n",
      "[[1.11279129 0.81020676 1.0051243  0.99614128 1.10227984 1.04499975\n",
      "  1.16490198 1.03514327 1.15026164 1.06879312]]\n",
      "{0: 2627, 1: 75}\n",
      "acc 0.9108068097705403\n",
      "(0.3466666666666667, 0.11926605504587157, 0.17747440273037546, None)\n",
      "alpha-mean 0.5\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 153924.25293354748\n",
      "[0.5021364  0.49898402 0.50097271 0.50090369 0.50192123 0.49968364\n",
      " 0.50236435 0.4994658  0.50061592 0.49981885]\n",
      "[[1.11662936 0.81351892 1.00873725 0.99979417 1.10565046 1.04205866\n",
      "  1.16834187 1.03188673 1.14699178 1.06542716]]\n",
      "{0: 2603, 1: 99}\n",
      "acc 0.9063656550703183\n",
      "(0.32323232323232326, 0.14678899082568808, 0.2018927444794953, None)\n",
      "\n",
      "1 loss 153860.13824837652\n",
      "[0.50309587 0.49982332 0.5018524  0.50180419 0.50277839 0.49895269\n",
      " 0.503034   0.49860044 0.49976091 0.49895436]\n",
      "[[1.1157173  0.81282822 1.00791334 0.9989635  1.1049232  1.04278029\n",
      "  1.16747933 1.03256933 1.14765218 1.06613709]]\n",
      "{0: 2607, 1: 95}\n",
      "acc 0.9078460399703923\n",
      "(0.3368421052631579, 0.14678899082568808, 0.20447284345047922, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 153794.9386158779\n",
      "[0.50405499 0.50066194 0.50273334 0.5027063  0.50363504 0.49822189\n",
      " 0.50370149 0.49773228 0.49889572 0.49808706]\n",
      "[[1.1148057  0.81213779 1.00708879 0.99813224 1.10419601 1.04350208\n",
      "  1.16661865 1.03325522 1.1483165  1.06685048]]\n",
      "{0: 2610, 1: 92}\n",
      "acc 0.9089563286454478\n",
      "(0.34782608695652173, 0.14678899082568808, 0.20645161290322583, None)\n",
      "\n",
      "3 loss 153729.12681287836\n",
      "[0.50501376 0.50149986 0.50361548 0.50360996 0.50449111 0.49749125\n",
      " 0.50436683 0.49686138 0.49802773 0.497217  ]\n",
      "[[1.11389455 0.81144762 1.00626364 0.99730046 1.10346894 1.04422403\n",
      "  1.16575989 1.03394436 1.14898469 1.06756728]]\n",
      "{0: 2614, 1: 88}\n",
      "acc 0.9096965210954848\n",
      "(0.3522727272727273, 0.14220183486238533, 0.20261437908496732, None)\n",
      "\n",
      "4 loss 153662.77625269737\n",
      "[0.50597217 0.50233706 0.50449881 0.5045151  0.50534654 0.49676078\n",
      " 0.50502984 0.4959878  0.49715699 0.49634424]\n",
      "[[1.11298385 0.81075771 1.00543795 0.99646821 1.10274206 1.04494612\n",
      "  1.16490309 1.0346367  1.1496567  1.06828743]]\n",
      "{0: 2619, 1: 83}\n",
      "acc 0.9093264248704663\n",
      "(0.3373493975903614, 0.12844036697247707, 0.18604651162790697, None)\n",
      "\n",
      "[0.50597217 0.50233706 0.50449881 0.5045151  0.50534654 0.49676078\n",
      " 0.50502984 0.4959878  0.49715699 0.49634424]\n",
      "[[1.11298385 0.81075771 1.00543795 0.99646821 1.10274206 1.04494612\n",
      "  1.16490309 1.0346367  1.1496567  1.06828743]]\n",
      "{0: 2619, 1: 83}\n",
      "acc 0.9093264248704663\n",
      "(0.3373493975903614, 0.12844036697247707, 0.18604651162790697, None)\n",
      "alpha-mean 0.6000000000000001\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 154226.6295606289\n",
      "[0.6020958  0.59885485 0.60090896 0.60081304 0.60180419 0.59970343\n",
      " 0.60231309 0.59956964 0.6007225  0.59992423]\n",
      "[[1.11670353 0.81368114 1.00885935 0.99995196 1.10580748 1.04203968\n",
      "  1.16831678 1.03171182 1.14675398 1.06520122]]\n",
      "{0: 2575, 1: 127}\n",
      "acc 0.8967431532198371\n",
      "(0.25984251968503935, 0.15137614678899083, 0.191304347826087, None)\n",
      "\n",
      "1 loss 154193.4852476797\n",
      "[0.60301322 0.59956249 0.60172482 0.60162173 0.60254428 0.59899198\n",
      " 0.60293163 0.59882199 0.59997591 0.5991956 ]\n",
      "[[1.11586824 0.81315626 1.00815815 0.99928086 1.10523762 1.04274255\n",
      "  1.16743011 1.03221956 1.14717676 1.06568709]]\n",
      "{0: 2583, 1: 119}\n",
      "acc 0.8997039230199851\n",
      "(0.2773109243697479, 0.15137614678899083, 0.19584569732937687, None)\n",
      "\n",
      "2 loss 154159.97314271668\n",
      "[0.60392999 0.60026911 0.60254216 0.60243097 0.60328396 0.59828039\n",
      " 0.60354645 0.59807085 0.59922452 0.59846218]\n",
      "[[1.11503367 0.81263172 1.00745649 0.99860987 1.1046674  1.04344582\n",
      "  1.16654469 1.03273126 1.14760395 1.0661778 ]]\n",
      "{0: 2591, 1: 111}\n",
      "acc 0.9026646928201333\n",
      "(0.2972972972972973, 0.15137614678899083, 0.2006079027355623, None)\n",
      "\n",
      "3 loss 154126.07737418517\n",
      "[0.60484612 0.60097469 0.60336089 0.60324087 0.60402318 0.59756866\n",
      " 0.60415783 0.59731604 0.59846706 0.59772473]\n",
      "[[1.11419983 0.81210753 1.00675444 0.99793908 1.10409684 1.04414947\n",
      "  1.16566057 1.03324689 1.14803551 1.0666733 ]]\n",
      "{0: 2597, 1: 105}\n",
      "acc 0.9041450777202072\n",
      "(0.3047619047619048, 0.14678899082568808, 0.19814241486068113, None)\n",
      "\n",
      "4 loss 154091.80720371567\n",
      "[0.6057616  0.60167922 0.6041808  0.60405092 0.60476192 0.5968568\n",
      " 0.60476577 0.59655767 0.59770483 0.59698318]\n",
      "[[1.11336671 0.81158368 1.00605206 0.99726855 1.10352598 1.04485349\n",
      "  1.16477782 1.0337664  1.14847144 1.06717355]]\n",
      "{0: 2599, 1: 103}\n",
      "acc 0.9048852701702442\n",
      "(0.3106796116504854, 0.14678899082568808, 0.19937694704049844, None)\n",
      "\n",
      "[0.6057616  0.60167922 0.6041808  0.60405092 0.60476192 0.5968568\n",
      " 0.60476577 0.59655767 0.59770483 0.59698318]\n",
      "[[1.11336671 0.81158368 1.00605206 0.99726855 1.10352598 1.04485349\n",
      "  1.16477782 1.0337664  1.14847144 1.06717355]]\n",
      "{0: 2599, 1: 103}\n",
      "acc 0.9048852701702442\n",
      "(0.3106796116504854, 0.14678899082568808, 0.19937694704049844, None)\n",
      "alpha-mean 0.7000000000000001\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 154419.85892351696\n",
      "[0.70199849 0.69863948 0.70064995 0.70050634 0.70158368 0.69974811\n",
      " 0.7024189  0.69989863 0.70116149 0.70031883]\n",
      "[[1.11684702 0.81388424 1.00909607 1.00020123 1.10603129 1.04198871\n",
      "  1.16832551 1.03148074 1.14652466 1.06476878]]\n",
      "{0: 2379, 1: 323}\n",
      "acc 0.8952627683197631\n",
      "(0.3993808049535604, 0.591743119266055, 0.47689463955637706, None)\n",
      "\n",
      "1 loss 154412.0944320077\n",
      "[0.70281514 0.69912683 0.7012039  0.70100454 0.70210083 0.69908183\n",
      " 0.70313802 0.69948195 0.70085416 0.69998278]\n",
      "[[1.11616031 0.81356764 1.00863199 0.99977896 1.10568849 1.04264002\n",
      "  1.1674484  1.03175502 1.14671642 1.0648187 ]]\n",
      "{0: 2388, 1: 314}\n",
      "acc 0.8985936343449297\n",
      "(0.410828025477707, 0.591743119266055, 0.48496240601503765, None)\n",
      "\n",
      "2 loss 154404.29311352302\n",
      "[0.7036304  0.69961253 0.70175796 0.70150177 0.70261692 0.69841554\n",
      " 0.70385303 0.69906154 0.70054362 0.69964356]\n",
      "[[1.11547508 0.81325195 1.00816643 0.99935532 1.10534605 1.04329152\n",
      "  1.1665718  1.03203151 1.14691    1.0648712 ]]\n",
      "{0: 2392, 1: 310}\n",
      "acc 0.9000740192450037\n",
      "(0.4161290322580645, 0.591743119266055, 0.48863636363636365, None)\n",
      "\n",
      "3 loss 154396.45568353802\n",
      "[0.70444425 0.70009655 0.70231192 0.70199854 0.70313194 0.69774924\n",
      " 0.70457133 0.69863844 0.70023073 0.69929905]\n",
      "[[1.11479133 0.81293715 1.00769945 0.99893033 1.10500399 1.0439432\n",
      "  1.16569574 1.0323102  1.14710539 1.06492631]]\n",
      "{0: 2401, 1: 301}\n",
      "acc 0.9026646928201333\n",
      "(0.42524916943521596, 0.5871559633027523, 0.49325626204238915, None)\n",
      "\n",
      "4 loss 154388.58431126399\n",
      "[0.70525669 0.7005789  0.70286542 0.70249399 0.70364588 0.69708293\n",
      " 0.70528778 0.69821268 0.69991554 0.69895001]\n",
      "[[1.11410906 0.81262325 1.00723105 0.99850403 1.10466231 1.04459504\n",
      "  1.16482024 1.03259108 1.14730257 1.06498403]]\n",
      "{0: 2402, 1: 300}\n",
      "acc 0.9030347890451518\n",
      "(0.4266666666666667, 0.5871559633027523, 0.49420849420849416, None)\n",
      "\n",
      "[0.70525669 0.7005789  0.70286542 0.70249399 0.70364588 0.69708293\n",
      " 0.70528778 0.69821268 0.69991554 0.69895001]\n",
      "[[1.11410906 0.81262325 1.00723105 0.99850403 1.10466231 1.04459504\n",
      "  1.16482024 1.03259108 1.14730257 1.06498403]]\n",
      "{0: 2402, 1: 300}\n",
      "acc 0.9030347890451518\n",
      "(0.4266666666666667, 0.5871559633027523, 0.49420849420849416, None)\n",
      "alpha-mean 0.8\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 154383.66560828217\n",
      "[0.80178968 0.79840525 0.80032777 0.80022986 0.80131478 0.79985738\n",
      " 0.80241745 0.80023172 0.80141595 0.8008523 ]\n",
      "[[1.11707354 0.81405804 1.00951065 1.0005744  1.10624022 1.04183987\n",
      "  1.16838791 1.03134809 1.14644999 1.06457379]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "1 loss 154382.0941822927\n",
      "[0.80238877 0.79865261 0.8005598  0.8004528  0.80156025 0.79930028\n",
      " 0.8031278  0.80015051 0.80136747 0.80105686]\n",
      "[[1.11662259 0.81391978 1.00946195 1.00052513 1.10610856 1.0423427\n",
      "  1.16757512 1.03148887 1.14656611 1.064428  ]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "2 loss 154380.52067854622\n",
      "[0.80298586 0.79889913 0.80079239 0.80067612 0.80180505 0.79874205\n",
      " 0.80383562 0.80006818 0.80131807 0.80126116]\n",
      "[[1.11617333 0.81378194 1.0094127  1.00047544 1.10597718 1.0428471\n",
      "  1.16676273 1.03163036 1.14668279 1.06428281]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "3 loss 154378.94456015225\n",
      "[0.80358095 0.79914482 0.80102554 0.80089983 0.8020492  0.79818268\n",
      " 0.80454088 0.79998473 0.80126776 0.80146521]\n",
      "[[1.11572576 0.8136445  1.0093629  1.00042534 1.10584606 1.04335307\n",
      "  1.16595074 1.03177256 1.14680005 1.06413822]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "4 loss 154377.36571089824\n",
      "[0.80417405 0.79938967 0.80125925 0.80112392 0.80229268 0.7976222\n",
      " 0.80524355 0.79990016 0.80121653 0.80166898]\n",
      "[[1.11527989 0.81350747 1.00931254 1.00037482 1.10571521 1.04386058\n",
      "  1.16513915 1.03191547 1.14691787 1.06399424]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "[0.80417405 0.79938967 0.80125925 0.80112392 0.80229268 0.7976222\n",
      " 0.80524355 0.79990016 0.80121653 0.80166898]\n",
      "[[1.11527989 0.81350747 1.00931254 1.00037482 1.10571521 1.04386058\n",
      "  1.16513915 1.03191547 1.14691787 1.06399424]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "alpha-mean 0.9\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 154366.02123819655\n",
      "[0.90147798 0.89821604 0.90000636 0.89991442 0.90110185 0.90141245\n",
      " 0.90239716 0.9002277  0.90138711 0.90076073]\n",
      "[[1.11733405 0.81418348 1.00977607 1.00082566 1.10638401 1.04033992\n",
      "  1.16861095 1.03141907 1.14652839 1.06464766]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "1 loss 154365.83867670663\n",
      "[0.9017553  0.89826966 0.89991733 0.89982271 0.90113328 0.90241143\n",
      " 0.90309043 0.9001435  0.90131079 0.90086837]\n",
      "[[1.11714924 0.81417367 1.00999141 1.00102599 1.10639671 1.03934141\n",
      "  1.16803143 1.03162972 1.14672182 1.0645787 ]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "2 loss 154365.658614053\n",
      "[0.90203154 0.89832324 0.8998283  0.899731   0.90116468 0.90341039\n",
      " 0.90378153 0.90005929 0.90123447 0.90097579]\n",
      "[[1.11696525 0.81416388 1.01020663 1.0012262  1.10640942 1.03834292\n",
      "  1.1674542  1.03184025 1.14691515 1.06450988]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "3 loss 154365.48086724675\n",
      "[0.90230669 0.89837677 0.89973928 0.89963931 0.90119604 0.90440935\n",
      " 0.90447044 0.89997506 0.90115815 0.901083  ]\n",
      "[[1.11678208 0.81415412 1.01042173 1.0014263  1.10642214 1.03734444\n",
      "  1.16687926 1.03205066 1.14710837 1.06444121]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "4 loss 154365.30540515805\n",
      "[0.90258075 0.89843026 0.89965026 0.89954763 0.90122737 0.90540829\n",
      " 0.90515714 0.89989083 0.90108182 0.90119001]\n",
      "[[1.11659974 0.81414439 1.01063671 1.0016263  1.10643488 1.03634598\n",
      "  1.16630664 1.03226094 1.14730149 1.06437269]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "[0.90258075 0.89843026 0.89965026 0.89954763 0.90122737 0.90540829\n",
      " 0.90515714 0.89989083 0.90108182 0.90119001]\n",
      "[[1.11659974 0.81414439 1.01063671 1.0016263  1.10643488 1.03634598\n",
      "  1.16630664 1.03226094 1.14730149 1.06437269]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "alpha-mean 1.0\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 154404.76830142058\n",
      "[1.00221162 0.99905521 1.00080604 1.0000068  1.00210089 1.00143328\n",
      " 1.00272321 1.00131029 1.00249672 1.00168307]\n",
      "[[1.11757355 0.81428642 1.00983121 1.00087959 1.10647389 1.04135549\n",
      "  1.1692218  1.03147985 1.14658913 1.06479859]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "1 loss 154404.76774150864\n",
      "[1.00324084 0.99976535 1.00184989 1.00000743 1.00313106 1.0024703\n",
      " 1.0037486  1.00234876 1.00352372 1.00271732]\n",
      "[[1.11760228 0.81435874 1.0101012  1.00113339 1.10656995 1.04147573\n",
      "  1.16924033 1.03175109 1.14684292 1.06487693]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "2 loss 154404.76691608585\n",
      "[1.00426279 0.99994513 1.00288141 1.00000797 1.00415357 1.00349671\n",
      " 1.0047683  1.00337602 1.00454439 1.00374213]\n",
      "[[1.11763168 0.81443107 1.01037122 1.00138719 1.10666626 1.04179666\n",
      "  1.16926354 1.03202239 1.14709685 1.06495567]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "3 loss 154404.76571253192\n",
      "[1.00528036 0.99997361 1.0039048  1.00000833 1.0051715  1.0045171\n",
      " 1.0057844  1.00439691 1.00556113 1.00476151]\n",
      "[[1.11766225 0.81450339 1.01064132 1.00164099 1.10676298 1.04233188\n",
      "  1.16929428 1.03229379 1.14735101 1.06503517]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "4 loss 154404.7640214301\n",
      "[1.00629502 0.99998399 1.00492333 1.0000084  1.0061864  1.0055337\n",
      " 1.00679801 1.00541382 1.00657521 1.00577741]\n",
      "[[1.11769461 0.8145757  1.01091157 1.00189479 1.10686036 1.04303077\n",
      "  1.16933607 1.03256539 1.14760551 1.06511587]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "[1.00629502 0.99998399 1.00492333 1.0000084  1.0061864  1.0055337\n",
      " 1.00679801 1.00541382 1.00657521 1.00577741]\n",
      "[[1.11769461 0.8145757  1.01091157 1.00189479 1.10686036 1.04303077\n",
      "  1.16933607 1.03256539 1.14760551 1.06511587]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "for i in np.linspace(0,1,11):\n",
    "    print(\"alpha-mean\",i)\n",
    "    R=train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                              pcl=np.array([-1,1],dtype=np.float64),norm=True,smooth=True,penalty=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-mean 0.0\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -28920.421611836453\n",
      "[ 0.00114834 -0.00192877  0.00101388  0.00092453  0.00101542 -0.00034952\n",
      "  0.00222818 -0.00060628  0.000545   -0.00027112]\n",
      "[[1.11757173 0.81428545 1.00865285 0.99971416 1.10642623 1.04210146\n",
      "  1.16867488 1.03211011 1.14724064 1.06563276]]\n",
      "{0: 2628, 1: 74}\n",
      "acc 0.9111769059955589\n",
      "(0.35135135135135137, 0.11926605504587157, 0.1780821917808219, None)\n",
      "\n",
      "1 loss -29068.159556315197\n",
      "[ 0.00112236 -0.00199761  0.00193483  0.00184548  0.00096838 -0.00111373\n",
      "  0.00276806 -0.00152729 -0.00037602 -0.00119214]\n",
      "[[1.11759771 0.81435429 1.0077435  0.99880186 1.10647327 1.04286568\n",
      "  1.16814008 1.03301515 1.14814892 1.06654532]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "2 loss -29216.976923887432\n",
      "[ 0.00109648 -0.00206599  0.00285757  0.00276821  0.00092267 -0.00187817\n",
      "  0.00331057 -0.0024501  -0.00129883 -0.00211495]\n",
      "[[1.11762359 0.81442267 1.00683235 0.99788778 1.10651898 1.04363011\n",
      "  1.16760252 1.03392203 1.14905904 1.06745972]]\n",
      "{0: 2635, 1: 67}\n",
      "acc 0.9122871946706144\n",
      "(0.3582089552238806, 0.11009174311926606, 0.16842105263157894, None)\n",
      "\n",
      "3 loss -29366.85959159653\n",
      "[ 0.00107071 -0.00213389  0.00378206  0.0036927   0.00087831 -0.00264281\n",
      "  0.00385564 -0.00337467 -0.00222339 -0.00303951]\n",
      "[[1.11764937 0.81449057 1.00591945 0.99697195 1.10656334 1.04439476\n",
      "  1.16706228 1.03483072 1.14997097 1.06837591]]\n",
      "{0: 2636, 1: 66}\n",
      "acc 0.9126572908956329\n",
      "(0.36363636363636365, 0.11009174311926606, 0.16901408450704228, None)\n",
      "\n",
      "4 loss -29517.799453741798\n",
      "[ 0.00104503 -0.00220131  0.00470827  0.00461891  0.0008353  -0.00340766\n",
      "  0.00440321 -0.00430096 -0.00314967 -0.0039658 ]\n",
      "[[1.11767504 0.81455799 1.00500485 0.99605442 1.10660635 1.04515962\n",
      "  1.16651942 1.03574119 1.15088466 1.06929386]]\n",
      "{0: 2639, 1: 63}\n",
      "acc 0.9130273871206513\n",
      "(0.36507936507936506, 0.10550458715596331, 0.16370106761565836, None)\n",
      "\n",
      "[ 0.00104503 -0.00220131  0.00470827  0.00461891  0.0008353  -0.00340766\n",
      "  0.00440321 -0.00430096 -0.00314967 -0.0039658 ]\n",
      "[[1.11767504 0.81455799 1.00500485 0.99605442 1.10660635 1.04515962\n",
      "  1.16651942 1.03574119 1.15088466 1.06929386]]\n",
      "{0: 2639, 1: 63}\n",
      "acc 0.9130273871206513\n",
      "(0.36507936507936506, 0.10550458715596331, 0.16370106761565836, None)\n",
      "alpha-mean 0.1\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -26376.542659086077\n",
      "[0.1011481  0.09807046 0.10101001 0.10092066 0.1010124  0.09965156\n",
      " 0.10222852 0.09939759 0.10054887 0.09973275]\n",
      "[[1.11757197 0.81428622 1.00866116 0.99972124 1.10642925 1.04210038\n",
      "  1.16867635 1.03209996 1.14723158 1.06562513]]\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9104367135455218\n",
      "(0.34210526315789475, 0.11926605504587157, 0.17687074829931976, None)\n",
      "\n",
      "1 loss -26508.10269444301\n",
      "[0.10112173 0.09800077 0.10192723 0.10183788 0.10096238 0.09888839\n",
      " 0.1027687  0.09848031 0.09963158 0.09881546]\n",
      "[[1.11759834 0.81435591 1.00775998 0.99881594 1.10647926 1.04286356\n",
      "  1.16814307 1.03299499 1.14813091 1.06653031]]\n",
      "{0: 2632, 1: 70}\n",
      "acc 0.9119170984455959\n",
      "(0.35714285714285715, 0.11467889908256881, 0.1736111111111111, None)\n",
      "\n",
      "2 loss -26640.724963430916\n",
      "[0.10109545 0.09793153 0.10284631 0.10275696 0.10091376 0.09812497\n",
      " 0.10331147 0.09756115 0.09871243 0.09789631]\n",
      "[[1.11762462 0.81442515 1.00685696 0.99790879 1.10652789 1.04362699\n",
      "  1.16760705 1.03389197 1.14903219 1.06743742]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "3 loss -26774.39647947106\n",
      "[0.10106927 0.09786275 0.10376722 0.10367787 0.10086653 0.09736131\n",
      " 0.10385678 0.09664017 0.09779145 0.09697533]\n",
      "[[1.11765081 0.81449393 1.00595214 0.99699985 1.10657512 1.04439065\n",
      "  1.16706836 1.03479085 1.14993537 1.06834641]]\n",
      "{0: 2635, 1: 67}\n",
      "acc 0.9122871946706144\n",
      "(0.3582089552238806, 0.11009174311926606, 0.16842105263157894, None)\n",
      "\n",
      "4 loss -26909.11001536762\n",
      "[0.10104318 0.09779444 0.10468992 0.10460057 0.10082071 0.09659742\n",
      " 0.10440455 0.0957174  0.09686868 0.09605255]\n",
      "[[1.11767689 0.81456224 1.00504557 0.99608914 1.10662094 1.04515456\n",
      "  1.16652705 1.0356916  1.15084041 1.06925724]]\n",
      "{0: 2636, 1: 66}\n",
      "acc 0.9119170984455959\n",
      "(0.3484848484848485, 0.10550458715596331, 0.1619718309859155, None)\n",
      "\n",
      "[0.10104318 0.09779444 0.10468992 0.10460057 0.10082071 0.09659742\n",
      " 0.10440455 0.0957174  0.09686868 0.09605255]\n",
      "[[1.11767689 0.81456224 1.00504557 0.99608914 1.10662094 1.04515456\n",
      "  1.16652705 1.0356916  1.15084041 1.06925724]]\n",
      "{0: 2636, 1: 66}\n",
      "acc 0.9119170984455959\n",
      "(0.3484848484848485, 0.10550458715596331, 0.1619718309859155, None)\n",
      "alpha-mean 0.2\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -23978.195802911952\n",
      "[0.20114783 0.19806984 0.20100479 0.20091544 0.20100884 0.19965289\n",
      " 0.20222902 0.19940282 0.20055409 0.19973797]\n",
      "[[1.11757224 0.81428684 1.00867396 0.99973235 1.10643281 1.04209906\n",
      "  1.16867932 1.03208431 1.1472173  1.06561345]]\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9096965210954848\n",
      "(0.3333333333333333, 0.11926605504587157, 0.17567567567567569, None)\n",
      "\n",
      "1 loss -24092.581597054635\n",
      "[0.20112105 0.19799941 0.20191697 0.20182761 0.20095531 0.19889102\n",
      " 0.20276967 0.19849057 0.19964185 0.19882573]\n",
      "[[1.11759903 0.81435727 1.00778543 0.99883806 1.10648634 1.04286094\n",
      "  1.16814908 1.03296389 1.1481025  1.0665073 ]]\n",
      "{0: 2627, 1: 75}\n",
      "acc 0.9108068097705403\n",
      "(0.3466666666666667, 0.11926605504587157, 0.17747440273037546, None)\n",
      "\n",
      "2 loss -24208.008864761687\n",
      "[0.20109435 0.19792942 0.20283112 0.20274177 0.20090322 0.19812886\n",
      " 0.20331289 0.19757635 0.19872762 0.1979115 ]\n",
      "[[1.11762573 0.81442726 1.006895   0.99794184 1.10653842 1.04362312\n",
      "  1.16761607 1.03384557 1.1489898  1.06740321]]\n",
      "{0: 2632, 1: 70}\n",
      "acc 0.9119170984455959\n",
      "(0.35714285714285715, 0.11467889908256881, 0.1736111111111111, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss -24324.46604019108\n",
      "[0.20106773 0.19785987 0.20374722 0.20365786 0.20085259 0.19736642\n",
      " 0.20385861 0.19666018 0.19781146 0.19699534]\n",
      "[[1.11765234 0.8144968  1.00600269 0.99704372 1.10658905 1.04438557\n",
      "  1.16708036 1.0347293  1.14987918 1.06830114]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "4 loss -24441.946989478885\n",
      "[0.20104121 0.19779079 0.2046652  0.20457585 0.20080344 0.19660371\n",
      " 0.20440678 0.19574212 0.19689341 0.19607728]\n",
      "[[1.11767887 0.81456588 1.00510857 0.99614376 1.10663821 1.04514829\n",
      "  1.16654204 1.03561505 1.15077058 1.06920105]]\n",
      "{0: 2635, 1: 67}\n",
      "acc 0.9122871946706144\n",
      "(0.3582089552238806, 0.11009174311926606, 0.16842105263157894, None)\n",
      "\n",
      "[0.20104121 0.19779079 0.2046652  0.20457585 0.20080344 0.19660371\n",
      " 0.20440678 0.19574212 0.19689341 0.19607728]\n",
      "[[1.11767887 0.81456588 1.00510857 0.99614376 1.10663821 1.04514829\n",
      "  1.16654204 1.03561505 1.15077058 1.06920105]]\n",
      "{0: 2635, 1: 67}\n",
      "acc 0.9122871946706144\n",
      "(0.3582089552238806, 0.11009174311926606, 0.16842105263157894, None)\n",
      "alpha-mean 0.30000000000000004\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -21771.88549894075\n",
      "[0.30114754 0.29806944 0.3009976  0.30090825 0.30100469 0.29965459\n",
      " 0.30222956 0.29941001 0.30056128 0.29974516]\n",
      "[[1.11757254 0.81428723 1.0086952  0.99975145 1.10643696 1.04209736\n",
      "  1.16868692 1.03205867 1.14719295 1.06559418]]\n",
      "{0: 2620, 1: 82}\n",
      "acc 0.9089563286454478\n",
      "(0.32926829268292684, 0.12385321100917432, 0.18000000000000005, None)\n",
      "\n",
      "1 loss -21868.036640468956\n",
      "[0.3011203  0.29799842 0.30190284 0.30181349 0.30094706 0.29889435\n",
      " 0.30277073 0.2985047  0.29965598 0.29883986]\n",
      "[[1.11759977 0.81435825 1.00782777 0.99887619 1.10649459 1.04285762\n",
      "  1.16816438 1.03291284 1.14805399 1.06646926]]\n",
      "{0: 2623, 1: 79}\n",
      "acc 0.9093264248704663\n",
      "(0.3291139240506329, 0.11926605504587157, 0.1750841750841751, None)\n",
      "\n",
      "2 loss -21965.19919353428\n",
      "[0.30109314 0.29792783 0.30281023 0.30272087 0.30089092 0.29813379\n",
      " 0.30331447 0.29759725 0.29874853 0.2979324 ]\n",
      "[[1.11762694 0.81442885 1.00695834 0.99799886 1.10655073 1.0436182\n",
      "  1.167639   1.03376936 1.14891742 1.06734663]]\n",
      "{0: 2626, 1: 76}\n",
      "acc 0.9104367135455218\n",
      "(0.34210526315789475, 0.11926605504587157, 0.17687074829931976, None)\n",
      "\n",
      "3 loss -22063.36337855594\n",
      "[0.30106606 0.29785767 0.30371971 0.30363035 0.30083629 0.29737291\n",
      " 0.3038607  0.2966877  0.29783898 0.29702285]\n",
      "[[1.11765402 0.81449901 1.00608697 0.99711952 1.10660536 1.04437911\n",
      "  1.16711087 1.03462818 1.14978322 1.06822623]]\n",
      "{0: 2631, 1: 71}\n",
      "acc 0.9108068097705403\n",
      "(0.3380281690140845, 0.11009174311926606, 0.16608996539792387, None)\n",
      "\n",
      "4 loss -22162.52442607711\n",
      "[0.30103905 0.29778796 0.30463124 0.30454189 0.3007832  0.29661171\n",
      " 0.30440937 0.2957761  0.29692738 0.29611125]\n",
      "[[1.11768102 0.81456871 1.00521371 0.99623822 1.10665845 1.04514032\n",
      "  1.16658007 1.03548925 1.15065131 1.06910802]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "\n",
      "[0.30103905 0.29778796 0.30463124 0.30454189 0.3007832  0.29661171\n",
      " 0.30440937 0.2957761  0.29692738 0.29611125]\n",
      "[[1.11768102 0.81456871 1.00521371 0.99623822 1.10665845 1.04514032\n",
      "  1.16658007 1.03548925 1.15065131 1.06910802]]\n",
      "{0: 2633, 1: 69}\n",
      "acc 0.9115470022205774\n",
      "(0.34782608695652173, 0.11009174311926606, 0.16724738675958187, None)\n",
      "alpha-mean 0.4\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -19816.827407460372\n",
      "[0.4011472  0.39806937 0.40098685 0.4008975  0.401      0.39965723\n",
      " 0.40222984 0.39942076 0.40057204 0.39975592]\n",
      "[[1.11757288 0.81428731 1.00873435 0.99978939 1.10644164 1.04209474\n",
      "  1.16871387 1.03201314 1.14714658 1.06555838]]\n",
      "{0: 2616, 1: 86}\n",
      "acc 0.9104367135455218\n",
      "(0.36046511627906974, 0.14220183486238533, 0.20394736842105263, None)\n",
      "\n",
      "1 loss -19893.71048147337\n",
      "[0.40111946 0.39799797 0.40188171 0.40179236 0.4009377  0.39889953\n",
      " 0.4027713  0.39852584 0.39967711 0.39886099]\n",
      "[[1.11760062 0.8143587  1.00790599 0.99895207 1.10650394 1.04285246\n",
      "  1.16821856 1.0328221  1.14796154 1.06639843]]\n",
      "{0: 2619, 1: 83}\n",
      "acc 0.9100666173205033\n",
      "(0.3493975903614458, 0.13302752293577982, 0.19269102990033224, None)\n",
      "\n",
      "2 loss -19971.557436599855\n",
      "[0.40109178 0.39792699 0.40277899 0.40268963 0.40087693 0.39814145\n",
      " 0.40331534 0.3976285  0.39877978 0.39796365]\n",
      "[[1.11762829 0.81442969 1.00707556 0.9981125  1.10656472 1.04361057\n",
      "  1.16772034 1.03363383 1.14877945 1.06724116]]\n",
      "{0: 2621, 1: 81}\n",
      "acc 0.9100666173205033\n",
      "(0.345679012345679, 0.12844036697247707, 0.18729096989966554, None)\n",
      "\n",
      "3 loss -20050.3607289453\n",
      "[0.40106417 0.39785644 0.40367863 0.40358927 0.4008177  0.39738298\n",
      " 0.4038619  0.3967288  0.39788008 0.39706395]\n",
      "[[1.1176559  0.81450024 1.00624312 0.99727077 1.10662395 1.04436907\n",
      "  1.16721931 1.03444826 1.14960025 1.06808652]]\n",
      "{0: 2624, 1: 78}\n",
      "acc 0.9111769059955589\n",
      "(0.358974358974359, 0.12844036697247707, 0.1891891891891892, None)\n",
      "\n",
      "4 loss -20130.11727634784\n",
      "[0.40103664 0.39778633 0.40458057 0.40449121 0.40076006 0.39662414\n",
      " 0.40441091 0.39582679 0.39697808 0.39616195]\n",
      "[[1.11768344 0.81457035 1.00540875 0.99642694 1.10668159 1.04512794\n",
      "  1.16671557 1.03526535 1.15042388 1.06893444]]\n",
      "{0: 2625, 1: 77}\n",
      "acc 0.9108068097705403\n",
      "(0.35064935064935066, 0.12385321100917432, 0.18305084745762712, None)\n",
      "\n",
      "[0.40103664 0.39778633 0.40458057 0.40449121 0.40076006 0.39662414\n",
      " 0.40441091 0.39582679 0.39697808 0.39616195]\n",
      "[[1.11768344 0.81457035 1.00540875 0.99642694 1.10668159 1.04512794\n",
      "  1.16671557 1.03526535 1.15042388 1.06893444]]\n",
      "{0: 2625, 1: 77}\n",
      "acc 0.9108068097705403\n",
      "(0.35064935064935066, 0.12385321100917432, 0.18305084745762712, None)\n",
      "alpha-mean 0.5\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -18180.099362868117\n",
      "[0.5011468  0.49806971 0.50092861 0.50086756 0.50099493 0.49966343\n",
      " 0.50209671 0.49945431 0.50060183 0.49980488]\n",
      "[[1.11757328 0.81428697 1.00881581 0.99988076 1.10644672 1.04208854\n",
      "  1.16889122 1.03192609 1.14704683 1.06547996]]\n",
      "{0: 2603, 1: 99}\n",
      "acc 0.9063656550703183\n",
      "(0.32323232323232326, 0.14678899082568808, 0.2018927444794953, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss -18233.865538499387\n",
      "[0.50111848 0.49799827 0.50176535 0.50173301 0.50092744 0.49891183\n",
      " 0.50250389 0.49857901 0.49973255 0.49892957]\n",
      "[[1.1176016  0.81435841 1.00806904 0.99913532 1.1065142  1.04284018\n",
      "  1.16857396 1.03264821 1.14776227 1.06624262]]\n",
      "{0: 2606, 1: 96}\n",
      "acc 0.9074759437453738\n",
      "(0.3333333333333333, 0.14678899082568808, 0.20382165605095542, None)\n",
      "\n",
      "2 loss -18288.958569170187\n",
      "[0.5010902  0.49792721 0.50260451 0.50260117 0.50086141 0.49815974\n",
      " 0.50291333 0.49770095 0.49885449 0.49805151]\n",
      "[[1.11762987 0.81442947 1.00732011 0.99838763 1.10658024 1.04359232\n",
      "  1.16825364 1.03337367 1.14848153 1.06700864]]\n",
      "{0: 2610, 1: 92}\n",
      "acc 0.9089563286454478\n",
      "(0.34782608695652173, 0.14678899082568808, 0.20645161290322583, None)\n",
      "\n",
      "3 loss -18344.90822574766\n",
      "[0.50106198 0.49785655 0.50344601 0.50347196 0.50079687 0.49740717\n",
      " 0.50332508 0.49682019 0.49797374 0.49717075]\n",
      "[[1.11765809 0.81450013 1.00656911 0.99763778 1.10664478 1.04434493\n",
      "  1.16793036 1.03410242 1.14920458 1.06777795]]\n",
      "{0: 2613, 1: 89}\n",
      "acc 0.9100666173205033\n",
      "(0.3595505617977528, 0.14678899082568808, 0.20846905537459282, None)\n",
      "\n",
      "4 loss -18401.65147234292\n",
      "[0.50103382 0.4977863  0.50428979 0.50434523 0.50073384 0.49665414\n",
      " 0.5037389  0.4959368  0.49709035 0.49628736]\n",
      "[[1.11768626 0.81457038 1.00581612 0.99688588 1.10670781 1.045098\n",
      "  1.16760423 1.03483441 1.14993133 1.06855049]]\n",
      "{0: 2618, 1: 84}\n",
      "acc 0.9096965210954848\n",
      "(0.34523809523809523, 0.13302752293577982, 0.19205298013245034, None)\n",
      "\n",
      "[0.50103382 0.4977863  0.50428979 0.50434523 0.50073384 0.49665414\n",
      " 0.5037389  0.4959368  0.49709035 0.49628736]\n",
      "[[1.11768626 0.81457038 1.00581612 0.99688588 1.10670781 1.045098\n",
      "  1.16760423 1.03483441 1.14993133 1.06855049]]\n",
      "{0: 2618, 1: 84}\n",
      "acc 0.9096965210954848\n",
      "(0.34523809523809523, 0.13302752293577982, 0.19205298013245034, None)\n",
      "alpha-mean 0.6000000000000001\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -16806.520172371387\n",
      "[0.60114655 0.59806937 0.60085401 0.60075575 0.60098396 0.59967532\n",
      " 0.6019192  0.59954531 0.60069308 0.59989646]\n",
      "[[1.11757353 0.8142873  1.00897583 1.00010148 1.10645769 1.04207667\n",
      "  1.16910063 1.03177288 1.14684298 1.0653119 ]]\n",
      "{0: 2575, 1: 127}\n",
      "acc 0.8967431532198371\n",
      "(0.25984251968503935, 0.15137614678899083, 0.191304347826087, None)\n",
      "\n",
      "1 loss -16834.969129938607\n",
      "[0.60111779 0.59799725 0.60161612 0.60150814 0.60090507 0.59893557\n",
      " 0.60214952 0.59877341 0.59991728 0.59914021]\n",
      "[[1.11760228 0.81435943 1.00838922 0.99957757 1.10653658 1.04281649\n",
      "  1.16899514 1.03234171 1.14735463 1.06590849]]\n",
      "{0: 2582, 1: 120}\n",
      "acc 0.8993338267949667\n",
      "(0.275, 0.15137614678899083, 0.19526627218934914, None)\n",
      "\n",
      "2 loss -16863.93191422365\n",
      "[0.60108908 0.59792541 0.60238124 0.60226231 0.60082727 0.59819527\n",
      " 0.60238183 0.59799803 0.59913688 0.59837933]\n",
      "[[1.117631   0.81443126 1.00780006 0.99905128 1.10661438 1.04355686\n",
      "  1.16888713 1.03291454 1.14787073 1.06650962]]\n",
      "{0: 2591, 1: 111}\n",
      "acc 0.9026646928201333\n",
      "(0.2972972972972973, 0.15137614678899083, 0.2006079027355623, None)\n",
      "\n",
      "3 loss -16893.4300570551\n",
      "[0.6010604  0.59785388 0.60314897 0.60301863 0.60075059 0.59745444\n",
      " 0.60261602 0.59721916 0.59835081 0.59761454]\n",
      "[[1.11765968 0.8145028  1.00720846 0.99852275 1.10669106 1.04429775\n",
      "  1.16877666 1.03349131 1.14839127 1.06711522]]\n",
      "{0: 2595, 1: 107}\n",
      "acc 0.9034048852701703\n",
      "(0.29906542056074764, 0.14678899082568808, 0.19692307692307692, None)\n",
      "\n",
      "4 loss -16923.450744822967\n",
      "[0.60103175 0.59778266 0.60391909 0.60377566 0.60067507 0.59671309\n",
      " 0.60285175 0.59643683 0.59756051 0.59684557]\n",
      "[[1.11768832 0.81457402 1.00661452 0.99799209 1.10676658 1.04503917\n",
      "  1.16866376 1.03407198 1.1489162  1.06772525]]\n",
      "{0: 2598, 1: 104}\n",
      "acc 0.9045151739452257\n",
      "(0.3076923076923077, 0.14678899082568808, 0.19875776397515527, None)\n",
      "\n",
      "[0.60103175 0.59778266 0.60391909 0.60377566 0.60067507 0.59671309\n",
      " 0.60285175 0.59643683 0.59756051 0.59684557]\n",
      "[[1.11768832 0.81457402 1.00661452 0.99799209 1.10676658 1.04503917\n",
      "  1.16866376 1.03407198 1.1489162  1.06772525]]\n",
      "{0: 2598, 1: 104}\n",
      "acc 0.9045151739452257\n",
      "(0.3076923076923077, 0.14678899082568808, 0.19875776397515527, None)\n",
      "alpha-mean 0.7000000000000001\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -15939.431711918833\n",
      "[0.70114658 0.6980671  0.7005352  0.70036628 0.70097048 0.69970941\n",
      " 0.70172842 0.69983442 0.70106882 0.70023938]\n",
      "[[1.1175735  0.81428958 1.00926217 1.00040094 1.10647117 1.04204262\n",
      "  1.16921675 1.03155796 1.14662476 1.06497891]]\n",
      "{0: 2379, 1: 323}\n",
      "acc 0.8952627683197631\n",
      "(0.3993808049535604, 0.591743119266055, 0.47689463955637706, None)\n",
      "\n",
      "1 loss -15945.547968058825\n",
      "[0.70111772 0.69799241 0.7009752  0.70072644 0.70087748 0.69900428\n",
      " 0.70176563 0.69935282 0.70067024 0.69982519]\n",
      "[[1.11760236 0.81436427 1.00896215 1.0001753  1.10656417 1.04274786\n",
      "  1.16922713 1.03190938 1.14691616 1.06524055]]\n",
      "{0: 2385, 1: 317}\n",
      "acc 0.8974833456698742\n",
      "(0.4069400630914827, 0.591743119266055, 0.4822429906542056, None)\n",
      "\n",
      "2 loss -15951.757772791365\n",
      "[0.70108887 0.69791784 0.70141635 0.7010881  0.70078491 0.69829879\n",
      " 0.7018038  0.69886784 0.70026877 0.69940672]\n",
      "[[1.1176312  0.81443884 1.0086587  0.9999462  1.10665674 1.04345345\n",
      "  1.16923675 1.03226318 1.14720957 1.06550534]]\n",
      "{0: 2389, 1: 313}\n",
      "acc 0.8989637305699482\n",
      "(0.41214057507987223, 0.591743119266055, 0.4858757062146893, None)\n",
      "\n",
      "3 loss -15958.059847491313\n",
      "[0.70106004 0.69784341 0.70185925 0.70145038 0.70069277 0.69759296\n",
      " 0.70184291 0.69838007 0.69986473 0.69898245]\n",
      "[[1.11766004 0.81451327 1.00835185 0.99971367 1.10674889 1.04415938\n",
      "  1.16924559 1.03261936 1.14750498 1.06577329]]\n",
      "{0: 2400, 1: 302}\n",
      "acc 0.9022945965951147\n",
      "(0.423841059602649, 0.5871559633027523, 0.49230769230769234, None)\n",
      "\n",
      "4 loss -15964.453597918462\n",
      "[0.70103121 0.69776911 0.70230358 0.70181466 0.70060106 0.69688679\n",
      " 0.70188297 0.69788888 0.69945783 0.6985552 ]\n",
      "[[1.11768886 0.81458757 1.00804164 0.99947771 1.1068406  1.04486566\n",
      "  1.16925366 1.03297791 1.14780238 1.06604442]]\n",
      "{0: 2401, 1: 301}\n",
      "acc 0.9026646928201333\n",
      "(0.42524916943521596, 0.5871559633027523, 0.49325626204238915, None)\n",
      "\n",
      "[0.70103121 0.69776911 0.70230358 0.70181466 0.70060106 0.69688679\n",
      " 0.70188297 0.69788888 0.69945783 0.6985552 ]\n",
      "[[1.11768886 0.81458757 1.00804164 0.99947771 1.1068406  1.04486566\n",
      "  1.16925366 1.03297791 1.14780238 1.06604442]]\n",
      "{0: 2401, 1: 301}\n",
      "acc 0.9026646928201333\n",
      "(0.42524916943521596, 0.5871559633027523, 0.49325626204238915, None)\n",
      "alpha-mean 0.8\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss -15617.795835581157\n",
      "[0.80114662 0.79806672 0.80022123 0.80011771 0.8009654  0.79980673\n",
      " 0.80167435 0.80015961 0.8013301  0.80070702]\n",
      "[[1.11757345 0.81428996 1.00963296 1.0007069  1.10647625 1.04194538\n",
      "  1.16922697 1.03140962 1.146522   1.06480009]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "1 loss -15618.934387292413\n",
      "[0.80111784 0.7979916  0.80034773 0.80022991 0.80086708 0.79919892\n",
      " 0.80165777 0.8000064  0.80119611 0.80076598]\n",
      "[[1.11760223 0.81436508 1.0097051  1.00078839 1.10657457 1.0425534\n",
      "  1.16924785 1.03161153 1.14670955 1.06488057]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "2 loss -15620.086200054015\n",
      "[0.80108907 0.79791653 0.80047546 0.80034316 0.8007689  0.79858972\n",
      " 0.80164134 0.79985185 0.801061   0.80082423]\n",
      "[[1.11763101 0.81444015 1.00977615 1.00086895 1.10667275 1.0431628\n",
      "  1.16926864 1.03181417 1.14689767 1.06496137]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "3 loss -15621.251340857134\n",
      "[0.8010603  0.79784152 0.80060444 0.80045749 0.80067087 0.79797914\n",
      " 0.80162507 0.79969593 0.80092475 0.80088176]\n",
      "[[1.11765978 0.81451516 1.00984612 1.00094859 1.10677078 1.04377358\n",
      "  1.16928933 1.03201753 1.14708635 1.06504247]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "4 loss -15622.429921608207\n",
      "[0.80103154 0.79776656 0.80073466 0.8005729  0.80057298 0.79736721\n",
      " 0.80160897 0.79953865 0.80078737 0.80093857]\n",
      "[[1.11768854 0.81459012 1.00991499 1.00102729 1.10686867 1.04438571\n",
      "  1.16930993 1.03222161 1.14727559 1.06512388]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "\n",
      "[0.80103154 0.79776656 0.80073466 0.8005729  0.80057298 0.79736721\n",
      " 0.80160897 0.79953865 0.80078737 0.80093857]\n",
      "[[1.11768854 0.81459012 1.00991499 1.00102729 1.10686867 1.04438571\n",
      "  1.16930993 1.03222161 1.14727559 1.06512388]]\n",
      "{0: 2294, 1: 408}\n",
      "acc 0.8808290155440415\n",
      "(0.37254901960784315, 0.6972477064220184, 0.4856230031948882, None)\n",
      "alpha-mean 0.9\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -15499.709186025439\n",
      "[0.90114659 0.89806781 0.89995791 0.89986302 0.90096542 0.90041339\n",
      " 0.90167754 0.90018924 0.90134299 0.90055397]\n",
      "[[1.11757348 0.81428887 1.00981192 1.00086355 1.10647623 1.04133855\n",
      "  1.16922052 1.03144909 1.14656283 1.06480805]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "1 loss -15499.832108050312\n",
      "[0.90111784 0.89799378 0.89982084 0.89972035 0.90086712 0.90041339\n",
      " 0.90166262 0.90006677 0.90122299 0.90045888]\n",
      "[[1.11760224 0.8143629  1.01006265 1.00110126 1.10657454 1.04133855\n",
      "  1.16923543 1.03168954 1.14679027 1.06489547]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "2 loss -15499.955271220799\n",
      "[0.90108909 0.89791976 0.89968367 0.89957759 0.90076881 0.90041339\n",
      " 0.90164771 0.89994425 0.90110293 0.90036378]\n",
      "[[1.11763099 0.81443692 1.01031325 1.00133885 1.10667285 1.04133855\n",
      "  1.16925034 1.03192984 1.14701758 1.06498291]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "3 loss -15500.07868474255\n",
      "[0.90106033 0.89784574 0.89954639 0.89943474 0.9006705  0.90041339\n",
      " 0.90163281 0.89982165 0.9009828  0.90026865]\n",
      "[[1.11765974 0.81451095 1.01056371 1.00157633 1.10677116 1.04133855\n",
      "  1.16926525 1.03217    1.14724478 1.06507038]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "4 loss -15500.202348950163\n",
      "[0.90103158 0.89777172 0.89940901 0.8992918  0.90057219 0.90041339\n",
      " 0.9016179  0.899699   0.9008626  0.90017349]\n",
      "[[1.11768849 0.81458497 1.01081404 1.00181369 1.10686947 1.04133855\n",
      "  1.16928015 1.03241001 1.14747185 1.06515788]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "\n",
      "[0.90103158 0.89777172 0.89940901 0.8992918  0.90057219 0.90041339\n",
      " 0.9016179  0.899699   0.9008626  0.90017349]\n",
      "[[1.11768849 0.81458497 1.01081404 1.00181369 1.10686947 1.04133855\n",
      "  1.16928015 1.03241001 1.14747185 1.06515788]]\n",
      "{0: 2308, 1: 394}\n",
      "acc 0.8852701702442635\n",
      "(0.383248730964467, 0.6926605504587156, 0.4934640522875816, None)\n",
      "alpha-mean 1.0\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -15441.244159159418\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11757313 0.8142873  1.00983121 1.00087959 1.10647382 1.04133855\n",
      "  1.1692205  1.03147985 1.1465891  1.06479855]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "1 loss -15441.24448844349\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11760143 0.81435963 1.01010119 1.00113339 1.10656974 1.04133855\n",
      "  1.16923539 1.03175107 1.14684279 1.06487669]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "2 loss -15441.244817769148\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11762974 0.81443195 1.01037117 1.00138719 1.10666564 1.04133855\n",
      "  1.16925027 1.03202229 1.14709649 1.06495483]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "3 loss -15441.24514717711\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11765804 0.81450427 1.01064116 1.00164099 1.10676155 1.04133855\n",
      "  1.16926516 1.03229352 1.14735018 1.06503296]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "4 loss -15441.24547666745\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11768635 0.81457658 1.01091115 1.00189479 1.10685745 1.04133855\n",
      "  1.16928004 1.03256474 1.14760388 1.0651111 ]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n",
      "\n",
      "[1.00117545 0.99814215 1.0000956  1.00000624 1.00106378 1.00041339\n",
      " 1.00169206 1.00031208 1.00146335 1.00064723]\n",
      "[[1.11768635 0.81457658 1.01091115 1.00189479 1.10685745 1.04133855\n",
      "  1.16928004 1.03256474 1.14760388 1.0651111 ]]\n",
      "{0: 2309, 1: 393}\n",
      "acc 0.884900074019245\n",
      "(0.3816793893129771, 0.6880733944954128, 0.4909983633387889, None)\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "for i in np.linspace(0,1,11):\n",
    "    print(\"alpha-mean\",i)\n",
    "    R=train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                              pcl=np.array([-1,1],dtype=np.float64),norm=False,smooth=True,penalty=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 154419.85892351693\n",
      "[0.70199849 0.69863948 0.70064995 0.70050634 0.70158368 0.69974811\n",
      " 0.7024189  0.69989863 0.70116149 0.70031883]\n",
      "[[1.11684702 0.81388424 1.00909607 1.00020123 1.10603129 1.04198871\n",
      "  1.16832551 1.03148074 1.14652466 1.06476878]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "1 loss 154412.0944320077\n",
      "[0.70281514 0.69912683 0.7012039  0.70100454 0.70210083 0.69908183\n",
      " 0.70313802 0.69948195 0.70085416 0.69998278]\n",
      "[[1.11616031 0.81356764 1.00863199 0.99977896 1.10568849 1.04264002\n",
      "  1.1674484  1.03175502 1.14671642 1.0648187 ]]\n",
      "{0: 2557, 1: 257}\n",
      "acc 0.9090262970859986\n",
      "(0.36964980544747084, 0.5026455026455027, 0.4260089686098655, None)\n",
      "\n",
      "2 loss 154404.293113523\n",
      "[0.7036304  0.69961253 0.70175796 0.70150177 0.70261692 0.69841554\n",
      " 0.70385303 0.69906154 0.70054362 0.69964356]\n",
      "[[1.11547508 0.81325195 1.00816643 0.99935532 1.10534605 1.04329152\n",
      "  1.1665718  1.03203151 1.14691    1.0648712 ]]\n",
      "{0: 2562, 1: 252}\n",
      "acc 0.9108031272210376\n",
      "(0.376984126984127, 0.5026455026455027, 0.4308390022675737, None)\n",
      "\n",
      "3 loss 154396.45568353802\n",
      "[0.70444425 0.70009655 0.70231192 0.70199854 0.70313194 0.69774924\n",
      " 0.70457133 0.69863844 0.70023073 0.69929905]\n",
      "[[1.11479133 0.81293715 1.00769945 0.99893033 1.10500399 1.0439432\n",
      "  1.16569574 1.0323102  1.14710539 1.06492631]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "4 loss 154388.58431126399\n",
      "[0.70525669 0.7005789  0.70286542 0.70249399 0.70364588 0.69708293\n",
      " 0.70528778 0.69821268 0.69991554 0.69895001]\n",
      "[[1.11410906 0.81262325 1.00723105 0.99850403 1.10466231 1.04459504\n",
      "  1.16482024 1.03259108 1.14730257 1.06498403]]\n",
      "{0: 2566, 1: 248}\n",
      "acc 0.912224591329069\n",
      "(0.38306451612903225, 0.5026455026455027, 0.43478260869565216, None)\n",
      "\n",
      "[0.70525669 0.7005789  0.70286542 0.70249399 0.70364588 0.69708293\n",
      " 0.70528778 0.69821268 0.69991554 0.69895001]\n",
      "[[1.11410906 0.81262325 1.00723105 0.99850403 1.10466231 1.04459504\n",
      "  1.16482024 1.03259108 1.14730257 1.06498403]]\n",
      "{0: 2566, 1: 248}\n",
      "acc 0.912224591329069\n",
      "acc 0.912224591329069\n",
      "[[2472  153]\n",
      " [  94   95]]\n",
      "(0.38306451612903225, 0.5026455026455027, 0.43478260869565216, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(0.7,0.001,seed),\n",
    "                          pcl=np.array([-1,1],dtype=np.float64),smooth=True,penalty=0,alp=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -15939.431711918833\n",
      "[0.70114658 0.6980671  0.7005352  0.70036628 0.70097048 0.69970941\n",
      " 0.70172842 0.69983442 0.70106882 0.70023938]\n",
      "[[1.1175735  0.81428958 1.00926217 1.00040094 1.10647117 1.04204262\n",
      "  1.16921675 1.03155796 1.14662476 1.06497891]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "1 loss -15945.54796805883\n",
      "[0.70111772 0.69799241 0.7009752  0.70072644 0.70087748 0.69900428\n",
      " 0.70176563 0.69935282 0.70067024 0.69982519]\n",
      "[[1.11760236 0.81436427 1.00896215 1.0001753  1.10656417 1.04274786\n",
      "  1.16922713 1.03190938 1.14691616 1.06524055]]\n",
      "{0: 2556, 1: 258}\n",
      "acc 0.9086709310589908\n",
      "(0.3682170542635659, 0.5026455026455027, 0.4250559284116331, None)\n",
      "\n",
      "2 loss -15951.757772791369\n",
      "[0.70108887 0.69791784 0.70141635 0.7010881  0.70078491 0.69829879\n",
      " 0.7018038  0.69886784 0.70026877 0.69940672]\n",
      "[[1.1176312  0.81443884 1.0086587  0.9999462  1.10665674 1.04345345\n",
      "  1.16923675 1.03226318 1.14720957 1.06550534]]\n",
      "{0: 2561, 1: 253}\n",
      "acc 0.9104477611940298\n",
      "(0.37549407114624506, 0.5026455026455027, 0.4298642533936652, None)\n",
      "\n",
      "3 loss -15958.059847491313\n",
      "[0.70106004 0.69784341 0.70185925 0.70145038 0.70069277 0.69759296\n",
      " 0.70184291 0.69838007 0.69986473 0.69898245]\n",
      "[[1.11766004 0.81451327 1.00835185 0.99971367 1.10674889 1.04415938\n",
      "  1.16924559 1.03261936 1.14750498 1.06577329]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "4 loss -15964.453597918462\n",
      "[0.70103121 0.69776911 0.70230358 0.70181466 0.70060106 0.69688679\n",
      " 0.70188297 0.69788888 0.69945783 0.6985552 ]\n",
      "[[1.11768886 0.81458757 1.00804164 0.99947771 1.1068406  1.04486566\n",
      "  1.16925366 1.03297791 1.14780238 1.06604442]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "[0.70103121 0.69776911 0.70230358 0.70181466 0.70060106 0.69688679\n",
      " 0.70188297 0.69788888 0.69945783 0.6985552 ]\n",
      "[[1.11768886 0.81458757 1.00804164 0.99947771 1.1068406  1.04486566\n",
      "  1.16925366 1.03297791 1.14780238 1.06604442]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "acc 0.9115138592750534\n",
      "[[2470  155]\n",
      " [  94   95]]\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(0.7,0.001,seed),\n",
    "                          pcl=np.array([-1,1],dtype=np.float64),norm=False,\\\n",
    "                          smooth=True,penalty=2,alp=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import _pickle as pkl\n",
    "# L_train = pkl.load(open(\"train_L_S_discrete.p\",\"rb\"))\n",
    "# L_train = sp.csr_matrix(L_train)\n",
    "\n",
    "# L_gold = pkl.load(open(\"gold_discrete.p\",\"rb\"))\n",
    "# print(np.array(L_gold).shape)\n",
    "# L_gold = sp.csr_matrix(L_gold)\n",
    "\n",
    "L_train = np.load(\"train_L_S_discrete.npy\")\n",
    "L_train = L_train[:,0,:].astype(int)\n",
    "print(np.array(L_train).shape)\n",
    "L_train = sp.csr_matrix(L_train)\n",
    "\n",
    "L_gold = np.load(\"test_L_S_discrete.npy\")\n",
    "L_gold = L_gold[:,0,:].astype(int)\n",
    "print(np.array(L_gold).shape)\n",
    "L_gold = sp.csr_matrix(L_gold)\n",
    "\n",
    "from snorkel.learning import GenerativeModel\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lt = time.localtime()\n",
    "\n",
    "print(\"started at: {}-{}-{}, {}:{}:{}\".format(lt.tm_mday,lt.tm_mon,lt.tm_year,lt.tm_hour,lt.tm_min,lt.tm_sec))\n",
    "\n",
    "gen_model.train(L_train, epochs = 100)\n",
    "# gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)\n",
    "\n",
    "\n",
    "print(\"trained in \",str(datetime.timedelta(seconds=time.time() - start_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
