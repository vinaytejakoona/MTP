{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df=pd.read_csv('./SMSSpamCollection',sep='\\t', header=None,na_filter=False,names=['class','text'])\n",
    "\n",
    "# df['class'] = df[\"class\"].astype('category')\n",
    "\n",
    "# df['true_label'] = df['class'].cat.codes\n",
    "\n",
    "# np.random.seed(1234)\n",
    "# msk = np.random.rand(len(df)) < 0.66\n",
    "\n",
    "# train_df = df[msk]\n",
    "# test_df = df[~msk]\n",
    "\n",
    "# true_labels = test_df['true_label'].tolist()\n",
    "\n",
    "# train_df.to_pickle(\"train_df\")\n",
    "# test_df.to_pickle(\"test_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>3193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text\n",
       "class      \n",
       "ham    3193\n",
       "spam    507"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle(\"train_df\")\n",
    "# train_df.head()\n",
    "train_df.groupby(\"class\").agg({\"text\": np.count_nonzero})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text\n",
       "class      \n",
       "ham    1632\n",
       "spam    240"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle(\"test_df\")\n",
    "\n",
    "true_labels = test_df['true_label'].tolist()\n",
    "\n",
    "test_df.groupby(\"class\").agg({\"text\": np.count_nonzero})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gensim.matutils as gm\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = KeyedVectors.load_word2vec_format('../../../snorkel/tutorials/glove_w2v.txt', binary=False)  # C binary format\n",
    "\n",
    "\n",
    "wordvec_unavailable= set()\n",
    "def write_to_file(wordvec_unavailable):\n",
    "    with open(\"wordvec_unavailable.txt\",\"w\") as f:\n",
    "        for word in wordvec_unavailable:\n",
    "            f.write(word+\"\\n\")\n",
    "\n",
    "def preprocess(tokens):\n",
    "    btw_words = [word for word in tokens if word not in STOPWORDS]\n",
    "    btw_words = [word for word in btw_words if word.isalpha()]\n",
    "    return btw_words\n",
    "\n",
    "def get_word_vectors(btw_words): # returns vector of embeddings of words\n",
    "    word_vectors= []\n",
    "    for word in btw_words:\n",
    "        try:\n",
    "            word_v = np.array(model[word])\n",
    "            word_v = word_v.reshape(len(word_v),1)\n",
    "            #print(word_v.shape)\n",
    "            word_vectors.append(model[word])\n",
    "        except:\n",
    "            wordvec_unavailable.add(word)\n",
    "    return word_vectors\n",
    "\n",
    "def get_similarity(word_vectors,target_word): # sent(list of word vecs) to word similarity\n",
    "    similarity = 0\n",
    "    target_word_vector = 0\n",
    "    try:\n",
    "        target_word_vector = model[target_word]\n",
    "    except:\n",
    "        wordvec_unavailable.add(target_word+\" t\")\n",
    "        return similarity\n",
    "    target_word_sparse = gm.any2sparse(target_word_vector,eps=1e-09)\n",
    "    for wv in word_vectors:\n",
    "        wv_sparse = gm.any2sparse(wv, eps=1e-09)\n",
    "        similarity = max(similarity,gm.cossim(wv_sparse,target_word_sparse))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28294\n",
      "8846 8879 8861\n"
     ]
    }
   ],
   "source": [
    "def read_words(words_file):\n",
    "    return [line for line in open(words_file, 'r') ]\n",
    "\n",
    "words = read_words(\"blacklist.txt\")\n",
    "\n",
    "spam = [word.strip('-_\\n/') for word in words]\n",
    "spam = [word.replace('-',' ') for word in spam]\n",
    "print(len(spam))\n",
    "\n",
    "\n",
    "# l1 = []\n",
    "# l2 = []\n",
    "# l3 = []\n",
    "# for i,w in enumerate(spam):\n",
    "#     if(i%3==0):\n",
    "#         l1.append(w)\n",
    "#     elif(i%3==1):\n",
    "#         l2.append(w)\n",
    "#     else:\n",
    "#         l3.append(w)\n",
    "        \n",
    "l1 = set()\n",
    "l2 = set()\n",
    "l3 = set()\n",
    "for i,w in enumerate(spam):\n",
    "    if(i%3==0):\n",
    "        l1.add(w)\n",
    "    elif(i%3==1):\n",
    "        l2.add(w)\n",
    "    else:\n",
    "        l3.add(w)\n",
    "print(len(l1),len(l2),len(l3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "####### Discrete ##########\n",
    "\n",
    "\n",
    "# Helper function to get last name\n",
    "\n",
    "import re\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "# def l1words(c):\n",
    "#     return (1,1) if re.search(ltp(l1), c['text'], flags=re.I) else (0,0)\n",
    "\n",
    "# def l2words(c):\n",
    "#      return (1,1) if re.search(ltp(l2), c['text'], flags=re.I) else (0,0)\n",
    "\n",
    "# def l3words(c):\n",
    "#      return (1,1) if re.search(ltp(l3), c['text'], flags=re.I) else (0,0)\n",
    "\n",
    "# notFree = ['you','toll','your','call','meet','talk','freez']\n",
    "\n",
    "# def notFreeSpam(c):\n",
    "#     return (-1,1) if re.search('(free.*'+ltp(notFree)+')|('+ltp(notFree)+'.*free)',\\\n",
    "#                                flags=re.I) else (0,0)\n",
    "\n",
    "def l1words(c):\n",
    "    return (1,1) if len(l1.intersection(c['text'].split())) > 0 else (0,0)\n",
    "\n",
    "def l2words(c):\n",
    "    return (1,1) if len(l2.intersection(c['text'].split())) > 0 else (0,0)\n",
    "\n",
    "def l3words(c):\n",
    "    return (1,1) if len(l3.intersection(c['text'].split())) > 0 else (0,0)\n",
    "\n",
    "\n",
    "\n",
    "notFree1 = {'toll','Toll','freely','call','meet','talk','feedback'}\n",
    "\n",
    "def notFreeSpam(c):\n",
    "    return (-1,1) if 'free' in c['text'].split() and len(notFree.intersection(c['text'].split()))>0 else (0,0)        \n",
    "\n",
    "notFree2 = {'not free','you are','when','wen'}\n",
    "\n",
    "def notFreeSpam2(c):\n",
    "    return (-1,1) if 'free' in c['text'].split() and re.search(ltp(notFree2),c['text'], flags= re.I) else (0,0)        \n",
    "\n",
    "person1 = {'I','i','u','you','ur','your','our','we','us','you\\'re,'}\n",
    "\n",
    "person2 = {'He','he','She','she','they','They','Them','them','their','Their'}\n",
    "\n",
    "def personWords(c):\n",
    "    return (-1,1) if 'free' in c['text'].split() and len(person1.intersection(c['text'].split()))>0 else (0,0)        \n",
    "\n",
    "def secondPersonWords(c):\n",
    "    return (-1,1) if 'free' in c['text'].split() and len(person2.intersection(c['text'].split()))>0 else (0,0)        \n",
    "\n",
    "def noOfCapChars(c):\n",
    "    return (1,1) if (sum(1 for ch in c['text'] if ch.isupper()) > 6) else (0,0)\n",
    "\n",
    "LFs = [\n",
    "   l1words,l2words,l3words,noOfCapChars,notFreeSpam,notFreeSpam2,personWords,secondPersonWords\n",
    "]\n",
    "\n",
    "LF_l = [1,1,1,1,-1,-1,-1,-1]\n",
    "\n",
    "\n",
    "print(len(LFs),len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "##### Continuous ################\n",
    "\n",
    "\n",
    "\n",
    "def l1words(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(c['text'].split())\n",
    "    l1 = ['free','credit','cheap','apply','buy','attention','shop','sex','soon','now','spam']\n",
    "    for w in l1:\n",
    "        sc=max(sc,get_similarity(word_vectors,w))\n",
    "    return (1,sc)\n",
    "\n",
    "def l2words(c):\n",
    "    sc = 0\n",
    "    l2 = ['gift','click','new','online','discount','earn','miss','hesitate','exclusive','urgent']\n",
    "    word_vectors = get_word_vectors(c['text'].split())\n",
    "    for w in l2:\n",
    "        sc=max(sc,get_similarity(word_vectors,w))\n",
    "    return (1,sc)\n",
    "\n",
    "def l3words(c):\n",
    "    sc = 0\n",
    "    l3 = ['cash','refund','insurance','money','guaranteed','save','win','teen','weight','hair']\n",
    "    word_vectors = get_word_vectors(c['text'].split())\n",
    "    for w in l3:\n",
    "        sc=max(sc,get_similarity(word_vectors,w))\n",
    "    return (1,sc)\n",
    "   \n",
    "def notFreeSpam(c):\n",
    "    sc = 0\n",
    "    notFree = ['not','when','call','meet','talk','feedback','toll']\n",
    "    word_vectors = get_word_vectors(c['text'].split())\n",
    "    for w in notFree:\n",
    "        sc=max(sc,get_similarity(word_vectors,w))\n",
    "    return (1,sc)\n",
    "   \n",
    "\n",
    "def notFreeSpam2(c):\n",
    "    sc = 0\n",
    "    notFree2 =  ['not free','you are','when']\n",
    "    word_vectors = get_word_vectors(c['text'].split())\n",
    "    for w in notFree2:\n",
    "        sc=max(sc,get_similarity(word_vectors,w))\n",
    "    return (1,sc)\n",
    "\n",
    "def personWords(c):\n",
    "    sc = 0\n",
    "    notFree2 = ['I','you','your','we','us']\n",
    "    word_vectors = get_word_vectors(c['text'].split())\n",
    "    for w in person1:\n",
    "        sc=max(sc,get_similarity(word_vectors,w))\n",
    "    return (-1,sc)\n",
    "    return (-1,1) if 'free' in c['text'].split() and re.search(ltp(notFree2),c['text'], flags= re.I) else (0,0)        \n",
    "\n",
    "def secondPersonWords(c):\n",
    "    sc = 0\n",
    "    notFree2 = ['he','she','they','them','their']\n",
    "    word_vectors = get_word_vectors(c['text'].split())\n",
    "    for w in person1:\n",
    "        sc=max(sc,get_similarity(word_vectors,w))\n",
    "    return (-1,sc)\n",
    "   \n",
    "    \n",
    "def noOfCapChars(c):\n",
    "    l = sum(1 for ch in c['text'] if ch.isupper()) \n",
    "    return (1,l/150)\n",
    "\n",
    "LFs = [\n",
    "   l1words,l2words,l3words,noOfCapChars,notFreeSpam,notFreeSpam2,personWords,secondPersonWords\n",
    "]\n",
    "\n",
    "LF_l = [1,1,1,1,-1,-1,-1,-1]\n",
    "\n",
    "print(len(LFs),len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' output:\n",
    "\n",
    "    [[[L_x1],[S_x1]],\n",
    "     [[L_x2],[S_x2]],\n",
    "     ......\n",
    "     ......\n",
    "    ]\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def get_L_S_Tensor(df,msg):     \n",
    "    L_S = []\n",
    "    print('labelling ',msg,' data')\n",
    "    for i in range(len(df.index)):\n",
    "        L_S_ci=[]\n",
    "        L=[]\n",
    "        S=[]\n",
    "        P_ik = []\n",
    "        for LF in LFs:\n",
    "#             print(i,LF.__name__)    \n",
    "#             print(df.iloc[i]['text'])\n",
    "            l,s = LF(df.iloc[i])\n",
    "            L.append(l)\n",
    "            S.append((s+1)/2)  #to scale scores in [0,1] \n",
    "        L_S_ci.append(L)\n",
    "        L_S_ci.append(S)\n",
    "        L_S.append(L_S_ci) \n",
    "        if(i%250==0 and i!=0):\n",
    "            print(str(i)+'data points labelled in',(time.time() - start_time)/60,'mins')\n",
    "        \n",
    "    return L_S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at: 9-6-2018, 20:24:46\n",
      "labelling  regex test  data\n",
      "250data points labelled in 0.004436842600504557 mins\n",
      "500data points labelled in 0.008656620979309082 mins\n",
      "750data points labelled in 0.01289513111114502 mins\n",
      "1000data points labelled in 0.017128411928812662 mins\n",
      "1250data points labelled in 0.021420172850290933 mins\n",
      "1500data points labelled in 0.02580949068069458 mins\n",
      "1750data points labelled in 0.0302552858988444 mins\n",
      "labelling  regex train  data\n",
      "250data points labelled in 0.03731296062469482 mins\n",
      "500data points labelled in 0.041551840305328366 mins\n",
      "750data points labelled in 0.045717823505401614 mins\n",
      "1000data points labelled in 0.04994643131891886 mins\n",
      "1250data points labelled in 0.054119853178660075 mins\n",
      "1500data points labelled in 0.05829683542251587 mins\n",
      "1750data points labelled in 0.06246569554011027 mins\n",
      "2000data points labelled in 0.06664372682571411 mins\n",
      "2250data points labelled in 0.07073365052541097 mins\n",
      "2500data points labelled in 0.0749161958694458 mins\n",
      "2750data points labelled in 0.07917277812957764 mins\n",
      "3000data points labelled in 0.08347198565800985 mins\n",
      "3250data points labelled in 0.08775001366933187 mins\n",
      "3500data points labelled in 0.09205952485402426 mins\n",
      "--- 5.732852935791016 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "start_time = time.time()\n",
    "\n",
    "lt = time.localtime()\n",
    "\n",
    "print(\"started at: {}-{}-{}, {}:{}:{}\".format(lt.tm_mday,lt.tm_mon,lt.tm_year,lt.tm_hour,lt.tm_min,lt.tm_sec))\n",
    "\n",
    "\n",
    "test_L_S = get_L_S_Tensor(test_df,'regex test')\n",
    "np.save(\"test_L_S_discrete\",np.array(test_L_S))\n",
    "\n",
    "train_L_S = get_L_S_Tensor(train_df,'regex train')\n",
    "np.save(\"train_L_S_discrete\",np.array(train_L_S))\n",
    "\n",
    "\n",
    "\n",
    "# test_L_S = get_L_S_Tensor(test_df,'regex test')\n",
    "# np.save(\"test_L_S_smooth\",np.array(test_L_S))\n",
    "\n",
    "# train_L_S = get_L_S_Tensor(train_df,'regex train')\n",
    "# np.save(\"train_L_S_smooth\",np.array(train_L_S))\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# test_L_S = get_L_S_Tensor(test_cands)\n",
    "# pkl.dump(test_L_S,open(\"test_L_S.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "(1872, 2, 16) (3700, 2, 16)\n"
     ]
    }
   ],
   "source": [
    "LF_l = [1,1,1,1,-1,-1,-1,-1]\n",
    "\n",
    "def merge(a,b):\n",
    "    c = []\n",
    "    for i in range(len(a)):\n",
    "        ci = []\n",
    "        ci_l = a[i,0,:].tolist()+b[i,0,:].tolist()\n",
    "        ci_s = a[i,1,:].tolist()+b[i,1,:].tolist()\n",
    "        ci.append(ci_l)\n",
    "        ci.append(ci_s)\n",
    "        c.append(ci)\n",
    "    return c\n",
    "import numpy as np\n",
    "test_L_S_s = np.load(\"test_L_S_smooth.npy\")\n",
    "train_L_S_s = np.load(\"train_L_S_smooth.npy\")\n",
    "\n",
    "test_L_S_d = np.load(\"test_L_S_discrete.npy\")\n",
    "train_L_S_d = np.load(\"train_L_S_discrete.npy\")\n",
    "\n",
    "test_L_S = np.array(merge(test_L_S_d,test_L_S_s))\n",
    "train_L_S = np.array(merge(train_L_S_d,train_L_S_s))\n",
    "\n",
    "dev_L_S = test_L_S\n",
    "gold_labels_dev = true_labels \n",
    "\n",
    "\n",
    "LF_l = LF_l + LF_l\n",
    "print(len(LF_l))\n",
    "NoOfLFs= len(LF_l)\n",
    "NoOfClasses = 2\n",
    "# LF_names = [lf.__name__ for lf in LFs] + ['s'+lf.__name__ for lf in LFs]\n",
    "# print(len(LF_names))\n",
    "print(test_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def draw2DArray(a):\n",
    "    fig = plt.figure(figsize=(6, 3.2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('colorMap')\n",
    "    plt.imshow(np.array(a))\n",
    "    ax.set_aspect('equal')\n",
    "    cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
    "    cax.get_xaxis().set_visible(False)\n",
    "    cax.get_yaxis().set_visible(False)\n",
    "    cax.patch.set_alpha(0)\n",
    "    cax.set_frame_on(False)\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.show()\n",
    "    \n",
    "      \n",
    "def report2dict(cr):\n",
    "    # Parse rows\n",
    "    tmp = list()\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0:\n",
    "            tmp.append(parsed_row)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    measures = tmp[0]\n",
    "\n",
    "    D_class_data = defaultdict(dict)\n",
    "    for row in tmp[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return pd.DataFrame(D_class_data).T\n",
    "\n",
    "def predictAndPrint(pl):\n",
    "    print(\"acc\",accuracy_score(true_labels,pl))\n",
    "#     print(precision_recall_fscore_support(true_labels,pl,average='macro'))\n",
    "    print(confusion_matrix(true_labels,pl))\n",
    "#     draw2DArray(confusion_matrix(gold_labels_dev,pl))\n",
    "    return report2dict(classification_report(true_labels, pl))# target_names=class_names))\n",
    "    \n",
    "\n",
    "\n",
    "def drawPRcurve(y_test,y_score,it_no):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    splt = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score,pos_label=1)\n",
    "\n",
    "    splt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    splt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.title('{0:d} Precision-Recall curve: AP={1:0.2f}'.format(it_no,\n",
    "              average_precision))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872, 2, 8) (3700, 2, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_L_S = np.load(\"test_L_S_discrete.npy\")\n",
    "train_L_S = np.load(\"train_L_S_discrete.npy\")\n",
    "dev_L_S = test_L_S\n",
    "gold_labels_dev = true_labels \n",
    "print(test_L_S.shape,train_L_S.shape)\n",
    "# LF_names= [lf.__name__ for lf in LFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872, 2, 8) (3700, 2, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_L_S = np.load(\"test_L_S_smooth.npy\")\n",
    "train_L_S = np.load(\"train_L_S_smooth.npy\")\n",
    "dev_L_S = test_L_S\n",
    "gold_labels_dev = true_labels \n",
    "print(test_L_S.shape,train_L_S.shape)\n",
    "\n",
    "# LF_names= ['s'+lf.__name__ for lf in LFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call this only once for a kernel startup\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# BATCH_SIZE = 32\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "LF_l = [1,1,1,1,-1,-1,-1,-1]\n",
    "NoOfLFs= len(LF_l)\n",
    "NoOfClasses = 2\n",
    "print(len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(lr,ep,th,af,batch_size=32,LF_acc=None,LF_rec=None,pcl=np.array([-1,1],dtype=np.float64),norm=True,\\\n",
    "          smooth=True,penalty=0,p3k=3,alp=1,Gamma=1.0,debug=True):\n",
    "    \n",
    "    ## lr : learning rate\n",
    "    ## ep : no of epochs\n",
    "    ## th : thetas initializer\n",
    "    ## af : alphas initializer\n",
    "    ## penalty : {1,2,3} use one of the three penalties, 0: no-penalty\n",
    "    ## p3k : parameter for penalty-3 \n",
    "    ## smooth : flag if smooth lfs are used \n",
    "    ## make sure smooth/discrete LF data is loaded into train_L_S and test_L_S\n",
    "    ## pcl : all possible class labels  = [-1,1] for binary, \n",
    "    ##       np.arange(0,NoOfClasses) for multiclass\n",
    "    ## alp : alpha parameter (to set a max value for alpha)\n",
    "    ## norm : use normalization or not\n",
    "    ## Gamma : penalty tuning parameter\n",
    "    \n",
    "    BATCH_SIZE = batch_size\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(dev_L_S).batch(len(dev_L_S))\n",
    "#         test_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "#         test_in`it_op = iterator.make_initializer(test_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=af,\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "        \n",
    "        \n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "    \n",
    "        g = tf.convert_to_tensor(Gamma, dtype=tf.float64)\n",
    "        \n",
    "        if(penalty in [4,5,7,8,9,10,11]):\n",
    "            LF_a = tf.convert_to_tensor(LF_acc, dtype=tf.float64)\n",
    "        \n",
    "        if(penalty in [6,7,11,12]):\n",
    "            LF_r = tf.convert_to_tensor(LF_rec, dtype=tf.float64)\n",
    "        \n",
    "        if(debug):\n",
    "            print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "        if(debug):\n",
    "            print(\"s\",s)\n",
    "            print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "        if(smooth):\n",
    "            s_ = tf.maximum(tf.subtract(s,tf.minimum(alphas,alp)), 0)\n",
    "            if(debug):\n",
    "                print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),-tf.ones_like(v))\n",
    "            if(debug):\n",
    "                print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        if(smooth):\n",
    "            pout = tf.map_fn(lambda c: l*c*s_ ,pcl,name=\"pout\")\n",
    "        else:\n",
    "            pout = tf.map_fn(lambda c: l*c ,pcl,name=\"pout\")\n",
    "\n",
    "        if(debug):\n",
    "            print(\"pout\",pout)    \n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,\\\n",
    "                           name=\"t_pout\")\n",
    "    \n",
    "        if(debug):\n",
    "            print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "        if(debug):\n",
    "            print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "            if(debug):\n",
    "                print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "            if(debug):\n",
    "                print(\"intsy\",out1)\n",
    "            return out1\n",
    "                \n",
    "\n",
    "        if(smooth):\n",
    "            #smooth normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                           pcl,name=\"zy\")\n",
    "        else:\n",
    "            #discrete normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                           pcl,name=\"zy\")\n",
    "            \n",
    "        ### for precision and recall t_pout\n",
    "        def pr_t_pout(j):\n",
    "            Lj = tf.map_fn(lambda li : tf.gather(li,j),l)\n",
    "            if(debug):\n",
    "                print(\"sft Lj\",Lj)\n",
    "            kj = tf.gather(k,j)\n",
    "            if(debug):\n",
    "                print(\"sft kj\",kj)\n",
    "            indices = tf.where(tf.equal(Lj,kj))\n",
    "            if(debug):\n",
    "                print(\"sft indices\",indices)\n",
    "            li_lij_eq_kj = tf.gather(l,tf.squeeze(indices,1))\n",
    "            if(smooth):\n",
    "                si_lij_eq_kj = tf.gather(s_,tf.squeeze(indices,1))\n",
    "            if(debug):\n",
    "                print(\"sft l_ij_eq_kj\",li_lij_eq_kj)\n",
    "            if(smooth):\n",
    "                prec_z = tf.reduce_sum(tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                           pcl,name=\"prec_zy\"))\n",
    "            else:\n",
    "                prec_z = tf.reduce_sum(tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                           pcl,name=\"prec_zy\"))\n",
    "            if(debug):\n",
    "                print(\"prec_z\",prec_z)\n",
    "            if(smooth):\n",
    "                prec_t_pout = (tf.matmul(li_lij_eq_kj*si_lij_eq_kj*kj, thetas,transpose_b=True))/prec_z\n",
    "            else:\n",
    "                prec_t_pout = (tf.matmul(li_lij_eq_kj*kj, thetas,transpose_b=True))/prec_z\n",
    "            if(debug):\n",
    "                print(\"prec_t_pout\",prec_t_pout)\n",
    "            return prec_t_pout\n",
    "           \n",
    "        def softplus_p(j):\n",
    "            aj = tf.gather(LF_a,j)\n",
    "            if(debug):\n",
    "                print(\"sft aj\",aj)\n",
    "            f_p =  tf.reduce_sum(aj - pr_t_pout(j))\n",
    "            if(debug):\n",
    "                print(\"f_p\",f_p)\n",
    "            sft_p = tf.nn.softplus(f_p,name=\"sft_p\")\n",
    "            if(debug):\n",
    "                print(\"sft_p\",sft_p)\n",
    "            return sft_p\n",
    "        \n",
    "        def softplus_r(j):\n",
    "            rj = tf.gather(LF_r,j)\n",
    "            if(debug):\n",
    "                print(\"sft aj\",rj)\n",
    "            f_r =  rj - tf.reduce_sum( pr_t_pout(j)) \n",
    "            if(debug):\n",
    "                print(\"f_r\",f_r)\n",
    "            sft_r = tf.nn.softplus(f_r,name=\"sft_r\")\n",
    "            if(debug):\n",
    "                print(\"sft_r\",sft_r)\n",
    "            return sft_r\n",
    "            \n",
    "        \n",
    "#         logsft = tf.map_fn(lambda j: tf.log(softplus(j)),np.arange(NoOfLFs),\\\n",
    "#                                              dtype=tf.float64)\n",
    "#         sft  =  tf.map_fn(lambda j: softplus(j),np.arange(NoOfLFs),\\\n",
    "#                                              dtype=tf.float64)\n",
    "        \n",
    "# \n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        if(debug):\n",
    "            print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        if(debug):\n",
    "            print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "        if(debug):\n",
    "            print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "        \n",
    "        if(not norm):\n",
    "            print(\"unnormlized loss\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  ))\n",
    "        elif(penalty == 1):\n",
    "            print(\"penalty1\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                      +(g*tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas)))\n",
    "        elif(penalty == 2):\n",
    "            print(\"penalty2\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     -(g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "        elif(penalty == 3):\n",
    "            print(\"penalty3\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     +(g*tf.reduce_sum(tf.log(1+tf.exp(-thetas-pk))))\n",
    "        elif(penalty == 4):\n",
    "            print(\"precision penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "        elif(penalty == 5):\n",
    "            print(\"precision log(softplus) penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: tf.log(softplus_p(j)),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "        elif(penalty == 6):\n",
    "            print(\"recall penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "        elif(penalty == 7):\n",
    "            print(\"precision and recall penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "        elif(penalty == 8):\n",
    "            print(\"precision and sign 1 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                + (g*tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas)))\n",
    "        elif(penalty == 9):\n",
    "            print(\"precision and sign 2 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                - (g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "        elif(penalty == 10):\n",
    "            print(\"precision and sign 3 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                + (g*tf.reduce_sum(tf.log(1+tf.exp(-thetas-p3k))))\n",
    "        elif(penalty == 11):\n",
    "            print(\"precision and recall and sign 2 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                  - (g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "        elif(penalty == 12):\n",
    "            print(\"recall and sign 2 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                  - (g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "        else:\n",
    "            print(\"normalized loss\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "       \n",
    "        if(debug):\n",
    "            print(\"loss\",loss)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "        if(debug):\n",
    "            print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(loss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,loss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "                print(\"dev set\")\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(gold_labels_dev,pl))\n",
    "                print(precision_recall_fscore_support(np.array(gold_labels_dev),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "#                 print(\"test set\")\n",
    "#                 sess.run(test_init_op)\n",
    "#                 a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "#                 unique, counts = np.unique(pl, return_counts=True)\n",
    "#                 print(dict(zip(unique, counts)))\n",
    "#                 print(\"acc\",accuracy_score(gold_labels_test,pl))\n",
    "#                 print(precision_recall_fscore_support(np.array(gold_labels_test),np.array(pl),average=\"binary\"))\n",
    "#                 print()\n",
    "                \n",
    "#             # Initialize an iterator over the validation dataset.\n",
    "#             sess.run(dev_init_op)\n",
    "#             a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "#             print(a)\n",
    "#             print(t)\n",
    "\n",
    "#             unique, counts = np.unique(pl, return_counts=True)\n",
    "#             print(dict(zip(unique, counts)))\n",
    "\n",
    "#             print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "# #             predictAndPrint(pl)\n",
    "#             print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3145. 3145. 3145. 3145. 3145. 3145. 3145. 3145. 3145. 3145. 3145. 3145.\n",
      " 3145. 3145. 3145. 3145.]\n",
      "batch-size: 64 alpha-init: 0.6\n",
      "recall penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 2959146.3576840125\n",
      "dev set\n",
      "[0.59966419 0.59662467 0.59861625 0.59852027 0.60260125 0.60197537\n",
      " 0.60325263 0.60187818 0.5999139  0.59909635 0.59828474 0.60192128\n",
      " 0.59827266 0.60234796 0.60196187 0.6019761 ]\n",
      "[[1.11906896 0.81573464 1.01104918 1.00212258 1.10485233 1.03977548\n",
      "  1.16764946 1.02963845 1.14787911 1.06627299 0.98509706 1.06512126\n",
      "  0.98392353 1.07701838 1.03926376 1.0406874 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "1 loss 2959123.0325994184\n",
      "dev set\n",
      "[0.59817455 0.5950781  0.59712625 0.59703654 0.60412528 0.60350861\n",
      " 0.6047882  0.60341265 0.59833777 0.59751978 0.59670813 0.60320012\n",
      " 0.59669131 0.60388211 0.60353535 0.60354959]\n",
      "[[1.1205784  0.81728596 1.01255366 1.00362401 1.10333518 1.03823884\n",
      "  1.16611921 1.0281014  1.14945499 1.0678478  0.98666936 1.06359618\n",
      "  0.9855036  1.07548098 1.03769335 1.039117  ]]\n",
      "{0: 268, 1: 1604}\n",
      "acc 0.2702991452991453\n",
      "(0.14900249376558602, 0.9958333333333333, 0.2592190889370933, None)\n",
      "\n",
      "2 loss 2959099.091542906\n",
      "dev set\n",
      "[0.59669196 0.59351834 0.59563232 0.59555282 0.60562886 0.60501396\n",
      " 0.6062999  0.60491652 0.596742   0.59592375 0.59511208 0.60453407\n",
      " 0.59508655 0.60538913 0.6051234  0.60513764]\n",
      "[[1.12208691 0.81885316 1.01406664 1.00513095 1.10183377 1.03672599\n",
      "  1.16461034 1.02659215 1.15105354 1.06944698 0.98826811 1.06205708\n",
      "  0.98711233 1.07396686 1.03610935 1.03753299]]\n",
      "{0: 249, 1: 1623}\n",
      "acc 0.26121794871794873\n",
      "(0.1478743068391867, 1.0, 0.2576489533011272, None)\n",
      "\n",
      "3 loss 2959074.5576285813\n",
      "dev set\n",
      "[0.59521227 0.59194816 0.5941349  0.59406956 0.60711142 0.60649175\n",
      " 0.6077903  0.60639119 0.59512795 0.59431007 0.59349838 0.60588704\n",
      " 0.59346057 0.60686934 0.60672449 0.60673873]\n",
      "[[1.12359826 0.82043344 1.01558756 1.00664289 1.10034852 1.03523593\n",
      "  1.16311902 1.025108   1.15267287 1.07106869 0.98989021 1.06050738\n",
      "  0.9887465  1.07247506 1.0345135  1.03593715]]\n",
      "{0: 237, 1: 1635}\n",
      "acc 0.2548076923076923\n",
      "(0.14678899082568808, 1.0, 0.256, None)\n",
      "\n",
      "4 loss 2959049.4376610215\n",
      "dev set\n",
      "[0.5937343  0.59036873 0.59263432 0.59258706 0.60857287 0.60794201\n",
      " 0.60926033 0.60783701 0.59349749 0.59267975 0.59186816 0.60726168\n",
      " 0.59181481 0.60832281 0.60833773 0.60835197]\n",
      "[[1.12511343 0.82202559 1.017116   1.00815944 1.09887932 1.03376817\n",
      "  1.16164381 1.02364793 1.15431184 1.07271179 0.99153419 1.05894851\n",
      "  0.99040434 1.07100507 1.03290685 1.03433051]]\n",
      "{0: 221, 1: 1651}\n",
      "acc 0.24626068376068377\n",
      "(0.145366444579043, 1.0, 0.2538339502908514, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 2959416.954827394\n",
      "dev set\n",
      "[0.69966524 0.69663719 0.69863909 0.69852092 0.70259612 0.70197004\n",
      " 0.70325423 0.7018766  0.69995962 0.69913805 0.69832824 0.70212647\n",
      " 0.69832135 0.70234282 0.70193073 0.70194498]\n",
      "[[1.11906753 0.81572306 1.0110278  1.00212092 1.10486333 1.03978456\n",
      "  1.16764937 1.02964163 1.14783635 1.06619373 0.98496896 1.06509764\n",
      "  0.98386591 1.0770271  1.03931087 1.0407345 ]]\n",
      "{0: 598, 1: 1274}\n",
      "acc 0.4423076923076923\n",
      "(0.18445839874411302, 0.9791666666666666, 0.3104359313077939, None)\n",
      "\n",
      "1 loss 2959406.1523360536\n",
      "dev set\n",
      "[0.69816929 0.69508922 0.69715592 0.69702865 0.70411728 0.70350065\n",
      " 0.7047906  0.70340833 0.6983898  0.6975692  0.69675277 0.70361835\n",
      " 0.69674684 0.70387445 0.70350009 0.70351434]\n",
      "[[1.12058187 0.81727704 1.01252651 1.0036293  1.10335547 1.03825557\n",
      "  1.16612264 1.02811293 1.1493958  1.06769372 0.98647199 1.06356343\n",
      "  0.98543293 1.07549704 1.03774791 1.03917154]]\n",
      "{0: 572, 1: 1300}\n",
      "acc 0.4284188034188034\n",
      "(0.18076923076923077, 0.9791666666666666, 0.3051948051948052, None)\n",
      "\n",
      "2 loss 2959394.6444137376\n",
      "dev set\n",
      "[0.69666875 0.69351508 0.69565435 0.69552614 0.70562091 0.70500435\n",
      " 0.70630537 0.70490943 0.6967734  0.69595351 0.69512102 0.70512689\n",
      " 0.69511849 0.70537983 0.70510845 0.7051227 ]\n",
      "[[1.12210591 0.81886028 1.01404765 1.00515273 1.10186086 1.03675063\n",
      "  1.16461582 1.02661406 1.15100211 1.06924452 0.9880352  1.06202319\n",
      "  0.98706259 1.0739906  1.03614319 1.03756683]]\n",
      "{0: 533, 1: 1339}\n",
      "acc 0.4075854700854701\n",
      "(0.1755041075429425, 0.9791666666666666, 0.2976567447751741, None)\n",
      "\n",
      "3 loss 2959382.4341058703\n",
      "dev set\n",
      "[0.69515941 0.69191795 0.69413621 0.69401404 0.70710647 0.70648124\n",
      " 0.70780172 0.70638142 0.69511428 0.6942959  0.69345017 0.70664905\n",
      " 0.6934421  0.70685908 0.7067519  0.70676615]\n",
      "[[1.1236435  0.82046961 1.01558936 1.00669049 1.10037986 1.03526889\n",
      "  1.16312419 1.02514186 1.15265227 1.07084474 0.98965266 1.06047889\n",
      "  0.98874732 1.07250694 1.03450203 1.03592568]]\n",
      "{0: 509, 1: 1363}\n",
      "acc 0.39476495726495725\n",
      "(0.1724137931034483, 0.9791666666666666, 0.2932002495321273, None)\n",
      "\n",
      "4 loss 2959369.5053301454\n",
      "dev set\n",
      "[0.69364028 0.69029943 0.69260252 0.69249281 0.70857391 0.70793128\n",
      " 0.70928078 0.70782471 0.69341381 0.69259418 0.69174011 0.70819178\n",
      " 0.69172198 0.70831218 0.70842548 0.70843972]\n",
      "[[1.12519542 0.82210335 1.01715053 1.00824201 1.09891235 1.03380986\n",
      "  1.16164599 1.02369509 1.154344   1.07249319 0.99132141 1.05893141\n",
      "  0.99048254 1.0710456  1.03282804 1.0342517 ]]\n",
      "{0: 495, 1: 1377}\n",
      "acc 0.3872863247863248\n",
      "(0.17066085693536673, 0.9791666666666666, 0.29066171923314776, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 2959507.901648301\n",
      "dev set\n",
      "[0.79970893 0.79670212 0.79873043 0.79854276 0.80256898 0.80195896\n",
      " 0.80324822 0.80187144 0.8005418  0.80019764 0.79913254 0.80213307\n",
      " 0.79892596 0.80233221 0.80069976 0.80071461]\n",
      "[[1.11902995 0.81566314 1.01094479 1.0021008  1.10491492 1.03980584\n",
      "  1.16766401 1.02965237 1.1475625  1.06554418 0.9843227  1.0650929\n",
      "  0.98319517 1.07704746 1.0419598  1.04338326]]\n",
      "{0: 943, 1: 929}\n",
      "acc 0.5998931623931624\n",
      "(0.22604951560818085, 0.875, 0.35928143712574856, None)\n",
      "\n",
      "1 loss 2959506.125882814\n",
      "dev set\n",
      "[0.79825866 0.79522427 0.79733378 0.79707752 0.80406645 0.80348063\n",
      " 0.80477588 0.80339645 0.79958655 0.79977874 0.79839188 0.80361994\n",
      " 0.7981698  0.80385531 0.80107941 0.8010949 ]\n",
      "[[1.12050463 0.81715362 1.01236674 1.00358488 1.10345713 1.03830308\n",
      "  1.16616122 1.02814472 1.14881915 1.06631762 0.98511256 1.06356611\n",
      "  0.98405644 1.0755424  1.04302838 1.04445168]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "2 loss 2959504.3019713415\n",
      "dev set\n",
      "[0.79680051 0.79371779 0.79591294 0.79560108 0.80555129 0.80497785\n",
      " 0.80628487 0.80489276 0.79854764 0.79936417 0.7976386  0.80511016\n",
      " 0.79737978 0.80535443 0.80161483 0.80163093]\n",
      "[[1.12199282 0.81867708 1.01381761 1.00508578 1.10200905 1.03682571\n",
      "  1.16467779 1.02666927 1.15011374 1.06709625 0.9859124  1.06204384\n",
      "  0.98502261 1.07406243 1.04399255 1.04541567]]\n",
      "{0: 931, 1: 941}\n",
      "acc 0.593482905982906\n",
      "(0.22316684378320936, 0.875, 0.35563082133784935, None)\n",
      "\n",
      "3 loss 2959502.3895118847\n",
      "dev set\n",
      "[0.79532828 0.79218197 0.79446902 0.79411219 0.8070228  0.80645111\n",
      " 0.80777936 0.80636231 0.79746485 0.79895108 0.79687796 0.80660193\n",
      " 0.79642292 0.80683002 0.80232917 0.80234582]\n",
      "[[1.12350033 0.82023417 1.01529619 1.00660459 1.10057147 1.03537216\n",
      "  1.16320748 1.02522204 1.15145077 1.06788347 0.98672067 1.06052751\n",
      "  0.9860938  1.07260606 1.04483455 1.04625747]]\n",
      "{0: 921, 1: 951}\n",
      "acc 0.5881410256410257\n",
      "(0.22082018927444794, 0.875, 0.3526448362720403, None)\n",
      "\n",
      "4 loss 2959500.3536381484\n",
      "dev set\n",
      "[0.79383872 0.79061443 0.79300073 0.79260947 0.80848123 0.80790067\n",
      " 0.80926129 0.80780573 0.79626694 0.79853765 0.79608976 0.80809487\n",
      " 0.79533069 0.80828235 0.803236   0.80325313]\n",
      "[[1.12503017 0.82182716 1.01680362 1.0081425  1.09914391 1.03394148\n",
      "  1.16174744 1.02380144 1.15283529 1.06868179 0.98753843 1.05901733\n",
      "  0.98727634 1.07117235 1.04552877 1.04695147]]\n",
      "{0: 905, 1: 967}\n",
      "acc 0.5806623931623932\n",
      "(0.21820062047569805, 0.8791666666666667, 0.3496271748135874, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 2959563.054145278\n",
      "dev set\n",
      "[0.89972471 0.89672798 0.8987667  0.8985574  0.90242612 0.90194001\n",
      " 0.90319372 0.90186582 0.90036395 0.89975288 0.8990156  0.90215955\n",
      " 0.89973145 0.90231423 0.89895773 0.89897201]\n",
      "[[1.11900818 0.81563597 1.01090233 1.00208234 1.1051225  1.03985046\n",
      "  1.16776293 1.02966955 1.14761053 1.06576254 0.98452437 1.06506401\n",
      "  0.9829988  1.07709005 1.04234777 1.04377141]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 2959562.065884377\n",
      "dev set\n",
      "[0.89829567 0.89529833 0.89741186 0.89709786 0.9037991  0.90339644\n",
      " 0.904651   0.90334266 0.8992485  0.89890438 0.8981713  0.90364235\n",
      " 0.89976251 0.90377471 0.89757481 0.89758913]\n",
      "[[1.12045958 0.81708148 1.01227987 1.00356056 1.10385615 1.03847944\n",
      "  1.1663838  1.02825904 1.14889471 1.06675623 0.98551933 1.06353646\n",
      "  0.98353631 1.07571194 1.04386459 1.04528822]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 2959561.089640687\n",
      "dev set\n",
      "[0.8968642  0.89385698 0.89604117 0.89562734 0.90517048 0.90481632\n",
      " 0.90609141 0.90477847 0.89812491 0.89806619 0.89732983 0.90512775\n",
      " 0.89978897 0.90519906 0.89620948 0.89622385]\n",
      "[[1.12192333 0.81854768 1.01368218 1.00505974 1.10258787 1.03715443\n",
      "  1.16502358 1.02690231 1.15019108 1.06774886 0.98652217 1.06203516\n",
      "  0.98408477 1.07437962 1.04539266 1.0468163 ]]\n",
      "{0: 1096, 1: 776}\n",
      "acc 0.6677350427350427\n",
      "(0.2538659793814433, 0.8208333333333333, 0.38779527559055116, None)\n",
      "\n",
      "3 loss 2959560.0940966345\n",
      "dev set\n",
      "[0.89542665 0.89240677 0.89465921 0.89414748 0.90653625 0.90620548\n",
      " 0.90752079 0.9061793  0.89699278 0.89723634 0.8964945  0.90659894\n",
      " 0.89981159 0.9065929  0.89481017 0.89482459]\n",
      "[[1.12340274 0.82003148 1.01510454 1.00657799 1.10132299 1.03586572\n",
      "  1.16367471 1.02558885 1.15150114 1.06874244 0.98752921 1.06056064\n",
      "  0.984638   1.07308368 1.04693512 1.04835876]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "4 loss 2959559.075969099\n",
      "dev set\n",
      "[0.89398243 0.89094926 0.89326806 0.89265924 0.90789533 0.90756631\n",
      " 0.90894116 0.90754764 0.89585266 0.8964147  0.89566653 0.90807134\n",
      " 0.89983177 0.90795858 0.89338201 0.89339648]\n",
      "[[1.12489808 0.82153103 1.01654463 1.00811407 1.10006326 1.03460949\n",
      "  1.16233501 1.02431445 1.15282477 1.06973703 0.98853902 1.05911266\n",
      "  0.98519314 1.07182038 1.04849393 1.04991756]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 2959594.30861785\n",
      "dev set\n",
      "[1.00305598 0.99647332 1.00199261 1.00039342 1.00295804 1.00239262\n",
      " 1.00351744 1.00229625 1.0033113  1.00259897 0.99848137 1.00261527\n",
      " 0.99836712 1.00271785 1.00238779 1.00240082]\n",
      "[[1.11852217 0.81599058 1.00979612 1.00062455 1.10728357 1.04180935\n",
      "  1.17046742 1.03161318 1.14748172 1.06534819 0.98506851 1.06725167\n",
      "  0.98395326 1.07930037 1.04127988 1.04271273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 2959594.2991849957\n",
      "dev set\n",
      "[1.00567548 0.99444771 1.00490842 1.00354565 1.00560324 1.00520037\n",
      " 1.00601612 1.00513088 1.00586279 1.00534892 0.99675969 1.0053605\n",
      " 0.99653644 1.00543189 1.0051969  1.00520625]\n",
      "[[1.12113552 0.81837243 1.01218445 1.00184673 1.10989332 1.04433805\n",
      "  1.17306255 1.03411415 1.15009048 1.06792288 0.98718332 1.06982909\n",
      "  0.98620584 1.08189124 1.04380729 1.04524358]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 2959594.2807646147\n",
      "dev set\n",
      "[1.00866844 0.99219657 1.00811028 1.00707845 1.00861405 1.00832349\n",
      " 1.00891336 1.00827274 1.00880395 1.00843332 0.99486749 1.00844169\n",
      " 0.99452714 1.00849095 1.00832097 1.00832778]\n",
      "[[1.1244219  0.82111427 1.01561253 1.00539887 1.11319323 1.04771633\n",
      "  1.17627342 1.03750452 1.15333664 1.07127533 0.98955132 1.07317933\n",
      "  0.98872102 1.08522604 1.04718618 1.04862081]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 2959594.2510706396\n",
      "dev set\n",
      "[1.01181601 0.98982236 1.01139456 1.01059179 1.01177216 1.0115545\n",
      " 1.01199512 1.01151602 1.01191697 1.01164036 0.99290618 1.01164664\n",
      " 0.99244854 1.0116804  1.01155259 1.01155775]\n",
      "[[1.12795601 0.82404126 1.01926914 1.00925872 1.11673748 1.05132577\n",
      "  1.17974806 1.04112489 1.15683932 1.07486286 0.99201925 1.076765\n",
      "  0.99133516 1.08879841 1.05079617 1.05222932]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 2959594.20846075\n",
      "dev set\n",
      "[1.01502558 0.98738171 1.01469656 1.01405129 1.01498722 1.01481853\n",
      " 1.01515848 1.01478837 1.0151032  1.01488986 0.99092007 1.01489475\n",
      " 0.99034634 1.01491645 1.01481704 1.01482107]\n",
      "[[1.13159202 0.82706344 1.0229937  1.01313787 1.12037965 1.05501461\n",
      "  1.18334084 1.04482171 1.16045303 1.07853692 0.99452338 1.08043772\n",
      "  0.99398309 1.09246057 1.05448541 1.05591749]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 1499872.0168507912\n",
      "dev set\n",
      "[0.60039562 0.59737345 0.59933317 0.59924291 0.60183893 0.60119658\n",
      " 0.60247399 0.60109617 0.60068538 0.59986868 0.5990571  0.60136649\n",
      " 0.59904548 0.60156903 0.6011875  0.60120173]\n",
      "[[1.11832616 0.81498387 1.01032437 1.00139064 1.10560648 1.04055511\n",
      "  1.16842537 1.03042301 1.14711073 1.06550213 0.98434062 1.06585009\n",
      "  0.98315676 1.07779813 1.04003465 1.04145829]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "1 loss 1499860.3994261825\n",
      "dev set\n",
      "[0.59961943 0.59659728 0.59856809 0.59847949 0.60261288 0.60197391\n",
      " 0.60325292 0.60187481 0.59990139 0.59908443 0.59827279 0.60207498\n",
      " 0.59826037 0.60234652 0.60197131 0.60198554]\n",
      "[[1.11910556 0.81576107 1.01109273 1.00215807 1.10483459 1.03977703\n",
      "  1.16764749 1.02964339 1.14789442 1.06628631 0.98512218 1.06507838\n",
      "  0.98394004 1.07701992 1.03925155 1.04067519]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "2 loss 1499848.62798613\n",
      "dev set\n",
      "[0.59884659 0.595817   0.597802   0.59771613 0.60338228 0.60274441\n",
      " 0.60402548 0.6026457  0.59911207 0.59829491 0.59748324 0.60279189\n",
      " 0.59746897 0.60311736 0.6027591  0.60277333]\n",
      "[[1.11988332 0.81654303 1.01186325 1.00292682 1.104066   1.03900491\n",
      "  1.16687565 1.0288711  1.14868415 1.06707699 0.98591115 1.06430239\n",
      "  0.98473122 1.07624754 1.03846466 1.0398883 ]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "3 loss 1499836.7071504728\n",
      "dev set\n",
      "[0.59807521 0.59503355 0.59703493 0.59695284 0.60414662 0.60350799\n",
      " 0.60479237 0.6034091  0.59831784 0.59750054 0.59668881 0.60351615\n",
      " 0.59667168 0.60388147 0.60355052 0.60356475]\n",
      "[[1.12066117 0.81732883 1.01263592 1.00369692 1.10330121 1.03823867\n",
      "  1.1661087  1.0281055  1.14947954 1.06787379 0.98670664 1.0635232\n",
      "  0.98552952 1.07548092 1.03767439 1.03909804]]\n",
      "{0: 267, 1: 1605}\n",
      "acc 0.26976495726495725\n",
      "(0.14890965732087227, 0.9958333333333333, 0.25907859078590784, None)\n",
      "\n",
      "4 loss 1499824.6371610074\n",
      "dev set\n",
      "[0.59730456 0.59424735 0.59626689 0.5961896  0.60490579 0.60426469\n",
      " 0.60555396 0.60416521 0.59751899 0.59670155 0.59588979 0.60426148\n",
      " 0.5958688  0.60463888 0.60434536 0.60435959]\n",
      "[[1.12143978 0.81811809 1.01341071 1.00446834 1.10254037 1.03747818\n",
      "  1.1653461  1.0273462  1.15028034 1.06867645 0.98750821 1.06274132\n",
      "  0.9863345  1.07471993 1.03688098 1.03830463]]\n",
      "{0: 262, 1: 1610}\n",
      "acc 0.2670940170940171\n",
      "(0.1484472049689441, 0.9958333333333333, 0.25837837837837835, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 1500139.4886623383\n",
      "dev set\n",
      "[0.70039506 0.69737727 0.6993397  0.69924173 0.70183793 0.70119485\n",
      " 0.70247463 0.7010955  0.70069793 0.69988049 0.69907069 0.70142461\n",
      " 0.69905932 0.70156736 0.70117924 0.70119348]\n",
      "[[1.1183267  0.8149803  1.01031828 1.00139142 1.10560877 1.04055792\n",
      "  1.16842485 1.03042414 1.14709825 1.06548425 0.98429824 1.06584442\n",
      "  0.98313919 1.07780083 1.04004807 1.04147171]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "1 loss 1500134.1369705517\n",
      "dev set\n",
      "[0.69961803 0.69660117 0.69857803 0.69847565 0.7026109  0.70197116\n",
      " 0.70325383 0.70187343 0.69991717 0.69910036 0.69829018 0.70218911\n",
      " 0.69827818 0.70234387 0.70196149 0.70197573]\n",
      "[[1.11910689 0.8157577  1.01108361 1.00216105 1.10483952 1.03978215\n",
      "  1.16764766 1.02964648 1.14787662 1.06625171 0.98505469 1.06507046\n",
      "  0.98391536 1.07702483 1.03926924 1.04069288]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "2 loss 1500128.6155481637\n",
      "dev set\n",
      "[0.69884163 0.69581761 0.69781132 0.697707   0.70337999 0.70274093\n",
      " 0.70402704 0.70264356 0.69912293 0.69830745 0.69749602 0.70295846\n",
      " 0.69748212 0.70311401 0.70275214 0.70276638]\n",
      "[[1.11988791 0.81654332 1.011855   1.00293447 1.104073   1.03901231\n",
      "  1.16687638 1.02887668 1.14866728 1.06703247 0.98582819 1.06429436\n",
      "  0.98470911 1.07625465 1.03847882 1.03990246]]\n",
      "{0: 582, 1: 1290}\n",
      "acc 0.4337606837606838\n",
      "(0.1821705426356589, 0.9791666666666666, 0.30718954248366015, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 1500122.9231608228\n",
      "dev set\n",
      "[0.69806376 0.69502756 0.69704002 0.69693575 0.70414473 0.703504\n",
      " 0.70479523 0.70340623 0.69831636 0.69750284 0.6966877  0.70373177\n",
      " 0.69667247 0.7038776  0.70355255 0.70356678]\n",
      "[[1.12067176 0.81733623 1.01263207 1.00371173 1.10330967 1.03824842\n",
      "  1.1661095  1.02811396 1.14946976 1.0678262  0.98661657 1.06351687\n",
      "  0.98551854 1.07549032 1.03767792 1.03910157]]\n",
      "{0: 571, 1: 1301}\n",
      "acc 0.42788461538461536\n",
      "(0.180630284396618, 0.9791666666666666, 0.30499675535366644, None)\n",
      "\n",
      "4 loss 1500117.0488815666\n",
      "dev set\n",
      "[0.69728363 0.69423146 0.69626433 0.69616196 0.70490503 0.70426035\n",
      " 0.70555884 0.70416164 0.69749868 0.69668732 0.69586402 0.70450861\n",
      " 0.69585005 0.70463464 0.70436237 0.70437661]\n",
      "[[1.12145915 0.81813597 1.01341456 1.00449279 1.10254961 1.03749041\n",
      "  1.16534633 1.02735789 1.15028367 1.06863259 0.98741897 1.06273831\n",
      "  0.98634253 1.07473177 1.03686726 1.03829091]]\n",
      "{0: 557, 1: 1315}\n",
      "acc 0.4204059829059829\n",
      "(0.17870722433460076, 0.9791666666666666, 0.30225080385852093, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 1500228.3159822559\n",
      "dev set\n",
      "[0.80040208 0.7973917  0.79936898 0.7992448  0.80183301 0.8011914\n",
      " 0.80247449 0.8010937  0.80087065 0.80035584 0.79937514 0.80142219\n",
      " 0.79924672 0.80156405 0.80067558 0.80069025]\n",
      "[[1.11832104 0.81496706 1.01029189 1.00138862 1.10561867 1.04056417\n",
      "  1.16842574 1.03042744 1.14701683 1.06521395 0.98402241 1.06584363\n",
      "  0.98290513 1.07780681 1.04144571 1.04286929]]\n",
      "{0: 956, 1: 916}\n",
      "acc 0.6057692307692307\n",
      "(0.22816593886462883, 0.8708333333333333, 0.3615916955017301, None)\n",
      "\n",
      "1 loss 1500227.3730363457\n",
      "dev set\n",
      "[0.79963544 0.79662967 0.79863465 0.79848396 0.8025999  0.80196487\n",
      " 0.80325259 0.80186944 0.80027114 0.80006573 0.79891031 0.80218459\n",
      " 0.7986728  0.80233786 0.80089551 0.80091065]\n",
      "[[1.11909255 0.8157319  1.01103316 1.00215363 1.10486202 1.0397955\n",
      "  1.16765214 1.02965537 1.14771102 1.06569702 0.98448719 1.06507122\n",
      "  0.98342539 1.07703756 1.04209289 1.04351641]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "2 loss 1500226.421444566\n",
      "dev set\n",
      "[0.79886873 0.79585912 0.79789243 0.79772    0.80336398 0.80273238\n",
      " 0.80402536 0.80263778 0.79964293 0.79977666 0.79843711 0.80294872\n",
      " 0.79820239 0.80310583 0.80118064 0.80119623]\n",
      "[[1.1198658  0.81650637 1.01178349 1.00292322 1.1041074  1.03903304\n",
      "  1.16688443 1.02889179 1.14841562 1.06618223 0.98495775 1.06429919\n",
      "  0.98398547 1.07627444 1.04270928 1.04413273]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "3 loss 1500225.450255434\n",
      "dev set\n",
      "[0.79809933 0.79508045 0.79714336 0.79695267 0.80412472 0.80349367\n",
      " 0.80479389 0.80339901 0.79898506 0.79948829 0.79795942 0.8037138\n",
      " 0.79769298 0.80386768 0.80153276 0.80154663]\n",
      "[[1.12064332 0.81729011 1.01254192 1.00369767 1.10335537 1.03827685\n",
      "  1.16612081 1.02813582 1.14913164 1.06667032 0.98543202 1.0635283\n",
      "  0.98458142 1.07551753 1.04329348 1.04471685]]\n",
      "{0: 939, 1: 933}\n",
      "acc 0.5977564102564102\n",
      "(0.22508038585209003, 0.875, 0.35805626598465473, None)\n",
      "\n",
      "4 loss 1500224.448609487\n",
      "dev set\n",
      "[0.79732597 0.7942934  0.79638754 0.7961817  0.80488202 0.80424872\n",
      " 0.80555879 0.80415334 0.79830837 0.79920005 0.79747831 0.80447955\n",
      " 0.79712178 0.80462342 0.80195668 0.80197059]\n",
      "[[1.12142626 0.81808336 1.01330834 1.00447723 1.10260599 1.0375268\n",
      "  1.16536034 1.02738701 1.1498602  1.06716185 0.98590964 1.06275878\n",
      "  0.98521259 1.07476669 1.04384166 1.04526496]]\n",
      "{0: 930, 1: 942}\n",
      "acc 0.592948717948718\n",
      "(0.2229299363057325, 0.875, 0.35532994923857875, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 1500283.2892503494\n",
      "dev set\n",
      "[0.9004065  0.89739654 0.89938178 0.89925089 0.9017991  0.9011867\n",
      " 0.90246517 0.90109245 0.90084229 0.90011293 0.89935565 0.90142955\n",
      " 0.89967606 0.90155962 0.8996437  0.89965795]\n",
      "[[1.11831581 0.81496177 1.0102774  1.00138171 1.10567118 1.04057603\n",
      "  1.16844345 1.03043158 1.14702807 1.06532461 0.98411292 1.06583455\n",
      "  0.98279672 1.07781806 1.04159327 1.04301691]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 1500282.7666493978\n",
      "dev set\n",
      "[0.89964738 0.89664624 0.8986608  0.89849418 0.90253231 0.90194538\n",
      " 0.90322904 0.90185761 0.90020371 0.89958083 0.89887157 0.9021922\n",
      " 0.89969653 0.90231934 0.89889397 0.89890822]\n",
      "[[1.11907975 0.81571561 1.01100442 1.00214257 1.1049697  1.03984025\n",
      "  1.16769734 1.02968264 1.14773284 1.06592003 0.98466633 1.06505949\n",
      "  0.98315641 1.07708023 1.04236374 1.04378738]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 1500282.2410588935\n",
      "dev set\n",
      "[0.89888982 0.89589189 0.89793386 0.89773403 0.90326584 0.90269431\n",
      " 0.90398762 0.9026118  0.89956371 0.89905191 0.89838625 0.90295219\n",
      " 0.89971937 0.90306944 0.89815259 0.89816388]\n",
      "[[1.11984498 0.81647593 1.01173982 1.00290952 1.10426698 1.03911734\n",
      "  1.16695791 1.02894854 1.14844021 1.06651544 0.98522424 1.06429069\n",
      "  0.98352472 1.07635515 1.04313708 1.04456072]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "3 loss 1500281.7244507722\n",
      "dev set\n",
      "[0.89813148 0.8951344  0.89720269 0.89697091 0.90399835 0.90343487\n",
      " 0.90474292 0.90335653 0.89892166 0.89852547 0.89790171 0.903715\n",
      " 0.89974054 0.90381125 0.89744578 0.89745708]\n",
      "[[1.12061383 0.81724187 1.01248196 1.00368214 1.10356469 1.03840473\n",
      "  1.16622222 1.02822647 1.14915133 1.06711175 0.98578465 1.06352856\n",
      "  0.98389847 1.07564034 1.04391398 1.04533764]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 1500281.207834328\n",
      "dev set\n",
      "[0.89737138 0.89437403 0.89646786 0.89620499 0.90472946 0.90416771\n",
      " 0.90549585 0.90409249 0.89827707 0.89800114 0.89741857 0.90447565\n",
      " 0.89975928 0.9045454  0.896732   0.8967451 ]\n",
      "[[1.12138719 0.81801317 1.01323028 1.00446026 1.10286335 1.03770127\n",
      "  1.16548902 1.0275152  1.14986668 1.06770929 0.98634693 1.06277327\n",
      "  0.98427601 1.0749347  1.0446942  1.04611786]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 1500314.3100505501\n",
      "dev set\n",
      "[1.00201359 0.99734421 1.00088108 1.00004839 1.0019049  1.00127123\n",
      " 1.00251906 1.00116737 1.00229477 1.00150093 0.99914553 1.00151928\n",
      " 0.99909634 1.00163526 1.00126595 1.00128022]\n",
      "[[1.11791412 0.81503141 1.00957676 1.00062431 1.10670237 1.04142232\n",
      "  1.16975205 1.03126654 1.14681051 1.06488128 0.98429211 1.06677891\n",
      "  0.98312189 1.0787924  1.04089483 1.04232233]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 1500314.3070143063\n",
      "dev set\n",
      "[1.00305772 0.996455   1.00204848 1.00099521 1.00296016 1.00240165\n",
      " 1.00351827 1.00230951 1.00331241 1.00260367 0.9983301  1.00261977\n",
      " 0.99825349 1.00272136 1.00239698 1.00240958]\n",
      "[[1.118794   0.81600835 1.00997554 1.0006487  1.10755814 1.0420359\n",
      "  1.17069588 1.03182509 1.14773409 1.06560326 0.98524254 1.0675086\n",
      "  0.98410443 1.07956713 1.04150569 1.04294053]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 1500314.3022320624\n",
      "dev set\n",
      "[1.004299   0.99547189 1.00343926 1.00248223 1.00421504 1.00374204\n",
      " 1.00469881 1.00366361 1.004519   1.00391349 0.99741248 1.00392709\n",
      " 0.99730377 1.00401241 1.00373808 1.00374877]\n",
      "[[1.1200506  0.81714609 1.01112732 1.0012959  1.10881515 1.0432589\n",
      "  1.17193477 1.03303373 1.14898329 1.06684823 0.98636079 1.06875477\n",
      "  0.9852582  1.08081898 1.04272803 1.04416462]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 1500314.295268882\n",
      "dev set\n",
      "[1.00567755 0.99441502 1.00495125 1.00411927 1.00560592 1.00520813\n",
      " 1.0060178  1.00514178 1.00586438 1.00535321 0.99642823 1.00536464\n",
      " 0.99628602 1.00543559 1.00520478 1.00521382]\n",
      "[[1.12153186 0.81840547 1.01266364 1.00277923 1.1103039  1.04478365\n",
      "  1.1733746  1.03456235 1.15044244 1.06836265 0.98758088 1.0702682\n",
      "  0.98651513 1.08232541 1.04425299 1.045689  ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 1500314.285783488\n",
      "dev set\n",
      "[1.00714535 0.99330311 1.00652894 1.00580936 1.0070838  1.00674752\n",
      " 1.00743369 1.00669108 1.00730382 1.00687135 0.99540195 1.00688102\n",
      " 0.9952262  1.00694004 1.00674468 1.00675235]\n",
      "[[1.12314746 0.81975239 1.01435943 1.0045387  1.1119276  1.04645318\n",
      "  1.17494725 1.03623882 1.15203489 1.07001683 0.98886316 1.07192109\n",
      "  0.98783449 1.0839695  1.04592288 1.04735793]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 795394.8717504588\n",
      "dev set\n",
      "[0.60076946 0.5977431  0.59969381 0.59961021 0.60146613 0.60081777\n",
      " 0.60209597 0.60071671 0.60106089 0.6002446  0.59943306 0.60104369\n",
      " 0.59942127 0.6011902  0.60081102 0.60082526]\n",
      "[[1.11795067 0.81461379 1.00996168 1.00102149 1.10597633 1.04093407\n",
      "  1.16880253 1.03080299 1.14673646 1.06512615 0.98397079 1.06621567\n",
      "  0.9827831  1.07817711 1.04041018 1.04183383]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "1 loss 795388.9365425562\n",
      "dev set\n",
      "[0.60036758 0.59734681 0.59929454 0.59921849 0.60186385 0.60121639\n",
      " 0.60249522 0.60111649 0.60066172 0.5998453  0.59903374 0.60142255\n",
      " 0.59902186 0.60158884 0.6012103  0.60122453]\n",
      "[[1.11835277 0.81501033 1.01036123 1.0014144  1.10557904 1.04053529\n",
      "  1.16840373 1.03040265 1.14713552 1.06552494 0.9843689  1.065819\n",
      "  0.9831814  1.07777831 1.04001116 1.0414348 ]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "2 loss 795382.9820775153\n",
      "dev set\n",
      "[0.59996633 0.59694928 0.5988946  0.59882664 0.60226081 0.6016137\n",
      " 0.60289319 0.6015148  0.60026111 0.59944459 0.59863302 0.60180469\n",
      " 0.59862081 0.60198621 0.6016107  0.60162493]\n",
      "[[1.11875462 0.81540826 1.01076169 1.00180773 1.10518225 1.04013766\n",
      "  1.16800621 1.03000368 1.1475362  1.06592532 0.98476898 1.06542084\n",
      "  0.98358173 1.07738063 1.03961103 1.04103467]]\n",
      "{0: 274, 1: 1598}\n",
      "acc 0.27350427350427353\n",
      "(0.14956195244055068, 0.9958333333333333, 0.2600652883569097, None)\n",
      "\n",
      "3 loss 795376.9848540034\n",
      "dev set\n",
      "[0.5995653  0.59655051 0.59849395 0.59843449 0.60265687 0.60200961\n",
      " 0.60328996 0.60191158 0.59985887 0.59904226 0.59823068 0.60218963\n",
      " 0.59821787 0.60238224 0.60201239 0.60202662]\n",
      "[[1.11915664 0.81580759 1.01116313 1.0022017  1.10478606 1.03974119\n",
      "  1.16760977 1.02960609 1.14793869 1.06632759 0.98517113 1.06502135\n",
      "  0.98398429 1.07698409 1.03920966 1.0406333 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "4 loss 795370.9443091367\n",
      "dev set\n",
      "[0.59916436 0.59615066 0.59809272 0.5980421  0.60305186 0.60240399\n",
      " 0.60368551 0.60230671 0.59945509 0.5986384  0.59782681 0.60257701\n",
      " 0.59781314 0.60277677 0.60241528 0.60242952]\n",
      "[[1.119559   0.81620818 1.01156546 1.00259627 1.10439062 1.039346\n",
      "  1.16721434 1.02920994 1.14834292 1.0667317  0.98557521 1.06462075\n",
      "  0.98438895 1.07658879 1.03880715 1.04023079]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 795660.7800291842\n",
      "dev set\n",
      "[0.70077002 0.69774433 0.69969605 0.69960929 0.70146621 0.70081733\n",
      " 0.70209617 0.7007165  0.70106488 0.70024853 0.69943766 0.70106274\n",
      " 0.69942578 0.70118977 0.70080838 0.70082262]\n",
      "[[1.11795025 0.81461263 1.00995962 1.0010222  1.10597633 1.04093478\n",
      "  1.16880235 1.03080333 1.14673261 1.06512267 0.98395925 1.06621389\n",
      "  0.98277646 1.07817779 1.04041486 1.0418385 ]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "1 loss 795658.0558000781\n",
      "dev set\n",
      "[0.70036833 0.69734867 0.69929869 0.69921673 0.70186394 0.70121569\n",
      " 0.70249537 0.70111601 0.70066768 0.69985174 0.699041   0.70145722\n",
      " 0.69902886 0.70158817 0.7012065  0.70122073]\n",
      "[[1.11835226 0.81500863 1.01035743 1.00141578 1.10557921 1.04053651\n",
      "  1.16840398 1.03040356 1.14712988 1.06551644 0.98434889 1.06581663\n",
      "  0.98317044 1.07777948 1.04001818 1.04144182]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "2 loss 795655.2978250459\n",
      "dev set\n",
      "[0.69996664 0.69695102 0.69889972 0.69882348 0.70226104 0.70161283\n",
      " 0.70289332 0.70151406 0.70026704 0.69945178 0.69864093 0.70185331\n",
      " 0.69862822 0.70198538 0.70160726 0.7016215 ]\n",
      "[[1.11875459 0.81540677 1.01075706 1.00181033 1.10518247 1.04013935\n",
      "  1.16800694 1.03000528 1.14753028 1.06591309 0.98474272 1.0654185\n",
      "  0.98356879 1.07738226 1.03961845 1.04104209]]\n",
      "{0: 605, 1: 1267}\n",
      "acc 0.44604700854700857\n",
      "(0.18547750591949486, 0.9791666666666666, 0.31187790311877905, None)\n",
      "\n",
      "3 loss 795652.4938449423\n",
      "dev set\n",
      "[0.69956443 0.6965513  0.69849907 0.69842926 0.70265743 0.70200864\n",
      " 0.7032902  0.70191056 0.69986275 0.69904821 0.69823732 0.70225093\n",
      " 0.69822359 0.7023813  0.70201086 0.7020251 ]\n",
      "[[1.1191578  0.81580718 1.01115862 1.00220614 1.10478617 1.03974334\n",
      "  1.1676109  1.02960849 1.14793409 1.06631326 0.98514074 1.06501956\n",
      "  0.98397172 1.07698616 1.03921553 1.04063917]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "4 loss 795649.6456218654\n",
      "dev set\n",
      "[0.69916151 0.69614963 0.69809688 0.69803412 0.70305293 0.70240297\n",
      " 0.70368603 0.70230541 0.69945493 0.69864147 0.69783018 0.70264989\n",
      " 0.69781509 0.70277578 0.7024164  0.70243064]\n",
      "[[1.11956206 0.81620975 1.01156199 1.00260319 1.10439047 1.03934864\n",
      "  1.16721575 1.02921323 1.14834127 1.06671697 0.98554279 1.06461999\n",
      "  0.98437902 1.07659134 1.03880955 1.04023319]]\n",
      "{0: 590, 1: 1282}\n",
      "acc 0.43803418803418803\n",
      "(0.18330733229329174, 0.9791666666666666, 0.3088042049934297, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 795748.5415657664\n",
      "dev set\n",
      "[0.80077363 0.79774795 0.79970489 0.79960891 0.8014655  0.80081648\n",
      " 0.80209632 0.80071593 0.8011005  0.80048737 0.79954111 0.80106171\n",
      " 0.7994966  0.80118896 0.80058227 0.80059678]\n",
      "[[1.11794728 0.81460935 1.00995169 1.00102251 1.10597788 1.04093628\n",
      "  1.16880224 1.03080432 1.14671287 1.06505694 0.98388316 1.06621321\n",
      "  0.98268284 1.07817923 1.04118632 1.04260994]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "1 loss 795748.0453372067\n",
      "dev set\n",
      "[0.80037552 0.79735644 0.7993168  0.79921769 0.80186203 0.80121427\n",
      " 0.80249507 0.80111449 0.80074065 0.80027161 0.79925809 0.80145549\n",
      " 0.7991677  0.80158681 0.80071678 0.80073163]\n",
      "[[1.11834631 0.8150016  1.01034126 1.00141488 1.10558318 1.04053936\n",
      "  1.16840497 1.03040644 1.14709184 1.06536469 0.9841818  1.06581598\n",
      "  0.98297285 1.0777822  1.04155864 1.04298225]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "2 loss 795747.5448556638\n",
      "dev set\n",
      "[0.79997709 0.79696266 0.79892631 0.79882574 0.80225816 0.80161097\n",
      " 0.80289267 0.8015116  0.80037322 0.80005663 0.79897296 0.80185027\n",
      " 0.79882667 0.80198359 0.80087414 0.80088931]\n",
      "[[1.11874603 0.81539634 1.01073345 1.0018083  1.10518869 1.04014352\n",
      "  1.1680091  1.03001028 1.14747382 1.06567261 0.98448034 1.06541845\n",
      "  0.98327397 1.07738625 1.04192534 1.04334893]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "3 loss 795747.0392427864\n",
      "dev set\n",
      "[0.79957772 0.7965663  0.79853339 0.79843264 0.80265384 0.80200648\n",
      " 0.80328939 0.80190722 0.79999659 0.79984203 0.79868596 0.80224584\n",
      " 0.79852929 0.80237921 0.80106034 0.80107492]\n",
      "[[1.11914708 0.81579394 1.01112837 1.00220324 1.10479447 1.03974888\n",
      "  1.16761417 1.02961575 1.14785925 1.06598144 0.98477954 1.06502077\n",
      "  0.98358706 1.07699147 1.04228463 1.0437082 ]]\n",
      "{0: 941, 1: 931}\n",
      "acc 0.5988247863247863\n",
      "(0.22556390977443608, 0.875, 0.35866780529462, None)\n",
      "\n",
      "4 loss 795746.5316722179\n",
      "dev set\n",
      "[0.79917718 0.7961674  0.79813822 0.79803838 0.80304887 0.8024006\n",
      " 0.80368527 0.80230125 0.79961085 0.79962774 0.79839755 0.802642\n",
      " 0.7982547  0.80277348 0.80127418 0.80128725]\n",
      "[[1.11954971 0.81619439 1.01152587 1.00259974 1.10440068 1.03935561\n",
      "  1.16722003 1.02922292 1.14824828 1.06629135 0.98507954 1.06462309\n",
      "  0.98391139 1.07659805 1.04263558 1.04405914]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall penalty\n",
      "0 loss 795803.4182141307\n",
      "dev set\n",
      "[0.90077642 0.89774973 0.89970992 0.89961101 0.90145631 0.90081573\n",
      " 0.90209463 0.90071554 0.90109916 0.90029145 0.89951498 0.90106535\n",
      " 0.89972337 0.90118827 0.9000118  0.90002604]\n",
      "[[1.11794436 0.81460741 1.00994637 1.00102013 1.10599284 1.04093873\n",
      "  1.16880542 1.03080553 1.14672123 1.06509567 0.9839133  1.06621072\n",
      "  0.98263782 1.07818152 1.04121648 1.04264013]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 795803.1438396462\n",
      "dev set\n",
      "[0.9003822  0.89736322 0.89932829 0.89922201 0.90184363 0.90121147\n",
      " 0.9024896  0.90111135 0.90073561 0.89995611 0.89921035 0.90146055\n",
      " 0.89972778 0.90158419 0.89961843 0.89963267]\n",
      "[[1.11833963 0.81499475 1.01032947 1.00141015 1.10561368 1.0405471\n",
      "  1.16841539 1.03041372 1.14710397 1.06545079 0.98424457 1.06581266\n",
      "  0.9828582  1.07778951 1.04161592 1.04303957]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 795802.8693457431\n",
      "dev set\n",
      "[0.89998809 0.89697573 0.89894485 0.89883223 0.90223139 0.90160536\n",
      " 0.90288324 0.90150478 0.90037188 0.89962175 0.89890696 0.90185556\n",
      " 0.89974078 0.90197828 0.89922454 0.89923879]\n",
      "[[1.11873543 0.81538362 1.01071491 1.00180154 1.10523382 1.04015792\n",
      "  1.1680273  1.03002527 1.14748719 1.06580574 0.98457591 1.06541576\n",
      "  0.9830797  1.07739992 1.04201629 1.04343993]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 795802.5933077876\n",
      "dev set\n",
      "[0.89959362 0.89658706 0.89855976 0.89844139 0.90261936 0.90199746\n",
      " 0.9032761  0.90189604 0.90000766 0.89928803 0.89860418 0.90225017\n",
      " 0.89975497 0.90237059 0.89882969 0.89884394]\n",
      "[[1.11913233 0.8157743  1.01110267 1.00219467 1.10485354 1.03977102\n",
      "  1.16764027 1.02963973 1.14787147 1.06616114 0.98490786 1.06502016\n",
      "  0.98330359 1.07701261 1.04241802 1.04384166]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 795802.3155988808\n",
      "dev set\n",
      "[0.89919861 0.89619734 0.89817328 0.89804958 0.9030073  0.90238772\n",
      " 0.90366835 0.90228514 0.89964279 0.89895488 0.89830191 0.90264416\n",
      " 0.899769   0.90276109 0.89843366 0.89844792]\n",
      "[[1.11953054 0.81616669 1.01149249 1.00258949 1.10447317 1.03938638\n",
      "  1.16725398 1.02925695 1.14825701 1.06651712 0.98524047 1.06462605\n",
      "  0.98352943 1.07662756 1.0428212  1.04424485]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 795834.3106187816\n",
      "dev set\n",
      "[1.00158846 0.9977371  1.00046728 1.00002156 1.0014773  1.00082839\n",
      " 1.0021032  1.00072474 1.00187522 1.0010627  0.99945553 1.00108154\n",
      " 0.99944395 1.00120069 1.00082306 1.00083747]\n",
      "[[1.117732   0.81462273 1.00956177 1.00062431 1.10653885 1.04136403\n",
      "  1.16949167 1.03122255 1.14658253 1.06478704 0.98395183 1.06668163\n",
      "  0.9827584  1.07867547 1.04083731 1.04226273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 795834.3093998579\n",
      "dev set\n",
      "[1.00204011 0.9973179  1.00094303 1.0002612  1.00193189 1.00130426\n",
      " 1.00254401 1.00120314 1.00232031 1.00153069 0.99905281 1.00154887\n",
      " 0.99904163 1.00166385 1.00129909 1.00131307]\n",
      "[[1.118066   0.81505934 1.00960194 1.00062446 1.10685236 1.04149586\n",
      "  1.1698833  1.03132351 1.14695497 1.06499258 0.98438848 1.06689297\n",
      "  0.98319517 1.07892205 1.04096749 1.04239736]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 795834.3078179954\n",
      "dev set\n",
      "[1.00255056 0.99687284 1.00151084 1.00079332 1.00244759 1.00185612\n",
      " 1.00303401 1.00176052 1.00281858 1.00206911 0.99861393 1.00208619\n",
      " 0.99860121 1.00219425 1.00185124 1.00186442]\n",
      "[[1.11852452 0.81554147 1.00980237 1.00064265 1.10730132 1.04182201\n",
      "  1.17036292 1.03161716 1.14742887 1.06537865 0.98489344 1.06728304\n",
      "  0.98370062 1.07933467 1.04129206 1.0427262 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 795834.3057908942\n",
      "dev set\n",
      "[1.00311972 0.9964009  1.00215251 1.00145369 1.00302337 1.00247519\n",
      " 1.00357578 1.0023864  1.00337172 1.00267241 0.99814136 1.00268821\n",
      " 0.99812587 1.00278802 1.00247067 1.00248289]\n",
      "[[1.11908726 0.81607021 1.01024193 1.0008198  1.10786219 1.04233595\n",
      "  1.17092283 1.03211469 1.14799177 1.0659189  0.985456   1.06782485\n",
      "  0.98426406 1.07988474 1.04180523 1.04324141]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 795834.303250502\n",
      "dev set\n",
      "[1.00374041 0.99590416 1.00284947 1.00218897 1.00365118 1.00314767\n",
      " 1.00416544 1.00306592 1.00397456 1.00332889 0.9976408  1.00334337\n",
      " 0.99762191 1.00343472 1.00314351 1.00315475]\n",
      "[[1.11973228 0.81664122 1.01086331 1.00129737 1.10850946 1.04298065\n",
      "  1.17155181 1.032755   1.14862867 1.06656878 0.98606363 1.06847489\n",
      "  0.98487285 1.08053502 1.04244975 1.04388643]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 443156.29832303466\n",
      "dev set\n",
      "[0.60096027 0.5979289  0.59988195 0.59979234 0.60127745 0.60062757\n",
      " 0.60190623 0.6005264  0.60124967 0.60043351 0.59962198 0.60087453\n",
      " 0.59961011 0.601      0.6006219  0.60063613]\n",
      "[[1.11775974 0.81442781 1.00977334 1.00083825 1.10616437 1.0411243\n",
      "  1.16899192 1.03099341 1.14654838 1.064937   0.98378384 1.06640104\n",
      "  0.98259542 1.07836735 1.0405987  1.04202234]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 443153.18304169644\n",
      "dev set\n",
      "[0.60075139 0.597722   0.59967409 0.59958652 0.6014846  0.60083498\n",
      " 0.60211407 0.60073439 0.60104224 0.60022605 0.59941452 0.60107971\n",
      " 0.59940263 0.60120741 0.60082936 0.60084359]\n",
      "[[1.11796858 0.81463475 1.00998123 1.00104428 1.10595733 1.04091686\n",
      "  1.16878409 1.03078516 1.14675593 1.06514408 0.98399099 1.06619355\n",
      "  0.98280267 1.0781599  1.04039121 1.04181486]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "2 loss 443150.1047493176\n",
      "dev set\n",
      "[0.60054325 0.59751558 0.59946668 0.59938162 0.60169094 0.60104146\n",
      " 0.60232105 0.6009415  0.60083522 0.60001899 0.59920746 0.60128534\n",
      " 0.59919552 0.6014139  0.60103636 0.60105059]\n",
      "[[1.11817675 0.81484125 1.01018871 1.00124946 1.10575105 1.0407103\n",
      "  1.1685771  1.03057776 1.14696312 1.06535073 0.98419783 1.06598635\n",
      "  0.9830096  1.07795334 1.04018421 1.04160785]]\n",
      "{0: 280, 1: 1592}\n",
      "acc 0.2767094017094017\n",
      "(0.15012562814070352, 0.9958333333333333, 0.2609170305676856, None)\n",
      "\n",
      "3 loss 443147.02271556674\n",
      "dev set\n",
      "[0.60033526 0.59730903 0.59925921 0.59917689 0.60189698 0.60124754\n",
      " 0.60252767 0.60114819 0.60062797 0.59981171 0.59900018 0.60149167\n",
      " 0.59898813 0.60162    0.60124351 0.60125774]\n",
      "[[1.11838485 0.81504791 1.0103963  1.00145454 1.10554499 1.0405041\n",
      "  1.16837045 1.03037073 1.14717056 1.06555764 0.984405   1.06577895\n",
      "  0.98321686 1.07774713 1.03997706 1.0414007 ]]\n",
      "{0: 278, 1: 1594}\n",
      "acc 0.27564102564102566\n",
      "(0.14993726474278546, 0.9958333333333333, 0.2606324972737186, None)\n",
      "\n",
      "4 loss 443143.93085920735\n",
      "dev set\n",
      "[0.60012727 0.5971022  0.59905154 0.59897216 0.60210282 0.60145331\n",
      " 0.60273404 0.60135454 0.60042034 0.59960405 0.59879251 0.60169871\n",
      " 0.59878029 0.6018258  0.60145097 0.6014652 ]\n",
      "[[1.11859305 0.81525488 1.01060415 1.00165972 1.10533907 1.04029817\n",
      "  1.168164   1.03016399 1.14737843 1.065765   0.98461264 1.06557122\n",
      "  0.98342464 1.07754117 1.03976962 1.04119326]]\n",
      "{0: 275, 1: 1597}\n",
      "acc 0.27403846153846156\n",
      "(0.14965560425798372, 0.9958333333333333, 0.26020685900925417, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 443421.42359608196\n",
      "dev set\n",
      "[0.70096017 0.6979291  0.69988255 0.6997928  0.70127755 0.70062746\n",
      " 0.70190631 0.70052635 0.70125037 0.70043408 0.69962264 0.70087881\n",
      " 0.69961094 0.70099989 0.70062143 0.70063567]\n",
      "[[1.11775985 0.81442762 1.00977278 1.00083785 1.10616422 1.04112449\n",
      "  1.16899183 1.0309935  1.14654808 1.06493565 0.9837815  1.06640084\n",
      "  0.98259474 1.07836753 1.0405993  1.04202295]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 443419.99303479184\n",
      "dev set\n",
      "[0.70075118 0.69772254 0.69967552 0.69958717 0.70148481 0.7008348\n",
      " 0.70211423 0.70073425 0.70104329 0.70022714 0.69941578 0.70108584\n",
      " 0.69940403 0.70120723 0.70082866 0.70084289]\n",
      "[[1.11796882 0.81463425 1.0099799  1.00104371 1.10595702 1.04091717\n",
      "  1.16878393 1.03078538 1.14675563 1.06514047 0.98398623 1.06619361\n",
      "  0.98280133 1.0781602  1.0403922  1.04181585]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "2 loss 443418.57382909744\n",
      "dev set\n",
      "[0.70054281 0.69751635 0.69946881 0.69938229 0.7016913  0.70104124\n",
      " 0.7023213  0.70094127 0.70083627 0.7000203  0.699209   0.7012926\n",
      " 0.69919711 0.70141369 0.7010357  0.70104994]\n",
      "[[1.11817722 0.81484054 1.01018673 1.00124887 1.10575052 1.04071072\n",
      "  1.16857688 1.03057813 1.14696307 1.06534504 0.98419098 1.06598683\n",
      "  0.98300798 1.07795374 1.04018525 1.0416089 ]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "3 loss 443417.14685267484\n",
      "dev set\n",
      "[0.70033445 0.69730988 0.69926184 0.69917743 0.70189754 0.7012473\n",
      " 0.70252805 0.70114787 0.70062861 0.69981297 0.6990016  0.70149961\n",
      " 0.69898948 0.70161976 0.70124322 0.70125746]\n",
      "[[1.11838569 0.81504715 1.01039387 1.00145408 1.10554423 1.04050463\n",
      "  1.16837012 1.03037128 1.1471711  1.06555016 0.98439645 1.06577996\n",
      "  0.98321543 1.07774763 1.03997778 1.04140142]]\n",
      "{0: 608, 1: 1264}\n",
      "acc 0.44764957264957267\n",
      "(0.18591772151898733, 0.9791666666666666, 0.3125, None)\n",
      "\n",
      "4 loss 443415.7088297014\n",
      "dev set\n",
      "[0.70012591 0.69710293 0.69905446 0.69897239 0.70210362 0.70145305\n",
      " 0.70273459 0.70135414 0.70042009 0.69960486 0.69879336 0.701707\n",
      " 0.69878092 0.70182554 0.70145142 0.70146566]\n",
      "[[1.11859442 0.81525428 1.01060149 1.00165956 1.10533802 1.0402988\n",
      "  1.16816354 1.03016474 1.14737992 1.06575611 0.98460286 1.06557289\n",
      "  0.98342392 1.07754178 1.03976956 1.04119321]]\n",
      "{0: 606, 1: 1266}\n",
      "acc 0.4465811965811966\n",
      "(0.18562401263823064, 0.9791666666666666, 0.31208499335989376, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 443508.65678004373\n",
      "dev set\n",
      "[0.80096077 0.79792991 0.79988473 0.7997941  0.8012775  0.80062722\n",
      " 0.80190634 0.80052619 0.80125369 0.80054345 0.79965421 0.80087838\n",
      " 0.79962036 0.80099966 0.80054749 0.80056189]\n",
      "[[1.11775938 0.81442688 1.00977081 1.00083669 1.10616436 1.04112493\n",
      "  1.16899179 1.03099375 1.1465465  1.06491414 0.98375529 1.06640076\n",
      "  0.98258168 1.07836795 1.04102759 1.04245124]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "1 loss 443508.39014527557\n",
      "dev set\n",
      "[0.80075258 0.797725   0.79968058 0.79959001 0.80148462 0.8008344\n",
      " 0.80211422 0.80073377 0.8010495  0.8004067  0.79948909 0.80108499\n",
      " 0.79942385 0.80120686 0.80064945 0.80066408]\n",
      "[[1.11796769 0.81463199 1.00997533 1.00104117 1.1059574  1.04091795\n",
      "  1.16878395 1.03078613 1.14675175 1.06509137 0.98392085 1.06619364\n",
      "  0.98276506 1.07816094 1.04123525 1.0426589 ]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "2 loss 443508.1263870532\n",
      "dev set\n",
      "[0.80054493 0.79752049 0.79947667 0.79938661 0.80169103 0.80104072\n",
      " 0.80232129 0.80094046 0.80084421 0.80027048 0.79932546 0.80129122\n",
      " 0.79922558 0.8014132  0.80075625 0.8007711 ]\n",
      "[[1.11817554 0.81483673 1.01017964 1.00124501 1.1057511  1.04071184\n",
      "  1.16857693 1.03057942 1.14695683 1.06526798 0.98408429 1.0659871\n",
      "  0.98294875 1.0779548  1.04144104 1.04286469]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "3 loss 443507.8607575374\n",
      "dev set\n",
      "[0.80033718 0.7973156  0.79927233 0.79918317 0.80189725 0.80124668\n",
      " 0.80252809 0.80114674 0.80063693 0.80013444 0.79916202 0.80149756\n",
      " 0.79902449 0.80161917 0.80087254 0.80088761]\n",
      "[[1.11838356 0.81504192 1.01038444 1.00144898 1.10554493 1.04050608\n",
      "  1.16837017 1.03037314 1.14716249 1.06544466 0.98424718 1.0657806\n",
      "  0.98313471 1.07774902 1.04164511 1.04306876]]\n",
      "{0: 950, 1: 922}\n",
      "acc 0.6036324786324786\n",
      "(0.227765726681128, 0.875, 0.3614457831325302, None)\n",
      "\n",
      "4 loss 443507.59233609686\n",
      "dev set\n",
      "[0.80012912 0.7971101  0.79906739 0.79897945 0.80210338 0.80145235\n",
      " 0.80273474 0.8013527  0.80042711 0.79999845 0.79899844 0.8017041\n",
      " 0.79882017 0.80182488 0.80099995 0.80101521]\n",
      "[[1.11859199 0.81524779 1.01058992 1.00165332 1.1053388  1.04030061\n",
      "  1.16816354 1.0301672  1.14736901 1.06562165 0.98440997 1.06557405\n",
      "  0.98332361 1.07754351 1.04184727 1.04327091]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 443563.4845282342\n",
      "dev set\n",
      "[0.90096201 0.8979306  0.89988606 0.89979506 0.90127578 0.90062728\n",
      " 0.90190594 0.90052617 0.9012569  0.90044859 0.89965151 0.90087923\n",
      " 0.89973815 0.90099973 0.90019261 0.90020685]\n",
      "[[1.1177582  0.81442617 1.00976943 1.00083567 1.10616716 1.04112513\n",
      "  1.16899258 1.0309939  1.14654589 1.0649273  0.98376352 1.06640012\n",
      "  0.98255891 1.07836812 1.04102728 1.04245093]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 443563.33814218943\n",
      "dev set\n",
      "[0.90075537 0.89772764 0.8996838  0.89959182 0.90148109 0.90083435\n",
      " 0.90211319 0.90073326 0.90105827 0.90026014 0.89948566 0.90108612\n",
      " 0.89973537 0.90120682 0.89998409 0.89999833]\n",
      "[[1.11796506 0.81462934 1.00997204 1.0010392  1.10596322 1.04091871\n",
      "  1.16878595 1.03078727 1.14674991 1.06512169 0.98394144 1.06619281\n",
      "  0.98270903 1.07816164 1.04123581 1.04265945]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 443563.19397231756\n",
      "dev set\n",
      "[0.90054936 0.89752545 0.89948193 0.89938927 0.90168585 0.90104041\n",
      " 0.90231961 0.90093927 0.9008604  0.90007233 0.89932205 0.90129236\n",
      " 0.89974145 0.90141292 0.8997762  0.89979044]\n",
      "[[1.11817141 0.81483183 1.01017436 1.00124216 1.10575975 1.04071337\n",
      "  1.1685802  1.03058186 1.1469533  1.06531549 0.98411767 1.06598637\n",
      "  0.98285633 1.07795624 1.04144386 1.04286751]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 443563.04977419536\n",
      "dev set\n",
      "[0.90034339 0.89732327 0.89927983 0.89918668 0.9018906  0.901246\n",
      " 0.9025258  0.90114473 0.90066266 0.89988471 0.89915925 0.90149845\n",
      " 0.89975017 0.90161853 0.89956826 0.8995825 ]\n",
      "[[1.11837787 0.81503447 1.01037704 1.00144529 1.10555623 1.04050862\n",
      "  1.16837471 1.03037712 1.14715675 1.06550929 0.9842935  1.06578031\n",
      "  0.98300321 1.07775142 1.0416521  1.04307575]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 443562.9052201145\n",
      "dev set\n",
      "[0.90013727 0.89712086 0.89907735 0.89898387 0.90209541 0.90145118\n",
      " 0.90273191 0.90134974 0.90046483 0.89969716 0.89899685 0.90170447\n",
      " 0.89975981 0.90182376 0.89936006 0.8993743 ]\n",
      "[[1.11858465 0.81523747 1.01058028 1.00164882 1.10535259 1.04030436\n",
      "  1.16816931 1.03017297 1.14736047 1.0657033  0.98446928 1.06557455\n",
      "  0.9831503  1.0775471  1.04186071 1.04328436]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 443594.31087060325\n",
      "dev set\n",
      "[1.00139093 0.99792787 1.00028993 1.00001511 1.00127934 1.00062862\n",
      " 1.00190725 1.00052625 1.00167865 1.00086299 0.9996309  1.0008819\n",
      " 0.9996154  1.00100155 1.00062333 1.00063765]\n",
      "[[1.11765598 0.81442931 1.00956014 1.00062431 1.10647395 1.04135092\n",
      "  1.16936892 1.03121411 1.1464788  1.06475933 0.98377149 1.06665251\n",
      "  0.98258364 1.07863668 1.04082446 1.04224915]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 443594.3103045555\n",
      "dev set\n",
      "[1.00160795 0.99771668 1.00050363 1.00008088 1.00149698 1.00085065\n",
      " 1.00212211 1.00074824 1.00189435 1.00108352 0.99942975 1.00110229\n",
      " 0.99941156 1.00122103 1.00084538 1.00085965]\n",
      "[[1.117812   0.81464363 1.00956523 1.00062431 1.10661777 1.04138975\n",
      "  1.16955828 1.03123884 1.14665722 1.06483822 0.98397772 1.0667348\n",
      "  0.98279281 1.07874    1.04086249 1.04228936]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 443594.3096623282\n",
      "dev set\n",
      "[1.00183684 0.99750087 1.00074284 1.00026389 1.00172718 1.00109064\n",
      " 1.00234625 1.00098934 1.00212035 1.00131984 0.99922106 1.0013383\n",
      " 0.99919961 1.00145511 1.00108543 1.00109951]\n",
      "[[1.1180018  0.81486673 1.00958875 1.00062461 1.10679919 1.04147337\n",
      "  1.16976866 1.03130212 1.14686128 1.06496652 0.98420175 1.06686634\n",
      "  0.98301999 1.07889027 1.04094504 1.04237479]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 443594.3089253701\n",
      "dev set\n",
      "[1.0020809  0.9972786  1.00100826 1.00050728 1.00197327 1.0013515\n",
      " 1.00258275 1.00125235 1.00235984 1.00157511 0.99900273 1.00159311\n",
      " 0.99897731 1.00170707 1.00134642 1.00136017]\n",
      "[[1.11822277 0.81510139 1.00965584 1.00062959 1.10701506 1.04161446\n",
      "  1.17000038 1.03142254 1.14709014 1.06514557 0.9844452  1.06704785\n",
      "  0.98326701 1.07908545 1.04108513 1.0425176 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 443594.30808079464\n",
      "dev set\n",
      "[1.00234142 0.99704911 1.00129821 1.000792   1.00223645 1.00163337\n",
      " 1.00283306 1.00153709 1.00261425 1.00184996 0.9987743  1.00186739\n",
      " 0.99874426 1.00197778 1.00162843 1.00164177]\n",
      "[[1.11847286 0.81534879 1.00978967 1.0006588  1.10726263 1.04181403\n",
      "  1.17025362 1.03160619 1.14734322 1.06537131 0.98470742 1.06727517\n",
      "  0.98353328 1.07932126 1.04128395 1.04271844]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 241877.01128313653\n",
      "dev set\n",
      "[0.60106778 0.59803511 0.59998839 0.59989896 0.6011709  0.60052065\n",
      " 0.60179949 0.60041947 0.60135623 0.6005401  0.59972857 0.60077116\n",
      " 0.59971669 0.60089307 0.60051527 0.6005295 ]\n",
      "[[1.11765226 0.81432158 1.00966686 1.00073158 1.10627078 1.04123126\n",
      "  1.1690985  1.03110038 1.14644183 1.06483032 0.98367771 1.06650714\n",
      "  0.98248889 1.0784743  1.04070531 1.04212896]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 241875.43316335764\n",
      "dev set\n",
      "[0.60096092 0.59792923 0.59988219 0.59979271 0.60127677 0.60062675\n",
      " 0.60190597 0.60052593 0.60125025 0.60043411 0.59962257 0.60087557\n",
      " 0.59961069 0.60099917 0.60062125 0.60063549]\n",
      "[[1.11775907 0.81442746 1.00977305 1.00083782 1.10616494 1.04112509\n",
      "  1.16899187 1.03099371 1.14654781 1.06493608 0.98378377 1.06640133\n",
      "  0.98259467 1.07836814 1.04059934 1.04202299]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "2 loss 241873.8618225236\n",
      "dev set\n",
      "[0.60085416 0.59782346 0.59977609 0.59968656 0.60138247 0.60073268\n",
      " 0.6020123  0.60063226 0.60114436 0.60032821 0.59951667 0.60098009\n",
      " 0.59950479 0.60110511 0.60072713 0.60074137]\n",
      "[[1.11786578 0.81453324 1.00987915 1.00094396 1.10605927 1.04101908\n",
      "  1.16888536 1.03088716 1.14665368 1.06504173 0.98388977 1.06629561\n",
      "  0.98270034 1.07826213 1.04049349 1.04191714]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "3 loss 241872.2895229431\n",
      "dev set\n",
      "[0.60074742 0.59771769 0.59966999 0.59958043 0.6014881  0.60083854\n",
      " 0.60211858 0.60073852 0.60103846 0.6002223  0.59941075 0.60108474\n",
      " 0.59939886 0.60121096 0.60083301 0.60084725]\n",
      "[[1.11797248 0.81463903 1.00998526 1.0010501  1.10595365 1.04091314\n",
      "  1.16877889 1.03078066 1.14675958 1.0651474  0.98399582 1.06618987\n",
      "  0.98280605 1.0781562  1.04038764 1.04181129]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "4 loss 241870.71508834488\n",
      "dev set\n",
      "[0.60064067 0.59761187 0.59956386 0.59947428 0.6015937  0.60094435\n",
      " 0.60222482 0.60084473 0.6009325  0.60011632 0.59930477 0.60118954\n",
      " 0.59929285 0.60131676 0.60093894 0.60095318]\n",
      "[[1.11807921 0.81474487 1.01009141 1.00115626 1.10584807 1.04080724\n",
      "  1.16867246 1.0306742  1.14686554 1.06525313 0.98410195 1.06608407\n",
      "  0.98291183 1.0780503  1.04028175 1.04170539]]\n",
      "{0: 283, 1: 1589}\n",
      "acc 0.2783119658119658\n",
      "(0.15040906230333542, 0.9958333333333333, 0.2613449972662657, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 242141.74904805477\n",
      "dev set\n",
      "[0.70106776 0.69803514 0.69998865 0.69989901 0.70117089 0.70052062\n",
      " 0.70179951 0.70041947 0.70135643 0.70054033 0.6997288  0.70077302\n",
      " 0.69971697 0.70089305 0.70051513 0.70052937]\n",
      "[[1.11765228 0.81432154 1.00966662 1.00073154 1.1062708  1.0412313\n",
      "  1.16909846 1.03110038 1.14644178 1.06482987 0.98367724 1.06650703\n",
      "  0.98248861 1.07847434 1.04070547 1.04212911]]\n",
      "{0: 617, 1: 1255}\n",
      "acc 0.45245726495726496\n",
      "(0.18725099601593626, 0.9791666666666666, 0.31438127090301005, None)\n",
      "\n",
      "1 loss 242141.0248848187\n",
      "dev set\n",
      "[0.70096085 0.69792925 0.69988277 0.69979272 0.70127674 0.70062671\n",
      " 0.70190605 0.70052595 0.70125057 0.70043464 0.69962304 0.7008788\n",
      " 0.69961123 0.70099914 0.70062101 0.70063524]\n",
      "[[1.11775915 0.81442744 1.00977252 1.00083782 1.10616499 1.04112514\n",
      "  1.16899173 1.03099367 1.14654772 1.06493474 0.98378316 1.06640114\n",
      "  0.98259394 1.07836819 1.04059965 1.0420233 ]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n",
      "2 loss 242140.3023536999\n",
      "dev set\n",
      "[0.70085401 0.69782343 0.69977697 0.69968649 0.70138243 0.70073265\n",
      " 0.70201247 0.70063231 0.70114474 0.700329   0.69951732 0.70098451\n",
      " 0.69950551 0.70110507 0.70072682 0.70074106]\n",
      "[[1.11786594 0.81453327 1.00987835 1.00094404 1.10605933 1.04101913\n",
      "  1.16888512 1.03088708 1.14665361 1.06503946 0.98388916 1.06629536\n",
      "  0.98269918 1.07826219 1.04049391 1.04191755]]\n",
      "{0: 612, 1: 1260}\n",
      "acc 0.4497863247863248\n",
      "(0.1865079365079365, 0.9791666666666666, 0.31333333333333335, None)\n",
      "\n",
      "3 loss 242139.57787405304\n",
      "dev set\n",
      "[0.70074717 0.69771757 0.69967112 0.69958026 0.70148806 0.70083851\n",
      " 0.70211883 0.7007386  0.70103881 0.70022328 0.69941151 0.70109025\n",
      " 0.69939968 0.70121093 0.7008327  0.70084694]\n",
      "[[1.11797274 0.81463915 1.00998422 1.00105028 1.10595374 1.04091319\n",
      "  1.16877855 1.03078053 1.14675957 1.06514423 0.98399531 1.06618957\n",
      "  0.98280453 1.07815625 1.0403881  1.04181175]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "4 loss 242138.85085933824\n",
      "dev set\n",
      "[0.70064029 0.69761163 0.69956521 0.69947397 0.70159365 0.70094433\n",
      " 0.70222516 0.70084484 0.70093274 0.70011743 0.69930555 0.70119605\n",
      " 0.69929369 0.70131674 0.70093869 0.70095293]\n",
      "[[1.1180796  0.81474513 1.01009017 1.00115658 1.10584816 1.04080729\n",
      "  1.16867199 1.03067403 1.14686567 1.06524912 0.98410165 1.06608375\n",
      "  0.98291003 1.07805035 1.04028218 1.04170582]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 242228.71738812706\n",
      "dev set\n",
      "[0.80106776 0.79803524 0.79998944 0.79989911 0.8011708  0.80052057\n",
      " 0.80179949 0.80041943 0.80135645 0.80054858 0.7997399  0.80077306\n",
      " 0.79972002 0.80089301 0.80048372 0.80049803]\n",
      "[[1.11765229 0.81432146 1.00966591 1.00073145 1.10627092 1.04123137\n",
      "  1.16909848 1.03110044 1.14644183 1.06482723 0.98367023 1.06650703\n",
      "  0.98248419 1.07847441 1.04091979 1.04234344]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "1 loss 242228.58103525665\n",
      "dev set\n",
      "[0.80096079 0.79792928 0.79988438 0.79979282 0.8012765  0.80062667\n",
      " 0.801906   0.80052585 0.80125075 0.8004632  0.79964781 0.80087899\n",
      " 0.79961826 0.80099909 0.80054103 0.80055546]\n",
      "[[1.11775921 0.81442743 1.00977108 1.00083774 1.10616534 1.04112523\n",
      "  1.16899177 1.03099382 1.1465475  1.06492556 0.98376675 1.06640123\n",
      "  0.9825804  1.07836827 1.0410254  1.04244904]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "2 loss 242228.44539151248\n",
      "dev set\n",
      "[0.80085389 0.79782335 0.79977933 0.79968657 0.80138202 0.80073261\n",
      " 0.80201239 0.80063214 0.80114498 0.80037958 0.79955606 0.80098486\n",
      " 0.79951628 0.80110504 0.80059719 0.80061176]\n",
      "[[1.11786608 0.81453339 1.00987624 1.000944   1.10605994 1.04101923\n",
      "  1.16888515 1.03088731 1.14665304 1.06502303 0.98386292 1.06629556\n",
      "  0.98267598 1.07826228 1.04113062 1.04255426]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 242228.30931963224\n",
      "dev set\n",
      "[0.80074695 0.79771733 0.79967419 0.79958027 0.80148748 0.80083849\n",
      " 0.80211875 0.80073837 0.80103893 0.80029666 0.79946437 0.80109074\n",
      " 0.79941383 0.80121091 0.80065465 0.80066935]\n",
      "[[1.11797298 0.81463944 1.0099815  1.00105031 1.10595459 1.04091328\n",
      "  1.16877857 1.03078086 1.14675864 1.0651202  0.98395898 1.06618992\n",
      "  0.98277166 1.07815633 1.04123552 1.04265916]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "4 loss 242228.17263506242\n",
      "dev set\n",
      "[0.80063995 0.79761118 0.79956892 0.7994739  0.80159291 0.80094433\n",
      " 0.80222508 0.80084454 0.80093248 0.80021412 0.79937267 0.80119666\n",
      " 0.79931079 0.80131675 0.80071435 0.80072916]\n",
      "[[1.11807997 0.81474563 1.01008689 1.00115671 1.10584925 1.04080737\n",
      "  1.168672   1.03067446 1.14686436 1.06521726 0.98405501 1.06608427\n",
      "  0.98286773 1.07805043 1.04134009 1.04276373]]\n",
      "{0: 957, 1: 915}\n",
      "acc 0.6063034188034188\n",
      "(0.2284153005464481, 0.8708333333333333, 0.361904761904762, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 242283.51874903968\n",
      "dev set\n",
      "[0.9010678  0.89803551 0.89998993 0.8998994  0.90117036 0.90052077\n",
      " 0.90179942 0.90041952 0.90135712 0.90054062 0.89973571 0.90077313\n",
      " 0.89978004 0.9008932  0.90030071 0.90031494]\n",
      "[[1.11765226 0.81432119 1.00966541 1.00073117 1.10627158 1.04123108\n",
      "  1.16909862 1.03110033 1.14644184 1.06483012 0.98367339 1.06650688\n",
      "  0.98247511 1.07847413 1.04091984 1.04234348]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 242283.44387473073\n",
      "dev set\n",
      "[0.90096079 0.89793001 0.89988543 0.8997935  0.90127548 0.90062729\n",
      " 0.90190591 0.90052616 0.90125279 0.90043656 0.89963832 0.90087887\n",
      " 0.89977531 0.9009997  0.90019462 0.90020886]\n",
      "[[1.11775925 0.81442672 1.00977    1.00083709 1.10616686 1.04112433\n",
      "  1.16899199 1.03099345 1.14654769 1.06493474 0.98377459 1.06640096\n",
      "  0.98255964 1.0783674  1.04102601 1.04244965]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 242283.36936073826\n",
      "dev set\n",
      "[0.90085383 0.89782458 0.89978094 0.89968764 0.90138045 0.90073369\n",
      " 0.9020123  0.90063267 0.90114871 0.9003329  0.89954123 0.90098445\n",
      " 0.89977753 0.90110608 0.90008868 0.90010292]\n",
      "[[1.11786621 0.8145322  1.00987461 1.000943   1.1060623  1.04101769\n",
      "  1.16888546 1.03088667 1.14665338 1.06503905 0.98387568 1.06629523\n",
      "  0.98264295 1.07826078 1.04113204 1.04255569]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 242283.29480696013\n",
      "dev set\n",
      "[0.90074685 0.89771911 0.89967637 0.89958173 0.90148538 0.90084002\n",
      " 0.90211866 0.90073911 0.9010447  0.9002294  0.89944427 0.90108998\n",
      " 0.89978247 0.9012124  0.89998276 0.89999699]\n",
      "[[1.11797322 0.81463774 1.00997932 1.00104897 1.10595776 1.04091112\n",
      "  1.16877893 1.03077998 1.14675907 1.06514327 0.98397678 1.06618958\n",
      "  0.9827259  1.07815422 1.04123808 1.04266172]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 242283.22016038944\n",
      "dev set\n",
      "[0.90063982 0.89761357 0.8995717  0.89947576 0.90159031 0.90094629\n",
      " 0.90222503 0.90084548 0.90094069 0.90012596 0.89934737 0.9011955\n",
      " 0.89978874 0.90131866 0.8998768  0.89989104]\n",
      "[[1.11808029 0.81474337 1.01008414 1.00115503 1.10585322 1.0408046\n",
      "  1.1686724  1.03067337 1.1468648  1.06524748 0.9840779  1.06608399\n",
      "  0.98280874 1.07804773 1.04134416 1.0427678 ]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 242314.31099013682\n",
      "dev set\n",
      "[1.00128293 0.9980349  1.00019532 1.0000116  1.00117128 1.0005208\n",
      " 1.00179948 1.00041921 1.00157079 1.00075478 0.9997301  1.00077368\n",
      " 0.99971758 1.00089335 1.00051553 1.00052979]\n",
      "[[1.11760898 0.81432188 1.00955981 1.00062431 1.10643436 1.0413456\n",
      "  1.169294   1.03121116 1.14641459 1.06474516 0.98367429 1.06663741\n",
      "  0.98248521 1.07861503 1.04081929 1.04224358]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 242314.31072071532\n",
      "dev set\n",
      "[1.00139046 0.99792835 1.00029761 1.00003223 1.00127892 1.00062914\n",
      " 1.00190664 1.00052734 1.00167809 1.00086293 0.99962457 1.00088181\n",
      " 0.99961322 1.00100132 1.00062387 1.00063813]\n",
      "[[1.11768858 0.81442894 1.00956069 1.00062431 1.10650762 1.04136101\n",
      "  1.16938996 1.03121959 1.14650534 1.06478257 0.98377988 1.06667674\n",
      "  0.9825895  1.07866621 1.04083428 1.04225971]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 242314.3104328601\n",
      "dev set\n",
      "[1.00149983 0.99782111 1.00040434 1.00009156 1.00138853 1.00074043\n",
      " 1.0020152  1.00063854 1.00178696 1.00097366 0.99951759 1.00099249\n",
      " 0.99950768 1.00111164 1.00073517 1.00074942]\n",
      "[[1.11777736 0.81453733 1.00956369 1.00062431 1.10659143 1.0413873\n",
      "  1.16949078 1.03123609 1.14660247 1.06483417 0.98388893 1.06673029\n",
      "  0.98269693 1.07873116 1.04086003 1.04228694]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 242314.31012373348\n",
      "dev set\n",
      "[1.00161186 0.99771278 1.00051693 1.00017812 1.00150095 1.00085577\n",
      " 1.00212582 1.00075401 1.00189813 1.00108796 0.99940864 1.00110669\n",
      " 0.99940021 1.00122525 1.00085052 1.00086473]\n",
      "[[1.11787389 0.81464769 1.00957135 1.00062442 1.10668413 1.04142706\n",
      "  1.16959613 1.03126409 1.14670519 1.06489959 0.98400234 1.0667975\n",
      "  0.98280857 1.07880843 1.04089917 1.04232776]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 242314.30979153627\n",
      "dev set\n",
      "[1.00172712 0.99760308 1.00063601 1.00028061 1.00161679 1.00097588\n",
      " 1.00223902 1.00087453 1.00201213 1.00120648 0.99929737 1.00122508\n",
      " 0.99929039 1.0013428  1.00097065 1.00098478]\n",
      "[[1.11797767 0.8147605  1.00958747 1.00062509 1.10678502 1.04148209\n",
      "  1.16970613 1.03130667 1.14681345 1.0649784  0.98412067 1.06687784\n",
      "  0.98292502 1.07889715 1.04095357 1.04238385]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 141237.36777369303\n",
      "dev set\n",
      "[0.60112151 0.59808849 0.60004187 0.59995247 0.60111754 0.60046714\n",
      " 0.60174595 0.6003659  0.60140963 0.60059351 0.59978199 0.60071995\n",
      " 0.5997701  0.60083957 0.60046185 0.60047609]\n",
      "[[1.11759856 0.81426819 1.00961338 1.00067808 1.10632411 1.04128479\n",
      "  1.16915207 1.03115401 1.14638846 1.06477703 0.98362432 1.06656042\n",
      "  0.98243553 1.07852783 1.04075872 1.04218237]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 141236.57326536922\n",
      "dev set\n",
      "[0.6010676  0.59803502 0.59998828 0.59989881 0.60117118 0.60052079\n",
      " 0.60179978 0.60041962 0.60135605 0.60053993 0.5997284  0.60077367\n",
      " 0.59971651 0.60089322 0.60051545 0.60052969]\n",
      "[[1.11765245 0.81432167 1.00966698 1.00073174 1.10627046 1.04123114\n",
      "  1.16909818 1.03110024 1.14644209 1.06483064 0.98367784 1.06650697\n",
      "  0.98248906 1.07847418 1.04070509 1.04212874]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "2 loss 141235.77940848982\n",
      "dev set\n",
      "[0.60101369 0.59798155 0.59993469 0.59984515 0.60122481 0.60057441\n",
      " 0.60185361 0.60047334 0.60130248 0.60048635 0.59967482 0.60082739\n",
      " 0.59966293 0.60094684 0.60056904 0.60058328]\n",
      "[[1.11770634 0.81437514 1.00972056 1.0007854  1.10621682 1.0411775\n",
      "  1.16904429 1.03104648 1.14649571 1.06488425 0.98373135 1.06645354\n",
      "  0.98254259 1.07842054 1.04065147 1.04207511]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "3 loss 141234.98512999952\n",
      "dev set\n",
      "[0.60095978 0.59792808 0.59988111 0.59979149 0.60127844 0.60062804\n",
      " 0.60190743 0.60052705 0.60124891 0.60043277 0.59962123 0.60088111\n",
      " 0.59960934 0.60100047 0.60062264 0.60063688]\n",
      "[[1.11776024 0.81442861 1.00977416 1.00083905 1.10616318 1.04112387\n",
      "  1.1689904  1.03099272 1.14654934 1.06493786 0.98378486 1.06640011\n",
      "  0.98259612 1.07836691 1.04059784 1.04202149]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 141234.19031644007\n",
      "dev set\n",
      "[0.60090586 0.59787461 0.59982752 0.59973783 0.60133206 0.60068165\n",
      " 0.60196125 0.60058076 0.60119532 0.60037918 0.59956764 0.60093485\n",
      " 0.59955574 0.60105408 0.60067624 0.60069048]\n",
      "[[1.11781414 0.8144821  1.00982775 1.00089272 1.10610955 1.04107024\n",
      "  1.16893652 1.03093897 1.14660299 1.06499148 0.98383839 1.06634667\n",
      "  0.98264966 1.07831328 1.04054421 1.04196785]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 141501.9115323114\n",
      "dev set\n",
      "[0.70112151 0.69808853 0.70004192 0.69995252 0.70111753 0.70046712\n",
      " 0.70174595 0.7003659  0.70140973 0.70059364 0.6997821  0.70071968\n",
      " 0.69977022 0.70083955 0.70046178 0.70047602]\n",
      "[[1.11759855 0.81426815 1.00961333 1.00067803 1.10632412 1.04128482\n",
      "  1.16915206 1.031154   1.14638846 1.06477704 0.98362414 1.06656043\n",
      "  0.98243539 1.07852786 1.04075877 1.04218242]]\n",
      "{0: 618, 1: 1254}\n",
      "acc 0.452991452991453\n",
      "(0.18740031897926634, 0.9791666666666666, 0.31459170013386883, None)\n",
      "\n",
      "1 loss 141501.54742188164\n",
      "dev set\n",
      "[0.70106761 0.6980351  0.69998841 0.69989893 0.70117116 0.70052073\n",
      " 0.70179979 0.70041963 0.70135631 0.70054024 0.6997287  0.70077298\n",
      " 0.69971682 0.70089316 0.70051527 0.70052951]\n",
      "[[1.11765244 0.81432159 1.00966685 1.00073162 1.10627049 1.04123122\n",
      "  1.16909816 1.03110022 1.14644209 1.06483065 0.98367739 1.06650701\n",
      "  0.98248871 1.07847426 1.04070522 1.04212886]]\n",
      "{0: 617, 1: 1255}\n",
      "acc 0.45245726495726496\n",
      "(0.18725099601593626, 0.9791666666666666, 0.31438127090301005, None)\n",
      "\n",
      "2 loss 141501.18344517532\n",
      "dev set\n",
      "[0.7010137  0.69798168 0.69993491 0.69984536 0.70122478 0.70057432\n",
      " 0.70185362 0.70047336 0.70130289 0.70048686 0.6996753  0.70082626\n",
      " 0.69966342 0.70094676 0.70056875 0.70058299]\n",
      "[[1.11770633 0.81437501 1.00972036 1.00078521 1.10621687 1.04117763\n",
      "  1.16904426 1.03104645 1.14649572 1.06488427 0.98373062 1.06645361\n",
      "  0.98254201 1.07842067 1.04065166 1.04207531]]\n",
      "{0: 616, 1: 1256}\n",
      "acc 0.4519230769230769\n",
      "(0.18710191082802546, 0.9791666666666666, 0.3141711229946524, None)\n",
      "\n",
      "3 loss 141500.81894087984\n",
      "dev set\n",
      "[0.70095979 0.69792826 0.6998814  0.69979177 0.70127839 0.70062791\n",
      " 0.70190746 0.70052708 0.70124946 0.70043346 0.69962189 0.70087954\n",
      " 0.69961002 0.70100034 0.70062224 0.70063648]\n",
      "[[1.11776023 0.81442845 1.00977388 1.00083879 1.10616325 1.04112405\n",
      "  1.16899036 1.03099268 1.14654937 1.0649379  0.98378386 1.06640021\n",
      "  0.98259533 1.07836709 1.0405981  1.04202174]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n",
      "4 loss 141500.45383990134\n",
      "dev set\n",
      "[0.70090588 0.69787482 0.69982789 0.69973818 0.701332   0.70068149\n",
      " 0.70196129 0.70058079 0.70119601 0.70038005 0.69956846 0.70093283\n",
      " 0.69955658 0.70105393 0.70067575 0.70068999]\n",
      "[[1.11781413 0.81448189 1.00982741 1.00089239 1.10610963 1.04107048\n",
      "  1.16893647 1.03093892 1.14660303 1.06499155 0.98383712 1.0663468\n",
      "  0.98264867 1.07831351 1.04054452 1.04196816]]\n",
      "{0: 613, 1: 1259}\n",
      "acc 0.45032051282051283\n",
      "(0.18665607625099284, 0.9791666666666666, 0.3135423615743829, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 141588.74793425016\n",
      "dev set\n",
      "[0.80112153 0.79808861 0.80004207 0.7999526  0.80111749 0.80046709\n",
      " 0.80174592 0.8003659  0.80140987 0.80059315 0.79978353 0.80071972\n",
      " 0.79977134 0.80083952 0.80044697 0.80046124]\n",
      "[[1.11759854 0.81426808 1.0096132  1.00067795 1.10632417 1.04128486\n",
      "  1.16915209 1.031154   1.14638859 1.06477734 0.98362395 1.06656042\n",
      "  0.98243292 1.0785279  1.04086651 1.04229015]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "1 loss 141588.67913142435\n",
      "dev set\n",
      "[0.80106765 0.7980353  0.79998879 0.79989914 0.80117106 0.80052065\n",
      " 0.80179972 0.80041964 0.80135666 0.80053915 0.79973237 0.8007731\n",
      " 0.79971969 0.80089309 0.8004777  0.80049204]\n",
      "[[1.1176524  0.8143214  1.0096665  1.00073143 1.10627063 1.04123134\n",
      "  1.16909824 1.03110021 1.14644242 1.06483138 0.98367688 1.06650698\n",
      "  0.98248236 1.07847437 1.04092053 1.04234418]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "2 loss 141588.61060431847\n",
      "dev set\n",
      "[0.80101377 0.79798202 0.79993552 0.79984569 0.80122462 0.8005742\n",
      " 0.80185352 0.80047336 0.80130344 0.80048515 0.79968137 0.80082645\n",
      " 0.79966812 0.80094663 0.80050698 0.80052139]\n",
      "[[1.11770627 0.8143747  1.0097198  1.00078489 1.10621709 1.04117783\n",
      "  1.16904438 1.03104644 1.14649626 1.06488542 0.98372977 1.06645356\n",
      "  0.98253156 1.07842086 1.04097453 1.04239818]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "3 loss 141588.5420070762\n",
      "dev set\n",
      "[0.80095988 0.79792872 0.79988225 0.79979224 0.80127817 0.80062773\n",
      " 0.80190731 0.80052709 0.80125018 0.80043117 0.79963041 0.8008798\n",
      " 0.79961651 0.80100017 0.80053599 0.80055046]\n",
      "[[1.11776015 0.81442801 1.0097731  1.00083836 1.10616356 1.04112432\n",
      "  1.16899052 1.03099267 1.14655011 1.06493947 0.98378266 1.06640014\n",
      "  0.98258073 1.07836735 1.0410285  1.04245214]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "4 loss 141588.47328766045\n",
      "dev set\n",
      "[0.80090598 0.79787541 0.79982897 0.79973878 0.80133172 0.80068126\n",
      " 0.8019611  0.8005808  0.80119686 0.80037719 0.79957947 0.80093316\n",
      " 0.79956485 0.80105371 0.80056515 0.80057969]\n",
      "[[1.11781404 0.81448134 1.00982641 1.00089184 1.10611004 1.04107083\n",
      "  1.16893667 1.03093891 1.14660399 1.06499353 0.98383555 1.06634673\n",
      "  0.98262993 1.07831385 1.04108243 1.04250607]]\n",
      "{0: 960, 1: 912}\n",
      "acc 0.6079059829059829\n",
      "(0.22916666666666666, 0.8708333333333333, 0.3628472222222222, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 141643.53593191737\n",
      "dev set\n",
      "[0.90112159 0.89808875 0.90004213 0.89995268 0.90111738 0.90046718\n",
      " 0.90174597 0.90036598 0.90140926 0.90059324 0.89978243 0.90071974\n",
      " 0.89980118 0.90083961 0.90035411 0.90036834]\n",
      "[[1.11759849 0.81426794 1.00961313 1.00067787 1.10632433 1.04128473\n",
      "  1.16915204 1.03115389 1.14638875 1.06477726 0.98362403 1.0665603\n",
      "  0.98243219 1.07852777 1.04086635 1.04228999]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 141643.49809006782\n",
      "dev set\n",
      "[0.90106779 0.89803567 0.89998894 0.89989934 0.90117078 0.90052088\n",
      " 0.90179984 0.90041984 0.90135521 0.90053926 0.89972954 0.90077313\n",
      " 0.89979927 0.9008933  0.90030009 0.90031433]\n",
      "[[1.11765228 0.81432103 1.00966634 1.00073122 1.10627102 1.04123101\n",
      "  1.1690981  1.03109995 1.14644278 1.06483119 0.9836771  1.06650669\n",
      "  0.98248047 1.07847405 1.04092017 1.04234382]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 141643.46030988474\n",
      "dev set\n",
      "[0.90101399 0.89798263 0.89993578 0.89984603 0.90122416 0.90057456\n",
      " 0.90185371 0.90047369 0.90130116 0.90048527 0.8996767  0.90082651\n",
      " 0.89980103 0.90094699 0.90024607 0.90026031]\n",
      "[[1.11770607 0.81437409 1.00971953 1.00078456 1.10621773 1.04117729\n",
      "  1.16904416 1.03104602 1.14649683 1.06488513 0.98373014 1.06645308\n",
      "  0.98252837 1.07842034 1.040974   1.04239764]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 141643.42251590214\n",
      "dev set\n",
      "[0.90096019 0.89792958 0.89988261 0.8997927  0.90127754 0.90062824\n",
      " 0.90190758 0.90052753 0.90124711 0.90043129 0.89962387 0.90087988\n",
      " 0.89980429 0.90100066 0.90019204 0.90020628]\n",
      "[[1.11775988 0.81442716 1.00977272 1.0008379  1.10616445 1.04112358\n",
      "  1.16899022 1.0309921  1.14655088 1.06493908 0.98378318 1.06639949\n",
      "  0.98257613 1.07836663 1.04102783 1.04245147]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 141643.38470010308\n",
      "dev set\n",
      "[0.90090638 0.89787654 0.89982944 0.89973938 0.90133092 0.90068191\n",
      " 0.90196145 0.90058136 0.90119306 0.90037731 0.89957104 0.90093324\n",
      " 0.89980834 0.90105433 0.900138   0.90015224]\n",
      "[[1.11781369 0.81448023 1.00982592 1.00089125 1.10611117 1.04106988\n",
      "  1.16893628 1.03093819 1.14660494 1.06499303 0.98383622 1.0663459\n",
      "  0.98262382 1.07831293 1.04108167 1.04250532]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall penalty\n",
      "0 loss 141674.31104878703\n",
      "dev set\n",
      "[1.00122927 0.99808841 1.00014685 1.00000976 1.00111761 1.0004672\n",
      " 1.00174587 1.00036581 1.00151716 1.00070107 0.99978236 1.00071998\n",
      " 0.99977031 1.00083965 1.00046193 1.00047617]\n",
      "[[1.11758189 0.81426829 1.00955973 1.00062431 1.10641144 1.04134324\n",
      "  1.16925307 1.03120999 1.14637863 1.0647377  0.98362326 1.06662938\n",
      "  0.98243468 1.07860295 1.040817   1.04224109]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 141674.3109175712\n",
      "dev set\n",
      "[1.00128314 0.99803477 1.00019822 1.00001877 1.00117149 1.00052117\n",
      " 1.00179968 1.00041971 1.001571   1.00075504 0.9997293  1.00077394\n",
      " 0.99971696 1.00089359 1.0005159  1.00053015]\n",
      "[[1.11762428 0.81432201 1.00955997 1.00062431 1.10645089 1.04135134\n",
      "  1.16930252 1.03121408 1.14642591 1.06475853 0.98367603 1.06665129\n",
      "  0.98248776 1.07863133 1.04082486 1.04224961]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 141674.31078173517\n",
      "dev set\n",
      "[1.00133729 0.99798101 1.00024983 1.00003922 1.00122568 1.00057558\n",
      " 1.0018537  1.00047402 1.00162507 1.0008094  0.99967608 1.00082829\n",
      " 0.99966341 1.00094789 1.00057031 1.00058456]\n",
      "[[1.11766942 0.81437594 1.00956057 1.00062431 1.10649361 1.04136291\n",
      "  1.16935323 1.03122047 1.14647494 1.06478423 0.98372926 1.06667808\n",
      "  0.98254134 1.07866433 1.04083613 1.04226169]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 141674.31064087703\n",
      "dev set\n",
      "[1.00139184 0.9979271  1.00030218 1.0000719  1.00128029 1.00063061\n",
      " 1.00190803 1.00052894 1.00167948 1.00086431 0.99962259 1.00088319\n",
      " 0.99960953 1.00100269 1.00062534 1.00063959]\n",
      "[[1.11771659 0.81443015 1.0095618  1.00062431 1.10653877 1.04137821\n",
      "  1.16940494 1.03122968 1.14652531 1.06481413 0.98378315 1.06670901\n",
      "  0.9825956  1.07870101 1.04085109 1.04227757]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 141674.31049478636\n",
      "dev set\n",
      "[1.00144689 0.99787297 1.00035562 1.00011142 1.00133544 1.00068641\n",
      " 1.00196275 1.00058468 1.00173433 1.00091991 0.99956872 1.00093877\n",
      " 0.99955523 1.00105813 1.00068115 1.0006954 ]\n",
      "[[1.11776551 0.81448474 1.00956407 1.00062433 1.10658599 1.04139747\n",
      "  1.16945758 1.0312422  1.14657686 1.06484785 0.98383787 1.06674368\n",
      "  0.9826507  1.07874088 1.04087    1.04229745]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = np.empty([len(LF_l)],dtype=np.float64)\n",
    "acc.fill(0.25)\n",
    "rec =  np.empty([len(LF_l)],dtype=np.float64)\n",
    "rec.fill(0.85*train_L_S.shape[0])\n",
    "print(rec)\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [64,128,256,512,1024,2048]:\n",
    "    for i in np.linspace(0.6,1,5):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = acc ,LF_rec = rec,\\\n",
    "                                    pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=6,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295.\n",
      " 1295. 1295. 1295. 1295.]\n",
      "batch-size: 64 alpha-init: 0.6\n",
      "precision and recall penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 1249128.694508861\n",
      "dev set\n",
      "[0.59966419 0.59662467 0.59861625 0.59852027 0.60260125 0.60197537\n",
      " 0.60325263 0.60187818 0.5999139  0.59909635 0.59828474 0.60192126\n",
      " 0.59827266 0.60234796 0.60196187 0.60197611]\n",
      "[[1.11906896 0.81573464 1.01104918 1.00212258 1.10485234 1.03977548\n",
      "  1.16764946 1.02963845 1.14787911 1.06627299 0.98509706 1.06512126\n",
      "  0.98392353 1.07701838 1.03926376 1.0406874 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "1 loss 1249105.3682796431\n",
      "dev set\n",
      "[0.59817455 0.5950781  0.59712625 0.59703653 0.60412528 0.60350861\n",
      " 0.6047882  0.60341265 0.59833777 0.59751978 0.59670813 0.60320008\n",
      " 0.59669131 0.60388211 0.60353535 0.60354959]\n",
      "[[1.1205784  0.81728596 1.01255367 1.00362401 1.10333518 1.03823884\n",
      "  1.16611921 1.0281014  1.14945499 1.0678478  0.98666937 1.06359619\n",
      "  0.9855036  1.07548098 1.03769335 1.039117  ]]\n",
      "{0: 268, 1: 1604}\n",
      "acc 0.2702991452991453\n",
      "(0.14900249376558602, 0.9958333333333333, 0.2592190889370933, None)\n",
      "\n",
      "2 loss 1249081.426079442\n",
      "dev set\n",
      "[0.59669196 0.59351834 0.59563232 0.59555281 0.60562886 0.60501396\n",
      " 0.6062999  0.60491653 0.596742   0.59592375 0.59511208 0.60453402\n",
      " 0.59508655 0.60538913 0.6051234  0.60513764]\n",
      "[[1.12208691 0.81885316 1.01406664 1.00513095 1.10183377 1.03672599\n",
      "  1.16461034 1.02659214 1.15105354 1.06944698 0.98826811 1.06205709\n",
      "  0.98711233 1.07396686 1.03610935 1.03753299]]\n",
      "{0: 249, 1: 1623}\n",
      "acc 0.26121794871794873\n",
      "(0.1478743068391867, 1.0, 0.2576489533011272, None)\n",
      "\n",
      "3 loss 1249056.891022919\n",
      "dev set\n",
      "[0.59521227 0.59194816 0.5941349  0.59406955 0.60711142 0.60649175\n",
      " 0.6077903  0.60639119 0.59512796 0.59431007 0.59349839 0.60588697\n",
      " 0.59346058 0.60686934 0.60672449 0.60673873]\n",
      "[[1.12359826 0.82043344 1.01558756 1.00664289 1.10034852 1.03523593\n",
      "  1.16311902 1.025108   1.15267287 1.07106869 0.98989021 1.06050739\n",
      "  0.9887465  1.07247505 1.03451351 1.03593716]]\n",
      "{0: 237, 1: 1635}\n",
      "acc 0.2548076923076923\n",
      "(0.14678899082568808, 1.0, 0.256, None)\n",
      "\n",
      "4 loss 1249031.7699155451\n",
      "dev set\n",
      "[0.5937343  0.59036873 0.59263431 0.59258705 0.60857287 0.60794201\n",
      " 0.60926033 0.60783701 0.59349749 0.59267976 0.59186817 0.6072616\n",
      " 0.59181482 0.60832281 0.60833772 0.60835196]\n",
      "[[1.12511343 0.82202558 1.017116   1.00815944 1.09887933 1.03376816\n",
      "  1.16164381 1.02364793 1.15431184 1.07271179 0.99153418 1.05894852\n",
      "  0.99040434 1.07100507 1.03290686 1.03433052]]\n",
      "{0: 221, 1: 1651}\n",
      "acc 0.24626068376068377\n",
      "(0.145366444579043, 1.0, 0.2538339502908514, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.7\n",
      "precision and recall penalty\n",
      "0 loss 1249399.3163817802\n",
      "dev set\n",
      "[0.69966524 0.69663719 0.69863909 0.69852092 0.70259612 0.70197004\n",
      " 0.70325423 0.7018766  0.69995961 0.69913804 0.69832823 0.70212646\n",
      " 0.69832134 0.70234282 0.70193074 0.70194499]\n",
      "[[1.11906753 0.81572306 1.01102781 1.00212092 1.10486333 1.03978456\n",
      "  1.16764937 1.02964163 1.14783636 1.06619375 0.98496898 1.06509765\n",
      "  0.98386592 1.0770271  1.03931086 1.04073449]]\n",
      "{0: 598, 1: 1274}\n",
      "acc 0.4423076923076923\n",
      "(0.18445839874411302, 0.9791666666666666, 0.3104359313077939, None)\n",
      "\n",
      "1 loss 1249388.5127967314\n",
      "dev set\n",
      "[0.69816929 0.69508922 0.69715591 0.69702864 0.70411728 0.70350065\n",
      " 0.70479059 0.70340833 0.69838978 0.69756919 0.69675276 0.70361833\n",
      " 0.69674683 0.70387445 0.7035001  0.70351435]\n",
      "[[1.12058188 0.81727704 1.01252651 1.00362931 1.10335548 1.03825557\n",
      "  1.16612264 1.02811293 1.14939582 1.06769375 0.98647202 1.06356344\n",
      "  0.98543294 1.07549704 1.0377479  1.03917153]]\n",
      "{0: 572, 1: 1300}\n",
      "acc 0.4284188034188034\n",
      "(0.18076923076923077, 0.9791666666666666, 0.3051948051948052, None)\n",
      "\n",
      "2 loss 1249377.003776552\n",
      "dev set\n",
      "[0.69666875 0.69351508 0.69565434 0.69552614 0.70562091 0.70500435\n",
      " 0.70630537 0.70490943 0.69677339 0.6959535  0.69512101 0.70512686\n",
      " 0.69511848 0.70537983 0.70510845 0.7051227 ]\n",
      "[[1.12210592 0.81886029 1.01404766 1.00515273 1.10186087 1.03675063\n",
      "  1.16461583 1.02661406 1.15100213 1.06924455 0.98803524 1.0620232\n",
      "  0.9870626  1.07399059 1.03614319 1.03756682]]\n",
      "{0: 533, 1: 1339}\n",
      "acc 0.4075854700854701\n",
      "(0.1755041075429425, 0.9791666666666666, 0.2976567447751741, None)\n",
      "\n",
      "3 loss 1249364.7923701734\n",
      "dev set\n",
      "[0.6951594  0.69191795 0.6941362  0.69401403 0.70710647 0.70648124\n",
      " 0.70780171 0.70638142 0.69511428 0.6942959  0.69345017 0.70664902\n",
      " 0.69344211 0.70685908 0.7067519  0.70676614]\n",
      "[[1.1236435  0.82046961 1.01558937 1.00669049 1.10037987 1.03526888\n",
      "  1.1631242  1.02514186 1.15265227 1.07084477 0.9896527  1.0604789\n",
      "  0.98874732 1.07250694 1.03450203 1.03592568]]\n",
      "{0: 509, 1: 1363}\n",
      "acc 0.39476495726495725\n",
      "(0.1724137931034483, 0.9791666666666666, 0.2932002495321273, None)\n",
      "\n",
      "4 loss 1249351.862499967\n",
      "dev set\n",
      "[0.69364027 0.69029943 0.69260251 0.6924928  0.7085739  0.70793129\n",
      " 0.70928078 0.70782471 0.69341382 0.69259419 0.69174013 0.70819174\n",
      " 0.691722   0.70831218 0.70842547 0.7084397 ]\n",
      "[[1.12519542 0.82210335 1.01715054 1.00824201 1.09891236 1.03380986\n",
      "  1.161646   1.0236951  1.154344   1.07249322 0.99132145 1.05893143\n",
      "  0.99048253 1.0710456  1.03282805 1.03425171]]\n",
      "{0: 495, 1: 1377}\n",
      "acc 0.3872863247863248\n",
      "(0.17066085693536673, 0.9791666666666666, 0.29066171923314776, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.8\n",
      "precision and recall penalty\n",
      "0 loss 1249490.281676954\n",
      "dev set\n",
      "[0.79970891 0.79670209 0.79873039 0.79854274 0.80256898 0.80195897\n",
      " 0.80324822 0.80187144 0.80054132 0.80019748 0.79913242 0.80213306\n",
      " 0.79892545 0.80233221 0.8007008  0.80071565]\n",
      "[[1.11902997 0.81566317 1.01094482 1.00210082 1.10491492 1.03980584\n",
      "  1.16766401 1.02965237 1.14756262 1.06554427 0.98432277 1.0650929\n",
      "  0.9831955  1.07704745 1.04195932 1.04338279]]\n",
      "{0: 943, 1: 929}\n",
      "acc 0.5998931623931624\n",
      "(0.22604951560818085, 0.875, 0.35928143712574856, None)\n",
      "\n",
      "1 loss 1249488.506018662\n",
      "dev set\n",
      "[0.79825865 0.79522425 0.79733375 0.79707751 0.80406643 0.80348062\n",
      " 0.80477586 0.80339643 0.79958575 0.79977849 0.79839169 0.80361993\n",
      " 0.79818753 0.80385529 0.80108131 0.8010968 ]\n",
      "[[1.12050464 0.81715363 1.01236677 1.00358489 1.10345715 1.03830309\n",
      "  1.16616124 1.02814473 1.14881931 1.06631777 0.98511267 1.06356611\n",
      "  0.984057   1.07554241 1.04302761 1.04445091]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "2 loss 1249486.682021631\n",
      "dev set\n",
      "[0.79680052 0.7937178  0.79591291 0.79560109 0.80555125 0.80497782\n",
      " 0.80628483 0.80489272 0.79854664 0.79936385 0.79763837 0.80511016\n",
      " 0.79739612 0.80535439 0.80161739 0.80163348]\n",
      "[[1.1219928  0.81867707 1.01381763 1.00508577 1.10200909 1.03682573\n",
      "  1.16467783 1.02666929 1.15011392 1.06709643 0.98591254 1.06204383\n",
      "  0.9850233  1.07406246 1.04399151 1.04541463]]\n",
      "{0: 931, 1: 941}\n",
      "acc 0.593482905982906\n",
      "(0.22316684378320936, 0.875, 0.35563082133784935, None)\n",
      "\n",
      "3 loss 1249484.7690446463\n",
      "dev set\n",
      "[0.79532828 0.79218198 0.79446898 0.79411219 0.80702275 0.80645106\n",
      " 0.8077793  0.80636225 0.79746271 0.79895068 0.79687766 0.80660193\n",
      " 0.79643791 0.80682997 0.80233245 0.80234909]\n",
      "[[1.12350032 0.82023416 1.01529622 1.00660459 1.10057151 1.0353722\n",
      "  1.16320753 1.02522208 1.15145101 1.0678837  0.98672086 1.06052749\n",
      "  0.98609469 1.0726061  1.0448331  1.04625602]]\n",
      "{0: 921, 1: 951}\n",
      "acc 0.5881410256410257\n",
      "(0.22082018927444794, 0.875, 0.3526448362720403, None)\n",
      "\n",
      "4 loss 1249482.7324975193\n",
      "dev set\n",
      "[0.79383871 0.79061441 0.79300066 0.79260946 0.80848117 0.8079006\n",
      " 0.80926123 0.80780567 0.79626467 0.79853716 0.79608938 0.80809488\n",
      " 0.79534446 0.80828229 0.80324004 0.80325718]\n",
      "[[1.12503017 0.82182717 1.01680367 1.00814251 1.09914395 1.03394152\n",
      "  1.16174749 1.02380149 1.15283562 1.06868208 0.98753866 1.0590173\n",
      "  0.98727749 1.07117239 1.04552674 1.04694944]]\n",
      "{0: 905, 1: 967}\n",
      "acc 0.5806623931623932\n",
      "(0.21820062047569805, 0.8791666666666667, 0.3496271748135874, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.9\n",
      "precision and recall penalty\n",
      "0 loss 1249545.4385579545\n",
      "dev set\n",
      "[0.89972466 0.8967279  0.89876662 0.89855737 0.90242613 0.90194002\n",
      " 0.90319373 0.90186583 0.90036381 0.89975274 0.8990155  0.90215953\n",
      " 0.89973098 0.90231425 0.89895799 0.89897227]\n",
      "[[1.11900822 0.81563604 1.0109024  1.00208236 1.10512247 1.03985044\n",
      "  1.16776291 1.02966953 1.14761058 1.06576263 0.98452443 1.06506401\n",
      "  0.98299902 1.07709003 1.04234771 1.04377135]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 1249544.450272091\n",
      "dev set\n",
      "[0.89829558 0.89529817 0.8974117  0.8970978  0.90379912 0.90339646\n",
      " 0.90465101 0.90334266 0.89924821 0.89890411 0.89817109 0.90364231\n",
      " 0.89976149 0.90377473 0.89757531 0.89758963]\n",
      "[[1.12045966 0.81708164 1.01228002 1.00356061 1.1038561  1.03847942\n",
      "  1.16638376 1.02825904 1.14889482 1.06675641 0.98551947 1.06353646\n",
      "  0.9835368  1.07571192 1.04386445 1.04528809]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 1249543.4740057117\n",
      "dev set\n",
      "[0.89686406 0.89385673 0.89604093 0.89562726 0.90517051 0.90481634\n",
      " 0.90609142 0.90477846 0.89812447 0.89806577 0.89732951 0.90512769\n",
      " 0.89978738 0.90519908 0.89621025 0.89622462]\n",
      "[[1.12192346 0.81854792 1.01368241 1.00505982 1.10258779 1.0371544\n",
      "  1.16502353 1.02690233 1.15019124 1.06774913 0.98652237 1.06203516\n",
      "  0.98408554 1.07437959 1.04539245 1.04681608]]\n",
      "{0: 1096, 1: 776}\n",
      "acc 0.6677350427350427\n",
      "(0.2538659793814433, 0.8208333333333333, 0.38779527559055116, None)\n",
      "\n",
      "3 loss 1249542.4784437558\n",
      "dev set\n",
      "[0.89542646 0.89240643 0.89465887 0.89414737 0.9065363  0.90620549\n",
      " 0.90752081 0.90617928 0.89699219 0.89723578 0.89649407 0.90659887\n",
      " 0.89980941 0.90659292 0.89481121 0.89482563]\n",
      "[[1.12340291 0.82003181 1.01510485 1.0065781  1.10132288 1.03586569\n",
      "  1.16367465 1.02558889 1.15150136 1.06874282 0.98752949 1.06056064\n",
      "  0.98463906 1.07308365 1.04693481 1.04835845]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "4 loss 1249541.460301198\n",
      "dev set\n",
      "[0.89398218 0.89094882 0.89326764 0.8926591  0.90789539 0.90756633\n",
      " 0.90894118 0.90754761 0.89585191 0.89641399 0.89566597 0.90807125\n",
      " 0.89982898 0.9079586  0.89338331 0.89339778]\n",
      "[[1.1248983  0.82153146 1.01654503 1.0081142  1.10006312 1.03460945\n",
      "  1.16233492 1.0243145  1.15282505 1.06973751 0.98853938 1.05911265\n",
      "  0.98519451 1.07182034 1.04849352 1.04991715]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 1.0\n",
      "precision and recall penalty\n",
      "0 loss 1249576.6964133803\n",
      "dev set\n",
      "[1.00305598 0.99647517 1.00199261 1.00039344 1.00295804 1.00239262\n",
      " 1.00351744 1.00229625 1.0033113  1.00259897 0.99848276 1.00261527\n",
      " 0.99836835 1.00271785 1.00238779 1.00240082]\n",
      "[[1.11852217 0.81598904 1.00979612 1.00062455 1.10728357 1.04180935\n",
      "  1.17046742 1.03161318 1.14748172 1.06534819 0.98506938 1.06725167\n",
      "  0.98395453 1.07930037 1.04127988 1.04271273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 1249576.686921431\n",
      "dev set\n",
      "[1.00567548 0.9944544  1.00490842 1.00354568 1.00560324 1.00520036\n",
      " 1.00601612 1.00513088 1.0058628  1.00534892 0.99676473 1.0053605\n",
      " 0.9965413  1.00543188 1.0051969  1.00520625]\n",
      "[[1.12113552 0.81836702 1.01218445 1.00184676 1.10989332 1.04433805\n",
      "  1.17306254 1.03411415 1.15009049 1.06792288 0.98718251 1.06982909\n",
      "  0.98620547 1.08189123 1.04380729 1.04524358]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 1249576.668464207\n",
      "dev set\n",
      "[1.00866845 0.99220837 1.00811029 1.00707847 1.00861404 1.00832349\n",
      " 1.00891335 1.00827273 1.00880396 1.00843332 0.9948757  1.00844169\n",
      " 0.99453501 1.00849094 1.00832096 1.00832777]\n",
      "[[1.1244219  0.82110507 1.01561253 1.0053989  1.11319322 1.04771633\n",
      "  1.17627342 1.03750452 1.15333664 1.07127534 0.98954896 1.07317933\n",
      "  0.98871919 1.08522604 1.04718618 1.04862081]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 1249576.6387549\n",
      "dev set\n",
      "[1.01181602 0.98983847 1.01139457 1.01059181 1.01177215 1.01155449\n",
      " 1.01199511 1.01151601 1.01191698 1.01164037 0.99291671 1.01164665\n",
      " 0.99245855 1.01168039 1.01155258 1.01155774]\n",
      "[[1.12795602 0.82402912 1.01926915 1.00925875 1.11673748 1.05132576\n",
      "  1.17974805 1.04112489 1.15683932 1.07486287 0.99201587 1.076765\n",
      "  0.9913324  1.08879841 1.05079616 1.05222932]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 1249576.5961448408\n",
      "dev set\n",
      "[1.01502559 0.98740124 1.01469657 1.0140513  1.0149872  1.01481852\n",
      " 1.01515847 1.01478836 1.01510322 1.01488988 0.99093225 1.01489476\n",
      " 0.99035783 1.01491643 1.01481702 1.01482106]\n",
      "[[1.13159203 0.82704919 1.02299371 1.01313789 1.12037964 1.05501461\n",
      "  1.18334083 1.0448217  1.16045304 1.07853693 0.99451941 1.08043773\n",
      "  0.99397984 1.09246056 1.0544854  1.05591749]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.6\n",
      "precision and recall penalty\n",
      "0 loss 648124.4154424588\n",
      "dev set\n",
      "[0.60039562 0.59737345 0.59933317 0.59924291 0.60183893 0.60119658\n",
      " 0.60247399 0.60109617 0.60068538 0.59986868 0.5990571  0.60136648\n",
      " 0.59904548 0.60156903 0.6011875  0.60120173]\n",
      "[[1.11832616 0.81498387 1.01032437 1.00139064 1.10560648 1.04055511\n",
      "  1.16842537 1.03042301 1.14711073 1.06550213 0.98434062 1.06585009\n",
      "  0.98315676 1.07779813 1.04003465 1.04145829]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "1 loss 648112.7974379167\n",
      "dev set\n",
      "[0.59961943 0.59659728 0.59856808 0.59847948 0.60261288 0.60197391\n",
      " 0.60325292 0.60187481 0.59990139 0.59908443 0.59827279 0.60207496\n",
      " 0.59826037 0.60234652 0.60197131 0.60198554]\n",
      "[[1.11910556 0.81576107 1.01109273 1.00215807 1.10483459 1.03977703\n",
      "  1.16764749 1.02964339 1.14789442 1.06628631 0.98512218 1.06507838\n",
      "  0.98394004 1.07701992 1.03925155 1.04067519]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "2 loss 648101.025417937\n",
      "dev set\n",
      "[0.59884659 0.595817   0.597802   0.59771613 0.60338228 0.60274441\n",
      " 0.60402548 0.6026457  0.59911207 0.59829491 0.59748324 0.60279187\n",
      " 0.59746897 0.60311736 0.6027591  0.60277333]\n",
      "[[1.11988332 0.81654303 1.01186325 1.00292682 1.104066   1.03900491\n",
      "  1.16687565 1.0288711  1.14868415 1.06707699 0.98591115 1.06430239\n",
      "  0.98473122 1.07624754 1.03846466 1.0398883 ]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "3 loss 648089.1040025995\n",
      "dev set\n",
      "[0.59807521 0.59503355 0.59703492 0.59695284 0.60414662 0.60350799\n",
      " 0.60479237 0.6034091  0.59831784 0.59750054 0.59668881 0.60351613\n",
      " 0.59667168 0.60388147 0.60355052 0.60356475]\n",
      "[[1.12066117 0.81732883 1.01263592 1.00369692 1.10330122 1.03823867\n",
      "  1.1661087  1.02810549 1.14947954 1.06787379 0.98670664 1.0635232\n",
      "  0.98552952 1.07548092 1.03767439 1.03909804]]\n",
      "{0: 267, 1: 1605}\n",
      "acc 0.26976495726495725\n",
      "(0.14890965732087227, 0.9958333333333333, 0.25907859078590784, None)\n",
      "\n",
      "4 loss 648077.0334337776\n",
      "dev set\n",
      "[0.59730456 0.59424735 0.59626689 0.5961896  0.60490579 0.60426469\n",
      " 0.60555396 0.60416521 0.59751899 0.59670155 0.59588979 0.60426146\n",
      " 0.5958688  0.60463888 0.60434535 0.60435959]\n",
      "[[1.12143978 0.81811809 1.01341071 1.00446834 1.10254037 1.03747818\n",
      "  1.1653461  1.0273462  1.15028034 1.06867645 0.98750821 1.06274132\n",
      "  0.9863345  1.07471993 1.03688098 1.03830463]]\n",
      "{0: 262, 1: 1610}\n",
      "acc 0.2670940170940171\n",
      "(0.1484472049689441, 0.9958333333333333, 0.25837837837837835, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.7\n",
      "precision and recall penalty\n",
      "0 loss 648391.9122170213\n",
      "dev set\n",
      "[0.70039506 0.69737726 0.6993397  0.69924172 0.70183793 0.70119485\n",
      " 0.70247463 0.7010955  0.70069793 0.69988049 0.69907069 0.70142461\n",
      " 0.69905931 0.70156736 0.70117924 0.70119348]\n",
      "[[1.1183267  0.8149803  1.01031828 1.00139142 1.10560877 1.04055792\n",
      "  1.16842485 1.03042414 1.14709825 1.06548425 0.98429825 1.06584442\n",
      "  0.9831392  1.07780083 1.04004807 1.04147171]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "1 loss 648386.5599751585\n",
      "dev set\n",
      "[0.69961803 0.69660117 0.69857803 0.69847565 0.7026109  0.70197116\n",
      " 0.70325383 0.70187343 0.69991716 0.69910035 0.69829017 0.70218911\n",
      " 0.69827818 0.70234387 0.70196149 0.70197573]\n",
      "[[1.11910689 0.8157577  1.01108361 1.00216105 1.10483952 1.03978214\n",
      "  1.16764766 1.02964648 1.14787662 1.06625172 0.9850547  1.06507046\n",
      "  0.98391536 1.07702483 1.03926923 1.04069287]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "2 loss 648381.0380018526\n",
      "dev set\n",
      "[0.69884163 0.69581761 0.69781132 0.69770699 0.70337999 0.70274093\n",
      " 0.70402704 0.70264356 0.69912292 0.69830745 0.69749602 0.70295846\n",
      " 0.69748212 0.70311401 0.70275214 0.70276638]\n",
      "[[1.11988791 0.81654332 1.011855   1.00293447 1.104073   1.03901231\n",
      "  1.16687638 1.02887668 1.14866729 1.06703248 0.9858282  1.06429436\n",
      "  0.98470912 1.07625465 1.03847882 1.03990246]]\n",
      "{0: 582, 1: 1290}\n",
      "acc 0.4337606837606838\n",
      "(0.1821705426356589, 0.9791666666666666, 0.30718954248366015, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 648375.3450635042\n",
      "dev set\n",
      "[0.69806376 0.69502756 0.69704001 0.69693575 0.70414473 0.703504\n",
      " 0.70479523 0.70340623 0.69831636 0.69750284 0.6966877  0.70373176\n",
      " 0.69667247 0.7038776  0.70355254 0.70356678]\n",
      "[[1.12067176 0.81733622 1.01263207 1.00371173 1.10330967 1.03824842\n",
      "  1.1661095  1.02811396 1.14946976 1.06782621 0.98661658 1.06351688\n",
      "  0.98551854 1.07549032 1.03767792 1.03910156]]\n",
      "{0: 571, 1: 1301}\n",
      "acc 0.42788461538461536\n",
      "(0.180630284396618, 0.9791666666666666, 0.30499675535366644, None)\n",
      "\n",
      "4 loss 648369.4702328773\n",
      "dev set\n",
      "[0.69728363 0.69423146 0.69626433 0.69616196 0.70490503 0.70426035\n",
      " 0.70555883 0.70416164 0.69749868 0.69668732 0.69586403 0.7045086\n",
      " 0.69585006 0.70463464 0.70436237 0.7043766 ]\n",
      "[[1.12145915 0.81813597 1.01341457 1.00449279 1.10254961 1.03749041\n",
      "  1.16534634 1.02735789 1.15028367 1.0686326  0.98741898 1.06273832\n",
      "  0.98634253 1.07473177 1.03686726 1.03829091]]\n",
      "{0: 557, 1: 1315}\n",
      "acc 0.4204059829059829\n",
      "(0.17870722433460076, 0.9791666666666666, 0.30225080385852093, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.8\n",
      "precision and recall penalty\n",
      "0 loss 648480.7580454674\n",
      "dev set\n",
      "[0.80040207 0.79739169 0.79936897 0.79924479 0.80183301 0.8011914\n",
      " 0.80247449 0.80109371 0.80087044 0.80035574 0.79937508 0.80142219\n",
      " 0.7992465  0.80156405 0.8006763  0.80069097]\n",
      "[[1.11832104 0.81496706 1.0102919  1.00138862 1.10561867 1.04056417\n",
      "  1.16842574 1.03042743 1.14701687 1.065214   0.98402245 1.06584363\n",
      "  0.98290528 1.07780681 1.04144554 1.04286912]]\n",
      "{0: 956, 1: 916}\n",
      "acc 0.6057692307692307\n",
      "(0.22816593886462883, 0.8708333333333333, 0.3615916955017301, None)\n",
      "\n",
      "1 loss 648479.8148222407\n",
      "dev set\n",
      "[0.79963543 0.79662965 0.79863462 0.79848396 0.80259989 0.80196487\n",
      " 0.80325259 0.80186944 0.8002707  0.80006554 0.79891018 0.80218458\n",
      " 0.79867231 0.80233786 0.80089708 0.80091222]\n",
      "[[1.11909255 0.81573192 1.01103319 1.00215363 1.10486202 1.03979549\n",
      "  1.16765214 1.02965537 1.1477111  1.06569712 0.98448727 1.06507122\n",
      "  0.98342573 1.07703755 1.04209255 1.04351607]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "2 loss 648478.8629182038\n",
      "dev set\n",
      "[0.79886871 0.79585909 0.79789239 0.79771999 0.80336398 0.80273238\n",
      " 0.80402536 0.80263778 0.79964226 0.79977637 0.79843691 0.80294871\n",
      " 0.7982015  0.80310583 0.8011831  0.80119868]\n",
      "[[1.11986582 0.8165064  1.01178352 1.00292323 1.10410741 1.03903304\n",
      "  1.16688443 1.02889179 1.14841575 1.06618238 0.98495787 1.06429919\n",
      "  0.98398602 1.07627444 1.04270872 1.04413217]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "3 loss 648477.8913713162\n",
      "dev set\n",
      "[0.7980993  0.79508039 0.7971433  0.79695265 0.80412471 0.80349367\n",
      " 0.80479389 0.803399   0.79898415 0.79948789 0.79795915 0.80371379\n",
      " 0.79769164 0.80386768 0.80153397 0.80154998]\n",
      "[[1.12064334 0.81729016 1.01254197 1.00369769 1.10335537 1.03827685\n",
      "  1.16612081 1.02813583 1.14913183 1.06667053 0.98543219 1.0635283\n",
      "  0.98458218 1.07551753 1.04329266 1.04471604]]\n",
      "{0: 939, 1: 933}\n",
      "acc 0.5977564102564102\n",
      "(0.22508038585209003, 0.875, 0.35805626598465473, None)\n",
      "\n",
      "4 loss 648476.8893895672\n",
      "dev set\n",
      "[0.79732592 0.79429333 0.79638746 0.79618167 0.80488202 0.80424872\n",
      " 0.80555879 0.80415334 0.79830725 0.79919954 0.79747795 0.80447954\n",
      " 0.79712004 0.80462342 0.80195837 0.80197476]\n",
      "[[1.1214263  0.81808343 1.01330841 1.00447725 1.10260599 1.0375268\n",
      "  1.16536034 1.02738702 1.14986044 1.0671621  0.98590985 1.06275878\n",
      "  0.98521356 1.07476669 1.04384055 1.04526385]]\n",
      "{0: 930, 1: 942}\n",
      "acc 0.592948717948718\n",
      "(0.2229299363057325, 0.875, 0.35532994923857875, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.9\n",
      "precision and recall penalty\n",
      "0 loss 648535.7356940376\n",
      "dev set\n",
      "[0.9004065  0.89739652 0.89938176 0.89925088 0.9017991  0.9011867\n",
      " 0.90246517 0.90109246 0.90084223 0.90011286 0.89935561 0.90142955\n",
      " 0.89967573 0.90155962 0.89964376 0.89965801]\n",
      "[[1.11831582 0.81496179 1.01027743 1.00138171 1.10567118 1.04057602\n",
      "  1.16844345 1.03043158 1.14702809 1.06532465 0.98411295 1.06583455\n",
      "  0.98279683 1.07781805 1.04159326 1.0430169 ]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 648535.2130763008\n",
      "dev set\n",
      "[0.89964736 0.8966462  0.89866074 0.89849417 0.90253231 0.90194538\n",
      " 0.90322904 0.90185761 0.90020359 0.8995807  0.89887147 0.90219219\n",
      " 0.89969579 0.90231934 0.89889409 0.89890834]\n",
      "[[1.11907977 0.81571565 1.01100447 1.00214258 1.10496968 1.03984024\n",
      "  1.16769733 1.02968264 1.14773287 1.06592011 0.98466639 1.06505949\n",
      "  0.98315667 1.07708023 1.04236371 1.04378735]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 648534.6874674385\n",
      "dev set\n",
      "[0.89888979 0.89589183 0.89793378 0.89773401 0.90326584 0.90269431\n",
      " 0.90398763 0.9026118  0.89956355 0.89905172 0.8983861  0.90295217\n",
      " 0.8997182  0.90306945 0.89815278 0.89816406]\n",
      "[[1.11984501 0.81647598 1.01173989 1.00290954 1.10426696 1.03911733\n",
      "  1.1669579  1.02894854 1.14844026 1.06651556 0.98522433 1.06429069\n",
      "  0.98352512 1.07635514 1.04313703 1.04456067]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "3 loss 648534.1708412064\n",
      "dev set\n",
      "[0.89813144 0.89513433 0.89720258 0.89697088 0.90399836 0.90343487\n",
      " 0.90474292 0.90335653 0.89892144 0.8985252  0.89790151 0.90371498\n",
      " 0.89973893 0.90381126 0.89744605 0.89745735]\n",
      "[[1.12061387 0.81724194 1.01248206 1.00368217 1.10356466 1.03840471\n",
      "  1.16622221 1.02822647 1.14915139 1.0671119  0.98578477 1.06352856\n",
      "  0.98389904 1.07564033 1.04391391 1.04533757]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 648533.6542091925\n",
      "dev set\n",
      "[0.89737132 0.89437393 0.89646773 0.89620495 0.90472948 0.90416772\n",
      " 0.90549585 0.90409249 0.8982768  0.89800081 0.89741831 0.90447562\n",
      " 0.89975723 0.9045454  0.89673236 0.89674547]\n",
      "[[1.12138724 0.81801327 1.0132304  1.00446028 1.10286331 1.03770126\n",
      "  1.16548901 1.0275152  1.14986676 1.06770949 0.98634709 1.06277327\n",
      "  0.98427673 1.07493469 1.04469411 1.04611777]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 1.0\n",
      "precision and recall penalty\n",
      "0 loss 648566.7599835811\n",
      "dev set\n",
      "[1.00201359 0.99734458 1.00088108 1.00004839 1.0019049  1.00127123\n",
      " 1.00251906 1.00116737 1.00229477 1.00150093 0.99914592 1.00151928\n",
      " 0.99909686 1.00163526 1.00126595 1.00128022]\n",
      "[[1.11791412 0.81503111 1.00957676 1.00062431 1.10670237 1.04142232\n",
      "  1.16975205 1.03126654 1.14681051 1.06488128 0.9842928  1.06677891\n",
      "  0.98312258 1.0787924  1.04089483 1.04232233]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 648566.7569130805\n",
      "dev set\n",
      "[1.00305772 0.99645682 1.00204848 1.00099521 1.00296016 1.00240165\n",
      " 1.00351827 1.00230951 1.00331241 1.00260367 0.99833208 1.00261977\n",
      " 0.99825557 1.00272136 1.00239698 1.00240958]\n",
      "[[1.118794   0.81600684 1.00997554 1.0006487  1.10755814 1.0420359\n",
      "  1.17069588 1.03182509 1.14773409 1.06560326 0.98524273 1.0675086\n",
      "  0.98410468 1.07956713 1.04150569 1.04294053]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 648566.7521002085\n",
      "dev set\n",
      "[1.004299   0.99547598 1.00343926 1.00248223 1.00421504 1.00374204\n",
      " 1.00469881 1.0036636  1.004519   1.00391349 0.99741655 1.00392709\n",
      " 0.99730783 1.00401241 1.00373807 1.00374877]\n",
      "[[1.1200506  0.81714275 1.01112732 1.00129591 1.10881515 1.0432589\n",
      "  1.17193477 1.03303373 1.14898329 1.06684824 0.98636006 1.06875477\n",
      "  0.98525759 1.08081898 1.04272803 1.04416462]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 648566.7451122454\n",
      "dev set\n",
      "[1.00567756 0.99442171 1.00495125 1.00411927 1.00560592 1.00520813\n",
      " 1.0060178  1.00514178 1.00586438 1.00535321 0.99643438 1.00536464\n",
      " 0.99629199 1.00543559 1.00520478 1.00521382]\n",
      "[[1.12153186 0.81840009 1.01266365 1.00277924 1.1103039  1.04478364\n",
      "  1.1733746  1.03456234 1.15044244 1.06836265 0.98757914 1.0702682\n",
      "  0.98651363 1.08232541 1.04425299 1.045689  ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 648566.7356084513\n",
      "dev set\n",
      "[1.00714536 0.99331241 1.00652894 1.00580936 1.00708379 1.00674752\n",
      " 1.00743369 1.00669108 1.00730382 1.00687136 0.99540994 1.00688102\n",
      " 0.99523384 1.00694003 1.00674467 1.00675235]\n",
      "[[1.12314746 0.81974503 1.01435943 1.0045387  1.11192759 1.04645318\n",
      "  1.17494725 1.03623882 1.15203489 1.07001683 0.98886052 1.07192109\n",
      "  0.98783219 1.08396949 1.04592288 1.04735793]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.6\n",
      "precision and recall penalty\n",
      "0 loss 357989.688577729\n",
      "dev set\n",
      "[0.60076946 0.5977431  0.59969381 0.59961021 0.60146613 0.60081777\n",
      " 0.60209597 0.60071671 0.60106089 0.6002446  0.59943306 0.60104369\n",
      " 0.59942127 0.6011902  0.60081102 0.60082526]\n",
      "[[1.11795067 0.81461379 1.00996168 1.00102149 1.10597633 1.04093407\n",
      "  1.16880253 1.03080299 1.14673646 1.06512615 0.98397079 1.06621567\n",
      "  0.9827831  1.07817711 1.04041018 1.04183383]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "1 loss 357983.7530726813\n",
      "dev set\n",
      "[0.60036758 0.59734681 0.59929454 0.59921849 0.60186385 0.60121639\n",
      " 0.60249522 0.60111649 0.60066172 0.5998453  0.59903374 0.60142254\n",
      " 0.59902186 0.60158884 0.6012103  0.60122453]\n",
      "[[1.11835277 0.81501033 1.01036123 1.0014144  1.10557904 1.04053529\n",
      "  1.16840373 1.03040265 1.14713552 1.06552494 0.9843689  1.065819\n",
      "  0.9831814  1.07777831 1.04001116 1.0414348 ]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "2 loss 357977.7983114064\n",
      "dev set\n",
      "[0.59996633 0.59694928 0.5988946  0.59882664 0.60226081 0.6016137\n",
      " 0.60289319 0.6015148  0.60026111 0.59944459 0.59863302 0.60180468\n",
      " 0.59862081 0.60198621 0.6016107  0.60162493]\n",
      "[[1.11875462 0.81540826 1.01076169 1.00180773 1.10518226 1.04013766\n",
      "  1.16800621 1.03000368 1.1475362  1.06592532 0.98476898 1.06542084\n",
      "  0.98358173 1.07738063 1.03961103 1.04103467]]\n",
      "{0: 274, 1: 1598}\n",
      "acc 0.27350427350427353\n",
      "(0.14956195244055068, 0.9958333333333333, 0.2600652883569097, None)\n",
      "\n",
      "3 loss 357971.8007914691\n",
      "dev set\n",
      "[0.5995653  0.59655051 0.59849395 0.59843449 0.60265686 0.60200961\n",
      " 0.60328996 0.60191158 0.59985887 0.59904226 0.59823068 0.60218962\n",
      " 0.59821787 0.60238224 0.60201239 0.60202662]\n",
      "[[1.11915664 0.81580759 1.01116313 1.0022017  1.10478606 1.03974119\n",
      "  1.16760977 1.02960609 1.14793869 1.06632759 0.98517113 1.06502135\n",
      "  0.98398429 1.07698409 1.03920966 1.0406333 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "4 loss 357965.75994999404\n",
      "dev set\n",
      "[0.59916436 0.59615066 0.59809272 0.5980421  0.60305186 0.60240399\n",
      " 0.60368551 0.60230671 0.59945509 0.5986384  0.59782681 0.602577\n",
      " 0.59781314 0.60277677 0.60241528 0.60242952]\n",
      "[[1.119559   0.81620818 1.01156546 1.00259627 1.10439062 1.039346\n",
      "  1.16721434 1.02920994 1.14834292 1.0667317  0.98557521 1.06462076\n",
      "  0.98438895 1.07658879 1.03880715 1.04023079]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.7\n",
      "precision and recall penalty\n",
      "0 loss 358255.6218131361\n",
      "dev set\n",
      "[0.70077002 0.69774433 0.69969605 0.69960929 0.70146621 0.70081733\n",
      " 0.70209617 0.7007165  0.70106488 0.70024853 0.69943766 0.70106274\n",
      " 0.69942577 0.70118977 0.70080838 0.70082262]\n",
      "[[1.11795025 0.81461263 1.00995962 1.0010222  1.10597633 1.04093478\n",
      "  1.16880235 1.03080333 1.14673261 1.06512267 0.98395925 1.06621389\n",
      "  0.98277647 1.07817779 1.04041486 1.0418385 ]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "1 loss 358252.89730300894\n",
      "dev set\n",
      "[0.70036833 0.69734867 0.69929869 0.69921673 0.70186394 0.70121569\n",
      " 0.70249537 0.70111602 0.70066767 0.69985174 0.699041   0.70145722\n",
      " 0.69902886 0.70158817 0.7012065  0.70122074]\n",
      "[[1.11835226 0.81500863 1.01035743 1.00141579 1.10557921 1.04053651\n",
      "  1.16840398 1.03040356 1.14712989 1.06551644 0.98434889 1.06581663\n",
      "  0.98317044 1.07777948 1.04001818 1.04144182]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "2 loss 358250.1390475651\n",
      "dev set\n",
      "[0.69996664 0.69695102 0.69889972 0.69882348 0.70226104 0.70161283\n",
      " 0.70289332 0.70151406 0.70026704 0.69945178 0.69864093 0.7018533\n",
      " 0.69862822 0.70198538 0.70160726 0.7016215 ]\n",
      "[[1.11875459 0.81540677 1.01075706 1.00181033 1.10518247 1.04013935\n",
      "  1.16800694 1.03000528 1.14753028 1.06591309 0.98474272 1.0654185\n",
      "  0.98356879 1.07738226 1.03961845 1.04104209]]\n",
      "{0: 605, 1: 1267}\n",
      "acc 0.44604700854700857\n",
      "(0.18547750591949486, 0.9791666666666666, 0.31187790311877905, None)\n",
      "\n",
      "3 loss 358247.3347866935\n",
      "dev set\n",
      "[0.69956443 0.6965513  0.69849907 0.69842926 0.70265743 0.70200864\n",
      " 0.7032902  0.70191056 0.69986275 0.6990482  0.69823732 0.70225093\n",
      " 0.69822359 0.7023813  0.70201086 0.7020251 ]\n",
      "[[1.1191578  0.81580719 1.01115862 1.00220614 1.10478618 1.03974334\n",
      "  1.1676109  1.02960848 1.1479341  1.06631326 0.98514075 1.06501956\n",
      "  0.98397172 1.07698616 1.03921552 1.04063917]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "4 loss 358244.4862826984\n",
      "dev set\n",
      "[0.69916151 0.69614963 0.69809688 0.69803412 0.70305293 0.70240297\n",
      " 0.70368603 0.70230541 0.69945493 0.69864147 0.69783018 0.70264988\n",
      " 0.69781509 0.70277578 0.7024164  0.70243064]\n",
      "[[1.11956206 0.81620975 1.01156199 1.00260319 1.10439047 1.03934863\n",
      "  1.16721575 1.02921323 1.14834127 1.06671698 0.98554279 1.06461999\n",
      "  0.98437902 1.07659134 1.03880955 1.04023319]]\n",
      "{0: 590, 1: 1282}\n",
      "acc 0.43803418803418803\n",
      "(0.18330733229329174, 0.9791666666666666, 0.3088042049934297, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.8\n",
      "precision and recall penalty\n",
      "0 loss 358343.40178878605\n",
      "dev set\n",
      "[0.80077363 0.79774795 0.79970489 0.79960891 0.8014655  0.80081648\n",
      " 0.80209632 0.80071593 0.80110044 0.80048731 0.79954109 0.8010617\n",
      " 0.79949651 0.80118896 0.80058272 0.80059723]\n",
      "[[1.11794728 0.81460935 1.00995169 1.00102251 1.10597788 1.04093628\n",
      "  1.16880224 1.03080432 1.14671288 1.06505696 0.98388317 1.06621321\n",
      "  0.9826829  1.07817923 1.04118627 1.04260989]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "1 loss 358342.90541495814\n",
      "dev set\n",
      "[0.80037552 0.79735643 0.7993168  0.79921768 0.80186203 0.80121427\n",
      " 0.80249507 0.80111449 0.80074053 0.8002715  0.79925804 0.80145549\n",
      " 0.79916751 0.80158681 0.80071781 0.80073266]\n",
      "[[1.11834632 0.8150016  1.01034126 1.00141488 1.10558318 1.04053936\n",
      "  1.16840497 1.03040644 1.14709186 1.06536473 0.98418184 1.06581598\n",
      "  0.982973   1.0777822  1.04155854 1.04298215]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "2 loss 358342.4047735501\n",
      "dev set\n",
      "[0.79997708 0.79696265 0.7989263  0.79882573 0.80225816 0.80161097\n",
      " 0.80289267 0.8015116  0.80037303 0.80005645 0.79897287 0.80185027\n",
      " 0.79882638 0.80198359 0.80087576 0.80089093]\n",
      "[[1.11874603 0.81539635 1.01073347 1.0018083  1.10518869 1.04014352\n",
      "  1.1680091  1.03001028 1.14747385 1.06567267 0.98448039 1.06541845\n",
      "  0.98327421 1.07738625 1.04192519 1.04334879]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "3 loss 358341.8989921066\n",
      "dev set\n",
      "[0.79957771 0.79656629 0.79853337 0.79843264 0.80265384 0.80200648\n",
      " 0.80328939 0.80190722 0.79999634 0.7998418  0.79868584 0.80224583\n",
      " 0.79852884 0.80237921 0.80106255 0.80107712]\n",
      "[[1.11914709 0.81579396 1.01112839 1.00220325 1.10479447 1.03974888\n",
      "  1.16761417 1.02961575 1.1478593  1.06598152 0.98477961 1.06502077\n",
      "  0.98358739 1.07699147 1.04228442 1.04370799]]\n",
      "{0: 941, 1: 931}\n",
      "acc 0.5988247863247863\n",
      "(0.22556390977443608, 0.875, 0.35866780529462, None)\n",
      "\n",
      "4 loss 358341.39123283833\n",
      "dev set\n",
      "[0.79917717 0.79616738 0.79813819 0.79803837 0.80304887 0.8024006\n",
      " 0.80368527 0.80230125 0.79961054 0.79962745 0.79839739 0.80264199\n",
      " 0.79825405 0.80277347 0.80127696 0.80129002]\n",
      "[[1.11954972 0.81619441 1.0115259  1.00259975 1.10440068 1.03935561\n",
      "  1.16722003 1.02922292 1.14824834 1.06629145 0.98507963 1.06462309\n",
      "  0.98391181 1.07659805 1.04263529 1.04405885]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision and recall penalty\n",
      "0 loss 358398.282760186\n",
      "dev set\n",
      "[0.90077641 0.89774972 0.89970991 0.899611   0.90145631 0.90081573\n",
      " 0.90209463 0.90071554 0.90109914 0.90029144 0.89951496 0.90106535\n",
      " 0.89972317 0.90118827 0.90001182 0.90002606]\n",
      "[[1.11794436 0.81460741 1.00994638 1.00102014 1.10599284 1.04093873\n",
      "  1.16880542 1.03080553 1.14672123 1.06509568 0.98391331 1.06621072\n",
      "  0.98263787 1.07818152 1.04121648 1.04264013]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 358398.0083754707\n",
      "dev set\n",
      "[0.90038219 0.89736321 0.89932827 0.89922201 0.90184363 0.90121147\n",
      " 0.9024896  0.90111135 0.90073558 0.89995607 0.89921031 0.90146055\n",
      " 0.89972732 0.90158419 0.89961846 0.8996327 ]\n",
      "[[1.11833964 0.81499476 1.01032949 1.00141015 1.10561368 1.04054709\n",
      "  1.16841539 1.03041371 1.14710398 1.0654508  0.98424459 1.06581266\n",
      "  0.98285833 1.0777895  1.04161592 1.04303956]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 358397.73387106456\n",
      "dev set\n",
      "[0.89998808 0.89697571 0.89894482 0.89883222 0.90223139 0.90160536\n",
      " 0.90288324 0.90150479 0.90037184 0.89962169 0.8989069  0.90185555\n",
      " 0.89974004 0.90197828 0.89922459 0.89923884]\n",
      "[[1.11873544 0.81538364 1.01071494 1.00180155 1.10523381 1.04015792\n",
      "  1.1680273  1.03002527 1.1474872  1.06580577 0.98457594 1.06541576\n",
      "  0.9830799  1.07739992 1.04201628 1.04343992]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 358397.4578225396\n",
      "dev set\n",
      "[0.8995936  0.89658703 0.89855972 0.89844138 0.90261937 0.90199746\n",
      " 0.9032761  0.90189605 0.9000076  0.89928795 0.89860409 0.90225016\n",
      " 0.89975396 0.9023706  0.89882976 0.898844  ]\n",
      "[[1.11913235 0.81577433 1.0111027  1.00219467 1.10485353 1.03977102\n",
      "  1.16764027 1.02963973 1.14787148 1.06616118 0.98490791 1.06502016\n",
      "  0.98330387 1.07701261 1.04241801 1.04384165]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 358397.180103024\n",
      "dev set\n",
      "[0.89919859 0.89619731 0.89817323 0.89804957 0.9030073  0.90238772\n",
      " 0.90366834 0.90228514 0.89964272 0.89895478 0.8983018  0.90264415\n",
      " 0.89976771 0.90276109 0.89843374 0.89844799]\n",
      "[[1.11953056 0.81616672 1.01149254 1.0025895  1.10447316 1.03938638\n",
      "  1.16725399 1.02925695 1.14825702 1.06651717 0.98524053 1.06462605\n",
      "  0.98352979 1.07662755 1.04282119 1.04424483]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 1.0\n",
      "precision and recall penalty\n",
      "0 loss 358429.1786626061\n",
      "dev set\n",
      "[1.00158846 0.99773717 1.00046728 1.00002156 1.0014773  1.00082839\n",
      " 1.0021032  1.00072474 1.00187522 1.0010627  0.99945562 1.00108154\n",
      " 0.9994441  1.00120069 1.00082306 1.00083747]\n",
      "[[1.117732   0.81462268 1.00956177 1.00062431 1.10653885 1.04136403\n",
      "  1.16949167 1.03122255 1.14658253 1.06478704 0.98395225 1.06668163\n",
      "  0.98275875 1.07867547 1.04083731 1.04226273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 358429.1774255278\n",
      "dev set\n",
      "[1.00204011 0.99731829 1.00094303 1.0002612  1.00193189 1.00130426\n",
      " 1.00254401 1.00120314 1.00232031 1.00153069 0.99905332 1.00154887\n",
      " 0.99904223 1.00166385 1.00129909 1.00131307]\n",
      "[[1.118066   0.81505901 1.00960194 1.00062446 1.10685236 1.04149586\n",
      "  1.1698833  1.03132351 1.14695497 1.06499258 0.98438895 1.06689297\n",
      "  0.98319551 1.07892205 1.04096749 1.04239736]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 358429.17582593445\n",
      "dev set\n",
      "[1.00255056 0.99687388 1.00151084 1.00079332 1.00244759 1.00185612\n",
      " 1.00303401 1.00176052 1.00281858 1.00206911 0.99861522 1.00208619\n",
      " 0.99860262 1.00219425 1.00185124 1.00186442]\n",
      "[[1.11852452 0.8155406  1.00980237 1.00064265 1.10730132 1.04182201\n",
      "  1.17036292 1.03161716 1.14742887 1.06537865 0.98489371 1.06728304\n",
      "  0.98370073 1.07933467 1.04129206 1.0427262 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 358429.17378195125\n",
      "dev set\n",
      "[1.00311972 0.99640285 1.00215251 1.00145369 1.00302337 1.00247519\n",
      " 1.00357578 1.0023864  1.00337172 1.00267241 0.99814367 1.00268821\n",
      " 0.99812828 1.00278802 1.00247067 1.00248289]\n",
      "[[1.11908726 0.81606858 1.01024193 1.0008198  1.10786219 1.04233595\n",
      "  1.17092283 1.03211469 1.14799177 1.0659189  0.98545589 1.06782485\n",
      "  0.98426377 1.07988474 1.04180523 1.04324141]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 358429.1712259493\n",
      "dev set\n",
      "[1.00374041 0.99590723 1.00284947 1.00218897 1.00365118 1.00314767\n",
      " 1.00416544 1.00306592 1.00397456 1.00332889 0.99764423 1.00334337\n",
      " 0.99762541 1.00343471 1.00314351 1.00315475]\n",
      "[[1.11973228 0.81663867 1.01086331 1.00129737 1.10850946 1.04298065\n",
      "  1.17155181 1.032755   1.14862867 1.06656878 0.98606305 1.06847489\n",
      "  0.98487208 1.08053502 1.04244975 1.04388643]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6\n",
      "precision and recall penalty\n",
      "0 loss 212923.6356376834\n",
      "dev set\n",
      "[0.60096027 0.5979289  0.59988195 0.59979234 0.60127745 0.60062757\n",
      " 0.60190623 0.6005264  0.60124967 0.60043351 0.59962198 0.60087453\n",
      " 0.59961011 0.601      0.6006219  0.60063613]\n",
      "[[1.11775974 0.81442781 1.00977334 1.00083825 1.10616437 1.0411243\n",
      "  1.16899192 1.03099341 1.14654838 1.064937   0.98378384 1.06640104\n",
      "  0.98259542 1.07836735 1.0405987  1.04202234]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 212920.52020049206\n",
      "dev set\n",
      "[0.60075139 0.597722   0.59967409 0.59958652 0.6014846  0.60083498\n",
      " 0.60211407 0.60073439 0.60104224 0.60022605 0.59941452 0.60107971\n",
      " 0.59940263 0.60120741 0.60082936 0.60084359]\n",
      "[[1.11796858 0.81463475 1.00998123 1.00104428 1.10595733 1.04091686\n",
      "  1.16878409 1.03078516 1.14675593 1.06514408 0.98399099 1.06619355\n",
      "  0.98280267 1.0781599  1.04039121 1.04181486]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "2 loss 212917.44175454677\n",
      "dev set\n",
      "[0.60054325 0.59751558 0.59946668 0.59938162 0.60169094 0.60104146\n",
      " 0.60232105 0.6009415  0.60083522 0.60001899 0.59920746 0.60128534\n",
      " 0.59919552 0.6014139  0.60103636 0.60105059]\n",
      "[[1.11817675 0.81484125 1.01018871 1.00124946 1.10575105 1.0407103\n",
      "  1.1685771  1.03057776 1.14696312 1.06535073 0.98419784 1.06598635\n",
      "  0.9830096  1.07795334 1.04018421 1.04160785]]\n",
      "{0: 280, 1: 1592}\n",
      "acc 0.2767094017094017\n",
      "(0.15012562814070352, 0.9958333333333333, 0.2609170305676856, None)\n",
      "\n",
      "3 loss 212914.35956750787\n",
      "dev set\n",
      "[0.60033526 0.59730903 0.59925921 0.59917689 0.60189698 0.60124754\n",
      " 0.60252767 0.60114819 0.60062797 0.59981171 0.59900018 0.60149166\n",
      " 0.59898813 0.60162    0.60124351 0.60125774]\n",
      "[[1.11838485 0.81504791 1.0103963  1.00145454 1.10554499 1.0405041\n",
      "  1.16837045 1.03037073 1.14717056 1.06555764 0.984405   1.06577895\n",
      "  0.98321686 1.07774713 1.03997706 1.0414007 ]]\n",
      "{0: 278, 1: 1594}\n",
      "acc 0.27564102564102566\n",
      "(0.14993726474278546, 0.9958333333333333, 0.2606324972737186, None)\n",
      "\n",
      "4 loss 212911.26755785878\n",
      "dev set\n",
      "[0.60012727 0.5971022  0.59905154 0.59897216 0.60210282 0.60145331\n",
      " 0.60273404 0.60135454 0.60042034 0.59960405 0.59879251 0.60169871\n",
      " 0.59878029 0.6018258  0.60145097 0.6014652 ]\n",
      "[[1.11859305 0.81525488 1.01060415 1.00165972 1.10533907 1.04029817\n",
      "  1.168164   1.03016399 1.14737843 1.065765   0.98461264 1.06557122\n",
      "  0.98342464 1.07754117 1.03976962 1.04119326]]\n",
      "{0: 275, 1: 1597}\n",
      "acc 0.27403846153846156\n",
      "(0.14965560425798372, 0.9958333333333333, 0.26020685900925417, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7\n",
      "precision and recall penalty\n",
      "0 loss 213188.78584261215\n",
      "dev set\n",
      "[0.70096017 0.6979291  0.69988255 0.6997928  0.70127755 0.70062746\n",
      " 0.70190631 0.70052635 0.70125037 0.70043408 0.69962264 0.70087881\n",
      " 0.69961094 0.70099989 0.70062143 0.70063567]\n",
      "[[1.11775985 0.81442762 1.00977278 1.00083785 1.10616422 1.04112449\n",
      "  1.16899183 1.0309935  1.14654808 1.06493565 0.9837815  1.06640084\n",
      "  0.98259474 1.07836753 1.0405993  1.04202295]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 213187.355134262\n",
      "dev set\n",
      "[0.70075118 0.69772254 0.69967552 0.69958717 0.70148481 0.7008348\n",
      " 0.70211423 0.70073425 0.70104329 0.70022714 0.69941578 0.70108584\n",
      " 0.69940403 0.70120723 0.70082866 0.70084289]\n",
      "[[1.11796882 0.81463425 1.0099799  1.00104371 1.10595702 1.04091717\n",
      "  1.16878393 1.03078538 1.14675563 1.06514048 0.98398623 1.06619361\n",
      "  0.98280133 1.0781602  1.0403922  1.04181585]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "2 loss 213185.93578361443\n",
      "dev set\n",
      "[0.70054281 0.69751635 0.69946881 0.69938229 0.7016913  0.70104124\n",
      " 0.7023213  0.70094127 0.70083627 0.7000203  0.699209   0.7012926\n",
      " 0.69919711 0.70141369 0.7010357  0.70104994]\n",
      "[[1.11817722 0.81484054 1.01018673 1.00124887 1.10575052 1.04071072\n",
      "  1.16857688 1.03057813 1.14696307 1.06534504 0.98419098 1.06598683\n",
      "  0.98300798 1.07795374 1.04018525 1.0416089 ]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "3 loss 213184.50866243968\n",
      "dev set\n",
      "[0.70033445 0.69730988 0.69926184 0.69917743 0.70189754 0.7012473\n",
      " 0.70252805 0.70114787 0.70062861 0.69981296 0.6990016  0.70149961\n",
      " 0.69898948 0.70161976 0.70124322 0.70125746]\n",
      "[[1.11838569 0.81504715 1.01039387 1.00145408 1.10554423 1.04050463\n",
      "  1.16837012 1.03037128 1.1471711  1.06555016 0.98439645 1.06577996\n",
      "  0.98321543 1.07774763 1.03997778 1.04140142]]\n",
      "{0: 608, 1: 1264}\n",
      "acc 0.44764957264957267\n",
      "(0.18591772151898733, 0.9791666666666666, 0.3125, None)\n",
      "\n",
      "4 loss 213183.0704946703\n",
      "dev set\n",
      "[0.70012591 0.69710293 0.69905445 0.69897239 0.70210362 0.70145305\n",
      " 0.70273459 0.70135414 0.70042009 0.69960486 0.69879336 0.701707\n",
      " 0.69878092 0.70182554 0.70145142 0.70146566]\n",
      "[[1.11859442 0.81525428 1.01060149 1.00165956 1.10533802 1.0402988\n",
      "  1.16816354 1.03016474 1.14737992 1.06575611 0.98460286 1.06557289\n",
      "  0.98342392 1.07754178 1.03976956 1.04119321]]\n",
      "{0: 606, 1: 1266}\n",
      "acc 0.4465811965811966\n",
      "(0.18562401263823064, 0.9791666666666666, 0.31208499335989376, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "precision and recall penalty\n",
      "0 loss 213276.03741319955\n",
      "dev set\n",
      "[0.80096077 0.79792991 0.79988473 0.7997941  0.8012775  0.80062722\n",
      " 0.80190634 0.80052619 0.80125368 0.80054342 0.79965421 0.80087838\n",
      " 0.79962035 0.80099966 0.80054776 0.80056215]\n",
      "[[1.11775938 0.81442688 1.00977082 1.00083669 1.10616436 1.04112493\n",
      "  1.16899179 1.03099375 1.1465465  1.06491415 0.9837553  1.06640076\n",
      "  0.98258169 1.07836795 1.04102759 1.04245123]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "1 loss 213275.77069773903\n",
      "dev set\n",
      "[0.80075258 0.79772499 0.79968058 0.79959001 0.80148462 0.8008344\n",
      " 0.80211422 0.80073378 0.80104948 0.80040665 0.79948907 0.80108499\n",
      " 0.79942382 0.80120686 0.80065011 0.80066473]\n",
      "[[1.11796769 0.81463199 1.00997533 1.00104117 1.1059574  1.04091795\n",
      "  1.16878395 1.03078613 1.14675176 1.06509138 0.98392086 1.06619365\n",
      "  0.9827651  1.07816094 1.04123525 1.04265889]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "2 loss 213275.50685496067\n",
      "dev set\n",
      "[0.80054493 0.79752048 0.79947666 0.79938661 0.80169103 0.80104072\n",
      " 0.80232129 0.80094046 0.80084418 0.8002704  0.79932542 0.80129122\n",
      " 0.79922553 0.8014132  0.80075729 0.80077214]\n",
      "[[1.11817554 0.81483674 1.01017965 1.00124501 1.1057511  1.04071184\n",
      "  1.16857693 1.03057942 1.14695684 1.06526799 0.98408431 1.0659871\n",
      "  0.98294881 1.0779548  1.04144104 1.04286468]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "3 loss 213275.24113601126\n",
      "dev set\n",
      "[0.80033718 0.7973156  0.79927233 0.79918316 0.80189725 0.80124668\n",
      " 0.80252809 0.80114674 0.8006369  0.80013434 0.79916197 0.80149756\n",
      " 0.79902442 0.80161917 0.80087396 0.80088902]\n",
      "[[1.11838356 0.81504192 1.01038445 1.00144898 1.10554493 1.04050608\n",
      "  1.16837017 1.03037314 1.1471625  1.06544469 0.98424721 1.0657806\n",
      "  0.9831348  1.07774902 1.0416451  1.04306874]]\n",
      "{0: 950, 1: 922}\n",
      "acc 0.6036324786324786\n",
      "(0.227765726681128, 0.875, 0.3614457831325302, None)\n",
      "\n",
      "4 loss 213274.97261996384\n",
      "dev set\n",
      "[0.80012911 0.79711009 0.79906739 0.79897945 0.80210338 0.80145235\n",
      " 0.80273474 0.8013527  0.80042706 0.79999832 0.79899837 0.8017041\n",
      " 0.79882008 0.80182488 0.80100173 0.80101698]\n",
      "[[1.11859199 0.81524779 1.01058993 1.00165332 1.1053388  1.04030061\n",
      "  1.16816354 1.0301672  1.14736902 1.06562168 0.98441001 1.06557405\n",
      "  0.98332373 1.07754351 1.04184725 1.04327089]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "precision and recall penalty\n",
      "0 loss 213330.86945282377\n",
      "dev set\n",
      "[0.90096201 0.8979306  0.89988606 0.89979506 0.90127578 0.90062728\n",
      " 0.90190594 0.90052617 0.90125689 0.90044858 0.89965151 0.90087923\n",
      " 0.89973801 0.90099973 0.90019261 0.90020685]\n",
      "[[1.1177582  0.81442617 1.00976943 1.00083567 1.10616716 1.04112513\n",
      "  1.16899258 1.0309939  1.14654589 1.0649273  0.98376353 1.06640012\n",
      "  0.98255893 1.07836812 1.04102728 1.04245093]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 213330.7230604717\n",
      "dev set\n",
      "[0.90075537 0.89772763 0.89968379 0.89959182 0.90148109 0.90083435\n",
      " 0.90211319 0.90073326 0.90105826 0.90026013 0.89948565 0.90108612\n",
      " 0.89973505 0.90120682 0.89998409 0.89999833]\n",
      "[[1.11796506 0.81462934 1.00997205 1.0010392  1.10596322 1.04091871\n",
      "  1.16878595 1.03078727 1.14674991 1.0651217  0.98394144 1.06619281\n",
      "  0.98270909 1.07816163 1.04123581 1.04265945]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 213330.57888450427\n",
      "dev set\n",
      "[0.90054935 0.89752545 0.89948192 0.89938926 0.90168585 0.90104042\n",
      " 0.90231961 0.90093927 0.90086039 0.90007232 0.89932203 0.90129236\n",
      " 0.89974093 0.90141292 0.8997762  0.89979044]\n",
      "[[1.11817141 0.81483184 1.01017436 1.00124216 1.10575975 1.04071337\n",
      "  1.1685802  1.03058185 1.1469533  1.06531549 0.98411769 1.06598637\n",
      "  0.98285643 1.07795624 1.04144386 1.04286751]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 213330.4346803226\n",
      "dev set\n",
      "[0.90034338 0.89732326 0.89927982 0.89918667 0.9018906  0.901246\n",
      " 0.9025258  0.90114473 0.90066264 0.89988469 0.89915921 0.90149845\n",
      " 0.89974948 0.90161853 0.89956826 0.8995825 ]\n",
      "[[1.11837787 0.81503447 1.01037705 1.0014453  1.10555623 1.04050862\n",
      "  1.16837471 1.03037712 1.14715675 1.0655093  0.98429352 1.06578031\n",
      "  0.98300335 1.07775142 1.0416521  1.04307575]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 213330.2901201872\n",
      "dev set\n",
      "[0.90013727 0.89712085 0.89907734 0.89898386 0.90209541 0.90145118\n",
      " 0.90273191 0.90134974 0.90046481 0.89969713 0.8989968  0.90170447\n",
      " 0.89975892 0.90182376 0.89936007 0.8993743 ]\n",
      "[[1.11858465 0.81523748 1.01058029 1.00164882 1.10535258 1.04030436\n",
      "  1.16816931 1.03017297 1.14736048 1.06570331 0.9844693  1.06557455\n",
      "  0.98315047 1.07754709 1.04186071 1.04328436]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "precision and recall penalty\n",
      "0 loss 213361.69929375686\n",
      "dev set\n",
      "[1.00139093 0.99792788 1.00028993 1.00001511 1.00127934 1.00062862\n",
      " 1.00190725 1.00052625 1.00167865 1.00086299 0.99963091 1.0008819\n",
      " 0.99961536 1.00100155 1.00062333 1.00063765]\n",
      "[[1.11765598 0.8144293  1.00956014 1.00062431 1.10647395 1.04135092\n",
      "  1.16936892 1.03121411 1.1464788  1.06475933 0.98377169 1.06665251\n",
      "  0.98258387 1.07863668 1.04082446 1.04224915]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 213361.69871806965\n",
      "dev set\n",
      "[1.00160795 0.99771676 1.00050363 1.00008088 1.00149698 1.00085065\n",
      " 1.00212211 1.00074824 1.00189435 1.00108352 0.99942983 1.00110229\n",
      " 0.99941157 1.00122103 1.00084538 1.00085965]\n",
      "[[1.117812   0.81464357 1.00956523 1.00062431 1.10661777 1.04138975\n",
      "  1.16955828 1.03123884 1.14665722 1.06483822 0.98397802 1.0667348\n",
      "  0.98279313 1.07874    1.04086249 1.04228936]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 213361.6980663713\n",
      "dev set\n",
      "[1.00183684 0.99750108 1.00074284 1.00026389 1.00172718 1.00109064\n",
      " 1.00234625 1.00098934 1.00212035 1.00131984 0.99922132 1.0013383\n",
      " 0.99919978 1.00145511 1.00108543 1.00109951]\n",
      "[[1.1180018  0.81486655 1.00958875 1.00062461 1.10679919 1.04147337\n",
      "  1.16976866 1.03130212 1.14686128 1.06496652 0.98420207 1.06686634\n",
      "  0.98302032 1.07889027 1.04094504 1.04237479]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 213361.69732003802\n",
      "dev set\n",
      "[1.0020809  0.99727903 1.00100826 1.00050728 1.00197327 1.0013515\n",
      " 1.00258275 1.00125235 1.00235984 1.00157511 0.99900328 1.00159311\n",
      " 0.99897778 1.00170707 1.00134642 1.00136017]\n",
      "[[1.11822277 0.81510102 1.00965584 1.00062959 1.10701506 1.04161446\n",
      "  1.17000038 1.03142254 1.14709014 1.06514557 0.98444548 1.06704785\n",
      "  0.98326729 1.07908545 1.04108513 1.0425176 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 213361.69646623702\n",
      "dev set\n",
      "[1.00234142 0.99704986 1.00129821 1.000792   1.00223645 1.00163337\n",
      " 1.00283306 1.00153709 1.00261425 1.00184996 0.99877525 1.00186739\n",
      " 0.9987451  1.00197778 1.00162843 1.00164177]\n",
      "[[1.11847286 0.81534816 1.00978967 1.0006588  1.10726263 1.04181403\n",
      "  1.17025362 1.03160619 1.14734322 1.06537131 0.98470759 1.06727517\n",
      "  0.98353345 1.07932126 1.04128395 1.04271844]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = np.empty([len(LF_l)],dtype=np.float64)\n",
    "acc.fill(0.25)\n",
    "rec =  np.empty([len(LF_l)],dtype=np.float64)\n",
    "rec.fill(0.35*train_L_S.shape[0])\n",
    "print(rec)\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [64,128,256,512]:\n",
    "    for i in np.linspace(0.6,1,5):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = acc ,LF_rec = rec,\\\n",
    "                                    pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=7,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295.\n",
      " 1295. 1295. 1295. 1295.]\n",
      "batch-size: 64 alpha-init: 0.6\n",
      "precision and recall and sign 2 penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 1249128.694508861\n",
      "dev set\n",
      "[0.59966419 0.59662467 0.59861625 0.59852027 0.60260125 0.60197537\n",
      " 0.60325263 0.60187818 0.5999139  0.59909635 0.59828474 0.60192126\n",
      " 0.59827266 0.60234796 0.60196187 0.60197611]\n",
      "[[1.11906896 0.81573464 1.01104918 1.00212258 1.10485234 1.03977548\n",
      "  1.16764946 1.02963845 1.14787911 1.06627299 0.98509706 1.06512126\n",
      "  0.98392353 1.07701838 1.03926376 1.0406874 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "1 loss 1249105.3682796431\n",
      "dev set\n",
      "[0.59817455 0.5950781  0.59712625 0.59703653 0.60412528 0.60350861\n",
      " 0.6047882  0.60341265 0.59833777 0.59751978 0.59670813 0.60320008\n",
      " 0.59669131 0.60388211 0.60353535 0.60354959]\n",
      "[[1.1205784  0.81728596 1.01255367 1.00362401 1.10333518 1.03823884\n",
      "  1.16611921 1.0281014  1.14945499 1.0678478  0.98666937 1.06359619\n",
      "  0.9855036  1.07548098 1.03769335 1.039117  ]]\n",
      "{0: 268, 1: 1604}\n",
      "acc 0.2702991452991453\n",
      "(0.14900249376558602, 0.9958333333333333, 0.2592190889370933, None)\n",
      "\n",
      "2 loss 1249081.426079442\n",
      "dev set\n",
      "[0.59669196 0.59351834 0.59563232 0.59555281 0.60562886 0.60501396\n",
      " 0.6062999  0.60491653 0.596742   0.59592375 0.59511208 0.60453402\n",
      " 0.59508655 0.60538913 0.6051234  0.60513764]\n",
      "[[1.12208691 0.81885316 1.01406664 1.00513095 1.10183377 1.03672599\n",
      "  1.16461034 1.02659214 1.15105354 1.06944698 0.98826811 1.06205709\n",
      "  0.98711233 1.07396686 1.03610935 1.03753299]]\n",
      "{0: 249, 1: 1623}\n",
      "acc 0.26121794871794873\n",
      "(0.1478743068391867, 1.0, 0.2576489533011272, None)\n",
      "\n",
      "3 loss 1249056.891022919\n",
      "dev set\n",
      "[0.59521227 0.59194816 0.5941349  0.59406955 0.60711142 0.60649175\n",
      " 0.6077903  0.60639119 0.59512796 0.59431007 0.59349839 0.60588697\n",
      " 0.59346058 0.60686934 0.60672449 0.60673873]\n",
      "[[1.12359826 0.82043344 1.01558756 1.00664289 1.10034852 1.03523593\n",
      "  1.16311902 1.025108   1.15267287 1.07106869 0.98989021 1.06050739\n",
      "  0.9887465  1.07247505 1.03451351 1.03593716]]\n",
      "{0: 237, 1: 1635}\n",
      "acc 0.2548076923076923\n",
      "(0.14678899082568808, 1.0, 0.256, None)\n",
      "\n",
      "4 loss 1249031.7699155451\n",
      "dev set\n",
      "[0.5937343  0.59036873 0.59263431 0.59258705 0.60857287 0.60794201\n",
      " 0.60926033 0.60783701 0.59349749 0.59267976 0.59186817 0.6072616\n",
      " 0.59181482 0.60832281 0.60833772 0.60835196]\n",
      "[[1.12511343 0.82202558 1.017116   1.00815944 1.09887933 1.03376816\n",
      "  1.16164381 1.02364793 1.15431184 1.07271179 0.99153418 1.05894852\n",
      "  0.99040434 1.07100507 1.03290686 1.03433052]]\n",
      "{0: 221, 1: 1651}\n",
      "acc 0.24626068376068377\n",
      "(0.145366444579043, 1.0, 0.2538339502908514, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.7\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 1249399.3163817802\n",
      "dev set\n",
      "[0.69966524 0.69663719 0.69863909 0.69852092 0.70259612 0.70197004\n",
      " 0.70325423 0.7018766  0.69995961 0.69913804 0.69832823 0.70212646\n",
      " 0.69832134 0.70234282 0.70193074 0.70194499]\n",
      "[[1.11906753 0.81572306 1.01102781 1.00212092 1.10486333 1.03978456\n",
      "  1.16764937 1.02964163 1.14783636 1.06619375 0.98496898 1.06509765\n",
      "  0.98386592 1.0770271  1.03931086 1.04073449]]\n",
      "{0: 598, 1: 1274}\n",
      "acc 0.4423076923076923\n",
      "(0.18445839874411302, 0.9791666666666666, 0.3104359313077939, None)\n",
      "\n",
      "1 loss 1249388.5127967314\n",
      "dev set\n",
      "[0.69816929 0.69508922 0.69715591 0.69702864 0.70411728 0.70350065\n",
      " 0.70479059 0.70340833 0.69838978 0.69756919 0.69675276 0.70361833\n",
      " 0.69674683 0.70387445 0.7035001  0.70351435]\n",
      "[[1.12058188 0.81727704 1.01252651 1.00362931 1.10335548 1.03825557\n",
      "  1.16612264 1.02811293 1.14939582 1.06769375 0.98647202 1.06356344\n",
      "  0.98543294 1.07549704 1.0377479  1.03917153]]\n",
      "{0: 572, 1: 1300}\n",
      "acc 0.4284188034188034\n",
      "(0.18076923076923077, 0.9791666666666666, 0.3051948051948052, None)\n",
      "\n",
      "2 loss 1249377.003776552\n",
      "dev set\n",
      "[0.69666875 0.69351508 0.69565434 0.69552614 0.70562091 0.70500435\n",
      " 0.70630537 0.70490943 0.69677339 0.6959535  0.69512101 0.70512686\n",
      " 0.69511848 0.70537983 0.70510845 0.7051227 ]\n",
      "[[1.12210592 0.81886029 1.01404766 1.00515273 1.10186087 1.03675063\n",
      "  1.16461583 1.02661406 1.15100213 1.06924455 0.98803524 1.0620232\n",
      "  0.9870626  1.07399059 1.03614319 1.03756682]]\n",
      "{0: 533, 1: 1339}\n",
      "acc 0.4075854700854701\n",
      "(0.1755041075429425, 0.9791666666666666, 0.2976567447751741, None)\n",
      "\n",
      "3 loss 1249364.7923701734\n",
      "dev set\n",
      "[0.6951594  0.69191795 0.6941362  0.69401403 0.70710647 0.70648124\n",
      " 0.70780171 0.70638142 0.69511428 0.6942959  0.69345017 0.70664902\n",
      " 0.69344211 0.70685908 0.7067519  0.70676614]\n",
      "[[1.1236435  0.82046961 1.01558937 1.00669049 1.10037987 1.03526888\n",
      "  1.1631242  1.02514186 1.15265227 1.07084477 0.9896527  1.0604789\n",
      "  0.98874732 1.07250694 1.03450203 1.03592568]]\n",
      "{0: 509, 1: 1363}\n",
      "acc 0.39476495726495725\n",
      "(0.1724137931034483, 0.9791666666666666, 0.2932002495321273, None)\n",
      "\n",
      "4 loss 1249351.862499967\n",
      "dev set\n",
      "[0.69364027 0.69029943 0.69260251 0.6924928  0.7085739  0.70793129\n",
      " 0.70928078 0.70782471 0.69341382 0.69259419 0.69174013 0.70819174\n",
      " 0.691722   0.70831218 0.70842547 0.7084397 ]\n",
      "[[1.12519542 0.82210335 1.01715054 1.00824201 1.09891236 1.03380986\n",
      "  1.161646   1.0236951  1.154344   1.07249322 0.99132145 1.05893143\n",
      "  0.99048253 1.0710456  1.03282805 1.03425171]]\n",
      "{0: 495, 1: 1377}\n",
      "acc 0.3872863247863248\n",
      "(0.17066085693536673, 0.9791666666666666, 0.29066171923314776, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.8\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 1249490.281676954\n",
      "dev set\n",
      "[0.79970891 0.79670209 0.79873039 0.79854274 0.80256898 0.80195897\n",
      " 0.80324822 0.80187144 0.80054132 0.80019748 0.79913242 0.80213306\n",
      " 0.79892545 0.80233221 0.8007008  0.80071565]\n",
      "[[1.11902997 0.81566317 1.01094482 1.00210082 1.10491492 1.03980584\n",
      "  1.16766401 1.02965237 1.14756262 1.06554427 0.98432277 1.0650929\n",
      "  0.9831955  1.07704745 1.04195932 1.04338279]]\n",
      "{0: 943, 1: 929}\n",
      "acc 0.5998931623931624\n",
      "(0.22604951560818085, 0.875, 0.35928143712574856, None)\n",
      "\n",
      "1 loss 1249488.506018662\n",
      "dev set\n",
      "[0.79825865 0.79522425 0.79733375 0.79707751 0.80406643 0.80348062\n",
      " 0.80477586 0.80339643 0.79958575 0.79977849 0.79839169 0.80361993\n",
      " 0.79818753 0.80385529 0.80108131 0.8010968 ]\n",
      "[[1.12050464 0.81715363 1.01236677 1.00358489 1.10345715 1.03830309\n",
      "  1.16616124 1.02814473 1.14881931 1.06631777 0.98511267 1.06356611\n",
      "  0.984057   1.07554241 1.04302761 1.04445091]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "2 loss 1249486.682021631\n",
      "dev set\n",
      "[0.79680052 0.7937178  0.79591291 0.79560109 0.80555125 0.80497782\n",
      " 0.80628483 0.80489272 0.79854664 0.79936385 0.79763837 0.80511016\n",
      " 0.79739612 0.80535439 0.80161739 0.80163348]\n",
      "[[1.1219928  0.81867707 1.01381763 1.00508577 1.10200909 1.03682573\n",
      "  1.16467783 1.02666929 1.15011392 1.06709643 0.98591254 1.06204383\n",
      "  0.9850233  1.07406246 1.04399151 1.04541463]]\n",
      "{0: 931, 1: 941}\n",
      "acc 0.593482905982906\n",
      "(0.22316684378320936, 0.875, 0.35563082133784935, None)\n",
      "\n",
      "3 loss 1249484.7690446463\n",
      "dev set\n",
      "[0.79532828 0.79218198 0.79446898 0.79411219 0.80702275 0.80645106\n",
      " 0.8077793  0.80636225 0.79746271 0.79895068 0.79687766 0.80660193\n",
      " 0.79643791 0.80682997 0.80233245 0.80234909]\n",
      "[[1.12350032 0.82023416 1.01529622 1.00660459 1.10057151 1.0353722\n",
      "  1.16320753 1.02522208 1.15145101 1.0678837  0.98672086 1.06052749\n",
      "  0.98609469 1.0726061  1.0448331  1.04625602]]\n",
      "{0: 921, 1: 951}\n",
      "acc 0.5881410256410257\n",
      "(0.22082018927444794, 0.875, 0.3526448362720403, None)\n",
      "\n",
      "4 loss 1249482.7324975193\n",
      "dev set\n",
      "[0.79383871 0.79061441 0.79300066 0.79260946 0.80848117 0.8079006\n",
      " 0.80926123 0.80780567 0.79626467 0.79853716 0.79608938 0.80809488\n",
      " 0.79534446 0.80828229 0.80324004 0.80325718]\n",
      "[[1.12503017 0.82182717 1.01680367 1.00814251 1.09914395 1.03394152\n",
      "  1.16174749 1.02380149 1.15283562 1.06868208 0.98753866 1.0590173\n",
      "  0.98727749 1.07117239 1.04552674 1.04694944]]\n",
      "{0: 905, 1: 967}\n",
      "acc 0.5806623931623932\n",
      "(0.21820062047569805, 0.8791666666666667, 0.3496271748135874, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.9\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 1249545.4385579545\n",
      "dev set\n",
      "[0.89972466 0.8967279  0.89876662 0.89855737 0.90242613 0.90194002\n",
      " 0.90319373 0.90186583 0.90036381 0.89975274 0.8990155  0.90215953\n",
      " 0.89973098 0.90231425 0.89895799 0.89897227]\n",
      "[[1.11900822 0.81563604 1.0109024  1.00208236 1.10512247 1.03985044\n",
      "  1.16776291 1.02966953 1.14761058 1.06576263 0.98452443 1.06506401\n",
      "  0.98299902 1.07709003 1.04234771 1.04377135]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 1249544.450272091\n",
      "dev set\n",
      "[0.89829558 0.89529817 0.8974117  0.8970978  0.90379912 0.90339646\n",
      " 0.90465101 0.90334266 0.89924821 0.89890411 0.89817109 0.90364231\n",
      " 0.89976149 0.90377473 0.89757531 0.89758963]\n",
      "[[1.12045966 0.81708164 1.01228002 1.00356061 1.1038561  1.03847942\n",
      "  1.16638376 1.02825904 1.14889482 1.06675641 0.98551947 1.06353646\n",
      "  0.9835368  1.07571192 1.04386445 1.04528809]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "2 loss 1249543.4740057117\n",
      "dev set\n",
      "[0.89686406 0.89385673 0.89604093 0.89562726 0.90517051 0.90481634\n",
      " 0.90609142 0.90477846 0.89812447 0.89806577 0.89732951 0.90512769\n",
      " 0.89978738 0.90519908 0.89621025 0.89622462]\n",
      "[[1.12192346 0.81854792 1.01368241 1.00505982 1.10258779 1.0371544\n",
      "  1.16502353 1.02690233 1.15019124 1.06774913 0.98652237 1.06203516\n",
      "  0.98408554 1.07437959 1.04539245 1.04681608]]\n",
      "{0: 1096, 1: 776}\n",
      "acc 0.6677350427350427\n",
      "(0.2538659793814433, 0.8208333333333333, 0.38779527559055116, None)\n",
      "\n",
      "3 loss 1249542.4784437558\n",
      "dev set\n",
      "[0.89542646 0.89240643 0.89465887 0.89414737 0.9065363  0.90620549\n",
      " 0.90752081 0.90617928 0.89699219 0.89723578 0.89649407 0.90659887\n",
      " 0.89980941 0.90659292 0.89481121 0.89482563]\n",
      "[[1.12340291 0.82003181 1.01510485 1.0065781  1.10132288 1.03586569\n",
      "  1.16367465 1.02558889 1.15150136 1.06874282 0.98752949 1.06056064\n",
      "  0.98463906 1.07308365 1.04693481 1.04835845]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "4 loss 1249541.460301198\n",
      "dev set\n",
      "[0.89398218 0.89094882 0.89326764 0.8926591  0.90789539 0.90756633\n",
      " 0.90894118 0.90754761 0.89585191 0.89641399 0.89566597 0.90807125\n",
      " 0.89982898 0.9079586  0.89338331 0.89339778]\n",
      "[[1.1248983  0.82153146 1.01654503 1.0081142  1.10006312 1.03460945\n",
      "  1.16233492 1.0243145  1.15282505 1.06973751 0.98853938 1.05911265\n",
      "  0.98519451 1.07182034 1.04849352 1.04991715]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 1.0\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 1249576.6964133803\n",
      "dev set\n",
      "[1.00305598 0.99647517 1.00199261 1.00039344 1.00295804 1.00239262\n",
      " 1.00351744 1.00229625 1.0033113  1.00259897 0.99848276 1.00261527\n",
      " 0.99836835 1.00271785 1.00238779 1.00240082]\n",
      "[[1.11852217 0.81598904 1.00979612 1.00062455 1.10728357 1.04180935\n",
      "  1.17046742 1.03161318 1.14748172 1.06534819 0.98506938 1.06725167\n",
      "  0.98395453 1.07930037 1.04127988 1.04271273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 1249576.686921431\n",
      "dev set\n",
      "[1.00567548 0.9944544  1.00490842 1.00354568 1.00560324 1.00520036\n",
      " 1.00601612 1.00513088 1.0058628  1.00534892 0.99676473 1.0053605\n",
      " 0.9965413  1.00543188 1.0051969  1.00520625]\n",
      "[[1.12113552 0.81836702 1.01218445 1.00184676 1.10989332 1.04433805\n",
      "  1.17306254 1.03411415 1.15009049 1.06792288 0.98718251 1.06982909\n",
      "  0.98620547 1.08189123 1.04380729 1.04524358]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 1249576.668464207\n",
      "dev set\n",
      "[1.00866845 0.99220837 1.00811029 1.00707847 1.00861404 1.00832349\n",
      " 1.00891335 1.00827273 1.00880396 1.00843332 0.9948757  1.00844169\n",
      " 0.99453501 1.00849094 1.00832096 1.00832777]\n",
      "[[1.1244219  0.82110507 1.01561253 1.0053989  1.11319322 1.04771633\n",
      "  1.17627342 1.03750452 1.15333664 1.07127534 0.98954896 1.07317933\n",
      "  0.98871919 1.08522604 1.04718618 1.04862081]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 1249576.6387549\n",
      "dev set\n",
      "[1.01181602 0.98983847 1.01139457 1.01059181 1.01177215 1.01155449\n",
      " 1.01199511 1.01151601 1.01191698 1.01164037 0.99291671 1.01164665\n",
      " 0.99245855 1.01168039 1.01155258 1.01155774]\n",
      "[[1.12795602 0.82402912 1.01926915 1.00925875 1.11673748 1.05132576\n",
      "  1.17974805 1.04112489 1.15683932 1.07486287 0.99201587 1.076765\n",
      "  0.9913324  1.08879841 1.05079616 1.05222932]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 1249576.5961448408\n",
      "dev set\n",
      "[1.01502559 0.98740124 1.01469657 1.0140513  1.0149872  1.01481852\n",
      " 1.01515847 1.01478836 1.01510322 1.01488988 0.99093225 1.01489476\n",
      " 0.99035783 1.01491643 1.01481702 1.01482106]\n",
      "[[1.13159203 0.82704919 1.02299371 1.01313789 1.12037964 1.05501461\n",
      "  1.18334083 1.0448217  1.16045304 1.07853693 0.99451941 1.08043773\n",
      "  0.99397984 1.09246056 1.0544854  1.05591749]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.6\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 648124.4154424588\n",
      "dev set\n",
      "[0.60039562 0.59737345 0.59933317 0.59924291 0.60183893 0.60119658\n",
      " 0.60247399 0.60109617 0.60068538 0.59986868 0.5990571  0.60136648\n",
      " 0.59904548 0.60156903 0.6011875  0.60120173]\n",
      "[[1.11832616 0.81498387 1.01032437 1.00139064 1.10560648 1.04055511\n",
      "  1.16842537 1.03042301 1.14711073 1.06550213 0.98434062 1.06585009\n",
      "  0.98315676 1.07779813 1.04003465 1.04145829]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "1 loss 648112.7974379167\n",
      "dev set\n",
      "[0.59961943 0.59659728 0.59856808 0.59847948 0.60261288 0.60197391\n",
      " 0.60325292 0.60187481 0.59990139 0.59908443 0.59827279 0.60207496\n",
      " 0.59826037 0.60234652 0.60197131 0.60198554]\n",
      "[[1.11910556 0.81576107 1.01109273 1.00215807 1.10483459 1.03977703\n",
      "  1.16764749 1.02964339 1.14789442 1.06628631 0.98512218 1.06507838\n",
      "  0.98394004 1.07701992 1.03925155 1.04067519]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "2 loss 648101.025417937\n",
      "dev set\n",
      "[0.59884659 0.595817   0.597802   0.59771613 0.60338228 0.60274441\n",
      " 0.60402548 0.6026457  0.59911207 0.59829491 0.59748324 0.60279187\n",
      " 0.59746897 0.60311736 0.6027591  0.60277333]\n",
      "[[1.11988332 0.81654303 1.01186325 1.00292682 1.104066   1.03900491\n",
      "  1.16687565 1.0288711  1.14868415 1.06707699 0.98591115 1.06430239\n",
      "  0.98473122 1.07624754 1.03846466 1.0398883 ]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "3 loss 648089.1040025995\n",
      "dev set\n",
      "[0.59807521 0.59503355 0.59703492 0.59695284 0.60414662 0.60350799\n",
      " 0.60479237 0.6034091  0.59831784 0.59750054 0.59668881 0.60351613\n",
      " 0.59667168 0.60388147 0.60355052 0.60356475]\n",
      "[[1.12066117 0.81732883 1.01263592 1.00369692 1.10330122 1.03823867\n",
      "  1.1661087  1.02810549 1.14947954 1.06787379 0.98670664 1.0635232\n",
      "  0.98552952 1.07548092 1.03767439 1.03909804]]\n",
      "{0: 267, 1: 1605}\n",
      "acc 0.26976495726495725\n",
      "(0.14890965732087227, 0.9958333333333333, 0.25907859078590784, None)\n",
      "\n",
      "4 loss 648077.0334337776\n",
      "dev set\n",
      "[0.59730456 0.59424735 0.59626689 0.5961896  0.60490579 0.60426469\n",
      " 0.60555396 0.60416521 0.59751899 0.59670155 0.59588979 0.60426146\n",
      " 0.5958688  0.60463888 0.60434535 0.60435959]\n",
      "[[1.12143978 0.81811809 1.01341071 1.00446834 1.10254037 1.03747818\n",
      "  1.1653461  1.0273462  1.15028034 1.06867645 0.98750821 1.06274132\n",
      "  0.9863345  1.07471993 1.03688098 1.03830463]]\n",
      "{0: 262, 1: 1610}\n",
      "acc 0.2670940170940171\n",
      "(0.1484472049689441, 0.9958333333333333, 0.25837837837837835, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.7\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 648391.9122170213\n",
      "dev set\n",
      "[0.70039506 0.69737726 0.6993397  0.69924172 0.70183793 0.70119485\n",
      " 0.70247463 0.7010955  0.70069793 0.69988049 0.69907069 0.70142461\n",
      " 0.69905931 0.70156736 0.70117924 0.70119348]\n",
      "[[1.1183267  0.8149803  1.01031828 1.00139142 1.10560877 1.04055792\n",
      "  1.16842485 1.03042414 1.14709825 1.06548425 0.98429825 1.06584442\n",
      "  0.9831392  1.07780083 1.04004807 1.04147171]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "1 loss 648386.5599751585\n",
      "dev set\n",
      "[0.69961803 0.69660117 0.69857803 0.69847565 0.7026109  0.70197116\n",
      " 0.70325383 0.70187343 0.69991716 0.69910035 0.69829017 0.70218911\n",
      " 0.69827818 0.70234387 0.70196149 0.70197573]\n",
      "[[1.11910689 0.8157577  1.01108361 1.00216105 1.10483952 1.03978214\n",
      "  1.16764766 1.02964648 1.14787662 1.06625172 0.9850547  1.06507046\n",
      "  0.98391536 1.07702483 1.03926923 1.04069287]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 648381.0380018526\n",
      "dev set\n",
      "[0.69884163 0.69581761 0.69781132 0.69770699 0.70337999 0.70274093\n",
      " 0.70402704 0.70264356 0.69912292 0.69830745 0.69749602 0.70295846\n",
      " 0.69748212 0.70311401 0.70275214 0.70276638]\n",
      "[[1.11988791 0.81654332 1.011855   1.00293447 1.104073   1.03901231\n",
      "  1.16687638 1.02887668 1.14866729 1.06703248 0.9858282  1.06429436\n",
      "  0.98470912 1.07625465 1.03847882 1.03990246]]\n",
      "{0: 582, 1: 1290}\n",
      "acc 0.4337606837606838\n",
      "(0.1821705426356589, 0.9791666666666666, 0.30718954248366015, None)\n",
      "\n",
      "3 loss 648375.3450635042\n",
      "dev set\n",
      "[0.69806376 0.69502756 0.69704001 0.69693575 0.70414473 0.703504\n",
      " 0.70479523 0.70340623 0.69831636 0.69750284 0.6966877  0.70373176\n",
      " 0.69667247 0.7038776  0.70355254 0.70356678]\n",
      "[[1.12067176 0.81733622 1.01263207 1.00371173 1.10330967 1.03824842\n",
      "  1.1661095  1.02811396 1.14946976 1.06782621 0.98661658 1.06351688\n",
      "  0.98551854 1.07549032 1.03767792 1.03910156]]\n",
      "{0: 571, 1: 1301}\n",
      "acc 0.42788461538461536\n",
      "(0.180630284396618, 0.9791666666666666, 0.30499675535366644, None)\n",
      "\n",
      "4 loss 648369.4702328773\n",
      "dev set\n",
      "[0.69728363 0.69423146 0.69626433 0.69616196 0.70490503 0.70426035\n",
      " 0.70555883 0.70416164 0.69749868 0.69668732 0.69586403 0.7045086\n",
      " 0.69585006 0.70463464 0.70436237 0.7043766 ]\n",
      "[[1.12145915 0.81813597 1.01341457 1.00449279 1.10254961 1.03749041\n",
      "  1.16534634 1.02735789 1.15028367 1.0686326  0.98741898 1.06273832\n",
      "  0.98634253 1.07473177 1.03686726 1.03829091]]\n",
      "{0: 557, 1: 1315}\n",
      "acc 0.4204059829059829\n",
      "(0.17870722433460076, 0.9791666666666666, 0.30225080385852093, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.8\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 648480.7580454674\n",
      "dev set\n",
      "[0.80040207 0.79739169 0.79936897 0.79924479 0.80183301 0.8011914\n",
      " 0.80247449 0.80109371 0.80087044 0.80035574 0.79937508 0.80142219\n",
      " 0.7992465  0.80156405 0.8006763  0.80069097]\n",
      "[[1.11832104 0.81496706 1.0102919  1.00138862 1.10561867 1.04056417\n",
      "  1.16842574 1.03042743 1.14701687 1.065214   0.98402245 1.06584363\n",
      "  0.98290528 1.07780681 1.04144554 1.04286912]]\n",
      "{0: 956, 1: 916}\n",
      "acc 0.6057692307692307\n",
      "(0.22816593886462883, 0.8708333333333333, 0.3615916955017301, None)\n",
      "\n",
      "1 loss 648479.8148222407\n",
      "dev set\n",
      "[0.79963543 0.79662965 0.79863462 0.79848396 0.80259989 0.80196487\n",
      " 0.80325259 0.80186944 0.8002707  0.80006554 0.79891018 0.80218458\n",
      " 0.79867231 0.80233786 0.80089708 0.80091222]\n",
      "[[1.11909255 0.81573192 1.01103319 1.00215363 1.10486202 1.03979549\n",
      "  1.16765214 1.02965537 1.1477111  1.06569712 0.98448727 1.06507122\n",
      "  0.98342573 1.07703755 1.04209255 1.04351607]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "2 loss 648478.8629182038\n",
      "dev set\n",
      "[0.79886871 0.79585909 0.79789239 0.79771999 0.80336398 0.80273238\n",
      " 0.80402536 0.80263778 0.79964226 0.79977637 0.79843691 0.80294871\n",
      " 0.7982015  0.80310583 0.8011831  0.80119868]\n",
      "[[1.11986582 0.8165064  1.01178352 1.00292323 1.10410741 1.03903304\n",
      "  1.16688443 1.02889179 1.14841575 1.06618238 0.98495787 1.06429919\n",
      "  0.98398602 1.07627444 1.04270872 1.04413217]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "3 loss 648477.8913713162\n",
      "dev set\n",
      "[0.7980993  0.79508039 0.7971433  0.79695265 0.80412471 0.80349367\n",
      " 0.80479389 0.803399   0.79898415 0.79948789 0.79795915 0.80371379\n",
      " 0.79769164 0.80386768 0.80153397 0.80154998]\n",
      "[[1.12064334 0.81729016 1.01254197 1.00369769 1.10335537 1.03827685\n",
      "  1.16612081 1.02813583 1.14913183 1.06667053 0.98543219 1.0635283\n",
      "  0.98458218 1.07551753 1.04329266 1.04471604]]\n",
      "{0: 939, 1: 933}\n",
      "acc 0.5977564102564102\n",
      "(0.22508038585209003, 0.875, 0.35805626598465473, None)\n",
      "\n",
      "4 loss 648476.8893895672\n",
      "dev set\n",
      "[0.79732592 0.79429333 0.79638746 0.79618167 0.80488202 0.80424872\n",
      " 0.80555879 0.80415334 0.79830725 0.79919954 0.79747795 0.80447954\n",
      " 0.79712004 0.80462342 0.80195837 0.80197476]\n",
      "[[1.1214263  0.81808343 1.01330841 1.00447725 1.10260599 1.0375268\n",
      "  1.16536034 1.02738702 1.14986044 1.0671621  0.98590985 1.06275878\n",
      "  0.98521356 1.07476669 1.04384055 1.04526385]]\n",
      "{0: 930, 1: 942}\n",
      "acc 0.592948717948718\n",
      "(0.2229299363057325, 0.875, 0.35532994923857875, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.9\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 648535.7356940376\n",
      "dev set\n",
      "[0.9004065  0.89739652 0.89938176 0.89925088 0.9017991  0.9011867\n",
      " 0.90246517 0.90109246 0.90084223 0.90011286 0.89935561 0.90142955\n",
      " 0.89967573 0.90155962 0.89964376 0.89965801]\n",
      "[[1.11831582 0.81496179 1.01027743 1.00138171 1.10567118 1.04057602\n",
      "  1.16844345 1.03043158 1.14702809 1.06532465 0.98411295 1.06583455\n",
      "  0.98279683 1.07781805 1.04159326 1.0430169 ]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 648535.2130763008\n",
      "dev set\n",
      "[0.89964736 0.8966462  0.89866074 0.89849417 0.90253231 0.90194538\n",
      " 0.90322904 0.90185761 0.90020359 0.8995807  0.89887147 0.90219219\n",
      " 0.89969579 0.90231934 0.89889409 0.89890834]\n",
      "[[1.11907977 0.81571565 1.01100447 1.00214258 1.10496968 1.03984024\n",
      "  1.16769733 1.02968264 1.14773287 1.06592011 0.98466639 1.06505949\n",
      "  0.98315667 1.07708023 1.04236371 1.04378735]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 648534.6874674385\n",
      "dev set\n",
      "[0.89888979 0.89589183 0.89793378 0.89773401 0.90326584 0.90269431\n",
      " 0.90398763 0.9026118  0.89956355 0.89905172 0.8983861  0.90295217\n",
      " 0.8997182  0.90306945 0.89815278 0.89816406]\n",
      "[[1.11984501 0.81647598 1.01173989 1.00290954 1.10426696 1.03911733\n",
      "  1.1669579  1.02894854 1.14844026 1.06651556 0.98522433 1.06429069\n",
      "  0.98352512 1.07635514 1.04313703 1.04456067]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "3 loss 648534.1708412064\n",
      "dev set\n",
      "[0.89813144 0.89513433 0.89720258 0.89697088 0.90399836 0.90343487\n",
      " 0.90474292 0.90335653 0.89892144 0.8985252  0.89790151 0.90371498\n",
      " 0.89973893 0.90381126 0.89744605 0.89745735]\n",
      "[[1.12061387 0.81724194 1.01248206 1.00368217 1.10356466 1.03840471\n",
      "  1.16622221 1.02822647 1.14915139 1.0671119  0.98578477 1.06352856\n",
      "  0.98389904 1.07564033 1.04391391 1.04533757]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 648533.6542091925\n",
      "dev set\n",
      "[0.89737132 0.89437393 0.89646773 0.89620495 0.90472948 0.90416772\n",
      " 0.90549585 0.90409249 0.8982768  0.89800081 0.89741831 0.90447562\n",
      " 0.89975723 0.9045454  0.89673236 0.89674547]\n",
      "[[1.12138724 0.81801327 1.0132304  1.00446028 1.10286331 1.03770126\n",
      "  1.16548901 1.0275152  1.14986676 1.06770949 0.98634709 1.06277327\n",
      "  0.98427673 1.07493469 1.04469411 1.04611777]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 1.0\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 648566.7599835811\n",
      "dev set\n",
      "[1.00201359 0.99734458 1.00088108 1.00004839 1.0019049  1.00127123\n",
      " 1.00251906 1.00116737 1.00229477 1.00150093 0.99914592 1.00151928\n",
      " 0.99909686 1.00163526 1.00126595 1.00128022]\n",
      "[[1.11791412 0.81503111 1.00957676 1.00062431 1.10670237 1.04142232\n",
      "  1.16975205 1.03126654 1.14681051 1.06488128 0.9842928  1.06677891\n",
      "  0.98312258 1.0787924  1.04089483 1.04232233]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 648566.7569130805\n",
      "dev set\n",
      "[1.00305772 0.99645682 1.00204848 1.00099521 1.00296016 1.00240165\n",
      " 1.00351827 1.00230951 1.00331241 1.00260367 0.99833208 1.00261977\n",
      " 0.99825557 1.00272136 1.00239698 1.00240958]\n",
      "[[1.118794   0.81600684 1.00997554 1.0006487  1.10755814 1.0420359\n",
      "  1.17069588 1.03182509 1.14773409 1.06560326 0.98524273 1.0675086\n",
      "  0.98410468 1.07956713 1.04150569 1.04294053]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 648566.7521002085\n",
      "dev set\n",
      "[1.004299   0.99547598 1.00343926 1.00248223 1.00421504 1.00374204\n",
      " 1.00469881 1.0036636  1.004519   1.00391349 0.99741655 1.00392709\n",
      " 0.99730783 1.00401241 1.00373807 1.00374877]\n",
      "[[1.1200506  0.81714275 1.01112732 1.00129591 1.10881515 1.0432589\n",
      "  1.17193477 1.03303373 1.14898329 1.06684824 0.98636006 1.06875477\n",
      "  0.98525759 1.08081898 1.04272803 1.04416462]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 648566.7451122454\n",
      "dev set\n",
      "[1.00567756 0.99442171 1.00495125 1.00411927 1.00560592 1.00520813\n",
      " 1.0060178  1.00514178 1.00586438 1.00535321 0.99643438 1.00536464\n",
      " 0.99629199 1.00543559 1.00520478 1.00521382]\n",
      "[[1.12153186 0.81840009 1.01266365 1.00277924 1.1103039  1.04478364\n",
      "  1.1733746  1.03456234 1.15044244 1.06836265 0.98757914 1.0702682\n",
      "  0.98651363 1.08232541 1.04425299 1.045689  ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 648566.7356084513\n",
      "dev set\n",
      "[1.00714536 0.99331241 1.00652894 1.00580936 1.00708379 1.00674752\n",
      " 1.00743369 1.00669108 1.00730382 1.00687136 0.99540994 1.00688102\n",
      " 0.99523384 1.00694003 1.00674467 1.00675235]\n",
      "[[1.12314746 0.81974503 1.01435943 1.0045387  1.11192759 1.04645318\n",
      "  1.17494725 1.03623882 1.15203489 1.07001683 0.98886052 1.07192109\n",
      "  0.98783219 1.08396949 1.04592288 1.04735793]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.6\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 357989.688577729\n",
      "dev set\n",
      "[0.60076946 0.5977431  0.59969381 0.59961021 0.60146613 0.60081777\n",
      " 0.60209597 0.60071671 0.60106089 0.6002446  0.59943306 0.60104369\n",
      " 0.59942127 0.6011902  0.60081102 0.60082526]\n",
      "[[1.11795067 0.81461379 1.00996168 1.00102149 1.10597633 1.04093407\n",
      "  1.16880253 1.03080299 1.14673646 1.06512615 0.98397079 1.06621567\n",
      "  0.9827831  1.07817711 1.04041018 1.04183383]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "1 loss 357983.7530726813\n",
      "dev set\n",
      "[0.60036758 0.59734681 0.59929454 0.59921849 0.60186385 0.60121639\n",
      " 0.60249522 0.60111649 0.60066172 0.5998453  0.59903374 0.60142254\n",
      " 0.59902186 0.60158884 0.6012103  0.60122453]\n",
      "[[1.11835277 0.81501033 1.01036123 1.0014144  1.10557904 1.04053529\n",
      "  1.16840373 1.03040265 1.14713552 1.06552494 0.9843689  1.065819\n",
      "  0.9831814  1.07777831 1.04001116 1.0414348 ]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "2 loss 357977.7983114064\n",
      "dev set\n",
      "[0.59996633 0.59694928 0.5988946  0.59882664 0.60226081 0.6016137\n",
      " 0.60289319 0.6015148  0.60026111 0.59944459 0.59863302 0.60180468\n",
      " 0.59862081 0.60198621 0.6016107  0.60162493]\n",
      "[[1.11875462 0.81540826 1.01076169 1.00180773 1.10518226 1.04013766\n",
      "  1.16800621 1.03000368 1.1475362  1.06592532 0.98476898 1.06542084\n",
      "  0.98358173 1.07738063 1.03961103 1.04103467]]\n",
      "{0: 274, 1: 1598}\n",
      "acc 0.27350427350427353\n",
      "(0.14956195244055068, 0.9958333333333333, 0.2600652883569097, None)\n",
      "\n",
      "3 loss 357971.8007914691\n",
      "dev set\n",
      "[0.5995653  0.59655051 0.59849395 0.59843449 0.60265686 0.60200961\n",
      " 0.60328996 0.60191158 0.59985887 0.59904226 0.59823068 0.60218962\n",
      " 0.59821787 0.60238224 0.60201239 0.60202662]\n",
      "[[1.11915664 0.81580759 1.01116313 1.0022017  1.10478606 1.03974119\n",
      "  1.16760977 1.02960609 1.14793869 1.06632759 0.98517113 1.06502135\n",
      "  0.98398429 1.07698409 1.03920966 1.0406333 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "4 loss 357965.75994999404\n",
      "dev set\n",
      "[0.59916436 0.59615066 0.59809272 0.5980421  0.60305186 0.60240399\n",
      " 0.60368551 0.60230671 0.59945509 0.5986384  0.59782681 0.602577\n",
      " 0.59781314 0.60277677 0.60241528 0.60242952]\n",
      "[[1.119559   0.81620818 1.01156546 1.00259627 1.10439062 1.039346\n",
      "  1.16721434 1.02920994 1.14834292 1.0667317  0.98557521 1.06462076\n",
      "  0.98438895 1.07658879 1.03880715 1.04023079]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.7\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 358255.6218131361\n",
      "dev set\n",
      "[0.70077002 0.69774433 0.69969605 0.69960929 0.70146621 0.70081733\n",
      " 0.70209617 0.7007165  0.70106488 0.70024853 0.69943766 0.70106274\n",
      " 0.69942577 0.70118977 0.70080838 0.70082262]\n",
      "[[1.11795025 0.81461263 1.00995962 1.0010222  1.10597633 1.04093478\n",
      "  1.16880235 1.03080333 1.14673261 1.06512267 0.98395925 1.06621389\n",
      "  0.98277647 1.07817779 1.04041486 1.0418385 ]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "1 loss 358252.89730300894\n",
      "dev set\n",
      "[0.70036833 0.69734867 0.69929869 0.69921673 0.70186394 0.70121569\n",
      " 0.70249537 0.70111602 0.70066767 0.69985174 0.699041   0.70145722\n",
      " 0.69902886 0.70158817 0.7012065  0.70122074]\n",
      "[[1.11835226 0.81500863 1.01035743 1.00141579 1.10557921 1.04053651\n",
      "  1.16840398 1.03040356 1.14712989 1.06551644 0.98434889 1.06581663\n",
      "  0.98317044 1.07777948 1.04001818 1.04144182]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "2 loss 358250.1390475651\n",
      "dev set\n",
      "[0.69996664 0.69695102 0.69889972 0.69882348 0.70226104 0.70161283\n",
      " 0.70289332 0.70151406 0.70026704 0.69945178 0.69864093 0.7018533\n",
      " 0.69862822 0.70198538 0.70160726 0.7016215 ]\n",
      "[[1.11875459 0.81540677 1.01075706 1.00181033 1.10518247 1.04013935\n",
      "  1.16800694 1.03000528 1.14753028 1.06591309 0.98474272 1.0654185\n",
      "  0.98356879 1.07738226 1.03961845 1.04104209]]\n",
      "{0: 605, 1: 1267}\n",
      "acc 0.44604700854700857\n",
      "(0.18547750591949486, 0.9791666666666666, 0.31187790311877905, None)\n",
      "\n",
      "3 loss 358247.3347866935\n",
      "dev set\n",
      "[0.69956443 0.6965513  0.69849907 0.69842926 0.70265743 0.70200864\n",
      " 0.7032902  0.70191056 0.69986275 0.6990482  0.69823732 0.70225093\n",
      " 0.69822359 0.7023813  0.70201086 0.7020251 ]\n",
      "[[1.1191578  0.81580719 1.01115862 1.00220614 1.10478618 1.03974334\n",
      "  1.1676109  1.02960848 1.1479341  1.06631326 0.98514075 1.06501956\n",
      "  0.98397172 1.07698616 1.03921552 1.04063917]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "4 loss 358244.4862826984\n",
      "dev set\n",
      "[0.69916151 0.69614963 0.69809688 0.69803412 0.70305293 0.70240297\n",
      " 0.70368603 0.70230541 0.69945493 0.69864147 0.69783018 0.70264988\n",
      " 0.69781509 0.70277578 0.7024164  0.70243064]\n",
      "[[1.11956206 0.81620975 1.01156199 1.00260319 1.10439047 1.03934863\n",
      "  1.16721575 1.02921323 1.14834127 1.06671698 0.98554279 1.06461999\n",
      "  0.98437902 1.07659134 1.03880955 1.04023319]]\n",
      "{0: 590, 1: 1282}\n",
      "acc 0.43803418803418803\n",
      "(0.18330733229329174, 0.9791666666666666, 0.3088042049934297, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.8\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 358343.40178878605\n",
      "dev set\n",
      "[0.80077363 0.79774795 0.79970489 0.79960891 0.8014655  0.80081648\n",
      " 0.80209632 0.80071593 0.80110044 0.80048731 0.79954109 0.8010617\n",
      " 0.79949651 0.80118896 0.80058272 0.80059723]\n",
      "[[1.11794728 0.81460935 1.00995169 1.00102251 1.10597788 1.04093628\n",
      "  1.16880224 1.03080432 1.14671288 1.06505696 0.98388317 1.06621321\n",
      "  0.9826829  1.07817923 1.04118627 1.04260989]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "1 loss 358342.90541495814\n",
      "dev set\n",
      "[0.80037552 0.79735643 0.7993168  0.79921768 0.80186203 0.80121427\n",
      " 0.80249507 0.80111449 0.80074053 0.8002715  0.79925804 0.80145549\n",
      " 0.79916751 0.80158681 0.80071781 0.80073266]\n",
      "[[1.11834632 0.8150016  1.01034126 1.00141488 1.10558318 1.04053936\n",
      "  1.16840497 1.03040644 1.14709186 1.06536473 0.98418184 1.06581598\n",
      "  0.982973   1.0777822  1.04155854 1.04298215]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "2 loss 358342.4047735501\n",
      "dev set\n",
      "[0.79997708 0.79696265 0.7989263  0.79882573 0.80225816 0.80161097\n",
      " 0.80289267 0.8015116  0.80037303 0.80005645 0.79897287 0.80185027\n",
      " 0.79882638 0.80198359 0.80087576 0.80089093]\n",
      "[[1.11874603 0.81539635 1.01073347 1.0018083  1.10518869 1.04014352\n",
      "  1.1680091  1.03001028 1.14747385 1.06567267 0.98448039 1.06541845\n",
      "  0.98327421 1.07738625 1.04192519 1.04334879]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "3 loss 358341.8989921066\n",
      "dev set\n",
      "[0.79957771 0.79656629 0.79853337 0.79843264 0.80265384 0.80200648\n",
      " 0.80328939 0.80190722 0.79999634 0.7998418  0.79868584 0.80224583\n",
      " 0.79852884 0.80237921 0.80106255 0.80107712]\n",
      "[[1.11914709 0.81579396 1.01112839 1.00220325 1.10479447 1.03974888\n",
      "  1.16761417 1.02961575 1.1478593  1.06598152 0.98477961 1.06502077\n",
      "  0.98358739 1.07699147 1.04228442 1.04370799]]\n",
      "{0: 941, 1: 931}\n",
      "acc 0.5988247863247863\n",
      "(0.22556390977443608, 0.875, 0.35866780529462, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 358341.39123283833\n",
      "dev set\n",
      "[0.79917717 0.79616738 0.79813819 0.79803837 0.80304887 0.8024006\n",
      " 0.80368527 0.80230125 0.79961054 0.79962745 0.79839739 0.80264199\n",
      " 0.79825405 0.80277347 0.80127696 0.80129002]\n",
      "[[1.11954972 0.81619441 1.0115259  1.00259975 1.10440068 1.03935561\n",
      "  1.16722003 1.02922292 1.14824834 1.06629145 0.98507963 1.06462309\n",
      "  0.98391181 1.07659805 1.04263529 1.04405885]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.9\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 358398.282760186\n",
      "dev set\n",
      "[0.90077641 0.89774972 0.89970991 0.899611   0.90145631 0.90081573\n",
      " 0.90209463 0.90071554 0.90109914 0.90029144 0.89951496 0.90106535\n",
      " 0.89972317 0.90118827 0.90001182 0.90002606]\n",
      "[[1.11794436 0.81460741 1.00994638 1.00102014 1.10599284 1.04093873\n",
      "  1.16880542 1.03080553 1.14672123 1.06509568 0.98391331 1.06621072\n",
      "  0.98263787 1.07818152 1.04121648 1.04264013]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 358398.0083754707\n",
      "dev set\n",
      "[0.90038219 0.89736321 0.89932827 0.89922201 0.90184363 0.90121147\n",
      " 0.9024896  0.90111135 0.90073558 0.89995607 0.89921031 0.90146055\n",
      " 0.89972732 0.90158419 0.89961846 0.8996327 ]\n",
      "[[1.11833964 0.81499476 1.01032949 1.00141015 1.10561368 1.04054709\n",
      "  1.16841539 1.03041371 1.14710398 1.0654508  0.98424459 1.06581266\n",
      "  0.98285833 1.0777895  1.04161592 1.04303956]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 358397.73387106456\n",
      "dev set\n",
      "[0.89998808 0.89697571 0.89894482 0.89883222 0.90223139 0.90160536\n",
      " 0.90288324 0.90150479 0.90037184 0.89962169 0.8989069  0.90185555\n",
      " 0.89974004 0.90197828 0.89922459 0.89923884]\n",
      "[[1.11873544 0.81538364 1.01071494 1.00180155 1.10523381 1.04015792\n",
      "  1.1680273  1.03002527 1.1474872  1.06580577 0.98457594 1.06541576\n",
      "  0.9830799  1.07739992 1.04201628 1.04343992]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 358397.4578225396\n",
      "dev set\n",
      "[0.8995936  0.89658703 0.89855972 0.89844138 0.90261937 0.90199746\n",
      " 0.9032761  0.90189605 0.9000076  0.89928795 0.89860409 0.90225016\n",
      " 0.89975396 0.9023706  0.89882976 0.898844  ]\n",
      "[[1.11913235 0.81577433 1.0111027  1.00219467 1.10485353 1.03977102\n",
      "  1.16764027 1.02963973 1.14787148 1.06616118 0.98490791 1.06502016\n",
      "  0.98330387 1.07701261 1.04241801 1.04384165]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 358397.180103024\n",
      "dev set\n",
      "[0.89919859 0.89619731 0.89817323 0.89804957 0.9030073  0.90238772\n",
      " 0.90366834 0.90228514 0.89964272 0.89895478 0.8983018  0.90264415\n",
      " 0.89976771 0.90276109 0.89843374 0.89844799]\n",
      "[[1.11953056 0.81616672 1.01149254 1.0025895  1.10447316 1.03938638\n",
      "  1.16725399 1.02925695 1.14825702 1.06651717 0.98524053 1.06462605\n",
      "  0.98352979 1.07662755 1.04282119 1.04424483]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 1.0\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 358429.1786626061\n",
      "dev set\n",
      "[1.00158846 0.99773717 1.00046728 1.00002156 1.0014773  1.00082839\n",
      " 1.0021032  1.00072474 1.00187522 1.0010627  0.99945562 1.00108154\n",
      " 0.9994441  1.00120069 1.00082306 1.00083747]\n",
      "[[1.117732   0.81462268 1.00956177 1.00062431 1.10653885 1.04136403\n",
      "  1.16949167 1.03122255 1.14658253 1.06478704 0.98395225 1.06668163\n",
      "  0.98275875 1.07867547 1.04083731 1.04226273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 358429.1774255278\n",
      "dev set\n",
      "[1.00204011 0.99731829 1.00094303 1.0002612  1.00193189 1.00130426\n",
      " 1.00254401 1.00120314 1.00232031 1.00153069 0.99905332 1.00154887\n",
      " 0.99904223 1.00166385 1.00129909 1.00131307]\n",
      "[[1.118066   0.81505901 1.00960194 1.00062446 1.10685236 1.04149586\n",
      "  1.1698833  1.03132351 1.14695497 1.06499258 0.98438895 1.06689297\n",
      "  0.98319551 1.07892205 1.04096749 1.04239736]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 358429.17582593445\n",
      "dev set\n",
      "[1.00255056 0.99687388 1.00151084 1.00079332 1.00244759 1.00185612\n",
      " 1.00303401 1.00176052 1.00281858 1.00206911 0.99861522 1.00208619\n",
      " 0.99860262 1.00219425 1.00185124 1.00186442]\n",
      "[[1.11852452 0.8155406  1.00980237 1.00064265 1.10730132 1.04182201\n",
      "  1.17036292 1.03161716 1.14742887 1.06537865 0.98489371 1.06728304\n",
      "  0.98370073 1.07933467 1.04129206 1.0427262 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 358429.17378195125\n",
      "dev set\n",
      "[1.00311972 0.99640285 1.00215251 1.00145369 1.00302337 1.00247519\n",
      " 1.00357578 1.0023864  1.00337172 1.00267241 0.99814367 1.00268821\n",
      " 0.99812828 1.00278802 1.00247067 1.00248289]\n",
      "[[1.11908726 0.81606858 1.01024193 1.0008198  1.10786219 1.04233595\n",
      "  1.17092283 1.03211469 1.14799177 1.0659189  0.98545589 1.06782485\n",
      "  0.98426377 1.07988474 1.04180523 1.04324141]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 358429.1712259493\n",
      "dev set\n",
      "[1.00374041 0.99590723 1.00284947 1.00218897 1.00365118 1.00314767\n",
      " 1.00416544 1.00306592 1.00397456 1.00332889 0.99764423 1.00334337\n",
      " 0.99762541 1.00343471 1.00314351 1.00315475]\n",
      "[[1.11973228 0.81663867 1.01086331 1.00129737 1.10850946 1.04298065\n",
      "  1.17155181 1.032755   1.14862867 1.06656878 0.98606305 1.06847489\n",
      "  0.98487208 1.08053502 1.04244975 1.04388643]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 212923.6356376834\n",
      "dev set\n",
      "[0.60096027 0.5979289  0.59988195 0.59979234 0.60127745 0.60062757\n",
      " 0.60190623 0.6005264  0.60124967 0.60043351 0.59962198 0.60087453\n",
      " 0.59961011 0.601      0.6006219  0.60063613]\n",
      "[[1.11775974 0.81442781 1.00977334 1.00083825 1.10616437 1.0411243\n",
      "  1.16899192 1.03099341 1.14654838 1.064937   0.98378384 1.06640104\n",
      "  0.98259542 1.07836735 1.0405987  1.04202234]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 212920.52020049206\n",
      "dev set\n",
      "[0.60075139 0.597722   0.59967409 0.59958652 0.6014846  0.60083498\n",
      " 0.60211407 0.60073439 0.60104224 0.60022605 0.59941452 0.60107971\n",
      " 0.59940263 0.60120741 0.60082936 0.60084359]\n",
      "[[1.11796858 0.81463475 1.00998123 1.00104428 1.10595733 1.04091686\n",
      "  1.16878409 1.03078516 1.14675593 1.06514408 0.98399099 1.06619355\n",
      "  0.98280267 1.0781599  1.04039121 1.04181486]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "2 loss 212917.44175454677\n",
      "dev set\n",
      "[0.60054325 0.59751558 0.59946668 0.59938162 0.60169094 0.60104146\n",
      " 0.60232105 0.6009415  0.60083522 0.60001899 0.59920746 0.60128534\n",
      " 0.59919552 0.6014139  0.60103636 0.60105059]\n",
      "[[1.11817675 0.81484125 1.01018871 1.00124946 1.10575105 1.0407103\n",
      "  1.1685771  1.03057776 1.14696312 1.06535073 0.98419784 1.06598635\n",
      "  0.9830096  1.07795334 1.04018421 1.04160785]]\n",
      "{0: 280, 1: 1592}\n",
      "acc 0.2767094017094017\n",
      "(0.15012562814070352, 0.9958333333333333, 0.2609170305676856, None)\n",
      "\n",
      "3 loss 212914.35956750787\n",
      "dev set\n",
      "[0.60033526 0.59730903 0.59925921 0.59917689 0.60189698 0.60124754\n",
      " 0.60252767 0.60114819 0.60062797 0.59981171 0.59900018 0.60149166\n",
      " 0.59898813 0.60162    0.60124351 0.60125774]\n",
      "[[1.11838485 0.81504791 1.0103963  1.00145454 1.10554499 1.0405041\n",
      "  1.16837045 1.03037073 1.14717056 1.06555764 0.984405   1.06577895\n",
      "  0.98321686 1.07774713 1.03997706 1.0414007 ]]\n",
      "{0: 278, 1: 1594}\n",
      "acc 0.27564102564102566\n",
      "(0.14993726474278546, 0.9958333333333333, 0.2606324972737186, None)\n",
      "\n",
      "4 loss 212911.26755785878\n",
      "dev set\n",
      "[0.60012727 0.5971022  0.59905154 0.59897216 0.60210282 0.60145331\n",
      " 0.60273404 0.60135454 0.60042034 0.59960405 0.59879251 0.60169871\n",
      " 0.59878029 0.6018258  0.60145097 0.6014652 ]\n",
      "[[1.11859305 0.81525488 1.01060415 1.00165972 1.10533907 1.04029817\n",
      "  1.168164   1.03016399 1.14737843 1.065765   0.98461264 1.06557122\n",
      "  0.98342464 1.07754117 1.03976962 1.04119326]]\n",
      "{0: 275, 1: 1597}\n",
      "acc 0.27403846153846156\n",
      "(0.14965560425798372, 0.9958333333333333, 0.26020685900925417, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision and recall and sign 2 penalty\n",
      "0 loss 213188.78584261215\n",
      "dev set\n",
      "[0.70096017 0.6979291  0.69988255 0.6997928  0.70127755 0.70062746\n",
      " 0.70190631 0.70052635 0.70125037 0.70043408 0.69962264 0.70087881\n",
      " 0.69961094 0.70099989 0.70062143 0.70063567]\n",
      "[[1.11775985 0.81442762 1.00977278 1.00083785 1.10616422 1.04112449\n",
      "  1.16899183 1.0309935  1.14654808 1.06493565 0.9837815  1.06640084\n",
      "  0.98259474 1.07836753 1.0405993  1.04202295]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n",
      "1 loss 213187.355134262\n",
      "dev set\n",
      "[0.70075118 0.69772254 0.69967552 0.69958717 0.70148481 0.7008348\n",
      " 0.70211423 0.70073425 0.70104329 0.70022714 0.69941578 0.70108584\n",
      " 0.69940403 0.70120723 0.70082866 0.70084289]\n",
      "[[1.11796882 0.81463425 1.0099799  1.00104371 1.10595702 1.04091717\n",
      "  1.16878393 1.03078538 1.14675563 1.06514048 0.98398623 1.06619361\n",
      "  0.98280133 1.0781602  1.0403922  1.04181585]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "2 loss 213185.93578361443\n",
      "dev set\n",
      "[0.70054281 0.69751635 0.69946881 0.69938229 0.7016913  0.70104124\n",
      " 0.7023213  0.70094127 0.70083627 0.7000203  0.699209   0.7012926\n",
      " 0.69919711 0.70141369 0.7010357  0.70104994]\n",
      "[[1.11817722 0.81484054 1.01018673 1.00124887 1.10575052 1.04071072\n",
      "  1.16857688 1.03057813 1.14696307 1.06534504 0.98419098 1.06598683\n",
      "  0.98300798 1.07795374 1.04018525 1.0416089 ]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "3 loss 213184.50866243968\n",
      "dev set\n",
      "[0.70033445 0.69730988 0.69926184 0.69917743 0.70189754 0.7012473\n",
      " 0.70252805 0.70114787 0.70062861 0.69981296 0.6990016  0.70149961\n",
      " 0.69898948 0.70161976 0.70124322 0.70125746]\n",
      "[[1.11838569 0.81504715 1.01039387 1.00145408 1.10554423 1.04050463\n",
      "  1.16837012 1.03037128 1.1471711  1.06555016 0.98439645 1.06577996\n",
      "  0.98321543 1.07774763 1.03997778 1.04140142]]\n",
      "{0: 608, 1: 1264}\n",
      "acc 0.44764957264957267\n",
      "(0.18591772151898733, 0.9791666666666666, 0.3125, None)\n",
      "\n",
      "4 loss 213183.0704946703\n",
      "dev set\n",
      "[0.70012591 0.69710293 0.69905445 0.69897239 0.70210362 0.70145305\n",
      " 0.70273459 0.70135414 0.70042009 0.69960486 0.69879336 0.701707\n",
      " 0.69878092 0.70182554 0.70145142 0.70146566]\n",
      "[[1.11859442 0.81525428 1.01060149 1.00165956 1.10533802 1.0402988\n",
      "  1.16816354 1.03016474 1.14737992 1.06575611 0.98460286 1.06557289\n",
      "  0.98342392 1.07754178 1.03976956 1.04119321]]\n",
      "{0: 606, 1: 1266}\n",
      "acc 0.4465811965811966\n",
      "(0.18562401263823064, 0.9791666666666666, 0.31208499335989376, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 213276.03741319955\n",
      "dev set\n",
      "[0.80096077 0.79792991 0.79988473 0.7997941  0.8012775  0.80062722\n",
      " 0.80190634 0.80052619 0.80125368 0.80054342 0.79965421 0.80087838\n",
      " 0.79962035 0.80099966 0.80054776 0.80056215]\n",
      "[[1.11775938 0.81442688 1.00977082 1.00083669 1.10616436 1.04112493\n",
      "  1.16899179 1.03099375 1.1465465  1.06491415 0.9837553  1.06640076\n",
      "  0.98258169 1.07836795 1.04102759 1.04245123]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "1 loss 213275.77069773903\n",
      "dev set\n",
      "[0.80075258 0.79772499 0.79968058 0.79959001 0.80148462 0.8008344\n",
      " 0.80211422 0.80073378 0.80104948 0.80040665 0.79948907 0.80108499\n",
      " 0.79942382 0.80120686 0.80065011 0.80066473]\n",
      "[[1.11796769 0.81463199 1.00997533 1.00104117 1.1059574  1.04091795\n",
      "  1.16878395 1.03078613 1.14675176 1.06509138 0.98392086 1.06619365\n",
      "  0.9827651  1.07816094 1.04123525 1.04265889]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "2 loss 213275.50685496067\n",
      "dev set\n",
      "[0.80054493 0.79752048 0.79947666 0.79938661 0.80169103 0.80104072\n",
      " 0.80232129 0.80094046 0.80084418 0.8002704  0.79932542 0.80129122\n",
      " 0.79922553 0.8014132  0.80075729 0.80077214]\n",
      "[[1.11817554 0.81483674 1.01017965 1.00124501 1.1057511  1.04071184\n",
      "  1.16857693 1.03057942 1.14695684 1.06526799 0.98408431 1.0659871\n",
      "  0.98294881 1.0779548  1.04144104 1.04286468]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "3 loss 213275.24113601126\n",
      "dev set\n",
      "[0.80033718 0.7973156  0.79927233 0.79918316 0.80189725 0.80124668\n",
      " 0.80252809 0.80114674 0.8006369  0.80013434 0.79916197 0.80149756\n",
      " 0.79902442 0.80161917 0.80087396 0.80088902]\n",
      "[[1.11838356 0.81504192 1.01038445 1.00144898 1.10554493 1.04050608\n",
      "  1.16837017 1.03037314 1.1471625  1.06544469 0.98424721 1.0657806\n",
      "  0.9831348  1.07774902 1.0416451  1.04306874]]\n",
      "{0: 950, 1: 922}\n",
      "acc 0.6036324786324786\n",
      "(0.227765726681128, 0.875, 0.3614457831325302, None)\n",
      "\n",
      "4 loss 213274.97261996384\n",
      "dev set\n",
      "[0.80012911 0.79711009 0.79906739 0.79897945 0.80210338 0.80145235\n",
      " 0.80273474 0.8013527  0.80042706 0.79999832 0.79899837 0.8017041\n",
      " 0.79882008 0.80182488 0.80100173 0.80101698]\n",
      "[[1.11859199 0.81524779 1.01058993 1.00165332 1.1053388  1.04030061\n",
      "  1.16816354 1.0301672  1.14736902 1.06562168 0.98441001 1.06557405\n",
      "  0.98332373 1.07754351 1.04184725 1.04327089]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 213330.86945282377\n",
      "dev set\n",
      "[0.90096201 0.8979306  0.89988606 0.89979506 0.90127578 0.90062728\n",
      " 0.90190594 0.90052617 0.90125689 0.90044858 0.89965151 0.90087923\n",
      " 0.89973801 0.90099973 0.90019261 0.90020685]\n",
      "[[1.1177582  0.81442617 1.00976943 1.00083567 1.10616716 1.04112513\n",
      "  1.16899258 1.0309939  1.14654589 1.0649273  0.98376353 1.06640012\n",
      "  0.98255893 1.07836812 1.04102728 1.04245093]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 213330.7230604717\n",
      "dev set\n",
      "[0.90075537 0.89772763 0.89968379 0.89959182 0.90148109 0.90083435\n",
      " 0.90211319 0.90073326 0.90105826 0.90026013 0.89948565 0.90108612\n",
      " 0.89973505 0.90120682 0.89998409 0.89999833]\n",
      "[[1.11796506 0.81462934 1.00997205 1.0010392  1.10596322 1.04091871\n",
      "  1.16878595 1.03078727 1.14674991 1.0651217  0.98394144 1.06619281\n",
      "  0.98270909 1.07816163 1.04123581 1.04265945]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 213330.57888450427\n",
      "dev set\n",
      "[0.90054935 0.89752545 0.89948192 0.89938926 0.90168585 0.90104042\n",
      " 0.90231961 0.90093927 0.90086039 0.90007232 0.89932203 0.90129236\n",
      " 0.89974093 0.90141292 0.8997762  0.89979044]\n",
      "[[1.11817141 0.81483184 1.01017436 1.00124216 1.10575975 1.04071337\n",
      "  1.1685802  1.03058185 1.1469533  1.06531549 0.98411769 1.06598637\n",
      "  0.98285643 1.07795624 1.04144386 1.04286751]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 213330.4346803226\n",
      "dev set\n",
      "[0.90034338 0.89732326 0.89927982 0.89918667 0.9018906  0.901246\n",
      " 0.9025258  0.90114473 0.90066264 0.89988469 0.89915921 0.90149845\n",
      " 0.89974948 0.90161853 0.89956826 0.8995825 ]\n",
      "[[1.11837787 0.81503447 1.01037705 1.0014453  1.10555623 1.04050862\n",
      "  1.16837471 1.03037712 1.14715675 1.0655093  0.98429352 1.06578031\n",
      "  0.98300335 1.07775142 1.0416521  1.04307575]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 213330.2901201872\n",
      "dev set\n",
      "[0.90013727 0.89712085 0.89907734 0.89898386 0.90209541 0.90145118\n",
      " 0.90273191 0.90134974 0.90046481 0.89969713 0.8989968  0.90170447\n",
      " 0.89975892 0.90182376 0.89936007 0.8993743 ]\n",
      "[[1.11858465 0.81523748 1.01058029 1.00164882 1.10535258 1.04030436\n",
      "  1.16816931 1.03017297 1.14736048 1.06570331 0.9844693  1.06557455\n",
      "  0.98315047 1.07754709 1.04186071 1.04328436]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "precision and recall and sign 2 penalty\n",
      "0 loss 213361.69929375686\n",
      "dev set\n",
      "[1.00139093 0.99792788 1.00028993 1.00001511 1.00127934 1.00062862\n",
      " 1.00190725 1.00052625 1.00167865 1.00086299 0.99963091 1.0008819\n",
      " 0.99961536 1.00100155 1.00062333 1.00063765]\n",
      "[[1.11765598 0.8144293  1.00956014 1.00062431 1.10647395 1.04135092\n",
      "  1.16936892 1.03121411 1.1464788  1.06475933 0.98377169 1.06665251\n",
      "  0.98258387 1.07863668 1.04082446 1.04224915]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 213361.69871806965\n",
      "dev set\n",
      "[1.00160795 0.99771676 1.00050363 1.00008088 1.00149698 1.00085065\n",
      " 1.00212211 1.00074824 1.00189435 1.00108352 0.99942983 1.00110229\n",
      " 0.99941157 1.00122103 1.00084538 1.00085965]\n",
      "[[1.117812   0.81464357 1.00956523 1.00062431 1.10661777 1.04138975\n",
      "  1.16955828 1.03123884 1.14665722 1.06483822 0.98397802 1.0667348\n",
      "  0.98279313 1.07874    1.04086249 1.04228936]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 213361.6980663713\n",
      "dev set\n",
      "[1.00183684 0.99750108 1.00074284 1.00026389 1.00172718 1.00109064\n",
      " 1.00234625 1.00098934 1.00212035 1.00131984 0.99922132 1.0013383\n",
      " 0.99919978 1.00145511 1.00108543 1.00109951]\n",
      "[[1.1180018  0.81486655 1.00958875 1.00062461 1.10679919 1.04147337\n",
      "  1.16976866 1.03130212 1.14686128 1.06496652 0.98420207 1.06686634\n",
      "  0.98302032 1.07889027 1.04094504 1.04237479]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 213361.69732003802\n",
      "dev set\n",
      "[1.0020809  0.99727903 1.00100826 1.00050728 1.00197327 1.0013515\n",
      " 1.00258275 1.00125235 1.00235984 1.00157511 0.99900328 1.00159311\n",
      " 0.99897778 1.00170707 1.00134642 1.00136017]\n",
      "[[1.11822277 0.81510102 1.00965584 1.00062959 1.10701506 1.04161446\n",
      "  1.17000038 1.03142254 1.14709014 1.06514557 0.98444548 1.06704785\n",
      "  0.98326729 1.07908545 1.04108513 1.0425176 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 213361.69646623702\n",
      "dev set\n",
      "[1.00234142 0.99704986 1.00129821 1.000792   1.00223645 1.00163337\n",
      " 1.00283306 1.00153709 1.00261425 1.00184996 0.99877525 1.00186739\n",
      " 0.9987451  1.00197778 1.00162843 1.00164177]\n",
      "[[1.11847286 0.81534816 1.00978967 1.0006588  1.10726263 1.04181403\n",
      "  1.17025362 1.03160619 1.14734322 1.06537131 0.98470759 1.06727517\n",
      "  0.98353345 1.07932126 1.04128395 1.04271844]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = np.empty([len(LF_l)],dtype=np.float64)\n",
    "acc.fill(0.25)\n",
    "rec =  np.empty([len(LF_l)],dtype=np.float64)\n",
    "rec.fill(0.35*train_L_S.shape[0])\n",
    "print(rec)\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [64,128,256,512]:\n",
    "    for i in np.linspace(0.6,1,5):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = acc ,LF_rec = rec,\\\n",
    "                                    pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=11,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295.\n",
      " 1295. 1295. 1295. 1295.]\n",
      "batch-size: 64 alpha-init: 0.6\n",
      "recall and sign 2 penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 1242346.3576840137\n",
      "dev set\n",
      "[0.59966419 0.59662467 0.59861625 0.59852027 0.60260125 0.60197537\n",
      " 0.60325263 0.60187818 0.5999139  0.59909635 0.59828474 0.60192128\n",
      " 0.59827266 0.60234796 0.60196187 0.6019761 ]\n",
      "[[1.11906896 0.81573464 1.01104918 1.00212258 1.10485233 1.03977548\n",
      "  1.16764946 1.02963845 1.14787911 1.06627299 0.98509706 1.06512126\n",
      "  0.98392353 1.07701838 1.03926376 1.0406874 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "1 loss 1242323.0325994184\n",
      "dev set\n",
      "[0.59817455 0.5950781  0.59712625 0.59703654 0.60412528 0.60350861\n",
      " 0.6047882  0.60341265 0.59833777 0.59751978 0.59670813 0.60320012\n",
      " 0.59669131 0.60388211 0.60353535 0.60354959]\n",
      "[[1.1205784  0.81728596 1.01255366 1.00362401 1.10333518 1.03823884\n",
      "  1.16611921 1.0281014  1.14945499 1.0678478  0.98666936 1.06359618\n",
      "  0.9855036  1.07548098 1.03769335 1.039117  ]]\n",
      "{0: 268, 1: 1604}\n",
      "acc 0.2702991452991453\n",
      "(0.14900249376558602, 0.9958333333333333, 0.2592190889370933, None)\n",
      "\n",
      "2 loss 1242299.0915429061\n",
      "dev set\n",
      "[0.59669196 0.59351834 0.59563232 0.59555282 0.60562886 0.60501396\n",
      " 0.6062999  0.60491652 0.596742   0.59592375 0.59511208 0.60453407\n",
      " 0.59508655 0.60538913 0.6051234  0.60513764]\n",
      "[[1.12208691 0.81885316 1.01406664 1.00513095 1.10183377 1.03672599\n",
      "  1.16461034 1.02659215 1.15105354 1.06944698 0.98826811 1.06205708\n",
      "  0.98711233 1.07396686 1.03610935 1.03753299]]\n",
      "{0: 249, 1: 1623}\n",
      "acc 0.26121794871794873\n",
      "(0.1478743068391867, 1.0, 0.2576489533011272, None)\n",
      "\n",
      "3 loss 1242274.5576285806\n",
      "dev set\n",
      "[0.59521227 0.59194816 0.5941349  0.59406956 0.60711142 0.60649175\n",
      " 0.6077903  0.60639119 0.59512795 0.59431007 0.59349838 0.60588704\n",
      " 0.59346057 0.60686934 0.60672449 0.60673873]\n",
      "[[1.12359826 0.82043344 1.01558756 1.00664289 1.10034852 1.03523593\n",
      "  1.16311902 1.025108   1.15267287 1.07106869 0.98989021 1.06050738\n",
      "  0.9887465  1.07247506 1.0345135  1.03593715]]\n",
      "{0: 237, 1: 1635}\n",
      "acc 0.2548076923076923\n",
      "(0.14678899082568808, 1.0, 0.256, None)\n",
      "\n",
      "4 loss 1242249.4376610217\n",
      "dev set\n",
      "[0.5937343  0.59036873 0.59263432 0.59258706 0.60857287 0.60794201\n",
      " 0.60926033 0.60783701 0.59349749 0.59267975 0.59186816 0.60726168\n",
      " 0.59181481 0.60832281 0.60833773 0.60835197]\n",
      "[[1.12511343 0.82202559 1.017116   1.00815944 1.09887932 1.03376817\n",
      "  1.16164381 1.02364793 1.15431184 1.07271179 0.99153419 1.05894851\n",
      "  0.99040434 1.07100507 1.03290685 1.03433051]]\n",
      "{0: 221, 1: 1651}\n",
      "acc 0.24626068376068377\n",
      "(0.145366444579043, 1.0, 0.2538339502908514, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.7\n",
      "recall and sign 2 penalty\n",
      "0 loss 1242616.9548273939\n",
      "dev set\n",
      "[0.69966524 0.69663719 0.69863909 0.69852092 0.70259612 0.70197004\n",
      " 0.70325423 0.7018766  0.69995962 0.69913805 0.69832824 0.70212647\n",
      " 0.69832135 0.70234282 0.70193073 0.70194498]\n",
      "[[1.11906753 0.81572306 1.0110278  1.00212092 1.10486333 1.03978456\n",
      "  1.16764937 1.02964163 1.14783635 1.06619373 0.98496896 1.06509764\n",
      "  0.98386591 1.0770271  1.03931087 1.0407345 ]]\n",
      "{0: 598, 1: 1274}\n",
      "acc 0.4423076923076923\n",
      "(0.18445839874411302, 0.9791666666666666, 0.3104359313077939, None)\n",
      "\n",
      "1 loss 1242606.1523360526\n",
      "dev set\n",
      "[0.69816929 0.69508922 0.69715592 0.69702865 0.70411728 0.70350065\n",
      " 0.7047906  0.70340833 0.6983898  0.6975692  0.69675277 0.70361835\n",
      " 0.69674684 0.70387445 0.70350009 0.70351434]\n",
      "[[1.12058187 0.81727704 1.01252651 1.0036293  1.10335547 1.03825557\n",
      "  1.16612264 1.02811293 1.1493958  1.06769372 0.98647199 1.06356343\n",
      "  0.98543293 1.07549704 1.03774791 1.03917154]]\n",
      "{0: 572, 1: 1300}\n",
      "acc 0.4284188034188034\n",
      "(0.18076923076923077, 0.9791666666666666, 0.3051948051948052, None)\n",
      "\n",
      "2 loss 1242594.6444137385\n",
      "dev set\n",
      "[0.69666875 0.69351508 0.69565435 0.69552614 0.70562091 0.70500435\n",
      " 0.70630537 0.70490943 0.6967734  0.69595351 0.69512102 0.70512689\n",
      " 0.69511849 0.70537983 0.70510845 0.7051227 ]\n",
      "[[1.12210591 0.81886028 1.01404765 1.00515273 1.10186086 1.03675063\n",
      "  1.16461582 1.02661406 1.15100211 1.06924452 0.9880352  1.06202319\n",
      "  0.98706259 1.0739906  1.03614319 1.03756683]]\n",
      "{0: 533, 1: 1339}\n",
      "acc 0.4075854700854701\n",
      "(0.1755041075429425, 0.9791666666666666, 0.2976567447751741, None)\n",
      "\n",
      "3 loss 1242582.4341058691\n",
      "dev set\n",
      "[0.69515941 0.69191795 0.69413621 0.69401404 0.70710647 0.70648124\n",
      " 0.70780172 0.70638142 0.69511428 0.6942959  0.69345017 0.70664905\n",
      " 0.6934421  0.70685908 0.7067519  0.70676615]\n",
      "[[1.1236435  0.82046961 1.01558936 1.00669049 1.10037986 1.03526889\n",
      "  1.16312419 1.02514186 1.15265227 1.07084474 0.98965266 1.06047889\n",
      "  0.98874732 1.07250694 1.03450203 1.03592568]]\n",
      "{0: 509, 1: 1363}\n",
      "acc 0.39476495726495725\n",
      "(0.1724137931034483, 0.9791666666666666, 0.2932002495321273, None)\n",
      "\n",
      "4 loss 1242569.5053301451\n",
      "dev set\n",
      "[0.69364028 0.69029943 0.69260252 0.69249281 0.70857391 0.70793128\n",
      " 0.70928078 0.70782471 0.69341381 0.69259418 0.69174011 0.70819178\n",
      " 0.69172198 0.70831218 0.70842548 0.70843972]\n",
      "[[1.12519542 0.82210335 1.01715053 1.00824201 1.09891235 1.03380986\n",
      "  1.16164599 1.02369509 1.154344   1.07249319 0.99132141 1.05893141\n",
      "  0.99048254 1.0710456  1.03282804 1.0342517 ]]\n",
      "{0: 495, 1: 1377}\n",
      "acc 0.3872863247863248\n",
      "(0.17066085693536673, 0.9791666666666666, 0.29066171923314776, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.8\n",
      "recall and sign 2 penalty\n",
      "0 loss 1242707.9016483016\n",
      "dev set\n",
      "[0.79970893 0.79670212 0.79873043 0.79854276 0.80256898 0.80195896\n",
      " 0.80324822 0.80187144 0.8005418  0.80019764 0.79913254 0.80213307\n",
      " 0.79892596 0.80233221 0.80069976 0.80071461]\n",
      "[[1.11902995 0.81566314 1.01094479 1.0021008  1.10491492 1.03980584\n",
      "  1.16766401 1.02965237 1.1475625  1.06554418 0.9843227  1.0650929\n",
      "  0.98319517 1.07704746 1.0419598  1.04338326]]\n",
      "{0: 943, 1: 929}\n",
      "acc 0.5998931623931624\n",
      "(0.22604951560818085, 0.875, 0.35928143712574856, None)\n",
      "\n",
      "1 loss 1242706.125882814\n",
      "dev set\n",
      "[0.79825866 0.79522427 0.79733378 0.79707752 0.80406645 0.80348063\n",
      " 0.80477588 0.80339645 0.79958655 0.79977874 0.79839188 0.80361994\n",
      " 0.7981698  0.80385531 0.80107941 0.8010949 ]\n",
      "[[1.12050463 0.81715362 1.01236674 1.00358488 1.10345713 1.03830308\n",
      "  1.16616122 1.02814472 1.14881915 1.06631762 0.98511256 1.06356611\n",
      "  0.98405644 1.0755424  1.04302838 1.04445168]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "2 loss 1242704.3019713426\n",
      "dev set\n",
      "[0.79680051 0.79371779 0.79591294 0.79560108 0.80555129 0.80497785\n",
      " 0.80628487 0.80489276 0.79854764 0.79936417 0.7976386  0.80511016\n",
      " 0.79737978 0.80535443 0.80161483 0.80163093]\n",
      "[[1.12199282 0.81867708 1.01381761 1.00508578 1.10200905 1.03682571\n",
      "  1.16467779 1.02666927 1.15011374 1.06709625 0.9859124  1.06204384\n",
      "  0.98502261 1.07406243 1.04399255 1.04541567]]\n",
      "{0: 931, 1: 941}\n",
      "acc 0.593482905982906\n",
      "(0.22316684378320936, 0.875, 0.35563082133784935, None)\n",
      "\n",
      "3 loss 1242702.3895118833\n",
      "dev set\n",
      "[0.79532828 0.79218197 0.79446902 0.79411219 0.8070228  0.80645111\n",
      " 0.80777936 0.80636231 0.79746485 0.79895108 0.79687796 0.80660193\n",
      " 0.79642292 0.80683002 0.80232917 0.80234582]\n",
      "[[1.12350033 0.82023417 1.01529619 1.00660459 1.10057147 1.03537216\n",
      "  1.16320748 1.02522204 1.15145077 1.06788347 0.98672067 1.06052751\n",
      "  0.9860938  1.07260606 1.04483455 1.04625747]]\n",
      "{0: 921, 1: 951}\n",
      "acc 0.5881410256410257\n",
      "(0.22082018927444794, 0.875, 0.3526448362720403, None)\n",
      "\n",
      "4 loss 1242700.3536381482\n",
      "dev set\n",
      "[0.79383872 0.79061443 0.79300073 0.79260947 0.80848123 0.80790067\n",
      " 0.80926129 0.80780573 0.79626694 0.79853765 0.79608976 0.80809487\n",
      " 0.79533069 0.80828235 0.803236   0.80325313]\n",
      "[[1.12503017 0.82182716 1.01680362 1.0081425  1.09914391 1.03394148\n",
      "  1.16174744 1.02380144 1.15283529 1.06868179 0.98753843 1.05901733\n",
      "  0.98727634 1.07117235 1.04552877 1.04695147]]\n",
      "{0: 905, 1: 967}\n",
      "acc 0.5806623931623932\n",
      "(0.21820062047569805, 0.8791666666666667, 0.3496271748135874, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.9\n",
      "recall and sign 2 penalty\n",
      "0 loss 1242763.054145278\n",
      "dev set\n",
      "[0.89972471 0.89672798 0.8987667  0.8985574  0.90242612 0.90194001\n",
      " 0.90319372 0.90186582 0.90036395 0.89975288 0.8990156  0.90215955\n",
      " 0.89973145 0.90231423 0.89895773 0.89897201]\n",
      "[[1.11900818 0.81563597 1.01090233 1.00208234 1.1051225  1.03985046\n",
      "  1.16776293 1.02966955 1.14761053 1.06576254 0.98452437 1.06506401\n",
      "  0.9829988  1.07709005 1.04234777 1.04377141]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 1242762.0658843773\n",
      "dev set\n",
      "[0.89829567 0.89529833 0.89741186 0.89709786 0.9037991  0.90339644\n",
      " 0.904651   0.90334266 0.8992485  0.89890438 0.8981713  0.90364235\n",
      " 0.89976251 0.90377471 0.89757481 0.89758913]\n",
      "[[1.12045958 0.81708148 1.01227987 1.00356056 1.10385615 1.03847944\n",
      "  1.1663838  1.02825904 1.14889471 1.06675623 0.98551933 1.06353646\n",
      "  0.98353631 1.07571194 1.04386459 1.04528822]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 1242761.0896406875\n",
      "dev set\n",
      "[0.8968642  0.89385698 0.89604117 0.89562734 0.90517048 0.90481632\n",
      " 0.90609141 0.90477847 0.89812491 0.89806619 0.89732983 0.90512775\n",
      " 0.89978897 0.90519906 0.89620948 0.89622385]\n",
      "[[1.12192333 0.81854768 1.01368218 1.00505974 1.10258787 1.03715443\n",
      "  1.16502358 1.02690231 1.15019108 1.06774886 0.98652217 1.06203516\n",
      "  0.98408477 1.07437962 1.04539266 1.0468163 ]]\n",
      "{0: 1096, 1: 776}\n",
      "acc 0.6677350427350427\n",
      "(0.2538659793814433, 0.8208333333333333, 0.38779527559055116, None)\n",
      "\n",
      "3 loss 1242760.0940966338\n",
      "dev set\n",
      "[0.89542665 0.89240677 0.89465921 0.89414748 0.90653625 0.90620548\n",
      " 0.90752079 0.9061793  0.89699278 0.89723634 0.8964945  0.90659894\n",
      " 0.89981159 0.9065929  0.89481017 0.89482459]\n",
      "[[1.12340274 0.82003148 1.01510454 1.00657799 1.10132299 1.03586572\n",
      "  1.16367471 1.02558885 1.15150114 1.06874244 0.98752921 1.06056064\n",
      "  0.984638   1.07308368 1.04693512 1.04835876]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "4 loss 1242759.0759690995\n",
      "dev set\n",
      "[0.89398243 0.89094926 0.89326806 0.89265924 0.90789533 0.90756631\n",
      " 0.90894116 0.90754764 0.89585266 0.8964147  0.89566653 0.90807134\n",
      " 0.89983177 0.90795858 0.89338201 0.89339648]\n",
      "[[1.12489808 0.82153103 1.01654463 1.00811407 1.10006326 1.03460949\n",
      "  1.16233501 1.02431445 1.15282477 1.06973703 0.98853902 1.05911266\n",
      "  0.98519314 1.07182038 1.04849393 1.04991756]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 1.0\n",
      "recall and sign 2 penalty\n",
      "0 loss 1242794.3086178505\n",
      "dev set\n",
      "[1.00305598 0.99647332 1.00199261 1.00039342 1.00295804 1.00239262\n",
      " 1.00351744 1.00229625 1.0033113  1.00259897 0.99848137 1.00261527\n",
      " 0.99836712 1.00271785 1.00238779 1.00240082]\n",
      "[[1.11852217 0.81599058 1.00979612 1.00062455 1.10728357 1.04180935\n",
      "  1.17046742 1.03161318 1.14748172 1.06534819 0.98506851 1.06725167\n",
      "  0.98395326 1.07930037 1.04127988 1.04271273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 1242794.2991849962\n",
      "dev set\n",
      "[1.00567548 0.99444771 1.00490842 1.00354565 1.00560324 1.00520037\n",
      " 1.00601612 1.00513088 1.00586279 1.00534892 0.99675969 1.0053605\n",
      " 0.99653644 1.00543189 1.0051969  1.00520625]\n",
      "[[1.12113552 0.81837243 1.01218445 1.00184673 1.10989332 1.04433805\n",
      "  1.17306255 1.03411415 1.15009048 1.06792288 0.98718332 1.06982909\n",
      "  0.98620584 1.08189124 1.04380729 1.04524358]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 1242794.280764615\n",
      "dev set\n",
      "[1.00866844 0.99219657 1.00811028 1.00707845 1.00861405 1.00832349\n",
      " 1.00891336 1.00827274 1.00880395 1.00843332 0.99486749 1.00844169\n",
      " 0.99452714 1.00849095 1.00832097 1.00832778]\n",
      "[[1.1244219  0.82111427 1.01561253 1.00539887 1.11319323 1.04771633\n",
      "  1.17627342 1.03750452 1.15333664 1.07127533 0.98955132 1.07317933\n",
      "  0.98872102 1.08522604 1.04718618 1.04862081]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 1242794.2510706398\n",
      "dev set\n",
      "[1.01181601 0.98982236 1.01139456 1.01059179 1.01177216 1.0115545\n",
      " 1.01199512 1.01151602 1.01191697 1.01164036 0.99290618 1.01164664\n",
      " 0.99244854 1.0116804  1.01155259 1.01155775]\n",
      "[[1.12795601 0.82404126 1.01926914 1.00925872 1.11673748 1.05132577\n",
      "  1.17974806 1.04112489 1.15683932 1.07486286 0.99201925 1.076765\n",
      "  0.99133516 1.08879841 1.05079617 1.05222932]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 1242794.2084607496\n",
      "dev set\n",
      "[1.01502558 0.98738171 1.01469656 1.01405129 1.01498722 1.01481853\n",
      " 1.01515848 1.01478837 1.0151032  1.01488986 0.99092007 1.01489475\n",
      " 0.99034634 1.01491645 1.01481704 1.01482107]\n",
      "[[1.13159202 0.82706344 1.0229937  1.01313787 1.12037965 1.05501461\n",
      "  1.18334084 1.04482171 1.16045303 1.07853692 0.99452338 1.08043772\n",
      "  0.99398309 1.09246057 1.05448541 1.05591749]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.6\n",
      "recall and sign 2 penalty\n",
      "0 loss 641472.016850791\n",
      "dev set\n",
      "[0.60039562 0.59737345 0.59933317 0.59924291 0.60183893 0.60119658\n",
      " 0.60247399 0.60109617 0.60068538 0.59986868 0.5990571  0.60136649\n",
      " 0.59904548 0.60156903 0.6011875  0.60120173]\n",
      "[[1.11832616 0.81498387 1.01032437 1.00139064 1.10560648 1.04055511\n",
      "  1.16842537 1.03042301 1.14711073 1.06550213 0.98434062 1.06585009\n",
      "  0.98315676 1.07779813 1.04003465 1.04145829]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "1 loss 641460.3994261825\n",
      "dev set\n",
      "[0.59961943 0.59659728 0.59856809 0.59847949 0.60261288 0.60197391\n",
      " 0.60325292 0.60187481 0.59990139 0.59908443 0.59827279 0.60207498\n",
      " 0.59826037 0.60234652 0.60197131 0.60198554]\n",
      "[[1.11910556 0.81576107 1.01109273 1.00215807 1.10483459 1.03977703\n",
      "  1.16764749 1.02964339 1.14789442 1.06628631 0.98512218 1.06507838\n",
      "  0.98394004 1.07701992 1.03925155 1.04067519]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "2 loss 641448.6279861302\n",
      "dev set\n",
      "[0.59884659 0.595817   0.597802   0.59771613 0.60338228 0.60274441\n",
      " 0.60402548 0.6026457  0.59911207 0.59829491 0.59748324 0.60279189\n",
      " 0.59746897 0.60311736 0.6027591  0.60277333]\n",
      "[[1.11988332 0.81654303 1.01186325 1.00292682 1.104066   1.03900491\n",
      "  1.16687565 1.0288711  1.14868415 1.06707699 0.98591115 1.06430239\n",
      "  0.98473122 1.07624754 1.03846466 1.0398883 ]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "3 loss 641436.7071504724\n",
      "dev set\n",
      "[0.59807521 0.59503355 0.59703493 0.59695284 0.60414662 0.60350799\n",
      " 0.60479237 0.6034091  0.59831784 0.59750054 0.59668881 0.60351615\n",
      " 0.59667168 0.60388147 0.60355052 0.60356475]\n",
      "[[1.12066117 0.81732883 1.01263592 1.00369692 1.10330121 1.03823867\n",
      "  1.1661087  1.0281055  1.14947954 1.06787379 0.98670664 1.0635232\n",
      "  0.98552952 1.07548092 1.03767439 1.03909804]]\n",
      "{0: 267, 1: 1605}\n",
      "acc 0.26976495726495725\n",
      "(0.14890965732087227, 0.9958333333333333, 0.25907859078590784, None)\n",
      "\n",
      "4 loss 641424.6371610075\n",
      "dev set\n",
      "[0.59730456 0.59424735 0.59626689 0.5961896  0.60490579 0.60426469\n",
      " 0.60555396 0.60416521 0.59751899 0.59670155 0.59588979 0.60426148\n",
      " 0.5958688  0.60463888 0.60434536 0.60435959]\n",
      "[[1.12143978 0.81811809 1.01341071 1.00446834 1.10254037 1.03747818\n",
      "  1.1653461  1.0273462  1.15028034 1.06867645 0.98750821 1.06274132\n",
      "  0.9863345  1.07471993 1.03688098 1.03830463]]\n",
      "{0: 262, 1: 1610}\n",
      "acc 0.2670940170940171\n",
      "(0.1484472049689441, 0.9958333333333333, 0.25837837837837835, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.7\n",
      "recall and sign 2 penalty\n",
      "0 loss 641739.4886623386\n",
      "dev set\n",
      "[0.70039506 0.69737727 0.6993397  0.69924173 0.70183793 0.70119485\n",
      " 0.70247463 0.7010955  0.70069793 0.69988049 0.69907069 0.70142461\n",
      " 0.69905932 0.70156736 0.70117924 0.70119348]\n",
      "[[1.1183267  0.8149803  1.01031828 1.00139142 1.10560877 1.04055792\n",
      "  1.16842485 1.03042414 1.14709825 1.06548425 0.98429824 1.06584442\n",
      "  0.98313919 1.07780083 1.04004807 1.04147171]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "1 loss 641734.1369705517\n",
      "dev set\n",
      "[0.69961803 0.69660117 0.69857803 0.69847565 0.7026109  0.70197116\n",
      " 0.70325383 0.70187343 0.69991717 0.69910036 0.69829018 0.70218911\n",
      " 0.69827818 0.70234387 0.70196149 0.70197573]\n",
      "[[1.11910689 0.8157577  1.01108361 1.00216105 1.10483952 1.03978215\n",
      "  1.16764766 1.02964648 1.14787662 1.06625171 0.98505469 1.06507046\n",
      "  0.98391536 1.07702483 1.03926924 1.04069288]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "2 loss 641728.6155481632\n",
      "dev set\n",
      "[0.69884163 0.69581761 0.69781132 0.697707   0.70337999 0.70274093\n",
      " 0.70402704 0.70264356 0.69912293 0.69830745 0.69749602 0.70295846\n",
      " 0.69748212 0.70311401 0.70275214 0.70276638]\n",
      "[[1.11988791 0.81654332 1.011855   1.00293447 1.104073   1.03901231\n",
      "  1.16687638 1.02887668 1.14866728 1.06703247 0.98582819 1.06429436\n",
      "  0.98470911 1.07625465 1.03847882 1.03990246]]\n",
      "{0: 582, 1: 1290}\n",
      "acc 0.4337606837606838\n",
      "(0.1821705426356589, 0.9791666666666666, 0.30718954248366015, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 641722.9231608228\n",
      "dev set\n",
      "[0.69806376 0.69502756 0.69704002 0.69693575 0.70414473 0.703504\n",
      " 0.70479523 0.70340623 0.69831636 0.69750284 0.6966877  0.70373177\n",
      " 0.69667247 0.7038776  0.70355255 0.70356678]\n",
      "[[1.12067176 0.81733623 1.01263207 1.00371173 1.10330967 1.03824842\n",
      "  1.1661095  1.02811396 1.14946976 1.0678262  0.98661657 1.06351687\n",
      "  0.98551854 1.07549032 1.03767792 1.03910157]]\n",
      "{0: 571, 1: 1301}\n",
      "acc 0.42788461538461536\n",
      "(0.180630284396618, 0.9791666666666666, 0.30499675535366644, None)\n",
      "\n",
      "4 loss 641717.0488815666\n",
      "dev set\n",
      "[0.69728363 0.69423146 0.69626433 0.69616196 0.70490503 0.70426035\n",
      " 0.70555884 0.70416164 0.69749868 0.69668732 0.69586402 0.70450861\n",
      " 0.69585005 0.70463464 0.70436237 0.70437661]\n",
      "[[1.12145915 0.81813597 1.01341456 1.00449279 1.10254961 1.03749041\n",
      "  1.16534633 1.02735789 1.15028367 1.06863259 0.98741897 1.06273831\n",
      "  0.98634253 1.07473177 1.03686726 1.03829091]]\n",
      "{0: 557, 1: 1315}\n",
      "acc 0.4204059829059829\n",
      "(0.17870722433460076, 0.9791666666666666, 0.30225080385852093, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.8\n",
      "recall and sign 2 penalty\n",
      "0 loss 641828.315982256\n",
      "dev set\n",
      "[0.80040208 0.7973917  0.79936898 0.7992448  0.80183301 0.8011914\n",
      " 0.80247449 0.8010937  0.80087065 0.80035584 0.79937514 0.80142219\n",
      " 0.79924672 0.80156405 0.80067558 0.80069025]\n",
      "[[1.11832104 0.81496706 1.01029189 1.00138862 1.10561867 1.04056417\n",
      "  1.16842574 1.03042744 1.14701683 1.06521395 0.98402241 1.06584363\n",
      "  0.98290513 1.07780681 1.04144571 1.04286929]]\n",
      "{0: 956, 1: 916}\n",
      "acc 0.6057692307692307\n",
      "(0.22816593886462883, 0.8708333333333333, 0.3615916955017301, None)\n",
      "\n",
      "1 loss 641827.3730363456\n",
      "dev set\n",
      "[0.79963544 0.79662967 0.79863465 0.79848396 0.8025999  0.80196487\n",
      " 0.80325259 0.80186944 0.80027114 0.80006573 0.79891031 0.80218459\n",
      " 0.7986728  0.80233786 0.80089551 0.80091065]\n",
      "[[1.11909255 0.8157319  1.01103316 1.00215363 1.10486202 1.0397955\n",
      "  1.16765214 1.02965537 1.14771102 1.06569702 0.98448719 1.06507122\n",
      "  0.98342539 1.07703756 1.04209289 1.04351641]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "2 loss 641826.4214445661\n",
      "dev set\n",
      "[0.79886873 0.79585912 0.79789243 0.79772    0.80336398 0.80273238\n",
      " 0.80402536 0.80263778 0.79964293 0.79977666 0.79843711 0.80294872\n",
      " 0.79820239 0.80310583 0.80118064 0.80119623]\n",
      "[[1.1198658  0.81650637 1.01178349 1.00292322 1.1041074  1.03903304\n",
      "  1.16688443 1.02889179 1.14841562 1.06618223 0.98495775 1.06429919\n",
      "  0.98398547 1.07627444 1.04270928 1.04413273]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "3 loss 641825.4502554344\n",
      "dev set\n",
      "[0.79809933 0.79508045 0.79714336 0.79695267 0.80412472 0.80349367\n",
      " 0.80479389 0.80339901 0.79898506 0.79948829 0.79795942 0.8037138\n",
      " 0.79769298 0.80386768 0.80153276 0.80154663]\n",
      "[[1.12064332 0.81729011 1.01254192 1.00369767 1.10335537 1.03827685\n",
      "  1.16612081 1.02813582 1.14913164 1.06667032 0.98543202 1.0635283\n",
      "  0.98458142 1.07551753 1.04329348 1.04471685]]\n",
      "{0: 939, 1: 933}\n",
      "acc 0.5977564102564102\n",
      "(0.22508038585209003, 0.875, 0.35805626598465473, None)\n",
      "\n",
      "4 loss 641824.4486094872\n",
      "dev set\n",
      "[0.79732597 0.7942934  0.79638754 0.7961817  0.80488202 0.80424872\n",
      " 0.80555879 0.80415334 0.79830837 0.79920005 0.79747831 0.80447955\n",
      " 0.79712178 0.80462342 0.80195668 0.80197059]\n",
      "[[1.12142626 0.81808336 1.01330834 1.00447723 1.10260599 1.0375268\n",
      "  1.16536034 1.02738701 1.1498602  1.06716185 0.98590964 1.06275878\n",
      "  0.98521259 1.07476669 1.04384166 1.04526496]]\n",
      "{0: 930, 1: 942}\n",
      "acc 0.592948717948718\n",
      "(0.2229299363057325, 0.875, 0.35532994923857875, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.9\n",
      "recall and sign 2 penalty\n",
      "0 loss 641883.2892503497\n",
      "dev set\n",
      "[0.9004065  0.89739654 0.89938178 0.89925089 0.9017991  0.9011867\n",
      " 0.90246517 0.90109245 0.90084229 0.90011293 0.89935565 0.90142955\n",
      " 0.89967606 0.90155962 0.8996437  0.89965795]\n",
      "[[1.11831581 0.81496177 1.0102774  1.00138171 1.10567118 1.04057603\n",
      "  1.16844345 1.03043158 1.14702807 1.06532461 0.98411292 1.06583455\n",
      "  0.98279672 1.07781806 1.04159327 1.04301691]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 641882.7666493972\n",
      "dev set\n",
      "[0.89964738 0.89664624 0.8986608  0.89849418 0.90253231 0.90194538\n",
      " 0.90322904 0.90185761 0.90020371 0.89958083 0.89887157 0.9021922\n",
      " 0.89969653 0.90231934 0.89889397 0.89890822]\n",
      "[[1.11907975 0.81571561 1.01100442 1.00214257 1.1049697  1.03984025\n",
      "  1.16769734 1.02968264 1.14773284 1.06592003 0.98466633 1.06505949\n",
      "  0.98315641 1.07708023 1.04236374 1.04378738]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 641882.2410588935\n",
      "dev set\n",
      "[0.89888982 0.89589189 0.89793386 0.89773403 0.90326584 0.90269431\n",
      " 0.90398762 0.9026118  0.89956371 0.89905191 0.89838625 0.90295219\n",
      " 0.89971937 0.90306944 0.89815259 0.89816388]\n",
      "[[1.11984498 0.81647593 1.01173982 1.00290952 1.10426698 1.03911734\n",
      "  1.16695791 1.02894854 1.14844021 1.06651544 0.98522424 1.06429069\n",
      "  0.98352472 1.07635515 1.04313708 1.04456072]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "3 loss 641881.7244507719\n",
      "dev set\n",
      "[0.89813148 0.8951344  0.89720269 0.89697091 0.90399835 0.90343487\n",
      " 0.90474292 0.90335653 0.89892166 0.89852547 0.89790171 0.903715\n",
      " 0.89974054 0.90381125 0.89744578 0.89745708]\n",
      "[[1.12061383 0.81724187 1.01248196 1.00368214 1.10356469 1.03840473\n",
      "  1.16622222 1.02822647 1.14915133 1.06711175 0.98578465 1.06352856\n",
      "  0.98389847 1.07564034 1.04391398 1.04533764]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 641881.207834328\n",
      "dev set\n",
      "[0.89737138 0.89437403 0.89646786 0.89620499 0.90472946 0.90416771\n",
      " 0.90549585 0.90409249 0.89827707 0.89800114 0.89741857 0.90447565\n",
      " 0.89975928 0.9045454  0.896732   0.8967451 ]\n",
      "[[1.12138719 0.81801317 1.01323028 1.00446026 1.10286335 1.03770127\n",
      "  1.16548902 1.0275152  1.14986668 1.06770929 0.98634693 1.06277327\n",
      "  0.98427601 1.0749347  1.0446942  1.04611786]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 1.0\n",
      "recall and sign 2 penalty\n",
      "0 loss 641914.3100505501\n",
      "dev set\n",
      "[1.00201359 0.99734421 1.00088108 1.00004839 1.0019049  1.00127123\n",
      " 1.00251906 1.00116737 1.00229477 1.00150093 0.99914553 1.00151928\n",
      " 0.99909634 1.00163526 1.00126595 1.00128022]\n",
      "[[1.11791412 0.81503141 1.00957676 1.00062431 1.10670237 1.04142232\n",
      "  1.16975205 1.03126654 1.14681051 1.06488128 0.98429211 1.06677891\n",
      "  0.98312189 1.0787924  1.04089483 1.04232233]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 641914.3070143061\n",
      "dev set\n",
      "[1.00305772 0.996455   1.00204848 1.00099521 1.00296016 1.00240165\n",
      " 1.00351827 1.00230951 1.00331241 1.00260367 0.9983301  1.00261977\n",
      " 0.99825349 1.00272136 1.00239698 1.00240958]\n",
      "[[1.118794   0.81600835 1.00997554 1.0006487  1.10755814 1.0420359\n",
      "  1.17069588 1.03182509 1.14773409 1.06560326 0.98524254 1.0675086\n",
      "  0.98410443 1.07956713 1.04150569 1.04294053]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 641914.3022320623\n",
      "dev set\n",
      "[1.004299   0.99547189 1.00343926 1.00248223 1.00421504 1.00374204\n",
      " 1.00469881 1.00366361 1.004519   1.00391349 0.99741248 1.00392709\n",
      " 0.99730377 1.00401241 1.00373808 1.00374877]\n",
      "[[1.1200506  0.81714609 1.01112732 1.0012959  1.10881515 1.0432589\n",
      "  1.17193477 1.03303373 1.14898329 1.06684823 0.98636079 1.06875477\n",
      "  0.9852582  1.08081898 1.04272803 1.04416462]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 641914.2952688826\n",
      "dev set\n",
      "[1.00567755 0.99441502 1.00495125 1.00411927 1.00560592 1.00520813\n",
      " 1.0060178  1.00514178 1.00586438 1.00535321 0.99642823 1.00536464\n",
      " 0.99628602 1.00543559 1.00520478 1.00521382]\n",
      "[[1.12153186 0.81840547 1.01266364 1.00277923 1.1103039  1.04478365\n",
      "  1.1733746  1.03456235 1.15044244 1.06836265 0.98758088 1.0702682\n",
      "  0.98651513 1.08232541 1.04425299 1.045689  ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 641914.2857834877\n",
      "dev set\n",
      "[1.00714535 0.99330311 1.00652894 1.00580936 1.0070838  1.00674752\n",
      " 1.00743369 1.00669108 1.00730382 1.00687135 0.99540195 1.00688102\n",
      " 0.9952262  1.00694004 1.00674468 1.00675235]\n",
      "[[1.12314746 0.81975239 1.01435943 1.0045387  1.1119276  1.04645318\n",
      "  1.17494725 1.03623882 1.15203489 1.07001683 0.98886316 1.07192109\n",
      "  0.98783449 1.0839695  1.04592288 1.04735793]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.6\n",
      "recall and sign 2 penalty\n",
      "0 loss 351394.8717504587\n",
      "dev set\n",
      "[0.60076946 0.5977431  0.59969381 0.59961021 0.60146613 0.60081777\n",
      " 0.60209597 0.60071671 0.60106089 0.6002446  0.59943306 0.60104369\n",
      " 0.59942127 0.6011902  0.60081102 0.60082526]\n",
      "[[1.11795067 0.81461379 1.00996168 1.00102149 1.10597633 1.04093407\n",
      "  1.16880253 1.03080299 1.14673646 1.06512615 0.98397079 1.06621567\n",
      "  0.9827831  1.07817711 1.04041018 1.04183383]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "1 loss 351388.93654255616\n",
      "dev set\n",
      "[0.60036758 0.59734681 0.59929454 0.59921849 0.60186385 0.60121639\n",
      " 0.60249522 0.60111649 0.60066172 0.5998453  0.59903374 0.60142255\n",
      " 0.59902186 0.60158884 0.6012103  0.60122453]\n",
      "[[1.11835277 0.81501033 1.01036123 1.0014144  1.10557904 1.04053529\n",
      "  1.16840373 1.03040265 1.14713552 1.06552494 0.9843689  1.065819\n",
      "  0.9831814  1.07777831 1.04001116 1.0414348 ]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "2 loss 351382.98207751545\n",
      "dev set\n",
      "[0.59996633 0.59694928 0.5988946  0.59882664 0.60226081 0.6016137\n",
      " 0.60289319 0.6015148  0.60026111 0.59944459 0.59863302 0.60180469\n",
      " 0.59862081 0.60198621 0.6016107  0.60162493]\n",
      "[[1.11875462 0.81540826 1.01076169 1.00180773 1.10518225 1.04013766\n",
      "  1.16800621 1.03000368 1.1475362  1.06592532 0.98476898 1.06542084\n",
      "  0.98358173 1.07738063 1.03961103 1.04103467]]\n",
      "{0: 274, 1: 1598}\n",
      "acc 0.27350427350427353\n",
      "(0.14956195244055068, 0.9958333333333333, 0.2600652883569097, None)\n",
      "\n",
      "3 loss 351376.9848540034\n",
      "dev set\n",
      "[0.5995653  0.59655051 0.59849395 0.59843449 0.60265687 0.60200961\n",
      " 0.60328996 0.60191158 0.59985887 0.59904226 0.59823068 0.60218963\n",
      " 0.59821787 0.60238224 0.60201239 0.60202662]\n",
      "[[1.11915664 0.81580759 1.01116313 1.0022017  1.10478606 1.03974119\n",
      "  1.16760977 1.02960609 1.14793869 1.06632759 0.98517113 1.06502135\n",
      "  0.98398429 1.07698409 1.03920966 1.0406333 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "4 loss 351370.9443091367\n",
      "dev set\n",
      "[0.59916436 0.59615066 0.59809272 0.5980421  0.60305186 0.60240399\n",
      " 0.60368551 0.60230671 0.59945509 0.5986384  0.59782681 0.60257701\n",
      " 0.59781314 0.60277677 0.60241528 0.60242952]\n",
      "[[1.119559   0.81620818 1.01156546 1.00259627 1.10439062 1.039346\n",
      "  1.16721434 1.02920994 1.14834292 1.0667317  0.98557521 1.06462075\n",
      "  0.98438895 1.07658879 1.03880715 1.04023079]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.7\n",
      "recall and sign 2 penalty\n",
      "0 loss 351660.7800291842\n",
      "dev set\n",
      "[0.70077002 0.69774433 0.69969605 0.69960929 0.70146621 0.70081733\n",
      " 0.70209617 0.7007165  0.70106488 0.70024853 0.69943766 0.70106274\n",
      " 0.69942578 0.70118977 0.70080838 0.70082262]\n",
      "[[1.11795025 0.81461263 1.00995962 1.0010222  1.10597633 1.04093478\n",
      "  1.16880235 1.03080333 1.14673261 1.06512267 0.98395925 1.06621389\n",
      "  0.98277646 1.07817779 1.04041486 1.0418385 ]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "1 loss 351658.05580007803\n",
      "dev set\n",
      "[0.70036833 0.69734867 0.69929869 0.69921673 0.70186394 0.70121569\n",
      " 0.70249537 0.70111601 0.70066768 0.69985174 0.699041   0.70145722\n",
      " 0.69902886 0.70158817 0.7012065  0.70122073]\n",
      "[[1.11835226 0.81500863 1.01035743 1.00141578 1.10557921 1.04053651\n",
      "  1.16840398 1.03040356 1.14712988 1.06551644 0.98434889 1.06581663\n",
      "  0.98317044 1.07777948 1.04001818 1.04144182]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "2 loss 351655.29782504594\n",
      "dev set\n",
      "[0.69996664 0.69695102 0.69889972 0.69882348 0.70226104 0.70161283\n",
      " 0.70289332 0.70151406 0.70026704 0.69945178 0.69864093 0.70185331\n",
      " 0.69862822 0.70198538 0.70160726 0.7016215 ]\n",
      "[[1.11875459 0.81540677 1.01075706 1.00181033 1.10518247 1.04013935\n",
      "  1.16800694 1.03000528 1.14753028 1.06591309 0.98474272 1.0654185\n",
      "  0.98356879 1.07738226 1.03961845 1.04104209]]\n",
      "{0: 605, 1: 1267}\n",
      "acc 0.44604700854700857\n",
      "(0.18547750591949486, 0.9791666666666666, 0.31187790311877905, None)\n",
      "\n",
      "3 loss 351652.49384494225\n",
      "dev set\n",
      "[0.69956443 0.6965513  0.69849907 0.69842926 0.70265743 0.70200864\n",
      " 0.7032902  0.70191056 0.69986275 0.69904821 0.69823732 0.70225093\n",
      " 0.69822359 0.7023813  0.70201086 0.7020251 ]\n",
      "[[1.1191578  0.81580718 1.01115862 1.00220614 1.10478617 1.03974334\n",
      "  1.1676109  1.02960849 1.14793409 1.06631326 0.98514074 1.06501956\n",
      "  0.98397172 1.07698616 1.03921553 1.04063917]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "4 loss 351649.6456218654\n",
      "dev set\n",
      "[0.69916151 0.69614963 0.69809688 0.69803412 0.70305293 0.70240297\n",
      " 0.70368603 0.70230541 0.69945493 0.69864147 0.69783018 0.70264989\n",
      " 0.69781509 0.70277578 0.7024164  0.70243064]\n",
      "[[1.11956206 0.81620975 1.01156199 1.00260319 1.10439047 1.03934864\n",
      "  1.16721575 1.02921323 1.14834127 1.06671697 0.98554279 1.06461999\n",
      "  0.98437902 1.07659134 1.03880955 1.04023319]]\n",
      "{0: 590, 1: 1282}\n",
      "acc 0.43803418803418803\n",
      "(0.18330733229329174, 0.9791666666666666, 0.3088042049934297, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.8\n",
      "recall and sign 2 penalty\n",
      "0 loss 351748.5415657666\n",
      "dev set\n",
      "[0.80077363 0.79774795 0.79970489 0.79960891 0.8014655  0.80081648\n",
      " 0.80209632 0.80071593 0.8011005  0.80048737 0.79954111 0.80106171\n",
      " 0.7994966  0.80118896 0.80058227 0.80059678]\n",
      "[[1.11794728 0.81460935 1.00995169 1.00102251 1.10597788 1.04093628\n",
      "  1.16880224 1.03080432 1.14671287 1.06505694 0.98388316 1.06621321\n",
      "  0.98268284 1.07817923 1.04118632 1.04260994]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "1 loss 351748.0453372067\n",
      "dev set\n",
      "[0.80037552 0.79735644 0.7993168  0.79921769 0.80186203 0.80121427\n",
      " 0.80249507 0.80111449 0.80074065 0.80027161 0.79925809 0.80145549\n",
      " 0.7991677  0.80158681 0.80071678 0.80073163]\n",
      "[[1.11834631 0.8150016  1.01034126 1.00141488 1.10558318 1.04053936\n",
      "  1.16840497 1.03040644 1.14709184 1.06536469 0.9841818  1.06581598\n",
      "  0.98297285 1.0777822  1.04155864 1.04298225]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "2 loss 351747.54485566384\n",
      "dev set\n",
      "[0.79997709 0.79696266 0.79892631 0.79882574 0.80225816 0.80161097\n",
      " 0.80289267 0.8015116  0.80037322 0.80005663 0.79897296 0.80185027\n",
      " 0.79882667 0.80198359 0.80087414 0.80088931]\n",
      "[[1.11874603 0.81539634 1.01073345 1.0018083  1.10518869 1.04014352\n",
      "  1.1680091  1.03001028 1.14747382 1.06567261 0.98448034 1.06541845\n",
      "  0.98327397 1.07738625 1.04192534 1.04334893]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "3 loss 351747.03924278636\n",
      "dev set\n",
      "[0.79957772 0.7965663  0.79853339 0.79843264 0.80265384 0.80200648\n",
      " 0.80328939 0.80190722 0.79999659 0.79984203 0.79868596 0.80224584\n",
      " 0.79852929 0.80237921 0.80106034 0.80107492]\n",
      "[[1.11914708 0.81579394 1.01112837 1.00220324 1.10479447 1.03974888\n",
      "  1.16761417 1.02961575 1.14785925 1.06598144 0.98477954 1.06502077\n",
      "  0.98358706 1.07699147 1.04228463 1.0437082 ]]\n",
      "{0: 941, 1: 931}\n",
      "acc 0.5988247863247863\n",
      "(0.22556390977443608, 0.875, 0.35866780529462, None)\n",
      "\n",
      "4 loss 351746.531672218\n",
      "dev set\n",
      "[0.79917718 0.7961674  0.79813822 0.79803838 0.80304887 0.8024006\n",
      " 0.80368527 0.80230125 0.79961085 0.79962774 0.79839755 0.802642\n",
      " 0.7982547  0.80277348 0.80127418 0.80128725]\n",
      "[[1.11954971 0.81619439 1.01152587 1.00259974 1.10440068 1.03935561\n",
      "  1.16722003 1.02922292 1.14824828 1.06629135 0.98507954 1.06462309\n",
      "  0.98391139 1.07659805 1.04263558 1.04405914]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.9\n",
      "recall and sign 2 penalty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 351803.4182141307\n",
      "dev set\n",
      "[0.90077642 0.89774973 0.89970992 0.89961101 0.90145631 0.90081573\n",
      " 0.90209463 0.90071554 0.90109916 0.90029145 0.89951498 0.90106535\n",
      " 0.89972337 0.90118827 0.9000118  0.90002604]\n",
      "[[1.11794436 0.81460741 1.00994637 1.00102013 1.10599284 1.04093873\n",
      "  1.16880542 1.03080553 1.14672123 1.06509567 0.9839133  1.06621072\n",
      "  0.98263782 1.07818152 1.04121648 1.04264013]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 351803.14383964636\n",
      "dev set\n",
      "[0.9003822  0.89736322 0.89932829 0.89922201 0.90184363 0.90121147\n",
      " 0.9024896  0.90111135 0.90073561 0.89995611 0.89921035 0.90146055\n",
      " 0.89972778 0.90158419 0.89961843 0.89963267]\n",
      "[[1.11833963 0.81499475 1.01032947 1.00141015 1.10561368 1.0405471\n",
      "  1.16841539 1.03041372 1.14710397 1.06545079 0.98424457 1.06581266\n",
      "  0.9828582  1.07778951 1.04161592 1.04303957]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 351802.8693457432\n",
      "dev set\n",
      "[0.89998809 0.89697573 0.89894485 0.89883223 0.90223139 0.90160536\n",
      " 0.90288324 0.90150478 0.90037188 0.89962175 0.89890696 0.90185556\n",
      " 0.89974078 0.90197828 0.89922454 0.89923879]\n",
      "[[1.11873543 0.81538362 1.01071491 1.00180154 1.10523382 1.04015792\n",
      "  1.1680273  1.03002527 1.14748719 1.06580574 0.98457591 1.06541576\n",
      "  0.9830797  1.07739992 1.04201629 1.04343993]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 351802.5933077878\n",
      "dev set\n",
      "[0.89959362 0.89658706 0.89855976 0.89844139 0.90261936 0.90199746\n",
      " 0.9032761  0.90189604 0.90000766 0.89928803 0.89860418 0.90225017\n",
      " 0.89975497 0.90237059 0.89882969 0.89884394]\n",
      "[[1.11913233 0.8157743  1.01110267 1.00219467 1.10485354 1.03977102\n",
      "  1.16764027 1.02963973 1.14787147 1.06616114 0.98490786 1.06502016\n",
      "  0.98330359 1.07701261 1.04241802 1.04384166]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 351802.3155988809\n",
      "dev set\n",
      "[0.89919861 0.89619734 0.89817328 0.89804958 0.9030073  0.90238772\n",
      " 0.90366835 0.90228514 0.89964279 0.89895488 0.89830191 0.90264416\n",
      " 0.899769   0.90276109 0.89843366 0.89844792]\n",
      "[[1.11953054 0.81616669 1.01149249 1.00258949 1.10447317 1.03938638\n",
      "  1.16725398 1.02925695 1.14825701 1.06651712 0.98524047 1.06462605\n",
      "  0.98352943 1.07662756 1.0428212  1.04424485]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 1.0\n",
      "recall and sign 2 penalty\n",
      "0 loss 351834.31061878154\n",
      "dev set\n",
      "[1.00158846 0.9977371  1.00046728 1.00002156 1.0014773  1.00082839\n",
      " 1.0021032  1.00072474 1.00187522 1.0010627  0.99945553 1.00108154\n",
      " 0.99944395 1.00120069 1.00082306 1.00083747]\n",
      "[[1.117732   0.81462273 1.00956177 1.00062431 1.10653885 1.04136403\n",
      "  1.16949167 1.03122255 1.14658253 1.06478704 0.98395183 1.06668163\n",
      "  0.9827584  1.07867547 1.04083731 1.04226273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 351834.3093998579\n",
      "dev set\n",
      "[1.00204011 0.9973179  1.00094303 1.0002612  1.00193189 1.00130426\n",
      " 1.00254401 1.00120314 1.00232031 1.00153069 0.99905281 1.00154887\n",
      " 0.99904163 1.00166385 1.00129909 1.00131307]\n",
      "[[1.118066   0.81505934 1.00960194 1.00062446 1.10685236 1.04149586\n",
      "  1.1698833  1.03132351 1.14695497 1.06499258 0.98438848 1.06689297\n",
      "  0.98319517 1.07892205 1.04096749 1.04239736]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 351834.3078179956\n",
      "dev set\n",
      "[1.00255056 0.99687284 1.00151084 1.00079332 1.00244759 1.00185612\n",
      " 1.00303401 1.00176052 1.00281858 1.00206911 0.99861393 1.00208619\n",
      " 0.99860121 1.00219425 1.00185124 1.00186442]\n",
      "[[1.11852452 0.81554147 1.00980237 1.00064265 1.10730132 1.04182201\n",
      "  1.17036292 1.03161716 1.14742887 1.06537865 0.98489344 1.06728304\n",
      "  0.98370062 1.07933467 1.04129206 1.0427262 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 351834.3057908942\n",
      "dev set\n",
      "[1.00311972 0.9964009  1.00215251 1.00145369 1.00302337 1.00247519\n",
      " 1.00357578 1.0023864  1.00337172 1.00267241 0.99814136 1.00268821\n",
      " 0.99812587 1.00278802 1.00247067 1.00248289]\n",
      "[[1.11908726 0.81607021 1.01024193 1.0008198  1.10786219 1.04233595\n",
      "  1.17092283 1.03211469 1.14799177 1.0659189  0.985456   1.06782485\n",
      "  0.98426406 1.07988474 1.04180523 1.04324141]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 351834.3032505019\n",
      "dev set\n",
      "[1.00374041 0.99590416 1.00284947 1.00218897 1.00365118 1.00314767\n",
      " 1.00416544 1.00306592 1.00397456 1.00332889 0.9976408  1.00334337\n",
      " 0.99762191 1.00343472 1.00314351 1.00315475]\n",
      "[[1.11973228 0.81664122 1.01086331 1.00129737 1.10850946 1.04298065\n",
      "  1.17155181 1.032755   1.14862867 1.06656878 0.98606363 1.06847489\n",
      "  0.98487285 1.08053502 1.04244975 1.04388643]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6\n",
      "recall and sign 2 penalty\n",
      "0 loss 206356.29832303466\n",
      "dev set\n",
      "[0.60096027 0.5979289  0.59988195 0.59979234 0.60127745 0.60062757\n",
      " 0.60190623 0.6005264  0.60124967 0.60043351 0.59962198 0.60087453\n",
      " 0.59961011 0.601      0.6006219  0.60063613]\n",
      "[[1.11775974 0.81442781 1.00977334 1.00083825 1.10616437 1.0411243\n",
      "  1.16899192 1.03099341 1.14654838 1.064937   0.98378384 1.06640104\n",
      "  0.98259542 1.07836735 1.0405987  1.04202234]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 206353.1830416964\n",
      "dev set\n",
      "[0.60075139 0.597722   0.59967409 0.59958652 0.6014846  0.60083498\n",
      " 0.60211407 0.60073439 0.60104224 0.60022605 0.59941452 0.60107971\n",
      " 0.59940263 0.60120741 0.60082936 0.60084359]\n",
      "[[1.11796858 0.81463475 1.00998123 1.00104428 1.10595733 1.04091686\n",
      "  1.16878409 1.03078516 1.14675593 1.06514408 0.98399099 1.06619355\n",
      "  0.98280267 1.0781599  1.04039121 1.04181486]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "2 loss 206350.10474931754\n",
      "dev set\n",
      "[0.60054325 0.59751558 0.59946668 0.59938162 0.60169094 0.60104146\n",
      " 0.60232105 0.6009415  0.60083522 0.60001899 0.59920746 0.60128534\n",
      " 0.59919552 0.6014139  0.60103636 0.60105059]\n",
      "[[1.11817675 0.81484125 1.01018871 1.00124946 1.10575105 1.0407103\n",
      "  1.1685771  1.03057776 1.14696312 1.06535073 0.98419783 1.06598635\n",
      "  0.9830096  1.07795334 1.04018421 1.04160785]]\n",
      "{0: 280, 1: 1592}\n",
      "acc 0.2767094017094017\n",
      "(0.15012562814070352, 0.9958333333333333, 0.2609170305676856, None)\n",
      "\n",
      "3 loss 206347.02271556674\n",
      "dev set\n",
      "[0.60033526 0.59730903 0.59925921 0.59917689 0.60189698 0.60124754\n",
      " 0.60252767 0.60114819 0.60062797 0.59981171 0.59900018 0.60149167\n",
      " 0.59898813 0.60162    0.60124351 0.60125774]\n",
      "[[1.11838485 0.81504791 1.0103963  1.00145454 1.10554499 1.0405041\n",
      "  1.16837045 1.03037073 1.14717056 1.06555764 0.984405   1.06577895\n",
      "  0.98321686 1.07774713 1.03997706 1.0414007 ]]\n",
      "{0: 278, 1: 1594}\n",
      "acc 0.27564102564102566\n",
      "(0.14993726474278546, 0.9958333333333333, 0.2606324972737186, None)\n",
      "\n",
      "4 loss 206343.93085920735\n",
      "dev set\n",
      "[0.60012727 0.5971022  0.59905154 0.59897216 0.60210282 0.60145331\n",
      " 0.60273404 0.60135454 0.60042034 0.59960405 0.59879251 0.60169871\n",
      " 0.59878029 0.6018258  0.60145097 0.6014652 ]\n",
      "[[1.11859305 0.81525488 1.01060415 1.00165972 1.10533907 1.04029817\n",
      "  1.168164   1.03016399 1.14737843 1.065765   0.98461264 1.06557122\n",
      "  0.98342464 1.07754117 1.03976962 1.04119326]]\n",
      "{0: 275, 1: 1597}\n",
      "acc 0.27403846153846156\n",
      "(0.14965560425798372, 0.9958333333333333, 0.26020685900925417, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7\n",
      "recall and sign 2 penalty\n",
      "0 loss 206621.42359608205\n",
      "dev set\n",
      "[0.70096017 0.6979291  0.69988255 0.6997928  0.70127755 0.70062746\n",
      " 0.70190631 0.70052635 0.70125037 0.70043408 0.69962264 0.70087881\n",
      " 0.69961094 0.70099989 0.70062143 0.70063567]\n",
      "[[1.11775985 0.81442762 1.00977278 1.00083785 1.10616422 1.04112449\n",
      "  1.16899183 1.0309935  1.14654808 1.06493565 0.9837815  1.06640084\n",
      "  0.98259474 1.07836753 1.0405993  1.04202295]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 206619.9930347919\n",
      "dev set\n",
      "[0.70075118 0.69772254 0.69967552 0.69958717 0.70148481 0.7008348\n",
      " 0.70211423 0.70073425 0.70104329 0.70022714 0.69941578 0.70108584\n",
      " 0.69940403 0.70120723 0.70082866 0.70084289]\n",
      "[[1.11796882 0.81463425 1.0099799  1.00104371 1.10595702 1.04091717\n",
      "  1.16878393 1.03078538 1.14675563 1.06514047 0.98398623 1.06619361\n",
      "  0.98280133 1.0781602  1.0403922  1.04181585]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "2 loss 206618.57382909747\n",
      "dev set\n",
      "[0.70054281 0.69751635 0.69946881 0.69938229 0.7016913  0.70104124\n",
      " 0.7023213  0.70094127 0.70083627 0.7000203  0.699209   0.7012926\n",
      " 0.69919711 0.70141369 0.7010357  0.70104994]\n",
      "[[1.11817722 0.81484054 1.01018673 1.00124887 1.10575052 1.04071072\n",
      "  1.16857688 1.03057813 1.14696307 1.06534504 0.98419098 1.06598683\n",
      "  0.98300798 1.07795374 1.04018525 1.0416089 ]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "3 loss 206617.14685267478\n",
      "dev set\n",
      "[0.70033445 0.69730988 0.69926184 0.69917743 0.70189754 0.7012473\n",
      " 0.70252805 0.70114787 0.70062861 0.69981297 0.6990016  0.70149961\n",
      " 0.69898948 0.70161976 0.70124322 0.70125746]\n",
      "[[1.11838569 0.81504715 1.01039387 1.00145408 1.10554423 1.04050463\n",
      "  1.16837012 1.03037128 1.1471711  1.06555016 0.98439645 1.06577996\n",
      "  0.98321543 1.07774763 1.03997778 1.04140142]]\n",
      "{0: 608, 1: 1264}\n",
      "acc 0.44764957264957267\n",
      "(0.18591772151898733, 0.9791666666666666, 0.3125, None)\n",
      "\n",
      "4 loss 206615.7088297014\n",
      "dev set\n",
      "[0.70012591 0.69710293 0.69905446 0.69897239 0.70210362 0.70145305\n",
      " 0.70273459 0.70135414 0.70042009 0.69960486 0.69879336 0.701707\n",
      " 0.69878092 0.70182554 0.70145142 0.70146566]\n",
      "[[1.11859442 0.81525428 1.01060149 1.00165956 1.10533802 1.0402988\n",
      "  1.16816354 1.03016474 1.14737992 1.06575611 0.98460286 1.06557289\n",
      "  0.98342392 1.07754178 1.03976956 1.04119321]]\n",
      "{0: 606, 1: 1266}\n",
      "acc 0.4465811965811966\n",
      "(0.18562401263823064, 0.9791666666666666, 0.31208499335989376, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "recall and sign 2 penalty\n",
      "0 loss 206708.65678004376\n",
      "dev set\n",
      "[0.80096077 0.79792991 0.79988473 0.7997941  0.8012775  0.80062722\n",
      " 0.80190634 0.80052619 0.80125369 0.80054345 0.79965421 0.80087838\n",
      " 0.79962036 0.80099966 0.80054749 0.80056189]\n",
      "[[1.11775938 0.81442688 1.00977081 1.00083669 1.10616436 1.04112493\n",
      "  1.16899179 1.03099375 1.1465465  1.06491414 0.98375529 1.06640076\n",
      "  0.98258168 1.07836795 1.04102759 1.04245124]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "1 loss 206708.39014527563\n",
      "dev set\n",
      "[0.80075258 0.797725   0.79968058 0.79959001 0.80148462 0.8008344\n",
      " 0.80211422 0.80073377 0.8010495  0.8004067  0.79948909 0.80108499\n",
      " 0.79942385 0.80120686 0.80064945 0.80066408]\n",
      "[[1.11796769 0.81463199 1.00997533 1.00104117 1.1059574  1.04091795\n",
      "  1.16878395 1.03078613 1.14675175 1.06509137 0.98392085 1.06619364\n",
      "  0.98276506 1.07816094 1.04123525 1.0426589 ]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "2 loss 206708.12638705323\n",
      "dev set\n",
      "[0.80054493 0.79752049 0.79947667 0.79938661 0.80169103 0.80104072\n",
      " 0.80232129 0.80094046 0.80084421 0.80027048 0.79932546 0.80129122\n",
      " 0.79922558 0.8014132  0.80075625 0.8007711 ]\n",
      "[[1.11817554 0.81483673 1.01017964 1.00124501 1.1057511  1.04071184\n",
      "  1.16857693 1.03057942 1.14695683 1.06526798 0.98408429 1.0659871\n",
      "  0.98294875 1.0779548  1.04144104 1.04286469]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "3 loss 206707.8607575374\n",
      "dev set\n",
      "[0.80033718 0.7973156  0.79927233 0.79918317 0.80189725 0.80124668\n",
      " 0.80252809 0.80114674 0.80063693 0.80013444 0.79916202 0.80149756\n",
      " 0.79902449 0.80161917 0.80087254 0.80088761]\n",
      "[[1.11838356 0.81504192 1.01038444 1.00144898 1.10554493 1.04050608\n",
      "  1.16837017 1.03037314 1.14716249 1.06544466 0.98424718 1.0657806\n",
      "  0.98313471 1.07774902 1.04164511 1.04306876]]\n",
      "{0: 950, 1: 922}\n",
      "acc 0.6036324786324786\n",
      "(0.227765726681128, 0.875, 0.3614457831325302, None)\n",
      "\n",
      "4 loss 206707.59233609686\n",
      "dev set\n",
      "[0.80012912 0.7971101  0.79906739 0.79897945 0.80210338 0.80145235\n",
      " 0.80273474 0.8013527  0.80042711 0.79999845 0.79899844 0.8017041\n",
      " 0.79882017 0.80182488 0.80099995 0.80101521]\n",
      "[[1.11859199 0.81524779 1.01058992 1.00165332 1.1053388  1.04030061\n",
      "  1.16816354 1.0301672  1.14736901 1.06562165 0.98440997 1.06557405\n",
      "  0.98332361 1.07754351 1.04184727 1.04327091]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "recall and sign 2 penalty\n",
      "0 loss 206763.48452823423\n",
      "dev set\n",
      "[0.90096201 0.8979306  0.89988606 0.89979506 0.90127578 0.90062728\n",
      " 0.90190594 0.90052617 0.9012569  0.90044859 0.89965151 0.90087923\n",
      " 0.89973815 0.90099973 0.90019261 0.90020685]\n",
      "[[1.1177582  0.81442617 1.00976943 1.00083567 1.10616716 1.04112513\n",
      "  1.16899258 1.0309939  1.14654589 1.0649273  0.98376352 1.06640012\n",
      "  0.98255891 1.07836812 1.04102728 1.04245093]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 206763.33814218946\n",
      "dev set\n",
      "[0.90075537 0.89772764 0.8996838  0.89959182 0.90148109 0.90083435\n",
      " 0.90211319 0.90073326 0.90105827 0.90026014 0.89948566 0.90108612\n",
      " 0.89973537 0.90120682 0.89998409 0.89999833]\n",
      "[[1.11796506 0.81462934 1.00997204 1.0010392  1.10596322 1.04091871\n",
      "  1.16878595 1.03078727 1.14674991 1.06512169 0.98394144 1.06619281\n",
      "  0.98270903 1.07816164 1.04123581 1.04265945]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 206763.19397231756\n",
      "dev set\n",
      "[0.90054936 0.89752545 0.89948193 0.89938927 0.90168585 0.90104041\n",
      " 0.90231961 0.90093927 0.9008604  0.90007233 0.89932205 0.90129236\n",
      " 0.89974145 0.90141292 0.8997762  0.89979044]\n",
      "[[1.11817141 0.81483183 1.01017436 1.00124216 1.10575975 1.04071337\n",
      "  1.1685802  1.03058186 1.1469533  1.06531549 0.98411767 1.06598637\n",
      "  0.98285633 1.07795624 1.04144386 1.04286751]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 206763.04977419527\n",
      "dev set\n",
      "[0.90034339 0.89732327 0.89927983 0.89918668 0.9018906  0.901246\n",
      " 0.9025258  0.90114473 0.90066266 0.89988471 0.89915925 0.90149845\n",
      " 0.89975017 0.90161853 0.89956826 0.8995825 ]\n",
      "[[1.11837787 0.81503447 1.01037704 1.00144529 1.10555623 1.04050862\n",
      "  1.16837471 1.03037712 1.14715675 1.06550929 0.9842935  1.06578031\n",
      "  0.98300321 1.07775142 1.0416521  1.04307575]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 206762.9052201146\n",
      "dev set\n",
      "[0.90013727 0.89712086 0.89907735 0.89898387 0.90209541 0.90145118\n",
      " 0.90273191 0.90134974 0.90046483 0.89969716 0.89899685 0.90170447\n",
      " 0.89975981 0.90182376 0.89936006 0.8993743 ]\n",
      "[[1.11858465 0.81523747 1.01058028 1.00164882 1.10535259 1.04030436\n",
      "  1.16816931 1.03017297 1.14736047 1.0657033  0.98446928 1.06557455\n",
      "  0.9831503  1.0775471  1.04186071 1.04328436]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "recall and sign 2 penalty\n",
      "0 loss 206794.31087060316\n",
      "dev set\n",
      "[1.00139093 0.99792787 1.00028993 1.00001511 1.00127934 1.00062862\n",
      " 1.00190725 1.00052625 1.00167865 1.00086299 0.9996309  1.0008819\n",
      " 0.9996154  1.00100155 1.00062333 1.00063765]\n",
      "[[1.11765598 0.81442931 1.00956014 1.00062431 1.10647395 1.04135092\n",
      "  1.16936892 1.03121411 1.1464788  1.06475933 0.98377149 1.06665251\n",
      "  0.98258364 1.07863668 1.04082446 1.04224915]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 206794.31030455543\n",
      "dev set\n",
      "[1.00160795 0.99771668 1.00050363 1.00008088 1.00149698 1.00085065\n",
      " 1.00212211 1.00074824 1.00189435 1.00108352 0.99942975 1.00110229\n",
      " 0.99941156 1.00122103 1.00084538 1.00085965]\n",
      "[[1.117812   0.81464363 1.00956523 1.00062431 1.10661777 1.04138975\n",
      "  1.16955828 1.03123884 1.14665722 1.06483822 0.98397772 1.0667348\n",
      "  0.98279281 1.07874    1.04086249 1.04228936]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 206794.30966232822\n",
      "dev set\n",
      "[1.00183684 0.99750087 1.00074284 1.00026389 1.00172718 1.00109064\n",
      " 1.00234625 1.00098934 1.00212035 1.00131984 0.99922106 1.0013383\n",
      " 0.99919961 1.00145511 1.00108543 1.00109951]\n",
      "[[1.1180018  0.81486673 1.00958875 1.00062461 1.10679919 1.04147337\n",
      "  1.16976866 1.03130212 1.14686128 1.06496652 0.98420175 1.06686634\n",
      "  0.98301999 1.07889027 1.04094504 1.04237479]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 206794.30892537007\n",
      "dev set\n",
      "[1.0020809  0.9972786  1.00100826 1.00050728 1.00197327 1.0013515\n",
      " 1.00258275 1.00125235 1.00235984 1.00157511 0.99900273 1.00159311\n",
      " 0.99897731 1.00170707 1.00134642 1.00136017]\n",
      "[[1.11822277 0.81510139 1.00965584 1.00062959 1.10701506 1.04161446\n",
      "  1.17000038 1.03142254 1.14709014 1.06514557 0.9844452  1.06704785\n",
      "  0.98326701 1.07908545 1.04108513 1.0425176 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 206794.3080807947\n",
      "dev set\n",
      "[1.00234142 0.99704911 1.00129821 1.000792   1.00223645 1.00163337\n",
      " 1.00283306 1.00153709 1.00261425 1.00184996 0.9987743  1.00186739\n",
      " 0.99874426 1.00197778 1.00162843 1.00164177]\n",
      "[[1.11847286 0.81534879 1.00978967 1.0006588  1.10726263 1.04181403\n",
      "  1.17025362 1.03160619 1.14734322 1.06537131 0.98470742 1.06727517\n",
      "  0.98353328 1.07932126 1.04128395 1.04271844]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6\n",
      "recall and sign 2 penalty\n",
      "0 loss 123477.01128313653\n",
      "dev set\n",
      "[0.60106778 0.59803511 0.59998839 0.59989896 0.6011709  0.60052065\n",
      " 0.60179949 0.60041947 0.60135623 0.6005401  0.59972857 0.60077116\n",
      " 0.59971669 0.60089307 0.60051527 0.6005295 ]\n",
      "[[1.11765226 0.81432158 1.00966686 1.00073158 1.10627078 1.04123126\n",
      "  1.1690985  1.03110038 1.14644183 1.06483032 0.98367771 1.06650714\n",
      "  0.98248889 1.0784743  1.04070531 1.04212896]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 123475.43316335767\n",
      "dev set\n",
      "[0.60096092 0.59792923 0.59988219 0.59979271 0.60127677 0.60062675\n",
      " 0.60190597 0.60052593 0.60125025 0.60043411 0.59962257 0.60087557\n",
      " 0.59961069 0.60099917 0.60062125 0.60063549]\n",
      "[[1.11775907 0.81442746 1.00977305 1.00083782 1.10616494 1.04112509\n",
      "  1.16899187 1.03099371 1.14654781 1.06493608 0.98378377 1.06640133\n",
      "  0.98259467 1.07836814 1.04059934 1.04202299]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "2 loss 123473.86182252361\n",
      "dev set\n",
      "[0.60085416 0.59782346 0.59977609 0.59968656 0.60138247 0.60073268\n",
      " 0.6020123  0.60063226 0.60114436 0.60032821 0.59951667 0.60098009\n",
      " 0.59950479 0.60110511 0.60072713 0.60074137]\n",
      "[[1.11786578 0.81453324 1.00987915 1.00094396 1.10605927 1.04101908\n",
      "  1.16888536 1.03088716 1.14665368 1.06504173 0.98388977 1.06629561\n",
      "  0.98270034 1.07826213 1.04049349 1.04191714]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "3 loss 123472.28952294309\n",
      "dev set\n",
      "[0.60074742 0.59771769 0.59966999 0.59958043 0.6014881  0.60083854\n",
      " 0.60211858 0.60073852 0.60103846 0.6002223  0.59941075 0.60108474\n",
      " 0.59939886 0.60121096 0.60083301 0.60084725]\n",
      "[[1.11797248 0.81463903 1.00998526 1.0010501  1.10595365 1.04091314\n",
      "  1.16877889 1.03078066 1.14675958 1.0651474  0.98399582 1.06618987\n",
      "  0.98280605 1.0781562  1.04038764 1.04181129]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "4 loss 123470.71508834488\n",
      "dev set\n",
      "[0.60064067 0.59761187 0.59956386 0.59947428 0.6015937  0.60094435\n",
      " 0.60222482 0.60084473 0.6009325  0.60011632 0.59930477 0.60118954\n",
      " 0.59929285 0.60131676 0.60093894 0.60095318]\n",
      "[[1.11807921 0.81474487 1.01009141 1.00115626 1.10584807 1.04080724\n",
      "  1.16867246 1.0306742  1.14686554 1.06525313 0.98410195 1.06608407\n",
      "  0.98291183 1.0780503  1.04028175 1.04170539]]\n",
      "{0: 283, 1: 1589}\n",
      "acc 0.2783119658119658\n",
      "(0.15040906230333542, 0.9958333333333333, 0.2613449972662657, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7\n",
      "recall and sign 2 penalty\n",
      "0 loss 123741.74904805477\n",
      "dev set\n",
      "[0.70106776 0.69803514 0.69998865 0.69989901 0.70117089 0.70052062\n",
      " 0.70179951 0.70041947 0.70135643 0.70054033 0.6997288  0.70077302\n",
      " 0.69971697 0.70089305 0.70051513 0.70052937]\n",
      "[[1.11765228 0.81432154 1.00966662 1.00073154 1.1062708  1.0412313\n",
      "  1.16909846 1.03110038 1.14644178 1.06482987 0.98367724 1.06650703\n",
      "  0.98248861 1.07847434 1.04070547 1.04212911]]\n",
      "{0: 617, 1: 1255}\n",
      "acc 0.45245726495726496\n",
      "(0.18725099601593626, 0.9791666666666666, 0.31438127090301005, None)\n",
      "\n",
      "1 loss 123741.02488481872\n",
      "dev set\n",
      "[0.70096085 0.69792925 0.69988277 0.69979272 0.70127674 0.70062671\n",
      " 0.70190605 0.70052595 0.70125057 0.70043464 0.69962304 0.7008788\n",
      " 0.69961123 0.70099914 0.70062101 0.70063524]\n",
      "[[1.11775915 0.81442744 1.00977252 1.00083782 1.10616499 1.04112514\n",
      "  1.16899173 1.03099367 1.14654772 1.06493474 0.98378316 1.06640114\n",
      "  0.98259394 1.07836819 1.04059965 1.0420233 ]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n",
      "2 loss 123740.3023536999\n",
      "dev set\n",
      "[0.70085401 0.69782343 0.69977697 0.69968649 0.70138243 0.70073265\n",
      " 0.70201247 0.70063231 0.70114474 0.700329   0.69951732 0.70098451\n",
      " 0.69950551 0.70110507 0.70072682 0.70074106]\n",
      "[[1.11786594 0.81453327 1.00987835 1.00094404 1.10605933 1.04101913\n",
      "  1.16888512 1.03088708 1.14665361 1.06503946 0.98388916 1.06629536\n",
      "  0.98269918 1.07826219 1.04049391 1.04191755]]\n",
      "{0: 612, 1: 1260}\n",
      "acc 0.4497863247863248\n",
      "(0.1865079365079365, 0.9791666666666666, 0.31333333333333335, None)\n",
      "\n",
      "3 loss 123739.57787405304\n",
      "dev set\n",
      "[0.70074717 0.69771757 0.69967112 0.69958026 0.70148806 0.70083851\n",
      " 0.70211883 0.7007386  0.70103881 0.70022328 0.69941151 0.70109025\n",
      " 0.69939968 0.70121093 0.7008327  0.70084694]\n",
      "[[1.11797274 0.81463915 1.00998422 1.00105028 1.10595374 1.04091319\n",
      "  1.16877855 1.03078053 1.14675957 1.06514423 0.98399531 1.06618957\n",
      "  0.98280453 1.07815625 1.0403881  1.04181175]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "4 loss 123738.85085933827\n",
      "dev set\n",
      "[0.70064029 0.69761163 0.69956521 0.69947397 0.70159365 0.70094433\n",
      " 0.70222516 0.70084484 0.70093274 0.70011743 0.69930555 0.70119605\n",
      " 0.69929369 0.70131674 0.70093869 0.70095293]\n",
      "[[1.1180796  0.81474513 1.01009017 1.00115658 1.10584816 1.04080729\n",
      "  1.16867199 1.03067403 1.14686567 1.06524912 0.98410165 1.06608375\n",
      "  0.98291003 1.07805035 1.04028218 1.04170582]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "recall and sign 2 penalty\n",
      "0 loss 123828.71738812709\n",
      "dev set\n",
      "[0.80106776 0.79803524 0.79998944 0.79989911 0.8011708  0.80052057\n",
      " 0.80179949 0.80041943 0.80135645 0.80054858 0.7997399  0.80077306\n",
      " 0.79972002 0.80089301 0.80048372 0.80049803]\n",
      "[[1.11765229 0.81432146 1.00966591 1.00073145 1.10627092 1.04123137\n",
      "  1.16909848 1.03110044 1.14644183 1.06482723 0.98367023 1.06650703\n",
      "  0.98248419 1.07847441 1.04091979 1.04234344]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "1 loss 123828.58103525665\n",
      "dev set\n",
      "[0.80096079 0.79792928 0.79988438 0.79979282 0.8012765  0.80062667\n",
      " 0.801906   0.80052585 0.80125075 0.8004632  0.79964781 0.80087899\n",
      " 0.79961826 0.80099909 0.80054103 0.80055546]\n",
      "[[1.11775921 0.81442743 1.00977108 1.00083774 1.10616534 1.04112523\n",
      "  1.16899177 1.03099382 1.1465475  1.06492556 0.98376675 1.06640123\n",
      "  0.9825804  1.07836827 1.0410254  1.04244904]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "2 loss 123828.44539151246\n",
      "dev set\n",
      "[0.80085389 0.79782335 0.79977933 0.79968657 0.80138202 0.80073261\n",
      " 0.80201239 0.80063214 0.80114498 0.80037958 0.79955606 0.80098486\n",
      " 0.79951628 0.80110504 0.80059719 0.80061176]\n",
      "[[1.11786608 0.81453339 1.00987624 1.000944   1.10605994 1.04101923\n",
      "  1.16888515 1.03088731 1.14665304 1.06502303 0.98386292 1.06629556\n",
      "  0.98267598 1.07826228 1.04113062 1.04255426]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 123828.30931963224\n",
      "dev set\n",
      "[0.80074695 0.79771733 0.79967419 0.79958027 0.80148748 0.80083849\n",
      " 0.80211875 0.80073837 0.80103893 0.80029666 0.79946437 0.80109074\n",
      " 0.79941383 0.80121091 0.80065465 0.80066935]\n",
      "[[1.11797298 0.81463944 1.0099815  1.00105031 1.10595459 1.04091328\n",
      "  1.16877857 1.03078086 1.14675864 1.0651202  0.98395898 1.06618992\n",
      "  0.98277166 1.07815633 1.04123552 1.04265916]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "4 loss 123828.1726350624\n",
      "dev set\n",
      "[0.80063995 0.79761118 0.79956892 0.7994739  0.80159291 0.80094433\n",
      " 0.80222508 0.80084454 0.80093248 0.80021412 0.79937267 0.80119666\n",
      " 0.79931079 0.80131675 0.80071435 0.80072916]\n",
      "[[1.11807997 0.81474563 1.01008689 1.00115671 1.10584925 1.04080737\n",
      "  1.168672   1.03067446 1.14686436 1.06521726 0.98405501 1.06608427\n",
      "  0.98286773 1.07805043 1.04134009 1.04276373]]\n",
      "{0: 957, 1: 915}\n",
      "acc 0.6063034188034188\n",
      "(0.2284153005464481, 0.8708333333333333, 0.361904761904762, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "recall and sign 2 penalty\n",
      "0 loss 123883.5187490397\n",
      "dev set\n",
      "[0.9010678  0.89803551 0.89998993 0.8998994  0.90117036 0.90052077\n",
      " 0.90179942 0.90041952 0.90135712 0.90054062 0.89973571 0.90077313\n",
      " 0.89978004 0.9008932  0.90030071 0.90031494]\n",
      "[[1.11765226 0.81432119 1.00966541 1.00073117 1.10627158 1.04123108\n",
      "  1.16909862 1.03110033 1.14644184 1.06483012 0.98367339 1.06650688\n",
      "  0.98247511 1.07847413 1.04091984 1.04234348]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 123883.44387473071\n",
      "dev set\n",
      "[0.90096079 0.89793001 0.89988543 0.8997935  0.90127548 0.90062729\n",
      " 0.90190591 0.90052616 0.90125279 0.90043656 0.89963832 0.90087887\n",
      " 0.89977531 0.9009997  0.90019462 0.90020886]\n",
      "[[1.11775925 0.81442672 1.00977    1.00083709 1.10616686 1.04112433\n",
      "  1.16899199 1.03099345 1.14654769 1.06493474 0.98377459 1.06640096\n",
      "  0.98255964 1.0783674  1.04102601 1.04244965]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 123883.36936073827\n",
      "dev set\n",
      "[0.90085383 0.89782458 0.89978094 0.89968764 0.90138045 0.90073369\n",
      " 0.9020123  0.90063267 0.90114871 0.9003329  0.89954123 0.90098445\n",
      " 0.89977753 0.90110608 0.90008868 0.90010292]\n",
      "[[1.11786621 0.8145322  1.00987461 1.000943   1.1060623  1.04101769\n",
      "  1.16888546 1.03088667 1.14665338 1.06503905 0.98387568 1.06629523\n",
      "  0.98264295 1.07826078 1.04113204 1.04255569]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 123883.29480696013\n",
      "dev set\n",
      "[0.90074685 0.89771911 0.89967637 0.89958173 0.90148538 0.90084002\n",
      " 0.90211866 0.90073911 0.9010447  0.9002294  0.89944427 0.90108998\n",
      " 0.89978247 0.9012124  0.89998276 0.89999699]\n",
      "[[1.11797322 0.81463774 1.00997932 1.00104897 1.10595776 1.04091112\n",
      "  1.16877893 1.03077998 1.14675907 1.06514327 0.98397678 1.06618958\n",
      "  0.9827259  1.07815422 1.04123808 1.04266172]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 123883.22016038945\n",
      "dev set\n",
      "[0.90063982 0.89761357 0.8995717  0.89947576 0.90159031 0.90094629\n",
      " 0.90222503 0.90084548 0.90094069 0.90012596 0.89934737 0.9011955\n",
      " 0.89978874 0.90131866 0.8998768  0.89989104]\n",
      "[[1.11808029 0.81474337 1.01008414 1.00115503 1.10585322 1.0408046\n",
      "  1.1686724  1.03067337 1.1468648  1.06524748 0.9840779  1.06608399\n",
      "  0.98280874 1.07804773 1.04134416 1.0427678 ]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "recall and sign 2 penalty\n",
      "0 loss 123914.31099013684\n",
      "dev set\n",
      "[1.00128293 0.9980349  1.00019532 1.0000116  1.00117128 1.0005208\n",
      " 1.00179948 1.00041921 1.00157079 1.00075478 0.9997301  1.00077368\n",
      " 0.99971758 1.00089335 1.00051553 1.00052979]\n",
      "[[1.11760898 0.81432188 1.00955981 1.00062431 1.10643436 1.0413456\n",
      "  1.169294   1.03121116 1.14641459 1.06474516 0.98367429 1.06663741\n",
      "  0.98248521 1.07861503 1.04081929 1.04224358]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 123914.31072071535\n",
      "dev set\n",
      "[1.00139046 0.99792835 1.00029761 1.00003223 1.00127892 1.00062914\n",
      " 1.00190664 1.00052734 1.00167809 1.00086293 0.99962457 1.00088181\n",
      " 0.99961322 1.00100132 1.00062387 1.00063813]\n",
      "[[1.11768858 0.81442894 1.00956069 1.00062431 1.10650762 1.04136101\n",
      "  1.16938996 1.03121959 1.14650534 1.06478257 0.98377988 1.06667674\n",
      "  0.9825895  1.07866621 1.04083428 1.04225971]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 123914.3104328601\n",
      "dev set\n",
      "[1.00149983 0.99782111 1.00040434 1.00009156 1.00138853 1.00074043\n",
      " 1.0020152  1.00063854 1.00178696 1.00097366 0.99951759 1.00099249\n",
      " 0.99950768 1.00111164 1.00073517 1.00074942]\n",
      "[[1.11777736 0.81453733 1.00956369 1.00062431 1.10659143 1.0413873\n",
      "  1.16949078 1.03123609 1.14660247 1.06483417 0.98388893 1.06673029\n",
      "  0.98269693 1.07873116 1.04086003 1.04228694]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 123914.31012373348\n",
      "dev set\n",
      "[1.00161186 0.99771278 1.00051693 1.00017812 1.00150095 1.00085577\n",
      " 1.00212582 1.00075401 1.00189813 1.00108796 0.99940864 1.00110669\n",
      " 0.99940021 1.00122525 1.00085052 1.00086473]\n",
      "[[1.11787389 0.81464769 1.00957135 1.00062442 1.10668413 1.04142706\n",
      "  1.16959613 1.03126409 1.14670519 1.06489959 0.98400234 1.0667975\n",
      "  0.98280857 1.07880843 1.04089917 1.04232776]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 123914.30979153627\n",
      "dev set\n",
      "[1.00172712 0.99760308 1.00063601 1.00028061 1.00161679 1.00097588\n",
      " 1.00223902 1.00087453 1.00201213 1.00120648 0.99929737 1.00122508\n",
      " 0.99929039 1.0013428  1.00097065 1.00098478]\n",
      "[[1.11797767 0.8147605  1.00958747 1.00062509 1.10678502 1.04148209\n",
      "  1.16970613 1.03130667 1.14681345 1.0649784  0.98412067 1.06687784\n",
      "  0.98292502 1.07889715 1.04095357 1.04238385]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6\n",
      "recall and sign 2 penalty\n",
      "0 loss 82037.36777369303\n",
      "dev set\n",
      "[0.60112151 0.59808849 0.60004187 0.59995247 0.60111754 0.60046714\n",
      " 0.60174595 0.6003659  0.60140963 0.60059351 0.59978199 0.60071995\n",
      " 0.5997701  0.60083957 0.60046185 0.60047609]\n",
      "[[1.11759856 0.81426819 1.00961338 1.00067808 1.10632411 1.04128479\n",
      "  1.16915207 1.03115401 1.14638846 1.06477703 0.98362432 1.06656042\n",
      "  0.98243553 1.07852783 1.04075872 1.04218237]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 82036.57326536922\n",
      "dev set\n",
      "[0.6010676  0.59803502 0.59998828 0.59989881 0.60117118 0.60052079\n",
      " 0.60179978 0.60041962 0.60135605 0.60053993 0.5997284  0.60077367\n",
      " 0.59971651 0.60089322 0.60051545 0.60052969]\n",
      "[[1.11765245 0.81432167 1.00966698 1.00073174 1.10627046 1.04123114\n",
      "  1.16909818 1.03110024 1.14644209 1.06483064 0.98367784 1.06650697\n",
      "  0.98248906 1.07847418 1.04070509 1.04212874]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "2 loss 82035.77940848982\n",
      "dev set\n",
      "[0.60101369 0.59798155 0.59993469 0.59984515 0.60122481 0.60057441\n",
      " 0.60185361 0.60047334 0.60130248 0.60048635 0.59967482 0.60082739\n",
      " 0.59966293 0.60094684 0.60056904 0.60058328]\n",
      "[[1.11770634 0.81437514 1.00972056 1.0007854  1.10621682 1.0411775\n",
      "  1.16904429 1.03104648 1.14649571 1.06488425 0.98373135 1.06645354\n",
      "  0.98254259 1.07842054 1.04065147 1.04207511]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "3 loss 82034.9851299995\n",
      "dev set\n",
      "[0.60095978 0.59792808 0.59988111 0.59979149 0.60127844 0.60062804\n",
      " 0.60190743 0.60052705 0.60124891 0.60043277 0.59962123 0.60088111\n",
      " 0.59960934 0.60100047 0.60062264 0.60063688]\n",
      "[[1.11776024 0.81442861 1.00977416 1.00083905 1.10616318 1.04112387\n",
      "  1.1689904  1.03099272 1.14654934 1.06493786 0.98378486 1.06640011\n",
      "  0.98259612 1.07836691 1.04059784 1.04202149]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 82034.19031644007\n",
      "dev set\n",
      "[0.60090586 0.59787461 0.59982752 0.59973783 0.60133206 0.60068165\n",
      " 0.60196125 0.60058076 0.60119532 0.60037918 0.59956764 0.60093485\n",
      " 0.59955574 0.60105408 0.60067624 0.60069048]\n",
      "[[1.11781414 0.8144821  1.00982775 1.00089272 1.10610955 1.04107024\n",
      "  1.16893652 1.03093897 1.14660299 1.06499148 0.98383839 1.06634667\n",
      "  0.98264966 1.07831328 1.04054421 1.04196785]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7\n",
      "recall and sign 2 penalty\n",
      "0 loss 82301.91153231141\n",
      "dev set\n",
      "[0.70112151 0.69808853 0.70004192 0.69995252 0.70111753 0.70046712\n",
      " 0.70174595 0.7003659  0.70140973 0.70059364 0.6997821  0.70071968\n",
      " 0.69977022 0.70083955 0.70046178 0.70047602]\n",
      "[[1.11759855 0.81426815 1.00961333 1.00067803 1.10632412 1.04128482\n",
      "  1.16915206 1.031154   1.14638846 1.06477704 0.98362414 1.06656043\n",
      "  0.98243539 1.07852786 1.04075877 1.04218242]]\n",
      "{0: 618, 1: 1254}\n",
      "acc 0.452991452991453\n",
      "(0.18740031897926634, 0.9791666666666666, 0.31459170013386883, None)\n",
      "\n",
      "1 loss 82301.54742188164\n",
      "dev set\n",
      "[0.70106761 0.6980351  0.69998841 0.69989893 0.70117116 0.70052073\n",
      " 0.70179979 0.70041963 0.70135631 0.70054024 0.6997287  0.70077298\n",
      " 0.69971682 0.70089316 0.70051527 0.70052951]\n",
      "[[1.11765244 0.81432159 1.00966685 1.00073162 1.10627049 1.04123122\n",
      "  1.16909816 1.03110022 1.14644209 1.06483065 0.98367739 1.06650701\n",
      "  0.98248871 1.07847426 1.04070522 1.04212886]]\n",
      "{0: 617, 1: 1255}\n",
      "acc 0.45245726495726496\n",
      "(0.18725099601593626, 0.9791666666666666, 0.31438127090301005, None)\n",
      "\n",
      "2 loss 82301.18344517532\n",
      "dev set\n",
      "[0.7010137  0.69798168 0.69993491 0.69984536 0.70122478 0.70057432\n",
      " 0.70185362 0.70047336 0.70130289 0.70048686 0.6996753  0.70082626\n",
      " 0.69966342 0.70094676 0.70056875 0.70058299]\n",
      "[[1.11770633 0.81437501 1.00972036 1.00078521 1.10621687 1.04117763\n",
      "  1.16904426 1.03104645 1.14649572 1.06488427 0.98373062 1.06645361\n",
      "  0.98254201 1.07842067 1.04065166 1.04207531]]\n",
      "{0: 616, 1: 1256}\n",
      "acc 0.4519230769230769\n",
      "(0.18710191082802546, 0.9791666666666666, 0.3141711229946524, None)\n",
      "\n",
      "3 loss 82300.81894087984\n",
      "dev set\n",
      "[0.70095979 0.69792826 0.6998814  0.69979177 0.70127839 0.70062791\n",
      " 0.70190746 0.70052708 0.70124946 0.70043346 0.69962189 0.70087954\n",
      " 0.69961002 0.70100034 0.70062224 0.70063648]\n",
      "[[1.11776023 0.81442845 1.00977388 1.00083879 1.10616325 1.04112405\n",
      "  1.16899036 1.03099268 1.14654937 1.0649379  0.98378386 1.06640021\n",
      "  0.98259533 1.07836709 1.0405981  1.04202174]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n",
      "4 loss 82300.45383990134\n",
      "dev set\n",
      "[0.70090588 0.69787482 0.69982789 0.69973818 0.701332   0.70068149\n",
      " 0.70196129 0.70058079 0.70119601 0.70038005 0.69956846 0.70093283\n",
      " 0.69955658 0.70105393 0.70067575 0.70068999]\n",
      "[[1.11781413 0.81448189 1.00982741 1.00089239 1.10610963 1.04107048\n",
      "  1.16893647 1.03093892 1.14660303 1.06499155 0.98383712 1.0663468\n",
      "  0.98264867 1.07831351 1.04054452 1.04196816]]\n",
      "{0: 613, 1: 1259}\n",
      "acc 0.45032051282051283\n",
      "(0.18665607625099284, 0.9791666666666666, 0.3135423615743829, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "recall and sign 2 penalty\n",
      "0 loss 82388.74793425013\n",
      "dev set\n",
      "[0.80112153 0.79808861 0.80004207 0.7999526  0.80111749 0.80046709\n",
      " 0.80174592 0.8003659  0.80140987 0.80059315 0.79978353 0.80071972\n",
      " 0.79977134 0.80083952 0.80044697 0.80046124]\n",
      "[[1.11759854 0.81426808 1.0096132  1.00067795 1.10632417 1.04128486\n",
      "  1.16915209 1.031154   1.14638859 1.06477734 0.98362395 1.06656042\n",
      "  0.98243292 1.0785279  1.04086651 1.04229015]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "1 loss 82388.67913142433\n",
      "dev set\n",
      "[0.80106765 0.7980353  0.79998879 0.79989914 0.80117106 0.80052065\n",
      " 0.80179972 0.80041964 0.80135666 0.80053915 0.79973237 0.8007731\n",
      " 0.79971969 0.80089309 0.8004777  0.80049204]\n",
      "[[1.1176524  0.8143214  1.0096665  1.00073143 1.10627063 1.04123134\n",
      "  1.16909824 1.03110021 1.14644242 1.06483138 0.98367688 1.06650698\n",
      "  0.98248236 1.07847437 1.04092053 1.04234418]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "2 loss 82388.61060431847\n",
      "dev set\n",
      "[0.80101377 0.79798202 0.79993552 0.79984569 0.80122462 0.8005742\n",
      " 0.80185352 0.80047336 0.80130344 0.80048515 0.79968137 0.80082645\n",
      " 0.79966812 0.80094663 0.80050698 0.80052139]\n",
      "[[1.11770627 0.8143747  1.0097198  1.00078489 1.10621709 1.04117783\n",
      "  1.16904438 1.03104644 1.14649626 1.06488542 0.98372977 1.06645356\n",
      "  0.98253156 1.07842086 1.04097453 1.04239818]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "3 loss 82388.54200707619\n",
      "dev set\n",
      "[0.80095988 0.79792872 0.79988225 0.79979224 0.80127817 0.80062773\n",
      " 0.80190731 0.80052709 0.80125018 0.80043117 0.79963041 0.8008798\n",
      " 0.79961651 0.80100017 0.80053599 0.80055046]\n",
      "[[1.11776015 0.81442801 1.0097731  1.00083836 1.10616356 1.04112432\n",
      "  1.16899052 1.03099267 1.14655011 1.06493947 0.98378266 1.06640014\n",
      "  0.98258073 1.07836735 1.0410285  1.04245214]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "4 loss 82388.47328766045\n",
      "dev set\n",
      "[0.80090598 0.79787541 0.79982897 0.79973878 0.80133172 0.80068126\n",
      " 0.8019611  0.8005808  0.80119686 0.80037719 0.79957947 0.80093316\n",
      " 0.79956485 0.80105371 0.80056515 0.80057969]\n",
      "[[1.11781404 0.81448134 1.00982641 1.00089184 1.10611004 1.04107083\n",
      "  1.16893667 1.03093891 1.14660399 1.06499353 0.98383555 1.06634673\n",
      "  0.98262993 1.07831385 1.04108243 1.04250607]]\n",
      "{0: 960, 1: 912}\n",
      "acc 0.6079059829059829\n",
      "(0.22916666666666666, 0.8708333333333333, 0.3628472222222222, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "recall and sign 2 penalty\n",
      "0 loss 82443.53593191737\n",
      "dev set\n",
      "[0.90112159 0.89808875 0.90004213 0.89995268 0.90111738 0.90046718\n",
      " 0.90174597 0.90036598 0.90140926 0.90059324 0.89978243 0.90071974\n",
      " 0.89980118 0.90083961 0.90035411 0.90036834]\n",
      "[[1.11759849 0.81426794 1.00961313 1.00067787 1.10632433 1.04128473\n",
      "  1.16915204 1.03115389 1.14638875 1.06477726 0.98362403 1.0665603\n",
      "  0.98243219 1.07852777 1.04086635 1.04228999]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 82443.49809006782\n",
      "dev set\n",
      "[0.90106779 0.89803567 0.89998894 0.89989934 0.90117078 0.90052088\n",
      " 0.90179984 0.90041984 0.90135521 0.90053926 0.89972954 0.90077313\n",
      " 0.89979927 0.9008933  0.90030009 0.90031433]\n",
      "[[1.11765228 0.81432103 1.00966634 1.00073122 1.10627102 1.04123101\n",
      "  1.1690981  1.03109995 1.14644278 1.06483119 0.9836771  1.06650669\n",
      "  0.98248047 1.07847405 1.04092017 1.04234382]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 82443.46030988476\n",
      "dev set\n",
      "[0.90101399 0.89798263 0.89993578 0.89984603 0.90122416 0.90057456\n",
      " 0.90185371 0.90047369 0.90130116 0.90048527 0.8996767  0.90082651\n",
      " 0.89980103 0.90094699 0.90024607 0.90026031]\n",
      "[[1.11770607 0.81437409 1.00971953 1.00078456 1.10621773 1.04117729\n",
      "  1.16904416 1.03104602 1.14649683 1.06488513 0.98373014 1.06645308\n",
      "  0.98252837 1.07842034 1.040974   1.04239764]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 82443.42251590213\n",
      "dev set\n",
      "[0.90096019 0.89792958 0.89988261 0.8997927  0.90127754 0.90062824\n",
      " 0.90190758 0.90052753 0.90124711 0.90043129 0.89962387 0.90087988\n",
      " 0.89980429 0.90100066 0.90019204 0.90020628]\n",
      "[[1.11775988 0.81442716 1.00977272 1.0008379  1.10616445 1.04112358\n",
      "  1.16899022 1.0309921  1.14655088 1.06493908 0.98378318 1.06639949\n",
      "  0.98257613 1.07836663 1.04102783 1.04245147]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 82443.3847001031\n",
      "dev set\n",
      "[0.90090638 0.89787654 0.89982944 0.89973938 0.90133092 0.90068191\n",
      " 0.90196145 0.90058136 0.90119306 0.90037731 0.89957104 0.90093324\n",
      " 0.89980834 0.90105433 0.900138   0.90015224]\n",
      "[[1.11781369 0.81448023 1.00982592 1.00089125 1.10611117 1.04106988\n",
      "  1.16893628 1.03093819 1.14660494 1.06499303 0.98383622 1.0663459\n",
      "  0.98262382 1.07831293 1.04108167 1.04250532]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall and sign 2 penalty\n",
      "0 loss 82474.31104878704\n",
      "dev set\n",
      "[1.00122927 0.99808841 1.00014685 1.00000976 1.00111761 1.0004672\n",
      " 1.00174587 1.00036581 1.00151716 1.00070107 0.99978236 1.00071998\n",
      " 0.99977031 1.00083965 1.00046193 1.00047617]\n",
      "[[1.11758189 0.81426829 1.00955973 1.00062431 1.10641144 1.04134324\n",
      "  1.16925307 1.03120999 1.14637863 1.0647377  0.98362326 1.06662938\n",
      "  0.98243468 1.07860295 1.040817   1.04224109]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 82474.31091757117\n",
      "dev set\n",
      "[1.00128314 0.99803477 1.00019822 1.00001877 1.00117149 1.00052117\n",
      " 1.00179968 1.00041971 1.001571   1.00075504 0.9997293  1.00077394\n",
      " 0.99971696 1.00089359 1.0005159  1.00053015]\n",
      "[[1.11762428 0.81432201 1.00955997 1.00062431 1.10645089 1.04135134\n",
      "  1.16930252 1.03121408 1.14642591 1.06475853 0.98367603 1.06665129\n",
      "  0.98248776 1.07863133 1.04082486 1.04224961]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 82474.31078173517\n",
      "dev set\n",
      "[1.00133729 0.99798101 1.00024983 1.00003922 1.00122568 1.00057558\n",
      " 1.0018537  1.00047402 1.00162507 1.0008094  0.99967608 1.00082829\n",
      " 0.99966341 1.00094789 1.00057031 1.00058456]\n",
      "[[1.11766942 0.81437594 1.00956057 1.00062431 1.10649361 1.04136291\n",
      "  1.16935323 1.03122047 1.14647494 1.06478423 0.98372926 1.06667808\n",
      "  0.98254134 1.07866433 1.04083613 1.04226169]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 82474.31064087703\n",
      "dev set\n",
      "[1.00139184 0.9979271  1.00030218 1.0000719  1.00128029 1.00063061\n",
      " 1.00190803 1.00052894 1.00167948 1.00086431 0.99962259 1.00088319\n",
      " 0.99960953 1.00100269 1.00062534 1.00063959]\n",
      "[[1.11771659 0.81443015 1.0095618  1.00062431 1.10653877 1.04137821\n",
      "  1.16940494 1.03122968 1.14652531 1.06481413 0.98378315 1.06670901\n",
      "  0.9825956  1.07870101 1.04085109 1.04227757]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 82474.31049478635\n",
      "dev set\n",
      "[1.00144689 0.99787297 1.00035562 1.00011142 1.00133544 1.00068641\n",
      " 1.00196275 1.00058468 1.00173433 1.00091991 0.99956872 1.00093877\n",
      " 0.99955523 1.00105813 1.00068115 1.0006954 ]\n",
      "[[1.11776551 0.81448474 1.00956407 1.00062433 1.10658599 1.04139747\n",
      "  1.16945758 1.0312422  1.14657686 1.06484785 0.98383787 1.06674368\n",
      "  0.9826507  1.07874088 1.04087    1.04229745]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = np.empty([len(LF_l)],dtype=np.float64)\n",
    "acc.fill(0.25)\n",
    "rec =  np.empty([len(LF_l)],dtype=np.float64)\n",
    "rec.fill(0.35*train_L_S.shape[0])\n",
    "print(rec)\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [64,128,256,512,1024,2048]:\n",
    "    for i in np.linspace(0.6,1,5):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = acc ,LF_rec = rec,\\\n",
    "                                    pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=12,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295.\n",
      " 1295. 1295. 1295. 1295.]\n",
      "batch-size: 64 alpha-init: 0.6\n",
      "recall penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 1242346.3576840137\n",
      "dev set\n",
      "[0.59966419 0.59662467 0.59861625 0.59852027 0.60260125 0.60197537\n",
      " 0.60325263 0.60187818 0.5999139  0.59909635 0.59828474 0.60192128\n",
      " 0.59827266 0.60234796 0.60196187 0.6019761 ]\n",
      "[[1.11906896 0.81573464 1.01104918 1.00212258 1.10485233 1.03977548\n",
      "  1.16764946 1.02963845 1.14787911 1.06627299 0.98509706 1.06512126\n",
      "  0.98392353 1.07701838 1.03926376 1.0406874 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "1 loss 1242323.0325994184\n",
      "dev set\n",
      "[0.59817455 0.5950781  0.59712625 0.59703654 0.60412528 0.60350861\n",
      " 0.6047882  0.60341265 0.59833777 0.59751978 0.59670813 0.60320012\n",
      " 0.59669131 0.60388211 0.60353535 0.60354959]\n",
      "[[1.1205784  0.81728596 1.01255366 1.00362401 1.10333518 1.03823884\n",
      "  1.16611921 1.0281014  1.14945499 1.0678478  0.98666936 1.06359618\n",
      "  0.9855036  1.07548098 1.03769335 1.039117  ]]\n",
      "{0: 268, 1: 1604}\n",
      "acc 0.2702991452991453\n",
      "(0.14900249376558602, 0.9958333333333333, 0.2592190889370933, None)\n",
      "\n",
      "2 loss 1242299.0915429061\n",
      "dev set\n",
      "[0.59669196 0.59351834 0.59563232 0.59555282 0.60562886 0.60501396\n",
      " 0.6062999  0.60491652 0.596742   0.59592375 0.59511208 0.60453407\n",
      " 0.59508655 0.60538913 0.6051234  0.60513764]\n",
      "[[1.12208691 0.81885316 1.01406664 1.00513095 1.10183377 1.03672599\n",
      "  1.16461034 1.02659215 1.15105354 1.06944698 0.98826811 1.06205708\n",
      "  0.98711233 1.07396686 1.03610935 1.03753299]]\n",
      "{0: 249, 1: 1623}\n",
      "acc 0.26121794871794873\n",
      "(0.1478743068391867, 1.0, 0.2576489533011272, None)\n",
      "\n",
      "3 loss 1242274.5576285806\n",
      "dev set\n",
      "[0.59521227 0.59194816 0.5941349  0.59406956 0.60711142 0.60649175\n",
      " 0.6077903  0.60639119 0.59512795 0.59431007 0.59349838 0.60588704\n",
      " 0.59346057 0.60686934 0.60672449 0.60673873]\n",
      "[[1.12359826 0.82043344 1.01558756 1.00664289 1.10034852 1.03523593\n",
      "  1.16311902 1.025108   1.15267287 1.07106869 0.98989021 1.06050738\n",
      "  0.9887465  1.07247506 1.0345135  1.03593715]]\n",
      "{0: 237, 1: 1635}\n",
      "acc 0.2548076923076923\n",
      "(0.14678899082568808, 1.0, 0.256, None)\n",
      "\n",
      "4 loss 1242249.4376610217\n",
      "dev set\n",
      "[0.5937343  0.59036873 0.59263432 0.59258706 0.60857287 0.60794201\n",
      " 0.60926033 0.60783701 0.59349749 0.59267975 0.59186816 0.60726168\n",
      " 0.59181481 0.60832281 0.60833773 0.60835197]\n",
      "[[1.12511343 0.82202559 1.017116   1.00815944 1.09887932 1.03376817\n",
      "  1.16164381 1.02364793 1.15431184 1.07271179 0.99153419 1.05894851\n",
      "  0.99040434 1.07100507 1.03290685 1.03433051]]\n",
      "{0: 221, 1: 1651}\n",
      "acc 0.24626068376068377\n",
      "(0.145366444579043, 1.0, 0.2538339502908514, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 1242616.9548273939\n",
      "dev set\n",
      "[0.69966524 0.69663719 0.69863909 0.69852092 0.70259612 0.70197004\n",
      " 0.70325423 0.7018766  0.69995962 0.69913805 0.69832824 0.70212647\n",
      " 0.69832135 0.70234282 0.70193073 0.70194498]\n",
      "[[1.11906753 0.81572306 1.0110278  1.00212092 1.10486333 1.03978456\n",
      "  1.16764937 1.02964163 1.14783635 1.06619373 0.98496896 1.06509764\n",
      "  0.98386591 1.0770271  1.03931087 1.0407345 ]]\n",
      "{0: 598, 1: 1274}\n",
      "acc 0.4423076923076923\n",
      "(0.18445839874411302, 0.9791666666666666, 0.3104359313077939, None)\n",
      "\n",
      "1 loss 1242606.1523360526\n",
      "dev set\n",
      "[0.69816929 0.69508922 0.69715592 0.69702865 0.70411728 0.70350065\n",
      " 0.7047906  0.70340833 0.6983898  0.6975692  0.69675277 0.70361835\n",
      " 0.69674684 0.70387445 0.70350009 0.70351434]\n",
      "[[1.12058187 0.81727704 1.01252651 1.0036293  1.10335547 1.03825557\n",
      "  1.16612264 1.02811293 1.1493958  1.06769372 0.98647199 1.06356343\n",
      "  0.98543293 1.07549704 1.03774791 1.03917154]]\n",
      "{0: 572, 1: 1300}\n",
      "acc 0.4284188034188034\n",
      "(0.18076923076923077, 0.9791666666666666, 0.3051948051948052, None)\n",
      "\n",
      "2 loss 1242594.6444137385\n",
      "dev set\n",
      "[0.69666875 0.69351508 0.69565435 0.69552614 0.70562091 0.70500435\n",
      " 0.70630537 0.70490943 0.6967734  0.69595351 0.69512102 0.70512689\n",
      " 0.69511849 0.70537983 0.70510845 0.7051227 ]\n",
      "[[1.12210591 0.81886028 1.01404765 1.00515273 1.10186086 1.03675063\n",
      "  1.16461582 1.02661406 1.15100211 1.06924452 0.9880352  1.06202319\n",
      "  0.98706259 1.0739906  1.03614319 1.03756683]]\n",
      "{0: 533, 1: 1339}\n",
      "acc 0.4075854700854701\n",
      "(0.1755041075429425, 0.9791666666666666, 0.2976567447751741, None)\n",
      "\n",
      "3 loss 1242582.4341058691\n",
      "dev set\n",
      "[0.69515941 0.69191795 0.69413621 0.69401404 0.70710647 0.70648124\n",
      " 0.70780172 0.70638142 0.69511428 0.6942959  0.69345017 0.70664905\n",
      " 0.6934421  0.70685908 0.7067519  0.70676615]\n",
      "[[1.1236435  0.82046961 1.01558936 1.00669049 1.10037986 1.03526889\n",
      "  1.16312419 1.02514186 1.15265227 1.07084474 0.98965266 1.06047889\n",
      "  0.98874732 1.07250694 1.03450203 1.03592568]]\n",
      "{0: 509, 1: 1363}\n",
      "acc 0.39476495726495725\n",
      "(0.1724137931034483, 0.9791666666666666, 0.2932002495321273, None)\n",
      "\n",
      "4 loss 1242569.5053301451\n",
      "dev set\n",
      "[0.69364028 0.69029943 0.69260252 0.69249281 0.70857391 0.70793128\n",
      " 0.70928078 0.70782471 0.69341381 0.69259418 0.69174011 0.70819178\n",
      " 0.69172198 0.70831218 0.70842548 0.70843972]\n",
      "[[1.12519542 0.82210335 1.01715053 1.00824201 1.09891235 1.03380986\n",
      "  1.16164599 1.02369509 1.154344   1.07249319 0.99132141 1.05893141\n",
      "  0.99048254 1.0710456  1.03282804 1.0342517 ]]\n",
      "{0: 495, 1: 1377}\n",
      "acc 0.3872863247863248\n",
      "(0.17066085693536673, 0.9791666666666666, 0.29066171923314776, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 1242707.9016483016\n",
      "dev set\n",
      "[0.79970893 0.79670212 0.79873043 0.79854276 0.80256898 0.80195896\n",
      " 0.80324822 0.80187144 0.8005418  0.80019764 0.79913254 0.80213307\n",
      " 0.79892596 0.80233221 0.80069976 0.80071461]\n",
      "[[1.11902995 0.81566314 1.01094479 1.0021008  1.10491492 1.03980584\n",
      "  1.16766401 1.02965237 1.1475625  1.06554418 0.9843227  1.0650929\n",
      "  0.98319517 1.07704746 1.0419598  1.04338326]]\n",
      "{0: 943, 1: 929}\n",
      "acc 0.5998931623931624\n",
      "(0.22604951560818085, 0.875, 0.35928143712574856, None)\n",
      "\n",
      "1 loss 1242706.125882814\n",
      "dev set\n",
      "[0.79825866 0.79522427 0.79733378 0.79707752 0.80406645 0.80348063\n",
      " 0.80477588 0.80339645 0.79958655 0.79977874 0.79839188 0.80361994\n",
      " 0.7981698  0.80385531 0.80107941 0.8010949 ]\n",
      "[[1.12050463 0.81715362 1.01236674 1.00358488 1.10345713 1.03830308\n",
      "  1.16616122 1.02814472 1.14881915 1.06631762 0.98511256 1.06356611\n",
      "  0.98405644 1.0755424  1.04302838 1.04445168]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "2 loss 1242704.3019713426\n",
      "dev set\n",
      "[0.79680051 0.79371779 0.79591294 0.79560108 0.80555129 0.80497785\n",
      " 0.80628487 0.80489276 0.79854764 0.79936417 0.7976386  0.80511016\n",
      " 0.79737978 0.80535443 0.80161483 0.80163093]\n",
      "[[1.12199282 0.81867708 1.01381761 1.00508578 1.10200905 1.03682571\n",
      "  1.16467779 1.02666927 1.15011374 1.06709625 0.9859124  1.06204384\n",
      "  0.98502261 1.07406243 1.04399255 1.04541567]]\n",
      "{0: 931, 1: 941}\n",
      "acc 0.593482905982906\n",
      "(0.22316684378320936, 0.875, 0.35563082133784935, None)\n",
      "\n",
      "3 loss 1242702.3895118833\n",
      "dev set\n",
      "[0.79532828 0.79218197 0.79446902 0.79411219 0.8070228  0.80645111\n",
      " 0.80777936 0.80636231 0.79746485 0.79895108 0.79687796 0.80660193\n",
      " 0.79642292 0.80683002 0.80232917 0.80234582]\n",
      "[[1.12350033 0.82023417 1.01529619 1.00660459 1.10057147 1.03537216\n",
      "  1.16320748 1.02522204 1.15145077 1.06788347 0.98672067 1.06052751\n",
      "  0.9860938  1.07260606 1.04483455 1.04625747]]\n",
      "{0: 921, 1: 951}\n",
      "acc 0.5881410256410257\n",
      "(0.22082018927444794, 0.875, 0.3526448362720403, None)\n",
      "\n",
      "4 loss 1242700.3536381482\n",
      "dev set\n",
      "[0.79383872 0.79061443 0.79300073 0.79260947 0.80848123 0.80790067\n",
      " 0.80926129 0.80780573 0.79626694 0.79853765 0.79608976 0.80809487\n",
      " 0.79533069 0.80828235 0.803236   0.80325313]\n",
      "[[1.12503017 0.82182716 1.01680362 1.0081425  1.09914391 1.03394148\n",
      "  1.16174744 1.02380144 1.15283529 1.06868179 0.98753843 1.05901733\n",
      "  0.98727634 1.07117235 1.04552877 1.04695147]]\n",
      "{0: 905, 1: 967}\n",
      "acc 0.5806623931623932\n",
      "(0.21820062047569805, 0.8791666666666667, 0.3496271748135874, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 1242763.054145278\n",
      "dev set\n",
      "[0.89972471 0.89672798 0.8987667  0.8985574  0.90242612 0.90194001\n",
      " 0.90319372 0.90186582 0.90036395 0.89975288 0.8990156  0.90215955\n",
      " 0.89973145 0.90231423 0.89895773 0.89897201]\n",
      "[[1.11900818 0.81563597 1.01090233 1.00208234 1.1051225  1.03985046\n",
      "  1.16776293 1.02966955 1.14761053 1.06576254 0.98452437 1.06506401\n",
      "  0.9829988  1.07709005 1.04234777 1.04377141]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 1242762.0658843773\n",
      "dev set\n",
      "[0.89829567 0.89529833 0.89741186 0.89709786 0.9037991  0.90339644\n",
      " 0.904651   0.90334266 0.8992485  0.89890438 0.8981713  0.90364235\n",
      " 0.89976251 0.90377471 0.89757481 0.89758913]\n",
      "[[1.12045958 0.81708148 1.01227987 1.00356056 1.10385615 1.03847944\n",
      "  1.1663838  1.02825904 1.14889471 1.06675623 0.98551933 1.06353646\n",
      "  0.98353631 1.07571194 1.04386459 1.04528822]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 1242761.0896406875\n",
      "dev set\n",
      "[0.8968642  0.89385698 0.89604117 0.89562734 0.90517048 0.90481632\n",
      " 0.90609141 0.90477847 0.89812491 0.89806619 0.89732983 0.90512775\n",
      " 0.89978897 0.90519906 0.89620948 0.89622385]\n",
      "[[1.12192333 0.81854768 1.01368218 1.00505974 1.10258787 1.03715443\n",
      "  1.16502358 1.02690231 1.15019108 1.06774886 0.98652217 1.06203516\n",
      "  0.98408477 1.07437962 1.04539266 1.0468163 ]]\n",
      "{0: 1096, 1: 776}\n",
      "acc 0.6677350427350427\n",
      "(0.2538659793814433, 0.8208333333333333, 0.38779527559055116, None)\n",
      "\n",
      "3 loss 1242760.0940966338\n",
      "dev set\n",
      "[0.89542665 0.89240677 0.89465921 0.89414748 0.90653625 0.90620548\n",
      " 0.90752079 0.9061793  0.89699278 0.89723634 0.8964945  0.90659894\n",
      " 0.89981159 0.9065929  0.89481017 0.89482459]\n",
      "[[1.12340274 0.82003148 1.01510454 1.00657799 1.10132299 1.03586572\n",
      "  1.16367471 1.02558885 1.15150114 1.06874244 0.98752921 1.06056064\n",
      "  0.984638   1.07308368 1.04693512 1.04835876]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "4 loss 1242759.0759690995\n",
      "dev set\n",
      "[0.89398243 0.89094926 0.89326806 0.89265924 0.90789533 0.90756631\n",
      " 0.90894116 0.90754764 0.89585266 0.8964147  0.89566653 0.90807134\n",
      " 0.89983177 0.90795858 0.89338201 0.89339648]\n",
      "[[1.12489808 0.82153103 1.01654463 1.00811407 1.10006326 1.03460949\n",
      "  1.16233501 1.02431445 1.15282477 1.06973703 0.98853902 1.05911266\n",
      "  0.98519314 1.07182038 1.04849393 1.04991756]]\n",
      "{0: 1092, 1: 780}\n",
      "acc 0.6655982905982906\n",
      "(0.25256410256410255, 0.8208333333333333, 0.3862745098039216, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 1242794.3086178505\n",
      "dev set\n",
      "[1.00305598 0.99647332 1.00199261 1.00039342 1.00295804 1.00239262\n",
      " 1.00351744 1.00229625 1.0033113  1.00259897 0.99848137 1.00261527\n",
      " 0.99836712 1.00271785 1.00238779 1.00240082]\n",
      "[[1.11852217 0.81599058 1.00979612 1.00062455 1.10728357 1.04180935\n",
      "  1.17046742 1.03161318 1.14748172 1.06534819 0.98506851 1.06725167\n",
      "  0.98395326 1.07930037 1.04127988 1.04271273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 1242794.2991849962\n",
      "dev set\n",
      "[1.00567548 0.99444771 1.00490842 1.00354565 1.00560324 1.00520037\n",
      " 1.00601612 1.00513088 1.00586279 1.00534892 0.99675969 1.0053605\n",
      " 0.99653644 1.00543189 1.0051969  1.00520625]\n",
      "[[1.12113552 0.81837243 1.01218445 1.00184673 1.10989332 1.04433805\n",
      "  1.17306255 1.03411415 1.15009048 1.06792288 0.98718332 1.06982909\n",
      "  0.98620584 1.08189124 1.04380729 1.04524358]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 1242794.280764615\n",
      "dev set\n",
      "[1.00866844 0.99219657 1.00811028 1.00707845 1.00861405 1.00832349\n",
      " 1.00891336 1.00827274 1.00880395 1.00843332 0.99486749 1.00844169\n",
      " 0.99452714 1.00849095 1.00832097 1.00832778]\n",
      "[[1.1244219  0.82111427 1.01561253 1.00539887 1.11319323 1.04771633\n",
      "  1.17627342 1.03750452 1.15333664 1.07127533 0.98955132 1.07317933\n",
      "  0.98872102 1.08522604 1.04718618 1.04862081]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 1242794.2510706398\n",
      "dev set\n",
      "[1.01181601 0.98982236 1.01139456 1.01059179 1.01177216 1.0115545\n",
      " 1.01199512 1.01151602 1.01191697 1.01164036 0.99290618 1.01164664\n",
      " 0.99244854 1.0116804  1.01155259 1.01155775]\n",
      "[[1.12795601 0.82404126 1.01926914 1.00925872 1.11673748 1.05132577\n",
      "  1.17974806 1.04112489 1.15683932 1.07486286 0.99201925 1.076765\n",
      "  0.99133516 1.08879841 1.05079617 1.05222932]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 1242794.2084607496\n",
      "dev set\n",
      "[1.01502558 0.98738171 1.01469656 1.01405129 1.01498722 1.01481853\n",
      " 1.01515848 1.01478837 1.0151032  1.01488986 0.99092007 1.01489475\n",
      " 0.99034634 1.01491645 1.01481704 1.01482107]\n",
      "[[1.13159202 0.82706344 1.0229937  1.01313787 1.12037965 1.05501461\n",
      "  1.18334084 1.04482171 1.16045303 1.07853692 0.99452338 1.08043772\n",
      "  0.99398309 1.09246057 1.05448541 1.05591749]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 641472.016850791\n",
      "dev set\n",
      "[0.60039562 0.59737345 0.59933317 0.59924291 0.60183893 0.60119658\n",
      " 0.60247399 0.60109617 0.60068538 0.59986868 0.5990571  0.60136649\n",
      " 0.59904548 0.60156903 0.6011875  0.60120173]\n",
      "[[1.11832616 0.81498387 1.01032437 1.00139064 1.10560648 1.04055511\n",
      "  1.16842537 1.03042301 1.14711073 1.06550213 0.98434062 1.06585009\n",
      "  0.98315676 1.07779813 1.04003465 1.04145829]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "1 loss 641460.3994261825\n",
      "dev set\n",
      "[0.59961943 0.59659728 0.59856809 0.59847949 0.60261288 0.60197391\n",
      " 0.60325292 0.60187481 0.59990139 0.59908443 0.59827279 0.60207498\n",
      " 0.59826037 0.60234652 0.60197131 0.60198554]\n",
      "[[1.11910556 0.81576107 1.01109273 1.00215807 1.10483459 1.03977703\n",
      "  1.16764749 1.02964339 1.14789442 1.06628631 0.98512218 1.06507838\n",
      "  0.98394004 1.07701992 1.03925155 1.04067519]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "2 loss 641448.6279861302\n",
      "dev set\n",
      "[0.59884659 0.595817   0.597802   0.59771613 0.60338228 0.60274441\n",
      " 0.60402548 0.6026457  0.59911207 0.59829491 0.59748324 0.60279189\n",
      " 0.59746897 0.60311736 0.6027591  0.60277333]\n",
      "[[1.11988332 0.81654303 1.01186325 1.00292682 1.104066   1.03900491\n",
      "  1.16687565 1.0288711  1.14868415 1.06707699 0.98591115 1.06430239\n",
      "  0.98473122 1.07624754 1.03846466 1.0398883 ]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "3 loss 641436.7071504724\n",
      "dev set\n",
      "[0.59807521 0.59503355 0.59703493 0.59695284 0.60414662 0.60350799\n",
      " 0.60479237 0.6034091  0.59831784 0.59750054 0.59668881 0.60351615\n",
      " 0.59667168 0.60388147 0.60355052 0.60356475]\n",
      "[[1.12066117 0.81732883 1.01263592 1.00369692 1.10330121 1.03823867\n",
      "  1.1661087  1.0281055  1.14947954 1.06787379 0.98670664 1.0635232\n",
      "  0.98552952 1.07548092 1.03767439 1.03909804]]\n",
      "{0: 267, 1: 1605}\n",
      "acc 0.26976495726495725\n",
      "(0.14890965732087227, 0.9958333333333333, 0.25907859078590784, None)\n",
      "\n",
      "4 loss 641424.6371610075\n",
      "dev set\n",
      "[0.59730456 0.59424735 0.59626689 0.5961896  0.60490579 0.60426469\n",
      " 0.60555396 0.60416521 0.59751899 0.59670155 0.59588979 0.60426148\n",
      " 0.5958688  0.60463888 0.60434536 0.60435959]\n",
      "[[1.12143978 0.81811809 1.01341071 1.00446834 1.10254037 1.03747818\n",
      "  1.1653461  1.0273462  1.15028034 1.06867645 0.98750821 1.06274132\n",
      "  0.9863345  1.07471993 1.03688098 1.03830463]]\n",
      "{0: 262, 1: 1610}\n",
      "acc 0.2670940170940171\n",
      "(0.1484472049689441, 0.9958333333333333, 0.25837837837837835, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 641739.4886623386\n",
      "dev set\n",
      "[0.70039506 0.69737727 0.6993397  0.69924173 0.70183793 0.70119485\n",
      " 0.70247463 0.7010955  0.70069793 0.69988049 0.69907069 0.70142461\n",
      " 0.69905932 0.70156736 0.70117924 0.70119348]\n",
      "[[1.1183267  0.8149803  1.01031828 1.00139142 1.10560877 1.04055792\n",
      "  1.16842485 1.03042414 1.14709825 1.06548425 0.98429824 1.06584442\n",
      "  0.98313919 1.07780083 1.04004807 1.04147171]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "1 loss 641734.1369705517\n",
      "dev set\n",
      "[0.69961803 0.69660117 0.69857803 0.69847565 0.7026109  0.70197116\n",
      " 0.70325383 0.70187343 0.69991717 0.69910036 0.69829018 0.70218911\n",
      " 0.69827818 0.70234387 0.70196149 0.70197573]\n",
      "[[1.11910689 0.8157577  1.01108361 1.00216105 1.10483952 1.03978215\n",
      "  1.16764766 1.02964648 1.14787662 1.06625171 0.98505469 1.06507046\n",
      "  0.98391536 1.07702483 1.03926924 1.04069288]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "2 loss 641728.6155481632\n",
      "dev set\n",
      "[0.69884163 0.69581761 0.69781132 0.697707   0.70337999 0.70274093\n",
      " 0.70402704 0.70264356 0.69912293 0.69830745 0.69749602 0.70295846\n",
      " 0.69748212 0.70311401 0.70275214 0.70276638]\n",
      "[[1.11988791 0.81654332 1.011855   1.00293447 1.104073   1.03901231\n",
      "  1.16687638 1.02887668 1.14866728 1.06703247 0.98582819 1.06429436\n",
      "  0.98470911 1.07625465 1.03847882 1.03990246]]\n",
      "{0: 582, 1: 1290}\n",
      "acc 0.4337606837606838\n",
      "(0.1821705426356589, 0.9791666666666666, 0.30718954248366015, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 641722.9231608228\n",
      "dev set\n",
      "[0.69806376 0.69502756 0.69704002 0.69693575 0.70414473 0.703504\n",
      " 0.70479523 0.70340623 0.69831636 0.69750284 0.6966877  0.70373177\n",
      " 0.69667247 0.7038776  0.70355255 0.70356678]\n",
      "[[1.12067176 0.81733623 1.01263207 1.00371173 1.10330967 1.03824842\n",
      "  1.1661095  1.02811396 1.14946976 1.0678262  0.98661657 1.06351687\n",
      "  0.98551854 1.07549032 1.03767792 1.03910157]]\n",
      "{0: 571, 1: 1301}\n",
      "acc 0.42788461538461536\n",
      "(0.180630284396618, 0.9791666666666666, 0.30499675535366644, None)\n",
      "\n",
      "4 loss 641717.0488815666\n",
      "dev set\n",
      "[0.69728363 0.69423146 0.69626433 0.69616196 0.70490503 0.70426035\n",
      " 0.70555884 0.70416164 0.69749868 0.69668732 0.69586402 0.70450861\n",
      " 0.69585005 0.70463464 0.70436237 0.70437661]\n",
      "[[1.12145915 0.81813597 1.01341456 1.00449279 1.10254961 1.03749041\n",
      "  1.16534633 1.02735789 1.15028367 1.06863259 0.98741897 1.06273831\n",
      "  0.98634253 1.07473177 1.03686726 1.03829091]]\n",
      "{0: 557, 1: 1315}\n",
      "acc 0.4204059829059829\n",
      "(0.17870722433460076, 0.9791666666666666, 0.30225080385852093, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 641828.315982256\n",
      "dev set\n",
      "[0.80040208 0.7973917  0.79936898 0.7992448  0.80183301 0.8011914\n",
      " 0.80247449 0.8010937  0.80087065 0.80035584 0.79937514 0.80142219\n",
      " 0.79924672 0.80156405 0.80067558 0.80069025]\n",
      "[[1.11832104 0.81496706 1.01029189 1.00138862 1.10561867 1.04056417\n",
      "  1.16842574 1.03042744 1.14701683 1.06521395 0.98402241 1.06584363\n",
      "  0.98290513 1.07780681 1.04144571 1.04286929]]\n",
      "{0: 956, 1: 916}\n",
      "acc 0.6057692307692307\n",
      "(0.22816593886462883, 0.8708333333333333, 0.3615916955017301, None)\n",
      "\n",
      "1 loss 641827.3730363456\n",
      "dev set\n",
      "[0.79963544 0.79662967 0.79863465 0.79848396 0.8025999  0.80196487\n",
      " 0.80325259 0.80186944 0.80027114 0.80006573 0.79891031 0.80218459\n",
      " 0.7986728  0.80233786 0.80089551 0.80091065]\n",
      "[[1.11909255 0.8157319  1.01103316 1.00215363 1.10486202 1.0397955\n",
      "  1.16765214 1.02965537 1.14771102 1.06569702 0.98448719 1.06507122\n",
      "  0.98342539 1.07703756 1.04209289 1.04351641]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "2 loss 641826.4214445661\n",
      "dev set\n",
      "[0.79886873 0.79585912 0.79789243 0.79772    0.80336398 0.80273238\n",
      " 0.80402536 0.80263778 0.79964293 0.79977666 0.79843711 0.80294872\n",
      " 0.79820239 0.80310583 0.80118064 0.80119623]\n",
      "[[1.1198658  0.81650637 1.01178349 1.00292322 1.1041074  1.03903304\n",
      "  1.16688443 1.02889179 1.14841562 1.06618223 0.98495775 1.06429919\n",
      "  0.98398547 1.07627444 1.04270928 1.04413273]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "3 loss 641825.4502554344\n",
      "dev set\n",
      "[0.79809933 0.79508045 0.79714336 0.79695267 0.80412472 0.80349367\n",
      " 0.80479389 0.80339901 0.79898506 0.79948829 0.79795942 0.8037138\n",
      " 0.79769298 0.80386768 0.80153276 0.80154663]\n",
      "[[1.12064332 0.81729011 1.01254192 1.00369767 1.10335537 1.03827685\n",
      "  1.16612081 1.02813582 1.14913164 1.06667032 0.98543202 1.0635283\n",
      "  0.98458142 1.07551753 1.04329348 1.04471685]]\n",
      "{0: 939, 1: 933}\n",
      "acc 0.5977564102564102\n",
      "(0.22508038585209003, 0.875, 0.35805626598465473, None)\n",
      "\n",
      "4 loss 641824.4486094872\n",
      "dev set\n",
      "[0.79732597 0.7942934  0.79638754 0.7961817  0.80488202 0.80424872\n",
      " 0.80555879 0.80415334 0.79830837 0.79920005 0.79747831 0.80447955\n",
      " 0.79712178 0.80462342 0.80195668 0.80197059]\n",
      "[[1.12142626 0.81808336 1.01330834 1.00447723 1.10260599 1.0375268\n",
      "  1.16536034 1.02738701 1.1498602  1.06716185 0.98590964 1.06275878\n",
      "  0.98521259 1.07476669 1.04384166 1.04526496]]\n",
      "{0: 930, 1: 942}\n",
      "acc 0.592948717948718\n",
      "(0.2229299363057325, 0.875, 0.35532994923857875, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 641883.2892503497\n",
      "dev set\n",
      "[0.9004065  0.89739654 0.89938178 0.89925089 0.9017991  0.9011867\n",
      " 0.90246517 0.90109245 0.90084229 0.90011293 0.89935565 0.90142955\n",
      " 0.89967606 0.90155962 0.8996437  0.89965795]\n",
      "[[1.11831581 0.81496177 1.0102774  1.00138171 1.10567118 1.04057603\n",
      "  1.16844345 1.03043158 1.14702807 1.06532461 0.98411292 1.06583455\n",
      "  0.98279672 1.07781806 1.04159327 1.04301691]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 641882.7666493972\n",
      "dev set\n",
      "[0.89964738 0.89664624 0.8986608  0.89849418 0.90253231 0.90194538\n",
      " 0.90322904 0.90185761 0.90020371 0.89958083 0.89887157 0.9021922\n",
      " 0.89969653 0.90231934 0.89889397 0.89890822]\n",
      "[[1.11907975 0.81571561 1.01100442 1.00214257 1.1049697  1.03984025\n",
      "  1.16769734 1.02968264 1.14773284 1.06592003 0.98466633 1.06505949\n",
      "  0.98315641 1.07708023 1.04236374 1.04378738]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 641882.2410588935\n",
      "dev set\n",
      "[0.89888982 0.89589189 0.89793386 0.89773403 0.90326584 0.90269431\n",
      " 0.90398762 0.9026118  0.89956371 0.89905191 0.89838625 0.90295219\n",
      " 0.89971937 0.90306944 0.89815259 0.89816388]\n",
      "[[1.11984498 0.81647593 1.01173982 1.00290952 1.10426698 1.03911734\n",
      "  1.16695791 1.02894854 1.14844021 1.06651544 0.98522424 1.06429069\n",
      "  0.98352472 1.07635515 1.04313708 1.04456072]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "3 loss 641881.7244507719\n",
      "dev set\n",
      "[0.89813148 0.8951344  0.89720269 0.89697091 0.90399835 0.90343487\n",
      " 0.90474292 0.90335653 0.89892166 0.89852547 0.89790171 0.903715\n",
      " 0.89974054 0.90381125 0.89744578 0.89745708]\n",
      "[[1.12061383 0.81724187 1.01248196 1.00368214 1.10356469 1.03840473\n",
      "  1.16622222 1.02822647 1.14915133 1.06711175 0.98578465 1.06352856\n",
      "  0.98389847 1.07564034 1.04391398 1.04533764]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 641881.207834328\n",
      "dev set\n",
      "[0.89737138 0.89437403 0.89646786 0.89620499 0.90472946 0.90416771\n",
      " 0.90549585 0.90409249 0.89827707 0.89800114 0.89741857 0.90447565\n",
      " 0.89975928 0.9045454  0.896732   0.8967451 ]\n",
      "[[1.12138719 0.81801317 1.01323028 1.00446026 1.10286335 1.03770127\n",
      "  1.16548902 1.0275152  1.14986668 1.06770929 0.98634693 1.06277327\n",
      "  0.98427601 1.0749347  1.0446942  1.04611786]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 641914.3100505501\n",
      "dev set\n",
      "[1.00201359 0.99734421 1.00088108 1.00004839 1.0019049  1.00127123\n",
      " 1.00251906 1.00116737 1.00229477 1.00150093 0.99914553 1.00151928\n",
      " 0.99909634 1.00163526 1.00126595 1.00128022]\n",
      "[[1.11791412 0.81503141 1.00957676 1.00062431 1.10670237 1.04142232\n",
      "  1.16975205 1.03126654 1.14681051 1.06488128 0.98429211 1.06677891\n",
      "  0.98312189 1.0787924  1.04089483 1.04232233]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 641914.3070143061\n",
      "dev set\n",
      "[1.00305772 0.996455   1.00204848 1.00099521 1.00296016 1.00240165\n",
      " 1.00351827 1.00230951 1.00331241 1.00260367 0.9983301  1.00261977\n",
      " 0.99825349 1.00272136 1.00239698 1.00240958]\n",
      "[[1.118794   0.81600835 1.00997554 1.0006487  1.10755814 1.0420359\n",
      "  1.17069588 1.03182509 1.14773409 1.06560326 0.98524254 1.0675086\n",
      "  0.98410443 1.07956713 1.04150569 1.04294053]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 641914.3022320623\n",
      "dev set\n",
      "[1.004299   0.99547189 1.00343926 1.00248223 1.00421504 1.00374204\n",
      " 1.00469881 1.00366361 1.004519   1.00391349 0.99741248 1.00392709\n",
      " 0.99730377 1.00401241 1.00373808 1.00374877]\n",
      "[[1.1200506  0.81714609 1.01112732 1.0012959  1.10881515 1.0432589\n",
      "  1.17193477 1.03303373 1.14898329 1.06684823 0.98636079 1.06875477\n",
      "  0.9852582  1.08081898 1.04272803 1.04416462]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 641914.2952688826\n",
      "dev set\n",
      "[1.00567755 0.99441502 1.00495125 1.00411927 1.00560592 1.00520813\n",
      " 1.0060178  1.00514178 1.00586438 1.00535321 0.99642823 1.00536464\n",
      " 0.99628602 1.00543559 1.00520478 1.00521382]\n",
      "[[1.12153186 0.81840547 1.01266364 1.00277923 1.1103039  1.04478365\n",
      "  1.1733746  1.03456235 1.15044244 1.06836265 0.98758088 1.0702682\n",
      "  0.98651513 1.08232541 1.04425299 1.045689  ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 641914.2857834877\n",
      "dev set\n",
      "[1.00714535 0.99330311 1.00652894 1.00580936 1.0070838  1.00674752\n",
      " 1.00743369 1.00669108 1.00730382 1.00687135 0.99540195 1.00688102\n",
      " 0.9952262  1.00694004 1.00674468 1.00675235]\n",
      "[[1.12314746 0.81975239 1.01435943 1.0045387  1.1119276  1.04645318\n",
      "  1.17494725 1.03623882 1.15203489 1.07001683 0.98886316 1.07192109\n",
      "  0.98783449 1.0839695  1.04592288 1.04735793]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall penalty\n",
      "0 loss 351394.8717504587\n",
      "dev set\n",
      "[0.60076946 0.5977431  0.59969381 0.59961021 0.60146613 0.60081777\n",
      " 0.60209597 0.60071671 0.60106089 0.6002446  0.59943306 0.60104369\n",
      " 0.59942127 0.6011902  0.60081102 0.60082526]\n",
      "[[1.11795067 0.81461379 1.00996168 1.00102149 1.10597633 1.04093407\n",
      "  1.16880253 1.03080299 1.14673646 1.06512615 0.98397079 1.06621567\n",
      "  0.9827831  1.07817711 1.04041018 1.04183383]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "1 loss 351388.93654255616\n",
      "dev set\n",
      "[0.60036758 0.59734681 0.59929454 0.59921849 0.60186385 0.60121639\n",
      " 0.60249522 0.60111649 0.60066172 0.5998453  0.59903374 0.60142255\n",
      " 0.59902186 0.60158884 0.6012103  0.60122453]\n",
      "[[1.11835277 0.81501033 1.01036123 1.0014144  1.10557904 1.04053529\n",
      "  1.16840373 1.03040265 1.14713552 1.06552494 0.9843689  1.065819\n",
      "  0.9831814  1.07777831 1.04001116 1.0414348 ]]\n",
      "{0: 279, 1: 1593}\n",
      "acc 0.2761752136752137\n",
      "(0.15003138731952292, 0.9958333333333333, 0.2607746863066012, None)\n",
      "\n",
      "2 loss 351382.98207751545\n",
      "dev set\n",
      "[0.59996633 0.59694928 0.5988946  0.59882664 0.60226081 0.6016137\n",
      " 0.60289319 0.6015148  0.60026111 0.59944459 0.59863302 0.60180469\n",
      " 0.59862081 0.60198621 0.6016107  0.60162493]\n",
      "[[1.11875462 0.81540826 1.01076169 1.00180773 1.10518225 1.04013766\n",
      "  1.16800621 1.03000368 1.1475362  1.06592532 0.98476898 1.06542084\n",
      "  0.98358173 1.07738063 1.03961103 1.04103467]]\n",
      "{0: 274, 1: 1598}\n",
      "acc 0.27350427350427353\n",
      "(0.14956195244055068, 0.9958333333333333, 0.2600652883569097, None)\n",
      "\n",
      "3 loss 351376.9848540034\n",
      "dev set\n",
      "[0.5995653  0.59655051 0.59849395 0.59843449 0.60265687 0.60200961\n",
      " 0.60328996 0.60191158 0.59985887 0.59904226 0.59823068 0.60218963\n",
      " 0.59821787 0.60238224 0.60201239 0.60202662]\n",
      "[[1.11915664 0.81580759 1.01116313 1.0022017  1.10478606 1.03974119\n",
      "  1.16760977 1.02960609 1.14793869 1.06632759 0.98517113 1.06502135\n",
      "  0.98398429 1.07698409 1.03920966 1.0406333 ]]\n",
      "{0: 273, 1: 1599}\n",
      "acc 0.27297008547008544\n",
      "(0.14946841776110067, 0.9958333333333333, 0.25992387166938546, None)\n",
      "\n",
      "4 loss 351370.9443091367\n",
      "dev set\n",
      "[0.59916436 0.59615066 0.59809272 0.5980421  0.60305186 0.60240399\n",
      " 0.60368551 0.60230671 0.59945509 0.5986384  0.59782681 0.60257701\n",
      " 0.59781314 0.60277677 0.60241528 0.60242952]\n",
      "[[1.119559   0.81620818 1.01156546 1.00259627 1.10439062 1.039346\n",
      "  1.16721434 1.02920994 1.14834292 1.0667317  0.98557521 1.06462075\n",
      "  0.98438895 1.07658879 1.03880715 1.04023079]]\n",
      "{0: 269, 1: 1603}\n",
      "acc 0.2708333333333333\n",
      "(0.14909544603867747, 0.9958333333333333, 0.25935973955507324, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 351660.7800291842\n",
      "dev set\n",
      "[0.70077002 0.69774433 0.69969605 0.69960929 0.70146621 0.70081733\n",
      " 0.70209617 0.7007165  0.70106488 0.70024853 0.69943766 0.70106274\n",
      " 0.69942578 0.70118977 0.70080838 0.70082262]\n",
      "[[1.11795025 0.81461263 1.00995962 1.0010222  1.10597633 1.04093478\n",
      "  1.16880235 1.03080333 1.14673261 1.06512267 0.98395925 1.06621389\n",
      "  0.98277646 1.07817779 1.04041486 1.0418385 ]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "1 loss 351658.05580007803\n",
      "dev set\n",
      "[0.70036833 0.69734867 0.69929869 0.69921673 0.70186394 0.70121569\n",
      " 0.70249537 0.70111601 0.70066768 0.69985174 0.699041   0.70145722\n",
      " 0.69902886 0.70158817 0.7012065  0.70122073]\n",
      "[[1.11835226 0.81500863 1.01035743 1.00141578 1.10557921 1.04053651\n",
      "  1.16840398 1.03040356 1.14712988 1.06551644 0.98434889 1.06581663\n",
      "  0.98317044 1.07777948 1.04001818 1.04144182]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "2 loss 351655.29782504594\n",
      "dev set\n",
      "[0.69996664 0.69695102 0.69889972 0.69882348 0.70226104 0.70161283\n",
      " 0.70289332 0.70151406 0.70026704 0.69945178 0.69864093 0.70185331\n",
      " 0.69862822 0.70198538 0.70160726 0.7016215 ]\n",
      "[[1.11875459 0.81540677 1.01075706 1.00181033 1.10518247 1.04013935\n",
      "  1.16800694 1.03000528 1.14753028 1.06591309 0.98474272 1.0654185\n",
      "  0.98356879 1.07738226 1.03961845 1.04104209]]\n",
      "{0: 605, 1: 1267}\n",
      "acc 0.44604700854700857\n",
      "(0.18547750591949486, 0.9791666666666666, 0.31187790311877905, None)\n",
      "\n",
      "3 loss 351652.49384494225\n",
      "dev set\n",
      "[0.69956443 0.6965513  0.69849907 0.69842926 0.70265743 0.70200864\n",
      " 0.7032902  0.70191056 0.69986275 0.69904821 0.69823732 0.70225093\n",
      " 0.69822359 0.7023813  0.70201086 0.7020251 ]\n",
      "[[1.1191578  0.81580718 1.01115862 1.00220614 1.10478617 1.03974334\n",
      "  1.1676109  1.02960849 1.14793409 1.06631326 0.98514074 1.06501956\n",
      "  0.98397172 1.07698616 1.03921553 1.04063917]]\n",
      "{0: 597, 1: 1275}\n",
      "acc 0.44177350427350426\n",
      "(0.1843137254901961, 0.9791666666666666, 0.3102310231023102, None)\n",
      "\n",
      "4 loss 351649.6456218654\n",
      "dev set\n",
      "[0.69916151 0.69614963 0.69809688 0.69803412 0.70305293 0.70240297\n",
      " 0.70368603 0.70230541 0.69945493 0.69864147 0.69783018 0.70264989\n",
      " 0.69781509 0.70277578 0.7024164  0.70243064]\n",
      "[[1.11956206 0.81620975 1.01156199 1.00260319 1.10439047 1.03934864\n",
      "  1.16721575 1.02921323 1.14834127 1.06671697 0.98554279 1.06461999\n",
      "  0.98437902 1.07659134 1.03880955 1.04023319]]\n",
      "{0: 590, 1: 1282}\n",
      "acc 0.43803418803418803\n",
      "(0.18330733229329174, 0.9791666666666666, 0.3088042049934297, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 351748.5415657666\n",
      "dev set\n",
      "[0.80077363 0.79774795 0.79970489 0.79960891 0.8014655  0.80081648\n",
      " 0.80209632 0.80071593 0.8011005  0.80048737 0.79954111 0.80106171\n",
      " 0.7994966  0.80118896 0.80058227 0.80059678]\n",
      "[[1.11794728 0.81460935 1.00995169 1.00102251 1.10597788 1.04093628\n",
      "  1.16880224 1.03080432 1.14671287 1.06505694 0.98388316 1.06621321\n",
      "  0.98268284 1.07817923 1.04118632 1.04260994]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "1 loss 351748.0453372067\n",
      "dev set\n",
      "[0.80037552 0.79735644 0.7993168  0.79921769 0.80186203 0.80121427\n",
      " 0.80249507 0.80111449 0.80074065 0.80027161 0.79925809 0.80145549\n",
      " 0.7991677  0.80158681 0.80071678 0.80073163]\n",
      "[[1.11834631 0.8150016  1.01034126 1.00141488 1.10558318 1.04053936\n",
      "  1.16840497 1.03040644 1.14709184 1.06536469 0.9841818  1.06581598\n",
      "  0.98297285 1.0777822  1.04155864 1.04298225]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "2 loss 351747.54485566384\n",
      "dev set\n",
      "[0.79997709 0.79696266 0.79892631 0.79882574 0.80225816 0.80161097\n",
      " 0.80289267 0.8015116  0.80037322 0.80005663 0.79897296 0.80185027\n",
      " 0.79882667 0.80198359 0.80087414 0.80088931]\n",
      "[[1.11874603 0.81539634 1.01073345 1.0018083  1.10518869 1.04014352\n",
      "  1.1680091  1.03001028 1.14747382 1.06567261 0.98448034 1.06541845\n",
      "  0.98327397 1.07738625 1.04192534 1.04334893]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "3 loss 351747.03924278636\n",
      "dev set\n",
      "[0.79957772 0.7965663  0.79853339 0.79843264 0.80265384 0.80200648\n",
      " 0.80328939 0.80190722 0.79999659 0.79984203 0.79868596 0.80224584\n",
      " 0.79852929 0.80237921 0.80106034 0.80107492]\n",
      "[[1.11914708 0.81579394 1.01112837 1.00220324 1.10479447 1.03974888\n",
      "  1.16761417 1.02961575 1.14785925 1.06598144 0.98477954 1.06502077\n",
      "  0.98358706 1.07699147 1.04228463 1.0437082 ]]\n",
      "{0: 941, 1: 931}\n",
      "acc 0.5988247863247863\n",
      "(0.22556390977443608, 0.875, 0.35866780529462, None)\n",
      "\n",
      "4 loss 351746.531672218\n",
      "dev set\n",
      "[0.79917718 0.7961674  0.79813822 0.79803838 0.80304887 0.8024006\n",
      " 0.80368527 0.80230125 0.79961085 0.79962774 0.79839755 0.802642\n",
      " 0.7982547  0.80277348 0.80127418 0.80128725]\n",
      "[[1.11954971 0.81619439 1.01152587 1.00259974 1.10440068 1.03935561\n",
      "  1.16722003 1.02922292 1.14824828 1.06629135 0.98507954 1.06462309\n",
      "  0.98391139 1.07659805 1.04263558 1.04405914]]\n",
      "{0: 940, 1: 932}\n",
      "acc 0.5982905982905983\n",
      "(0.22532188841201717, 0.875, 0.3583617747440273, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 351803.4182141307\n",
      "dev set\n",
      "[0.90077642 0.89774973 0.89970992 0.89961101 0.90145631 0.90081573\n",
      " 0.90209463 0.90071554 0.90109916 0.90029145 0.89951498 0.90106535\n",
      " 0.89972337 0.90118827 0.9000118  0.90002604]\n",
      "[[1.11794436 0.81460741 1.00994637 1.00102013 1.10599284 1.04093873\n",
      "  1.16880542 1.03080553 1.14672123 1.06509567 0.9839133  1.06621072\n",
      "  0.98263782 1.07818152 1.04121648 1.04264013]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 351803.14383964636\n",
      "dev set\n",
      "[0.9003822  0.89736322 0.89932829 0.89922201 0.90184363 0.90121147\n",
      " 0.9024896  0.90111135 0.90073561 0.89995611 0.89921035 0.90146055\n",
      " 0.89972778 0.90158419 0.89961843 0.89963267]\n",
      "[[1.11833963 0.81499475 1.01032947 1.00141015 1.10561368 1.0405471\n",
      "  1.16841539 1.03041372 1.14710397 1.06545079 0.98424457 1.06581266\n",
      "  0.9828582  1.07778951 1.04161592 1.04303957]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 351802.8693457432\n",
      "dev set\n",
      "[0.89998809 0.89697573 0.89894485 0.89883223 0.90223139 0.90160536\n",
      " 0.90288324 0.90150478 0.90037188 0.89962175 0.89890696 0.90185556\n",
      " 0.89974078 0.90197828 0.89922454 0.89923879]\n",
      "[[1.11873543 0.81538362 1.01071491 1.00180154 1.10523382 1.04015792\n",
      "  1.1680273  1.03002527 1.14748719 1.06580574 0.98457591 1.06541576\n",
      "  0.9830797  1.07739992 1.04201629 1.04343993]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 351802.5933077878\n",
      "dev set\n",
      "[0.89959362 0.89658706 0.89855976 0.89844139 0.90261936 0.90199746\n",
      " 0.9032761  0.90189604 0.90000766 0.89928803 0.89860418 0.90225017\n",
      " 0.89975497 0.90237059 0.89882969 0.89884394]\n",
      "[[1.11913233 0.8157743  1.01110267 1.00219467 1.10485354 1.03977102\n",
      "  1.16764027 1.02963973 1.14787147 1.06616114 0.98490786 1.06502016\n",
      "  0.98330359 1.07701261 1.04241802 1.04384166]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "4 loss 351802.3155988809\n",
      "dev set\n",
      "[0.89919861 0.89619734 0.89817328 0.89804958 0.9030073  0.90238772\n",
      " 0.90366835 0.90228514 0.89964279 0.89895488 0.89830191 0.90264416\n",
      " 0.899769   0.90276109 0.89843366 0.89844792]\n",
      "[[1.11953054 0.81616669 1.01149249 1.00258949 1.10447317 1.03938638\n",
      "  1.16725398 1.02925695 1.14825701 1.06651712 0.98524047 1.06462605\n",
      "  0.98352943 1.07662756 1.0428212  1.04424485]]\n",
      "{0: 1095, 1: 777}\n",
      "acc 0.6672008547008547\n",
      "(0.25353925353925355, 0.8208333333333333, 0.38741396263520156, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 351834.31061878154\n",
      "dev set\n",
      "[1.00158846 0.9977371  1.00046728 1.00002156 1.0014773  1.00082839\n",
      " 1.0021032  1.00072474 1.00187522 1.0010627  0.99945553 1.00108154\n",
      " 0.99944395 1.00120069 1.00082306 1.00083747]\n",
      "[[1.117732   0.81462273 1.00956177 1.00062431 1.10653885 1.04136403\n",
      "  1.16949167 1.03122255 1.14658253 1.06478704 0.98395183 1.06668163\n",
      "  0.9827584  1.07867547 1.04083731 1.04226273]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 351834.3093998579\n",
      "dev set\n",
      "[1.00204011 0.9973179  1.00094303 1.0002612  1.00193189 1.00130426\n",
      " 1.00254401 1.00120314 1.00232031 1.00153069 0.99905281 1.00154887\n",
      " 0.99904163 1.00166385 1.00129909 1.00131307]\n",
      "[[1.118066   0.81505934 1.00960194 1.00062446 1.10685236 1.04149586\n",
      "  1.1698833  1.03132351 1.14695497 1.06499258 0.98438848 1.06689297\n",
      "  0.98319517 1.07892205 1.04096749 1.04239736]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 351834.3078179956\n",
      "dev set\n",
      "[1.00255056 0.99687284 1.00151084 1.00079332 1.00244759 1.00185612\n",
      " 1.00303401 1.00176052 1.00281858 1.00206911 0.99861393 1.00208619\n",
      " 0.99860121 1.00219425 1.00185124 1.00186442]\n",
      "[[1.11852452 0.81554147 1.00980237 1.00064265 1.10730132 1.04182201\n",
      "  1.17036292 1.03161716 1.14742887 1.06537865 0.98489344 1.06728304\n",
      "  0.98370062 1.07933467 1.04129206 1.0427262 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 351834.3057908942\n",
      "dev set\n",
      "[1.00311972 0.9964009  1.00215251 1.00145369 1.00302337 1.00247519\n",
      " 1.00357578 1.0023864  1.00337172 1.00267241 0.99814136 1.00268821\n",
      " 0.99812587 1.00278802 1.00247067 1.00248289]\n",
      "[[1.11908726 0.81607021 1.01024193 1.0008198  1.10786219 1.04233595\n",
      "  1.17092283 1.03211469 1.14799177 1.0659189  0.985456   1.06782485\n",
      "  0.98426406 1.07988474 1.04180523 1.04324141]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 351834.3032505019\n",
      "dev set\n",
      "[1.00374041 0.99590416 1.00284947 1.00218897 1.00365118 1.00314767\n",
      " 1.00416544 1.00306592 1.00397456 1.00332889 0.9976408  1.00334337\n",
      " 0.99762191 1.00343472 1.00314351 1.00315475]\n",
      "[[1.11973228 0.81664122 1.01086331 1.00129737 1.10850946 1.04298065\n",
      "  1.17155181 1.032755   1.14862867 1.06656878 0.98606363 1.06847489\n",
      "  0.98487285 1.08053502 1.04244975 1.04388643]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 206356.29832303466\n",
      "dev set\n",
      "[0.60096027 0.5979289  0.59988195 0.59979234 0.60127745 0.60062757\n",
      " 0.60190623 0.6005264  0.60124967 0.60043351 0.59962198 0.60087453\n",
      " 0.59961011 0.601      0.6006219  0.60063613]\n",
      "[[1.11775974 0.81442781 1.00977334 1.00083825 1.10616437 1.0411243\n",
      "  1.16899192 1.03099341 1.14654838 1.064937   0.98378384 1.06640104\n",
      "  0.98259542 1.07836735 1.0405987  1.04202234]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 206353.1830416964\n",
      "dev set\n",
      "[0.60075139 0.597722   0.59967409 0.59958652 0.6014846  0.60083498\n",
      " 0.60211407 0.60073439 0.60104224 0.60022605 0.59941452 0.60107971\n",
      " 0.59940263 0.60120741 0.60082936 0.60084359]\n",
      "[[1.11796858 0.81463475 1.00998123 1.00104428 1.10595733 1.04091686\n",
      "  1.16878409 1.03078516 1.14675593 1.06514408 0.98399099 1.06619355\n",
      "  0.98280267 1.0781599  1.04039121 1.04181486]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "2 loss 206350.10474931754\n",
      "dev set\n",
      "[0.60054325 0.59751558 0.59946668 0.59938162 0.60169094 0.60104146\n",
      " 0.60232105 0.6009415  0.60083522 0.60001899 0.59920746 0.60128534\n",
      " 0.59919552 0.6014139  0.60103636 0.60105059]\n",
      "[[1.11817675 0.81484125 1.01018871 1.00124946 1.10575105 1.0407103\n",
      "  1.1685771  1.03057776 1.14696312 1.06535073 0.98419783 1.06598635\n",
      "  0.9830096  1.07795334 1.04018421 1.04160785]]\n",
      "{0: 280, 1: 1592}\n",
      "acc 0.2767094017094017\n",
      "(0.15012562814070352, 0.9958333333333333, 0.2609170305676856, None)\n",
      "\n",
      "3 loss 206347.02271556674\n",
      "dev set\n",
      "[0.60033526 0.59730903 0.59925921 0.59917689 0.60189698 0.60124754\n",
      " 0.60252767 0.60114819 0.60062797 0.59981171 0.59900018 0.60149167\n",
      " 0.59898813 0.60162    0.60124351 0.60125774]\n",
      "[[1.11838485 0.81504791 1.0103963  1.00145454 1.10554499 1.0405041\n",
      "  1.16837045 1.03037073 1.14717056 1.06555764 0.984405   1.06577895\n",
      "  0.98321686 1.07774713 1.03997706 1.0414007 ]]\n",
      "{0: 278, 1: 1594}\n",
      "acc 0.27564102564102566\n",
      "(0.14993726474278546, 0.9958333333333333, 0.2606324972737186, None)\n",
      "\n",
      "4 loss 206343.93085920735\n",
      "dev set\n",
      "[0.60012727 0.5971022  0.59905154 0.59897216 0.60210282 0.60145331\n",
      " 0.60273404 0.60135454 0.60042034 0.59960405 0.59879251 0.60169871\n",
      " 0.59878029 0.6018258  0.60145097 0.6014652 ]\n",
      "[[1.11859305 0.81525488 1.01060415 1.00165972 1.10533907 1.04029817\n",
      "  1.168164   1.03016399 1.14737843 1.065765   0.98461264 1.06557122\n",
      "  0.98342464 1.07754117 1.03976962 1.04119326]]\n",
      "{0: 275, 1: 1597}\n",
      "acc 0.27403846153846156\n",
      "(0.14965560425798372, 0.9958333333333333, 0.26020685900925417, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 206621.42359608205\n",
      "dev set\n",
      "[0.70096017 0.6979291  0.69988255 0.6997928  0.70127755 0.70062746\n",
      " 0.70190631 0.70052635 0.70125037 0.70043408 0.69962264 0.70087881\n",
      " 0.69961094 0.70099989 0.70062143 0.70063567]\n",
      "[[1.11775985 0.81442762 1.00977278 1.00083785 1.10616422 1.04112449\n",
      "  1.16899183 1.0309935  1.14654808 1.06493565 0.9837815  1.06640084\n",
      "  0.98259474 1.07836753 1.0405993  1.04202295]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n",
      "1 loss 206619.9930347919\n",
      "dev set\n",
      "[0.70075118 0.69772254 0.69967552 0.69958717 0.70148481 0.7008348\n",
      " 0.70211423 0.70073425 0.70104329 0.70022714 0.69941578 0.70108584\n",
      " 0.69940403 0.70120723 0.70082866 0.70084289]\n",
      "[[1.11796882 0.81463425 1.0099799  1.00104371 1.10595702 1.04091717\n",
      "  1.16878393 1.03078538 1.14675563 1.06514047 0.98398623 1.06619361\n",
      "  0.98280133 1.0781602  1.0403922  1.04181585]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 206618.57382909747\n",
      "dev set\n",
      "[0.70054281 0.69751635 0.69946881 0.69938229 0.7016913  0.70104124\n",
      " 0.7023213  0.70094127 0.70083627 0.7000203  0.699209   0.7012926\n",
      " 0.69919711 0.70141369 0.7010357  0.70104994]\n",
      "[[1.11817722 0.81484054 1.01018673 1.00124887 1.10575052 1.04071072\n",
      "  1.16857688 1.03057813 1.14696307 1.06534504 0.98419098 1.06598683\n",
      "  0.98300798 1.07795374 1.04018525 1.0416089 ]]\n",
      "{0: 609, 1: 1263}\n",
      "acc 0.4481837606837607\n",
      "(0.18606492478226444, 0.9791666666666666, 0.31270791749833665, None)\n",
      "\n",
      "3 loss 206617.14685267478\n",
      "dev set\n",
      "[0.70033445 0.69730988 0.69926184 0.69917743 0.70189754 0.7012473\n",
      " 0.70252805 0.70114787 0.70062861 0.69981297 0.6990016  0.70149961\n",
      " 0.69898948 0.70161976 0.70124322 0.70125746]\n",
      "[[1.11838569 0.81504715 1.01039387 1.00145408 1.10554423 1.04050463\n",
      "  1.16837012 1.03037128 1.1471711  1.06555016 0.98439645 1.06577996\n",
      "  0.98321543 1.07774763 1.03997778 1.04140142]]\n",
      "{0: 608, 1: 1264}\n",
      "acc 0.44764957264957267\n",
      "(0.18591772151898733, 0.9791666666666666, 0.3125, None)\n",
      "\n",
      "4 loss 206615.7088297014\n",
      "dev set\n",
      "[0.70012591 0.69710293 0.69905446 0.69897239 0.70210362 0.70145305\n",
      " 0.70273459 0.70135414 0.70042009 0.69960486 0.69879336 0.701707\n",
      " 0.69878092 0.70182554 0.70145142 0.70146566]\n",
      "[[1.11859442 0.81525428 1.01060149 1.00165956 1.10533802 1.0402988\n",
      "  1.16816354 1.03016474 1.14737992 1.06575611 0.98460286 1.06557289\n",
      "  0.98342392 1.07754178 1.03976956 1.04119321]]\n",
      "{0: 606, 1: 1266}\n",
      "acc 0.4465811965811966\n",
      "(0.18562401263823064, 0.9791666666666666, 0.31208499335989376, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 206708.65678004376\n",
      "dev set\n",
      "[0.80096077 0.79792991 0.79988473 0.7997941  0.8012775  0.80062722\n",
      " 0.80190634 0.80052619 0.80125369 0.80054345 0.79965421 0.80087838\n",
      " 0.79962036 0.80099966 0.80054749 0.80056189]\n",
      "[[1.11775938 0.81442688 1.00977081 1.00083669 1.10616436 1.04112493\n",
      "  1.16899179 1.03099375 1.1465465  1.06491414 0.98375529 1.06640076\n",
      "  0.98258168 1.07836795 1.04102759 1.04245124]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "1 loss 206708.39014527563\n",
      "dev set\n",
      "[0.80075258 0.797725   0.79968058 0.79959001 0.80148462 0.8008344\n",
      " 0.80211422 0.80073377 0.8010495  0.8004067  0.79948909 0.80108499\n",
      " 0.79942385 0.80120686 0.80064945 0.80066408]\n",
      "[[1.11796769 0.81463199 1.00997533 1.00104117 1.1059574  1.04091795\n",
      "  1.16878395 1.03078613 1.14675175 1.06509137 0.98392085 1.06619364\n",
      "  0.98276506 1.07816094 1.04123525 1.0426589 ]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "2 loss 206708.12638705323\n",
      "dev set\n",
      "[0.80054493 0.79752049 0.79947667 0.79938661 0.80169103 0.80104072\n",
      " 0.80232129 0.80094046 0.80084421 0.80027048 0.79932546 0.80129122\n",
      " 0.79922558 0.8014132  0.80075625 0.8007711 ]\n",
      "[[1.11817554 0.81483673 1.01017964 1.00124501 1.1057511  1.04071184\n",
      "  1.16857693 1.03057942 1.14695683 1.06526798 0.98408429 1.0659871\n",
      "  0.98294875 1.0779548  1.04144104 1.04286469]]\n",
      "{0: 955, 1: 917}\n",
      "acc 0.6063034188034188\n",
      "(0.22900763358778625, 0.875, 0.36300777873811585, None)\n",
      "\n",
      "3 loss 206707.8607575374\n",
      "dev set\n",
      "[0.80033718 0.7973156  0.79927233 0.79918317 0.80189725 0.80124668\n",
      " 0.80252809 0.80114674 0.80063693 0.80013444 0.79916202 0.80149756\n",
      " 0.79902449 0.80161917 0.80087254 0.80088761]\n",
      "[[1.11838356 0.81504192 1.01038444 1.00144898 1.10554493 1.04050608\n",
      "  1.16837017 1.03037314 1.14716249 1.06544466 0.98424718 1.0657806\n",
      "  0.98313471 1.07774902 1.04164511 1.04306876]]\n",
      "{0: 950, 1: 922}\n",
      "acc 0.6036324786324786\n",
      "(0.227765726681128, 0.875, 0.3614457831325302, None)\n",
      "\n",
      "4 loss 206707.59233609686\n",
      "dev set\n",
      "[0.80012912 0.7971101  0.79906739 0.79897945 0.80210338 0.80145235\n",
      " 0.80273474 0.8013527  0.80042711 0.79999845 0.79899844 0.8017041\n",
      " 0.79882017 0.80182488 0.80099995 0.80101521]\n",
      "[[1.11859199 0.81524779 1.01058992 1.00165332 1.1053388  1.04030061\n",
      "  1.16816354 1.0301672  1.14736901 1.06562165 0.98440997 1.06557405\n",
      "  0.98332361 1.07754351 1.04184727 1.04327091]]\n",
      "{0: 942, 1: 930}\n",
      "acc 0.5993589743589743\n",
      "(0.22580645161290322, 0.875, 0.358974358974359, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 206763.48452823423\n",
      "dev set\n",
      "[0.90096201 0.8979306  0.89988606 0.89979506 0.90127578 0.90062728\n",
      " 0.90190594 0.90052617 0.9012569  0.90044859 0.89965151 0.90087923\n",
      " 0.89973815 0.90099973 0.90019261 0.90020685]\n",
      "[[1.1177582  0.81442617 1.00976943 1.00083567 1.10616716 1.04112513\n",
      "  1.16899258 1.0309939  1.14654589 1.0649273  0.98376352 1.06640012\n",
      "  0.98255891 1.07836812 1.04102728 1.04245093]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 206763.33814218946\n",
      "dev set\n",
      "[0.90075537 0.89772764 0.8996838  0.89959182 0.90148109 0.90083435\n",
      " 0.90211319 0.90073326 0.90105827 0.90026014 0.89948566 0.90108612\n",
      " 0.89973537 0.90120682 0.89998409 0.89999833]\n",
      "[[1.11796506 0.81462934 1.00997204 1.0010392  1.10596322 1.04091871\n",
      "  1.16878595 1.03078727 1.14674991 1.06512169 0.98394144 1.06619281\n",
      "  0.98270903 1.07816164 1.04123581 1.04265945]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 206763.19397231756\n",
      "dev set\n",
      "[0.90054936 0.89752545 0.89948193 0.89938927 0.90168585 0.90104041\n",
      " 0.90231961 0.90093927 0.9008604  0.90007233 0.89932205 0.90129236\n",
      " 0.89974145 0.90141292 0.8997762  0.89979044]\n",
      "[[1.11817141 0.81483183 1.01017436 1.00124216 1.10575975 1.04071337\n",
      "  1.1685802  1.03058186 1.1469533  1.06531549 0.98411767 1.06598637\n",
      "  0.98285633 1.07795624 1.04144386 1.04286751]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 206763.04977419527\n",
      "dev set\n",
      "[0.90034339 0.89732327 0.89927983 0.89918668 0.9018906  0.901246\n",
      " 0.9025258  0.90114473 0.90066266 0.89988471 0.89915925 0.90149845\n",
      " 0.89975017 0.90161853 0.89956826 0.8995825 ]\n",
      "[[1.11837787 0.81503447 1.01037704 1.00144529 1.10555623 1.04050862\n",
      "  1.16837471 1.03037712 1.14715675 1.06550929 0.9842935  1.06578031\n",
      "  0.98300321 1.07775142 1.0416521  1.04307575]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 206762.9052201146\n",
      "dev set\n",
      "[0.90013727 0.89712086 0.89907735 0.89898387 0.90209541 0.90145118\n",
      " 0.90273191 0.90134974 0.90046483 0.89969716 0.89899685 0.90170447\n",
      " 0.89975981 0.90182376 0.89936006 0.8993743 ]\n",
      "[[1.11858465 0.81523747 1.01058028 1.00164882 1.10535259 1.04030436\n",
      "  1.16816931 1.03017297 1.14736047 1.0657033  0.98446928 1.06557455\n",
      "  0.9831503  1.0775471  1.04186071 1.04328436]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 206794.31087060316\n",
      "dev set\n",
      "[1.00139093 0.99792787 1.00028993 1.00001511 1.00127934 1.00062862\n",
      " 1.00190725 1.00052625 1.00167865 1.00086299 0.9996309  1.0008819\n",
      " 0.9996154  1.00100155 1.00062333 1.00063765]\n",
      "[[1.11765598 0.81442931 1.00956014 1.00062431 1.10647395 1.04135092\n",
      "  1.16936892 1.03121411 1.1464788  1.06475933 0.98377149 1.06665251\n",
      "  0.98258364 1.07863668 1.04082446 1.04224915]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 206794.31030455543\n",
      "dev set\n",
      "[1.00160795 0.99771668 1.00050363 1.00008088 1.00149698 1.00085065\n",
      " 1.00212211 1.00074824 1.00189435 1.00108352 0.99942975 1.00110229\n",
      " 0.99941156 1.00122103 1.00084538 1.00085965]\n",
      "[[1.117812   0.81464363 1.00956523 1.00062431 1.10661777 1.04138975\n",
      "  1.16955828 1.03123884 1.14665722 1.06483822 0.98397772 1.0667348\n",
      "  0.98279281 1.07874    1.04086249 1.04228936]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 206794.30966232822\n",
      "dev set\n",
      "[1.00183684 0.99750087 1.00074284 1.00026389 1.00172718 1.00109064\n",
      " 1.00234625 1.00098934 1.00212035 1.00131984 0.99922106 1.0013383\n",
      " 0.99919961 1.00145511 1.00108543 1.00109951]\n",
      "[[1.1180018  0.81486673 1.00958875 1.00062461 1.10679919 1.04147337\n",
      "  1.16976866 1.03130212 1.14686128 1.06496652 0.98420175 1.06686634\n",
      "  0.98301999 1.07889027 1.04094504 1.04237479]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 206794.30892537007\n",
      "dev set\n",
      "[1.0020809  0.9972786  1.00100826 1.00050728 1.00197327 1.0013515\n",
      " 1.00258275 1.00125235 1.00235984 1.00157511 0.99900273 1.00159311\n",
      " 0.99897731 1.00170707 1.00134642 1.00136017]\n",
      "[[1.11822277 0.81510139 1.00965584 1.00062959 1.10701506 1.04161446\n",
      "  1.17000038 1.03142254 1.14709014 1.06514557 0.9844452  1.06704785\n",
      "  0.98326701 1.07908545 1.04108513 1.0425176 ]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 206794.3080807947\n",
      "dev set\n",
      "[1.00234142 0.99704911 1.00129821 1.000792   1.00223645 1.00163337\n",
      " 1.00283306 1.00153709 1.00261425 1.00184996 0.9987743  1.00186739\n",
      " 0.99874426 1.00197778 1.00162843 1.00164177]\n",
      "[[1.11847286 0.81534879 1.00978967 1.0006588  1.10726263 1.04181403\n",
      "  1.17025362 1.03160619 1.14734322 1.06537131 0.98470742 1.06727517\n",
      "  0.98353328 1.07932126 1.04128395 1.04271844]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 123477.01128313653\n",
      "dev set\n",
      "[0.60106778 0.59803511 0.59998839 0.59989896 0.6011709  0.60052065\n",
      " 0.60179949 0.60041947 0.60135623 0.6005401  0.59972857 0.60077116\n",
      " 0.59971669 0.60089307 0.60051527 0.6005295 ]\n",
      "[[1.11765226 0.81432158 1.00966686 1.00073158 1.10627078 1.04123126\n",
      "  1.1690985  1.03110038 1.14644183 1.06483032 0.98367771 1.06650714\n",
      "  0.98248889 1.0784743  1.04070531 1.04212896]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 123475.43316335767\n",
      "dev set\n",
      "[0.60096092 0.59792923 0.59988219 0.59979271 0.60127677 0.60062675\n",
      " 0.60190597 0.60052593 0.60125025 0.60043411 0.59962257 0.60087557\n",
      " 0.59961069 0.60099917 0.60062125 0.60063549]\n",
      "[[1.11775907 0.81442746 1.00977305 1.00083782 1.10616494 1.04112509\n",
      "  1.16899187 1.03099371 1.14654781 1.06493608 0.98378377 1.06640133\n",
      "  0.98259467 1.07836814 1.04059934 1.04202299]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "2 loss 123473.86182252361\n",
      "dev set\n",
      "[0.60085416 0.59782346 0.59977609 0.59968656 0.60138247 0.60073268\n",
      " 0.6020123  0.60063226 0.60114436 0.60032821 0.59951667 0.60098009\n",
      " 0.59950479 0.60110511 0.60072713 0.60074137]\n",
      "[[1.11786578 0.81453324 1.00987915 1.00094396 1.10605927 1.04101908\n",
      "  1.16888536 1.03088716 1.14665368 1.06504173 0.98388977 1.06629561\n",
      "  0.98270034 1.07826213 1.04049349 1.04191714]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "3 loss 123472.28952294309\n",
      "dev set\n",
      "[0.60074742 0.59771769 0.59966999 0.59958043 0.6014881  0.60083854\n",
      " 0.60211858 0.60073852 0.60103846 0.6002223  0.59941075 0.60108474\n",
      " 0.59939886 0.60121096 0.60083301 0.60084725]\n",
      "[[1.11797248 0.81463903 1.00998526 1.0010501  1.10595365 1.04091314\n",
      "  1.16877889 1.03078066 1.14675958 1.0651474  0.98399582 1.06618987\n",
      "  0.98280605 1.0781562  1.04038764 1.04181129]]\n",
      "{0: 284, 1: 1588}\n",
      "acc 0.2777777777777778\n",
      "(0.14987405541561713, 0.9916666666666667, 0.26039387308533923, None)\n",
      "\n",
      "4 loss 123470.71508834488\n",
      "dev set\n",
      "[0.60064067 0.59761187 0.59956386 0.59947428 0.6015937  0.60094435\n",
      " 0.60222482 0.60084473 0.6009325  0.60011632 0.59930477 0.60118954\n",
      " 0.59929285 0.60131676 0.60093894 0.60095318]\n",
      "[[1.11807921 0.81474487 1.01009141 1.00115626 1.10584807 1.04080724\n",
      "  1.16867246 1.0306742  1.14686554 1.06525313 0.98410195 1.06608407\n",
      "  0.98291183 1.0780503  1.04028175 1.04170539]]\n",
      "{0: 283, 1: 1589}\n",
      "acc 0.2783119658119658\n",
      "(0.15040906230333542, 0.9958333333333333, 0.2613449972662657, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 123741.74904805477\n",
      "dev set\n",
      "[0.70106776 0.69803514 0.69998865 0.69989901 0.70117089 0.70052062\n",
      " 0.70179951 0.70041947 0.70135643 0.70054033 0.6997288  0.70077302\n",
      " 0.69971697 0.70089305 0.70051513 0.70052937]\n",
      "[[1.11765228 0.81432154 1.00966662 1.00073154 1.1062708  1.0412313\n",
      "  1.16909846 1.03110038 1.14644178 1.06482987 0.98367724 1.06650703\n",
      "  0.98248861 1.07847434 1.04070547 1.04212911]]\n",
      "{0: 617, 1: 1255}\n",
      "acc 0.45245726495726496\n",
      "(0.18725099601593626, 0.9791666666666666, 0.31438127090301005, None)\n",
      "\n",
      "1 loss 123741.02488481872\n",
      "dev set\n",
      "[0.70096085 0.69792925 0.69988277 0.69979272 0.70127674 0.70062671\n",
      " 0.70190605 0.70052595 0.70125057 0.70043464 0.69962304 0.7008788\n",
      " 0.69961123 0.70099914 0.70062101 0.70063524]\n",
      "[[1.11775915 0.81442744 1.00977252 1.00083782 1.10616499 1.04112514\n",
      "  1.16899173 1.03099367 1.14654772 1.06493474 0.98378316 1.06640114\n",
      "  0.98259394 1.07836819 1.04059965 1.0420233 ]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n",
      "2 loss 123740.3023536999\n",
      "dev set\n",
      "[0.70085401 0.69782343 0.69977697 0.69968649 0.70138243 0.70073265\n",
      " 0.70201247 0.70063231 0.70114474 0.700329   0.69951732 0.70098451\n",
      " 0.69950551 0.70110507 0.70072682 0.70074106]\n",
      "[[1.11786594 0.81453327 1.00987835 1.00094404 1.10605933 1.04101913\n",
      "  1.16888512 1.03088708 1.14665361 1.06503946 0.98388916 1.06629536\n",
      "  0.98269918 1.07826219 1.04049391 1.04191755]]\n",
      "{0: 612, 1: 1260}\n",
      "acc 0.4497863247863248\n",
      "(0.1865079365079365, 0.9791666666666666, 0.31333333333333335, None)\n",
      "\n",
      "3 loss 123739.57787405304\n",
      "dev set\n",
      "[0.70074717 0.69771757 0.69967112 0.69958026 0.70148806 0.70083851\n",
      " 0.70211883 0.7007386  0.70103881 0.70022328 0.69941151 0.70109025\n",
      " 0.69939968 0.70121093 0.7008327  0.70084694]\n",
      "[[1.11797274 0.81463915 1.00998422 1.00105028 1.10595374 1.04091319\n",
      "  1.16877855 1.03078053 1.14675957 1.06514423 0.98399531 1.06618957\n",
      "  0.98280453 1.07815625 1.0403881  1.04181175]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "4 loss 123738.85085933827\n",
      "dev set\n",
      "[0.70064029 0.69761163 0.69956521 0.69947397 0.70159365 0.70094433\n",
      " 0.70222516 0.70084484 0.70093274 0.70011743 0.69930555 0.70119605\n",
      " 0.69929369 0.70131674 0.70093869 0.70095293]\n",
      "[[1.1180796  0.81474513 1.01009017 1.00115658 1.10584816 1.04080729\n",
      "  1.16867199 1.03067403 1.14686567 1.06524912 0.98410165 1.06608375\n",
      "  0.98291003 1.07805035 1.04028218 1.04170582]]\n",
      "{0: 610, 1: 1262}\n",
      "acc 0.44871794871794873\n",
      "(0.1862123613312203, 0.9791666666666666, 0.31291611185086554, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 123828.71738812709\n",
      "dev set\n",
      "[0.80106776 0.79803524 0.79998944 0.79989911 0.8011708  0.80052057\n",
      " 0.80179949 0.80041943 0.80135645 0.80054858 0.7997399  0.80077306\n",
      " 0.79972002 0.80089301 0.80048372 0.80049803]\n",
      "[[1.11765229 0.81432146 1.00966591 1.00073145 1.10627092 1.04123137\n",
      "  1.16909848 1.03110044 1.14644183 1.06482723 0.98367023 1.06650703\n",
      "  0.98248419 1.07847441 1.04091979 1.04234344]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "1 loss 123828.58103525665\n",
      "dev set\n",
      "[0.80096079 0.79792928 0.79988438 0.79979282 0.8012765  0.80062667\n",
      " 0.801906   0.80052585 0.80125075 0.8004632  0.79964781 0.80087899\n",
      " 0.79961826 0.80099909 0.80054103 0.80055546]\n",
      "[[1.11775921 0.81442743 1.00977108 1.00083774 1.10616534 1.04112523\n",
      "  1.16899177 1.03099382 1.1465475  1.06492556 0.98376675 1.06640123\n",
      "  0.9825804  1.07836827 1.0410254  1.04244904]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "2 loss 123828.44539151246\n",
      "dev set\n",
      "[0.80085389 0.79782335 0.79977933 0.79968657 0.80138202 0.80073261\n",
      " 0.80201239 0.80063214 0.80114498 0.80037958 0.79955606 0.80098486\n",
      " 0.79951628 0.80110504 0.80059719 0.80061176]\n",
      "[[1.11786608 0.81453339 1.00987624 1.000944   1.10605994 1.04101923\n",
      "  1.16888515 1.03088731 1.14665304 1.06502303 0.98386292 1.06629556\n",
      "  0.98267598 1.07826228 1.04113062 1.04255426]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n",
      "3 loss 123828.30931963224\n",
      "dev set\n",
      "[0.80074695 0.79771733 0.79967419 0.79958027 0.80148748 0.80083849\n",
      " 0.80211875 0.80073837 0.80103893 0.80029666 0.79946437 0.80109074\n",
      " 0.79941383 0.80121091 0.80065465 0.80066935]\n",
      "[[1.11797298 0.81463944 1.0099815  1.00105031 1.10595459 1.04091328\n",
      "  1.16877857 1.03078086 1.14675864 1.0651202  0.98395898 1.06618992\n",
      "  0.98277166 1.07815633 1.04123552 1.04265916]]\n",
      "{0: 958, 1: 914}\n",
      "acc 0.6068376068376068\n",
      "(0.2286652078774617, 0.8708333333333333, 0.3622183708838822, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 123828.1726350624\n",
      "dev set\n",
      "[0.80063995 0.79761118 0.79956892 0.7994739  0.80159291 0.80094433\n",
      " 0.80222508 0.80084454 0.80093248 0.80021412 0.79937267 0.80119666\n",
      " 0.79931079 0.80131675 0.80071435 0.80072916]\n",
      "[[1.11807997 0.81474563 1.01008689 1.00115671 1.10584925 1.04080737\n",
      "  1.168672   1.03067446 1.14686436 1.06521726 0.98405501 1.06608427\n",
      "  0.98286773 1.07805043 1.04134009 1.04276373]]\n",
      "{0: 957, 1: 915}\n",
      "acc 0.6063034188034188\n",
      "(0.2284153005464481, 0.8708333333333333, 0.361904761904762, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 123883.5187490397\n",
      "dev set\n",
      "[0.9010678  0.89803551 0.89998993 0.8998994  0.90117036 0.90052077\n",
      " 0.90179942 0.90041952 0.90135712 0.90054062 0.89973571 0.90077313\n",
      " 0.89978004 0.9008932  0.90030071 0.90031494]\n",
      "[[1.11765226 0.81432119 1.00966541 1.00073117 1.10627158 1.04123108\n",
      "  1.16909862 1.03110033 1.14644184 1.06483012 0.98367339 1.06650688\n",
      "  0.98247511 1.07847413 1.04091984 1.04234348]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 123883.44387473071\n",
      "dev set\n",
      "[0.90096079 0.89793001 0.89988543 0.8997935  0.90127548 0.90062729\n",
      " 0.90190591 0.90052616 0.90125279 0.90043656 0.89963832 0.90087887\n",
      " 0.89977531 0.9009997  0.90019462 0.90020886]\n",
      "[[1.11775925 0.81442672 1.00977    1.00083709 1.10616686 1.04112433\n",
      "  1.16899199 1.03099345 1.14654769 1.06493474 0.98377459 1.06640096\n",
      "  0.98255964 1.0783674  1.04102601 1.04244965]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 123883.36936073827\n",
      "dev set\n",
      "[0.90085383 0.89782458 0.89978094 0.89968764 0.90138045 0.90073369\n",
      " 0.9020123  0.90063267 0.90114871 0.9003329  0.89954123 0.90098445\n",
      " 0.89977753 0.90110608 0.90008868 0.90010292]\n",
      "[[1.11786621 0.8145322  1.00987461 1.000943   1.1060623  1.04101769\n",
      "  1.16888546 1.03088667 1.14665338 1.06503905 0.98387568 1.06629523\n",
      "  0.98264295 1.07826078 1.04113204 1.04255569]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 123883.29480696013\n",
      "dev set\n",
      "[0.90074685 0.89771911 0.89967637 0.89958173 0.90148538 0.90084002\n",
      " 0.90211866 0.90073911 0.9010447  0.9002294  0.89944427 0.90108998\n",
      " 0.89978247 0.9012124  0.89998276 0.89999699]\n",
      "[[1.11797322 0.81463774 1.00997932 1.00104897 1.10595776 1.04091112\n",
      "  1.16877893 1.03077998 1.14675907 1.06514327 0.98397678 1.06618958\n",
      "  0.9827259  1.07815422 1.04123808 1.04266172]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 123883.22016038945\n",
      "dev set\n",
      "[0.90063982 0.89761357 0.8995717  0.89947576 0.90159031 0.90094629\n",
      " 0.90222503 0.90084548 0.90094069 0.90012596 0.89934737 0.9011955\n",
      " 0.89978874 0.90131866 0.8998768  0.89989104]\n",
      "[[1.11808029 0.81474337 1.01008414 1.00115503 1.10585322 1.0408046\n",
      "  1.1686724  1.03067337 1.1468648  1.06524748 0.9840779  1.06608399\n",
      "  0.98280874 1.07804773 1.04134416 1.0427678 ]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 123914.31099013684\n",
      "dev set\n",
      "[1.00128293 0.9980349  1.00019532 1.0000116  1.00117128 1.0005208\n",
      " 1.00179948 1.00041921 1.00157079 1.00075478 0.9997301  1.00077368\n",
      " 0.99971758 1.00089335 1.00051553 1.00052979]\n",
      "[[1.11760898 0.81432188 1.00955981 1.00062431 1.10643436 1.0413456\n",
      "  1.169294   1.03121116 1.14641459 1.06474516 0.98367429 1.06663741\n",
      "  0.98248521 1.07861503 1.04081929 1.04224358]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "1 loss 123914.31072071535\n",
      "dev set\n",
      "[1.00139046 0.99792835 1.00029761 1.00003223 1.00127892 1.00062914\n",
      " 1.00190664 1.00052734 1.00167809 1.00086293 0.99962457 1.00088181\n",
      " 0.99961322 1.00100132 1.00062387 1.00063813]\n",
      "[[1.11768858 0.81442894 1.00956069 1.00062431 1.10650762 1.04136101\n",
      "  1.16938996 1.03121959 1.14650534 1.06478257 0.98377988 1.06667674\n",
      "  0.9825895  1.07866621 1.04083428 1.04225971]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 123914.3104328601\n",
      "dev set\n",
      "[1.00149983 0.99782111 1.00040434 1.00009156 1.00138853 1.00074043\n",
      " 1.0020152  1.00063854 1.00178696 1.00097366 0.99951759 1.00099249\n",
      " 0.99950768 1.00111164 1.00073517 1.00074942]\n",
      "[[1.11777736 0.81453733 1.00956369 1.00062431 1.10659143 1.0413873\n",
      "  1.16949078 1.03123609 1.14660247 1.06483417 0.98388893 1.06673029\n",
      "  0.98269693 1.07873116 1.04086003 1.04228694]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 123914.31012373348\n",
      "dev set\n",
      "[1.00161186 0.99771278 1.00051693 1.00017812 1.00150095 1.00085577\n",
      " 1.00212582 1.00075401 1.00189813 1.00108796 0.99940864 1.00110669\n",
      " 0.99940021 1.00122525 1.00085052 1.00086473]\n",
      "[[1.11787389 0.81464769 1.00957135 1.00062442 1.10668413 1.04142706\n",
      "  1.16959613 1.03126409 1.14670519 1.06489959 0.98400234 1.0667975\n",
      "  0.98280857 1.07880843 1.04089917 1.04232776]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 123914.30979153627\n",
      "dev set\n",
      "[1.00172712 0.99760308 1.00063601 1.00028061 1.00161679 1.00097588\n",
      " 1.00223902 1.00087453 1.00201213 1.00120648 0.99929737 1.00122508\n",
      " 0.99929039 1.0013428  1.00097065 1.00098478]\n",
      "[[1.11797767 0.8147605  1.00958747 1.00062509 1.10678502 1.04148209\n",
      "  1.16970613 1.03130667 1.14681345 1.0649784  0.98412067 1.06687784\n",
      "  0.98292502 1.07889715 1.04095357 1.04238385]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6\n",
      "recall penalty\n",
      "0 loss 82037.36777369303\n",
      "dev set\n",
      "[0.60112151 0.59808849 0.60004187 0.59995247 0.60111754 0.60046714\n",
      " 0.60174595 0.6003659  0.60140963 0.60059351 0.59978199 0.60071995\n",
      " 0.5997701  0.60083957 0.60046185 0.60047609]\n",
      "[[1.11759856 0.81426819 1.00961338 1.00067808 1.10632411 1.04128479\n",
      "  1.16915207 1.03115401 1.14638846 1.06477703 0.98362432 1.06656042\n",
      "  0.98243553 1.07852783 1.04075872 1.04218237]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "1 loss 82036.57326536922\n",
      "dev set\n",
      "[0.6010676  0.59803502 0.59998828 0.59989881 0.60117118 0.60052079\n",
      " 0.60179978 0.60041962 0.60135605 0.60053993 0.5997284  0.60077367\n",
      " 0.59971651 0.60089322 0.60051545 0.60052969]\n",
      "[[1.11765245 0.81432167 1.00966698 1.00073174 1.10627046 1.04123114\n",
      "  1.16909818 1.03110024 1.14644209 1.06483064 0.98367784 1.06650697\n",
      "  0.98248906 1.07847418 1.04070509 1.04212874]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "2 loss 82035.77940848982\n",
      "dev set\n",
      "[0.60101369 0.59798155 0.59993469 0.59984515 0.60122481 0.60057441\n",
      " 0.60185361 0.60047334 0.60130248 0.60048635 0.59967482 0.60082739\n",
      " 0.59966293 0.60094684 0.60056904 0.60058328]\n",
      "[[1.11770634 0.81437514 1.00972056 1.0007854  1.10621682 1.0411775\n",
      "  1.16904429 1.03104648 1.14649571 1.06488425 0.98373135 1.06645354\n",
      "  0.98254259 1.07842054 1.04065147 1.04207511]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "3 loss 82034.9851299995\n",
      "dev set\n",
      "[0.60095978 0.59792808 0.59988111 0.59979149 0.60127844 0.60062804\n",
      " 0.60190743 0.60052705 0.60124891 0.60043277 0.59962123 0.60088111\n",
      " 0.59960934 0.60100047 0.60062264 0.60063688]\n",
      "[[1.11776024 0.81442861 1.00977416 1.00083905 1.10616318 1.04112387\n",
      "  1.1689904  1.03099272 1.14654934 1.06493786 0.98378486 1.06640011\n",
      "  0.98259612 1.07836691 1.04059784 1.04202149]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "4 loss 82034.19031644007\n",
      "dev set\n",
      "[0.60090586 0.59787461 0.59982752 0.59973783 0.60133206 0.60068165\n",
      " 0.60196125 0.60058076 0.60119532 0.60037918 0.59956764 0.60093485\n",
      " 0.59955574 0.60105408 0.60067624 0.60069048]\n",
      "[[1.11781414 0.8144821  1.00982775 1.00089272 1.10610955 1.04107024\n",
      "  1.16893652 1.03093897 1.14660299 1.06499148 0.98383839 1.06634667\n",
      "  0.98264966 1.07831328 1.04054421 1.04196785]]\n",
      "{0: 285, 1: 1587}\n",
      "acc 0.2783119658119658\n",
      "(0.14996849401386264, 0.9916666666666667, 0.26053639846743293, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall penalty\n",
      "0 loss 82301.91153231141\n",
      "dev set\n",
      "[0.70112151 0.69808853 0.70004192 0.69995252 0.70111753 0.70046712\n",
      " 0.70174595 0.7003659  0.70140973 0.70059364 0.6997821  0.70071968\n",
      " 0.69977022 0.70083955 0.70046178 0.70047602]\n",
      "[[1.11759855 0.81426815 1.00961333 1.00067803 1.10632412 1.04128482\n",
      "  1.16915206 1.031154   1.14638846 1.06477704 0.98362414 1.06656043\n",
      "  0.98243539 1.07852786 1.04075877 1.04218242]]\n",
      "{0: 618, 1: 1254}\n",
      "acc 0.452991452991453\n",
      "(0.18740031897926634, 0.9791666666666666, 0.31459170013386883, None)\n",
      "\n",
      "1 loss 82301.54742188164\n",
      "dev set\n",
      "[0.70106761 0.6980351  0.69998841 0.69989893 0.70117116 0.70052073\n",
      " 0.70179979 0.70041963 0.70135631 0.70054024 0.6997287  0.70077298\n",
      " 0.69971682 0.70089316 0.70051527 0.70052951]\n",
      "[[1.11765244 0.81432159 1.00966685 1.00073162 1.10627049 1.04123122\n",
      "  1.16909816 1.03110022 1.14644209 1.06483065 0.98367739 1.06650701\n",
      "  0.98248871 1.07847426 1.04070522 1.04212886]]\n",
      "{0: 617, 1: 1255}\n",
      "acc 0.45245726495726496\n",
      "(0.18725099601593626, 0.9791666666666666, 0.31438127090301005, None)\n",
      "\n",
      "2 loss 82301.18344517532\n",
      "dev set\n",
      "[0.7010137  0.69798168 0.69993491 0.69984536 0.70122478 0.70057432\n",
      " 0.70185362 0.70047336 0.70130289 0.70048686 0.6996753  0.70082626\n",
      " 0.69966342 0.70094676 0.70056875 0.70058299]\n",
      "[[1.11770633 0.81437501 1.00972036 1.00078521 1.10621687 1.04117763\n",
      "  1.16904426 1.03104645 1.14649572 1.06488427 0.98373062 1.06645361\n",
      "  0.98254201 1.07842067 1.04065166 1.04207531]]\n",
      "{0: 616, 1: 1256}\n",
      "acc 0.4519230769230769\n",
      "(0.18710191082802546, 0.9791666666666666, 0.3141711229946524, None)\n",
      "\n",
      "3 loss 82300.81894087984\n",
      "dev set\n",
      "[0.70095979 0.69792826 0.6998814  0.69979177 0.70127839 0.70062791\n",
      " 0.70190746 0.70052708 0.70124946 0.70043346 0.69962189 0.70087954\n",
      " 0.69961002 0.70100034 0.70062224 0.70063648]\n",
      "[[1.11776023 0.81442845 1.00977388 1.00083879 1.10616325 1.04112405\n",
      "  1.16899036 1.03099268 1.14654937 1.0649379  0.98378386 1.06640021\n",
      "  0.98259533 1.07836709 1.0405981  1.04202174]]\n",
      "{0: 614, 1: 1258}\n",
      "acc 0.45085470085470086\n",
      "(0.18680445151033387, 0.9791666666666666, 0.3137516688918558, None)\n",
      "\n",
      "4 loss 82300.45383990134\n",
      "dev set\n",
      "[0.70090588 0.69787482 0.69982789 0.69973818 0.701332   0.70068149\n",
      " 0.70196129 0.70058079 0.70119601 0.70038005 0.69956846 0.70093283\n",
      " 0.69955658 0.70105393 0.70067575 0.70068999]\n",
      "[[1.11781413 0.81448189 1.00982741 1.00089239 1.10610963 1.04107048\n",
      "  1.16893647 1.03093892 1.14660303 1.06499155 0.98383712 1.0663468\n",
      "  0.98264867 1.07831351 1.04054452 1.04196816]]\n",
      "{0: 613, 1: 1259}\n",
      "acc 0.45032051282051283\n",
      "(0.18665607625099284, 0.9791666666666666, 0.3135423615743829, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 82388.74793425013\n",
      "dev set\n",
      "[0.80112153 0.79808861 0.80004207 0.7999526  0.80111749 0.80046709\n",
      " 0.80174592 0.8003659  0.80140987 0.80059315 0.79978353 0.80071972\n",
      " 0.79977134 0.80083952 0.80044697 0.80046124]\n",
      "[[1.11759854 0.81426808 1.0096132  1.00067795 1.10632417 1.04128486\n",
      "  1.16915209 1.031154   1.14638859 1.06477734 0.98362395 1.06656042\n",
      "  0.98243292 1.0785279  1.04086651 1.04229015]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "1 loss 82388.67913142433\n",
      "dev set\n",
      "[0.80106765 0.7980353  0.79998879 0.79989914 0.80117106 0.80052065\n",
      " 0.80179972 0.80041964 0.80135666 0.80053915 0.79973237 0.8007731\n",
      " 0.79971969 0.80089309 0.8004777  0.80049204]\n",
      "[[1.1176524  0.8143214  1.0096665  1.00073143 1.10627063 1.04123134\n",
      "  1.16909824 1.03110021 1.14644242 1.06483138 0.98367688 1.06650698\n",
      "  0.98248236 1.07847437 1.04092053 1.04234418]]\n",
      "{0: 962, 1: 910}\n",
      "acc 0.6089743589743589\n",
      "(0.22967032967032966, 0.8708333333333333, 0.3634782608695652, None)\n",
      "\n",
      "2 loss 82388.61060431847\n",
      "dev set\n",
      "[0.80101377 0.79798202 0.79993552 0.79984569 0.80122462 0.8005742\n",
      " 0.80185352 0.80047336 0.80130344 0.80048515 0.79968137 0.80082645\n",
      " 0.79966812 0.80094663 0.80050698 0.80052139]\n",
      "[[1.11770627 0.8143747  1.0097198  1.00078489 1.10621709 1.04117783\n",
      "  1.16904438 1.03104644 1.14649626 1.06488542 0.98372977 1.06645356\n",
      "  0.98253156 1.07842086 1.04097453 1.04239818]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "3 loss 82388.54200707619\n",
      "dev set\n",
      "[0.80095988 0.79792872 0.79988225 0.79979224 0.80127817 0.80062773\n",
      " 0.80190731 0.80052709 0.80125018 0.80043117 0.79963041 0.8008798\n",
      " 0.79961651 0.80100017 0.80053599 0.80055046]\n",
      "[[1.11776015 0.81442801 1.0097731  1.00083836 1.10616356 1.04112432\n",
      "  1.16899052 1.03099267 1.14655011 1.06493947 0.98378266 1.06640014\n",
      "  0.98258073 1.07836735 1.0410285  1.04245214]]\n",
      "{0: 961, 1: 911}\n",
      "acc 0.6084401709401709\n",
      "(0.22941822173435786, 0.8708333333333333, 0.3631624674196351, None)\n",
      "\n",
      "4 loss 82388.47328766045\n",
      "dev set\n",
      "[0.80090598 0.79787541 0.79982897 0.79973878 0.80133172 0.80068126\n",
      " 0.8019611  0.8005808  0.80119686 0.80037719 0.79957947 0.80093316\n",
      " 0.79956485 0.80105371 0.80056515 0.80057969]\n",
      "[[1.11781404 0.81448134 1.00982641 1.00089184 1.10611004 1.04107083\n",
      "  1.16893667 1.03093891 1.14660399 1.06499353 0.98383555 1.06634673\n",
      "  0.98262993 1.07831385 1.04108243 1.04250607]]\n",
      "{0: 960, 1: 912}\n",
      "acc 0.6079059829059829\n",
      "(0.22916666666666666, 0.8708333333333333, 0.3628472222222222, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 82443.53593191737\n",
      "dev set\n",
      "[0.90112159 0.89808875 0.90004213 0.89995268 0.90111738 0.90046718\n",
      " 0.90174597 0.90036598 0.90140926 0.90059324 0.89978243 0.90071974\n",
      " 0.89980118 0.90083961 0.90035411 0.90036834]\n",
      "[[1.11759849 0.81426794 1.00961313 1.00067787 1.10632433 1.04128473\n",
      "  1.16915204 1.03115389 1.14638875 1.06477726 0.98362403 1.0665603\n",
      "  0.98243219 1.07852777 1.04086635 1.04228999]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "1 loss 82443.49809006782\n",
      "dev set\n",
      "[0.90106779 0.89803567 0.89998894 0.89989934 0.90117078 0.90052088\n",
      " 0.90179984 0.90041984 0.90135521 0.90053926 0.89972954 0.90077313\n",
      " 0.89979927 0.9008933  0.90030009 0.90031433]\n",
      "[[1.11765228 0.81432103 1.00966634 1.00073122 1.10627102 1.04123101\n",
      "  1.1690981  1.03109995 1.14644278 1.06483119 0.9836771  1.06650669\n",
      "  0.98248047 1.07847405 1.04092017 1.04234382]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "2 loss 82443.46030988476\n",
      "dev set\n",
      "[0.90101399 0.89798263 0.89993578 0.89984603 0.90122416 0.90057456\n",
      " 0.90185371 0.90047369 0.90130116 0.90048527 0.8996767  0.90082651\n",
      " 0.89980103 0.90094699 0.90024607 0.90026031]\n",
      "[[1.11770607 0.81437409 1.00971953 1.00078456 1.10621773 1.04117729\n",
      "  1.16904416 1.03104602 1.14649683 1.06488513 0.98373014 1.06645308\n",
      "  0.98252837 1.07842034 1.040974   1.04239764]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "3 loss 82443.42251590213\n",
      "dev set\n",
      "[0.90096019 0.89792958 0.89988261 0.8997927  0.90127754 0.90062824\n",
      " 0.90190758 0.90052753 0.90124711 0.90043129 0.89962387 0.90087988\n",
      " 0.89980429 0.90100066 0.90019204 0.90020628]\n",
      "[[1.11775988 0.81442716 1.00977272 1.0008379  1.10616445 1.04112358\n",
      "  1.16899022 1.0309921  1.14655088 1.06493908 0.98378318 1.06639949\n",
      "  0.98257613 1.07836663 1.04102783 1.04245147]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "4 loss 82443.3847001031\n",
      "dev set\n",
      "[0.90090638 0.89787654 0.89982944 0.89973938 0.90133092 0.90068191\n",
      " 0.90196145 0.90058136 0.90119306 0.90037731 0.89957104 0.90093324\n",
      " 0.89980834 0.90105433 0.900138   0.90015224]\n",
      "[[1.11781369 0.81448023 1.00982592 1.00089125 1.10611117 1.04106988\n",
      "  1.16893628 1.03093819 1.14660494 1.06499303 0.98383622 1.0663459\n",
      "  0.98262382 1.07831293 1.04108167 1.04250532]]\n",
      "{0: 1094, 1: 778}\n",
      "acc 0.6666666666666666\n",
      "(0.2532133676092545, 0.8208333333333333, 0.38703339882121807, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 82474.31104878704\n",
      "dev set\n",
      "[1.00122927 0.99808841 1.00014685 1.00000976 1.00111761 1.0004672\n",
      " 1.00174587 1.00036581 1.00151716 1.00070107 0.99978236 1.00071998\n",
      " 0.99977031 1.00083965 1.00046193 1.00047617]\n",
      "[[1.11758189 0.81426829 1.00955973 1.00062431 1.10641144 1.04134324\n",
      "  1.16925307 1.03120999 1.14637863 1.0647377  0.98362326 1.06662938\n",
      "  0.98243468 1.07860295 1.040817   1.04224109]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 82474.31091757117\n",
      "dev set\n",
      "[1.00128314 0.99803477 1.00019822 1.00001877 1.00117149 1.00052117\n",
      " 1.00179968 1.00041971 1.001571   1.00075504 0.9997293  1.00077394\n",
      " 0.99971696 1.00089359 1.0005159  1.00053015]\n",
      "[[1.11762428 0.81432201 1.00955997 1.00062431 1.10645089 1.04135134\n",
      "  1.16930252 1.03121408 1.14642591 1.06475853 0.98367603 1.06665129\n",
      "  0.98248776 1.07863133 1.04082486 1.04224961]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "2 loss 82474.31078173517\n",
      "dev set\n",
      "[1.00133729 0.99798101 1.00024983 1.00003922 1.00122568 1.00057558\n",
      " 1.0018537  1.00047402 1.00162507 1.0008094  0.99967608 1.00082829\n",
      " 0.99966341 1.00094789 1.00057031 1.00058456]\n",
      "[[1.11766942 0.81437594 1.00956057 1.00062431 1.10649361 1.04136291\n",
      "  1.16935323 1.03122047 1.14647494 1.06478423 0.98372926 1.06667808\n",
      "  0.98254134 1.07866433 1.04083613 1.04226169]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "3 loss 82474.31064087703\n",
      "dev set\n",
      "[1.00139184 0.9979271  1.00030218 1.0000719  1.00128029 1.00063061\n",
      " 1.00190803 1.00052894 1.00167948 1.00086431 0.99962259 1.00088319\n",
      " 0.99960953 1.00100269 1.00062534 1.00063959]\n",
      "[[1.11771659 0.81443015 1.0095618  1.00062431 1.10653877 1.04137821\n",
      "  1.16940494 1.03122968 1.14652531 1.06481413 0.98378315 1.06670901\n",
      "  0.9825956  1.07870101 1.04085109 1.04227757]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n",
      "4 loss 82474.31049478635\n",
      "dev set\n",
      "[1.00144689 0.99787297 1.00035562 1.00011142 1.00133544 1.00068641\n",
      " 1.00196275 1.00058468 1.00173433 1.00091991 0.99956872 1.00093877\n",
      " 0.99955523 1.00105813 1.00068115 1.0006954 ]\n",
      "[[1.11776551 0.81448474 1.00956407 1.00062433 1.10658599 1.04139747\n",
      "  1.16945758 1.0312422  1.14657686 1.06484785 0.98383787 1.06674368\n",
      "  0.9826507  1.07874088 1.04087    1.04229745]]\n",
      "{0: 1020, 1: 852}\n",
      "acc 0.5908119658119658\n",
      "(0.19131455399061034, 0.6791666666666667, 0.2985347985347986, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = np.empty([len(LF_l)],dtype=np.float64)\n",
    "acc.fill(0.25)\n",
    "rec =  np.empty([len(LF_l)],dtype=np.float64)\n",
    "rec.fill(0.35*train_L_S.shape[0])\n",
    "print(rec)\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [64,128,256,512,1024,2048]:\n",
    "    for i in np.linspace(0.6,1,5):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = acc ,LF_rec = rec,\\\n",
    "                                    pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=6,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1295. 1295. 1295. 1295. 1295. 1295. 1295. 1295.]\n",
      "batch-size: 64 alpha-init: 0.6\n",
      "recall penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 621458.5404233874\n",
      "dev set\n",
      "[0.59977473 0.59669853 0.59867669 0.60150101 0.59969289 0.60197459\n",
      " 0.60321691 0.60183472]\n",
      "[[1.11893333 0.81559947 1.01073512 0.99909126 1.10771657 1.03977863\n",
      "  1.16771999 1.0297279 ]]\n",
      "{0: 721, 1: 1151}\n",
      "acc 0.4236111111111111\n",
      "(0.1355343179843614, 0.65, 0.22429906542056074, None)\n",
      "\n",
      "1 loss 621454.9790565936\n",
      "dev set\n",
      "[0.5981989  0.59510638 0.59709554 0.60301373 0.59811978 0.60352355\n",
      " 0.60481623 0.60343445]\n",
      "[[1.12049799 0.81715749 1.0121731  0.99754957 1.10927498 1.0382307\n",
      "  1.16611668 1.02812487]]\n",
      "{0: 675, 1: 1197}\n",
      "acc 0.40544871794871795\n",
      "(0.13533834586466165, 0.675, 0.2254697286012526, None)\n",
      "\n",
      "2 loss 621450.675549065\n",
      "dev set\n",
      "[0.59646397 0.59337522 0.59536149 0.60452458 0.59636236 0.60505987\n",
      " 0.60648478 0.60510577]\n",
      "[[1.12221431 0.81888142 1.01383999 0.99600962 1.111028   1.03669508\n",
      "  1.16440982 1.0264133 ]]\n",
      "{0: 620, 1: 1252}\n",
      "acc 0.38247863247863245\n",
      "(0.134185303514377, 0.7, 0.225201072386059, None)\n",
      "\n",
      "3 loss 621445.5550760408\n",
      "dev set\n",
      "[0.59459719 0.59152816 0.59350045 0.6060358  0.59445853 0.60658283\n",
      " 0.60821691 0.60684256]\n",
      "[[1.12405824 0.8207441  1.01568908 0.99447249 1.11293539 1.03517231\n",
      "  1.16261335 1.02460845]]\n",
      "{0: 586, 1: 1286}\n",
      "acc 0.36645299145299143\n",
      "(0.1321928460342146, 0.7083333333333334, 0.22280471821756223, None)\n",
      "\n",
      "4 loss 621439.5476353997\n",
      "dev set\n",
      "[0.59262319 0.58958221 0.59153381 0.60754423 0.59243892 0.60809205\n",
      " 0.61000764 0.60863945]\n",
      "[[1.1260096  0.8227225  1.01768283 0.99293826 1.11496561 1.03366255\n",
      "  1.16073922 1.02272338]]\n",
      "{0: 547, 1: 1325}\n",
      "acc 0.3530982905982906\n",
      "(0.13358490566037737, 0.7375, 0.22619808306709266, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 621371.8174158145\n",
      "dev set\n",
      "[0.70278072 0.69973924 0.70168481 0.70154796 0.70267331 0.70197016\n",
      " 0.70009288 0.69871194]\n",
      "[[1.11596505 0.81263943 1.00797051 0.99907899 1.10477732 1.03978837\n",
      "  1.17080353 1.0328054 ]]\n",
      "{0: 1341, 1: 531}\n",
      "acc 0.6853632478632479\n",
      "(0.1713747645951036, 0.37916666666666665, 0.23605706874189364, None)\n",
      "\n",
      "1 loss 621366.9844922062\n",
      "dev set\n",
      "[0.70439513 0.70136069 0.70329619 0.70308264 0.70430016 0.70352549\n",
      " 0.69845926 0.69707815]\n",
      "[[1.11435593 0.81105725 1.00638884 0.99754254 1.10316024 1.03824368\n",
      "  1.17242566 1.03442737]]\n",
      "{0: 1378, 1: 494}\n",
      "acc 0.6987179487179487\n",
      "(0.1720647773279352, 0.3541666666666667, 0.23160762942779292, None)\n",
      "\n",
      "2 loss 621361.6452729701\n",
      "dev set\n",
      "[0.70605768 0.70301864 0.70496092 0.70460167 0.70597246 0.70507837\n",
      " 0.69675241 0.69537364]\n",
      "[[1.11269887 0.80944735 1.00478554 0.99602235 1.10150124 1.03670641\n",
      "  1.17409692 1.03609796]]\n",
      "{0: 1414, 1: 458}\n",
      "acc 0.7083333333333334\n",
      "(0.16593886462882096, 0.31666666666666665, 0.2177650429799427, None)\n",
      "\n",
      "3 loss 621355.7459010116\n",
      "dev set\n",
      "[0.70777212 0.70472274 0.70667076 0.70610382 0.70768256 0.70662824\n",
      " 0.69497738 0.69360117]\n",
      "[[1.11099678 0.80781143 1.00316157 0.99451935 1.09980193 1.03517735\n",
      "  1.17581763 1.03781751]]\n",
      "{0: 1440, 1: 432}\n",
      "acc 0.719017094017094\n",
      "(0.16898148148148148, 0.30416666666666664, 0.21726190476190477, None)\n",
      "\n",
      "4 loss 621349.2410404537\n",
      "dev set\n",
      "[0.70953406 0.70647664 0.70842252 0.70758844 0.70944103 0.70817509\n",
      " 0.69314063 0.69176782]\n",
      "[[1.10925425 0.80615414 1.00152012 0.99303372 1.09806608 1.03365655\n",
      "  1.17758567 1.03958395]]\n",
      "{0: 1478, 1: 394}\n",
      "acc 0.7329059829059829\n",
      "(0.1700507614213198, 0.2791666666666667, 0.21135646687697163, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 621297.4989867096\n",
      "dev set\n",
      "[0.80272097 0.79956742 0.80146972 0.80154968 0.80258632 0.8019542\n",
      " 0.80011077 0.79873038]\n",
      "[[1.1160026  0.81284763 1.00824307 0.99907576 1.10482403 1.03981584\n",
      "  1.17078744 1.03278929]]\n",
      "{0: 1608, 1: 264}\n",
      "acc 0.7831196581196581\n",
      "(0.1856060606060606, 0.20416666666666666, 0.19444444444444445, None)\n",
      "\n",
      "1 loss 621293.1075449012\n",
      "dev set\n",
      "[0.80429195 0.80098658 0.80290321 0.80308276 0.80411716 0.80348991\n",
      " 0.79852035 0.79714304]\n",
      "[[1.11446138 0.81148552 1.00686562 0.99754314 1.10328167 1.03830745\n",
      "  1.17237844 1.0343803 ]]\n",
      "{0: 1619, 1: 253}\n",
      "acc 0.7879273504273504\n",
      "(0.18972332015810275, 0.2, 0.19472616632860043, None)\n",
      "\n",
      "2 loss 621288.5954573286\n",
      "dev set\n",
      "[0.80587504 0.80241547 0.80434298 0.80459791 0.80563245 0.80501834\n",
      " 0.79691492 0.7955349 ]\n",
      "[[1.11292122 0.8101098  1.00549066 0.99603167 1.10174079 1.03681366\n",
      "  1.1739893  1.03599115]]\n",
      "{0: 1634, 1: 238}\n",
      "acc 0.7959401709401709\n",
      "(0.20168067226890757, 0.2, 0.200836820083682, None)\n",
      "\n",
      "3 loss 621283.95946519\n",
      "dev set\n",
      "[0.80747412 0.80385167 0.80578516 0.80609429 0.80717747 0.80653845\n",
      " 0.79528866 0.7939075 ]\n",
      "[[1.11138204 0.80872382 1.00411571 0.99454184 1.10020043 1.03533564\n",
      "  1.17562087 1.03762269]]\n",
      "{0: 1641, 1: 231}\n",
      "acc 0.7996794871794872\n",
      "(0.2077922077922078, 0.2, 0.20382165605095542, None)\n",
      "\n",
      "4 loss 621279.1573484775\n",
      "dev set\n",
      "[0.80909926 0.80529453 0.80718458 0.80757185 0.80873771 0.80805002\n",
      " 0.79364335 0.79226159]\n",
      "[[1.10984544 0.80732874 1.00273958 0.99307344 1.09866224 1.03387358\n",
      "  1.17727311 1.03927488]]\n",
      "{0: 1651, 1: 221}\n",
      "acc 0.8028846153846154\n",
      "(0.2081447963800905, 0.19166666666666668, 0.19956616052060738, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 621362.6773159606\n",
      "dev set\n",
      "[0.90239488 0.89946131 0.90121521 0.9015589  0.902528   0.90192516\n",
      " 0.90011205 0.89873197]\n",
      "[[1.11674042 0.81295679 1.00869311 0.99906943 1.1051245  1.03987499\n",
      "  1.17078601 1.03278787]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "1 loss 621361.2501265202\n",
      "dev set\n",
      "[0.90367125 0.90075826 0.90237314 0.90308562 0.90388422 0.90338918\n",
      " 0.8985255  0.8971487 ]\n",
      "[[1.11580215 0.81173253 1.00775908 0.99755185 1.10391745 1.03850618\n",
      "  1.17238167 1.03438342]]\n",
      "{0: 1753, 1: 119}\n",
      "acc 0.8370726495726496\n",
      "(0.226890756302521, 0.1125, 0.15041782729805012, None)\n",
      "\n",
      "2 loss 621359.7957259605\n",
      "dev set\n",
      "[0.90489534 0.90207407 0.90353292 0.90458352 0.90478282 0.90482532\n",
      " 0.89692712 0.89554888]\n",
      "[[1.11480885 0.81048866 1.0068109  0.99607323 1.10268962 1.03718406\n",
      "  1.17400166 1.03600316]]\n",
      "{0: 1768, 1: 104}\n",
      "acc 0.8450854700854701\n",
      "(0.25961538461538464, 0.1125, 0.15697674418604654, None)\n",
      "\n",
      "3 loss 621358.3128565961\n",
      "dev set\n",
      "[0.90577386 0.90340442 0.90469968 0.90605183 0.90575848 0.90623604\n",
      " 0.89531151 0.89393073]\n",
      "[[1.11376051 0.80923007 1.00584473 0.99463294 1.10142989 1.03590338\n",
      "  1.1756466  1.03764779]]\n",
      "{0: 1768, 1: 104}\n",
      "acc 0.8450854700854701\n",
      "(0.25961538461538464, 0.1125, 0.15697674418604654, None)\n",
      "\n",
      "4 loss 621356.7791200769\n",
      "dev set\n",
      "[0.90673148 0.90474775 0.90587497 0.907492   0.90682594 0.90762189\n",
      " 0.89367785 0.8922949 ]\n",
      "[[1.11265736 0.80795902 1.00486017 0.99322981 1.10014113 1.03466251\n",
      "  1.17731638 1.03931722]]\n",
      "{0: 1768, 1: 104}\n",
      "acc 0.8450854700854701\n",
      "(0.25961538461538464, 0.1125, 0.15697674418604654, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 621397.1550774645\n",
      "dev set\n",
      "[1.00305603 0.99676604 1.00199359 1.00054616 1.002958   1.00239262\n",
      " 1.00351738 1.00229622]\n",
      "[[1.11852251 0.81567652 1.00979691 1.00062525 1.1072832  1.04180893\n",
      "  1.17046717 1.03161275]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "1 loss 621397.1538751182\n",
      "dev set\n",
      "[1.00567561 0.9953266  1.004909   1.00370502 1.00560314 1.00520044\n",
      " 1.00601588 1.00513096]\n",
      "[[1.12113613 0.81742628 1.0121863  1.00199342 1.10989267 1.04433718\n",
      "  1.17306207 1.03411322]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 621397.1518922576\n",
      "dev set\n",
      "[1.00866878 0.99379391 1.00811073 1.00720029 1.00861374 1.00832345\n",
      " 1.00891283 1.00827272]\n",
      "[[1.1244227  0.81940743 1.01561442 1.00554375 1.11319238 1.04771528\n",
      "  1.17627273 1.03750342]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 621397.1485542459\n",
      "dev set\n",
      "[1.01181681 0.99218494 1.01139526 1.01068707 1.01177139 1.01155403\n",
      " 1.01199408 1.01151558]\n",
      "[[1.12795715 0.82154176 1.01927124 1.00938076 1.11673631 1.05132439\n",
      "  1.17974702 1.04112347]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 621397.143261602\n",
      "dev set\n",
      "[1.01502713 0.9905149  1.01469791 1.01412872 1.01498568 1.01481729\n",
      " 1.01515667 1.01478717]\n",
      "[[1.13159368 0.82377927 1.02299624 1.0132423  1.12037794 1.05501269\n",
      "  1.18333926 1.04481974]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.6\n",
      "recall penalty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 321019.31571709225\n",
      "dev set\n",
      "[0.60045237 0.59740365 0.59936662 0.60077152 0.60035353 0.60119566\n",
      " 0.60246023 0.60107947]\n",
      "[[1.11826776 0.81493609 1.01019048 0.99985003 1.10707535 1.04055668\n",
      "  1.16844947 1.03045326]]\n",
      "{0: 737, 1: 1135}\n",
      "acc 0.42895299145299143\n",
      "(0.13480176211453745, 0.6375, 0.22254545454545455, None)\n",
      "\n",
      "1 loss 321017.6456095978\n",
      "dev set\n",
      "[0.59969516 0.59663629 0.59860623 0.60154391 0.59960334 0.60197519\n",
      " 0.60324329 0.60186228]\n",
      "[[1.11902984 0.81569398 1.01087606 0.99907332 1.10781618 1.03977749\n",
      "  1.16767032 1.02967501]]\n",
      "{0: 718, 1: 1154}\n",
      "acc 0.422008547008547\n",
      "(0.13518197573656845, 0.65, 0.22381635581061693, None)\n",
      "\n",
      "2 loss 321015.80276300356\n",
      "dev set\n",
      "[0.59889093 0.59582891 0.59780111 0.6023167  0.59879732 0.60275189\n",
      " 0.60404491 0.60266435]\n",
      "[[1.11983526 0.81650005 1.01163244 0.99829661 1.10861589 1.03900108\n",
      "  1.1668625  1.02886655]]\n",
      "{0: 695, 1: 1177}\n",
      "acc 0.41399572649572647\n",
      "(0.13593882752761258, 0.6666666666666666, 0.2258292166549047, None)\n",
      "\n",
      "3 loss 321013.77324405377\n",
      "dev set\n",
      "[0.59804459 0.59498518 0.59695566 0.60308916 0.59794209 0.60352541\n",
      " 0.6048641  0.6034846 ]\n",
      "[[1.12067986 0.81734944 1.01245025 0.99752052 1.10946721 1.03822779\n",
      "  1.16602816 1.02803023]]\n",
      "{0: 675, 1: 1197}\n",
      "acc 0.40544871794871795\n",
      "(0.13533834586466165, 0.675, 0.2254697286012526, None)\n",
      "\n",
      "4 loss 321011.5471455385\n",
      "dev set\n",
      "[0.59716045 0.5941088  0.59607398 0.60386072 0.59704362 0.60429563\n",
      " 0.60570012 0.60432225]\n",
      "[[1.12156011 0.81823795 1.0133217  0.99674522 1.11036389 1.03745772\n",
      "  1.16516913 1.02716809]]\n",
      "{0: 647, 1: 1225}\n",
      "acc 0.3926282051282051\n",
      "(0.13387755102040816, 0.6833333333333333, 0.22389078498293513, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 320932.99450959894\n",
      "dev set\n",
      "[0.70197004 0.69893369 0.70088499 0.70078318 0.70185897 0.70119393\n",
      " 0.70089937 0.69951915]\n",
      "[[1.11675872 0.81342847 1.00877065 0.99984661 1.10558447 1.04055978\n",
      "  1.16999854 1.03200037]]\n",
      "{0: 1328, 1: 544}\n",
      "acc 0.6794871794871795\n",
      "(0.16911764705882354, 0.38333333333333336, 0.23469387755102042, None)\n",
      "\n",
      "1 loss 320930.6960001103\n",
      "dev set\n",
      "[0.70276624 0.69972903 0.70167969 0.7015592  0.70265666 0.70197405\n",
      " 0.70010171 0.69872132]\n",
      "[[1.11596576 0.81264174 1.00798339 0.99907027 1.10478912 1.03978217\n",
      "  1.17079495 1.03279673]]\n",
      "{0: 1341, 1: 531}\n",
      "acc 0.6853632478632479\n",
      "(0.1713747645951036, 0.37916666666666665, 0.23605706874189364, None)\n",
      "\n",
      "2 loss 320928.27815359324\n",
      "dev set\n",
      "[0.70357202 0.70053581 0.70248477 0.70233182 0.70346561 0.70275387\n",
      " 0.69928602 0.69790594]\n",
      "[[1.11516097 0.81184826 1.0071911  0.99829752 1.10398352 1.03900594\n",
      "  1.17160279 1.03360441]]\n",
      "{0: 1367, 1: 505}\n",
      "acc 0.6971153846153846\n",
      "(0.17623762376237623, 0.37083333333333335, 0.2389261744966443, None)\n",
      "\n",
      "3 loss 320925.73255850194\n",
      "dev set\n",
      "[0.7043865  0.7013563  0.70330035 0.70310045 0.70428706 0.70353303\n",
      " 0.69845074 0.69707145]\n",
      "[[1.1143435  0.81104715 1.00639262 0.99752892 1.10316661 1.03823159\n",
      "  1.17242354 1.03442486]]\n",
      "{0: 1378, 1: 494}\n",
      "acc 0.6987179487179487\n",
      "(0.1720647773279352, 0.3541666666666667, 0.23160762942779292, None)\n",
      "\n",
      "4 loss 320923.04620248\n",
      "dev set\n",
      "[0.70521521 0.70218729 0.70413016 0.70386489 0.7051215  0.70431141\n",
      " 0.69759625 0.69621871]\n",
      "[[1.11351354 0.81023858 1.00558794 0.99676464 1.10233851 1.03745929\n",
      "  1.17325741 1.0352583 ]]\n",
      "{0: 1398, 1: 474}\n",
      "acc 0.7019230769230769\n",
      "(0.16455696202531644, 0.325, 0.2184873949579832, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 320858.57588018046\n",
      "dev set\n",
      "[0.80195167 0.79888862 0.80085703 0.80078337 0.80183522 0.8011894\n",
      " 0.80090464 0.79952452]\n",
      "[[1.11677079 0.81348825 1.00880749 0.99984553 1.10558997 1.04056746\n",
      "  1.16999328 1.03199513]]\n",
      "{0: 1597, 1: 275}\n",
      "acc 0.7772435897435898\n",
      "(0.1781818181818182, 0.20416666666666666, 0.19029126213592235, None)\n",
      "\n",
      "1 loss 320856.39686951734\n",
      "dev set\n",
      "[0.80273497 0.79962579 0.80160657 0.80155884 0.80259987 0.80196451\n",
      " 0.80011533 0.79873516]\n",
      "[[1.11599376 0.81277122 1.00806131 0.99906982 1.10480812 1.03979907\n",
      "  1.17078272 1.03278457]]\n",
      "{0: 1608, 1: 264}\n",
      "acc 0.7831196581196581\n",
      "(0.1856060606060606, 0.20416666666666666, 0.19444444444444445, None)\n",
      "\n",
      "2 loss 320854.1967836352\n",
      "dev set\n",
      "[0.80352411 0.80036481 0.80235559 0.80233029 0.80336657 0.80273848\n",
      " 0.79932172 0.79794325]\n",
      "[[1.11521715 0.81205031 1.00731757 0.99829901 1.10402728 1.03903331\n",
      "  1.17157664 1.03357849]]\n",
      "{0: 1610, 1: 262}\n",
      "acc 0.7841880341880342\n",
      "(0.18702290076335878, 0.20416666666666666, 0.19521912350597612, None)\n",
      "\n",
      "3 loss 320851.957248844\n",
      "dev set\n",
      "[0.80431636 0.80110657 0.80310693 0.80309714 0.80414233 0.80351065\n",
      " 0.79852364 0.79714604]\n",
      "[[1.11444047 0.81132606 1.0065744  0.99753363 1.10324679 1.03827105\n",
      "  1.17237579 1.03437762]]\n",
      "{0: 1621, 1: 251}\n",
      "acc 0.7889957264957265\n",
      "(0.19123505976095617, 0.2, 0.19551934826883913, None)\n",
      "\n",
      "4 loss 320849.6881204112\n",
      "dev set\n",
      "[0.80511332 0.80185068 0.80386055 0.80385922 0.80490596 0.80428081\n",
      " 0.79772189 0.79634323]\n",
      "[[1.11366368 0.81059887 1.00583114 0.99677377 1.10246644 1.03751259\n",
      "  1.17318034 1.03518214]]\n",
      "{0: 1631, 1: 241}\n",
      "acc 0.7943376068376068\n",
      "(0.1991701244813278, 0.2, 0.19958419958419957, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 320923.02927842864\n",
      "dev set\n",
      "[0.90184614 0.89884729 0.90073624 0.90078656 0.9018484  0.90118214\n",
      " 0.90090531 0.89952535]\n",
      "[[1.11702434 0.813531   1.00901872 0.99984289 1.10562754 1.04058293\n",
      "  1.16999234 1.0319942 ]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "1 loss 320922.32226655184\n",
      "dev set\n",
      "[0.90254673 0.89953629 0.90141782 0.90156163 0.90260118 0.90194086\n",
      " 0.90011689 0.89873669]\n",
      "[[1.11645506 0.81286983 1.00842435 0.99906925 1.10493432 1.03984891\n",
      "  1.17078261 1.03278445]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "2 loss 320921.6040573853\n",
      "dev set\n",
      "[0.90325655 0.90023163 0.9020978  0.90232967 0.90335378 0.90269299\n",
      " 0.89932476 0.89794537]\n",
      "[[1.11586585 0.81220215 1.00782837 0.99830514 1.10424228 1.03912631\n",
      "  1.17157857 1.03358038]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "3 loss 320920.8762287791\n",
      "dev set\n",
      "[0.90397565 0.90093225 0.90277898 0.90309029 0.903997   0.90343858\n",
      " 0.89852825 0.89715094]\n",
      "[[1.11526009 0.81152904 1.00722793 0.99755091 1.10354764 1.03841453\n",
      "  1.17238101 1.03438273]]\n",
      "{0: 1753, 1: 119}\n",
      "acc 0.8370726495726496\n",
      "(0.226890756302521, 0.1125, 0.15041782729805012, None)\n",
      "\n",
      "4 loss 320920.1452764673\n",
      "dev set\n",
      "[0.90469929 0.90163732 0.9034623  0.90384354 0.90446963 0.90417794\n",
      " 0.89772901 0.89635147]\n",
      "[[1.11463973 0.81085141 1.00662214 0.9968066  1.10284543 1.03771305\n",
      "  1.17319003 1.03519161]]\n",
      "{0: 1768, 1: 104}\n",
      "acc 0.8450854700854701\n",
      "(0.25961538461538464, 0.1125, 0.15697674418604654, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 320957.15530936024\n",
      "dev set\n",
      "[1.0020136  0.99742021 1.00088174 1.0000735  1.00190489 1.00127122\n",
      " 1.00251905 1.00116734]\n",
      "[[1.11791426 0.81495405 1.00957685 1.00062431 1.10670222 1.04142221\n",
      "  1.16975195 1.03126644]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "1 loss 320957.1547842492\n",
      "dev set\n",
      "[1.00305776 0.9966831  1.00204907 1.00109011 1.00296013 1.00240167\n",
      " 1.00351821 1.00230951]\n",
      "[[1.1187943  0.81577553 1.0099764  1.00066045 1.10755781 1.04203544\n",
      "  1.17069569 1.0318246 ]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 320957.1541431577\n",
      "dev set\n",
      "[1.00429907 0.99591463 1.00343968 1.00257319 1.00421499 1.0037421\n",
      " 1.00469868 1.00366367]\n",
      "[[1.120051   0.81669408 1.01112864 1.00136934 1.10881471 1.04325824\n",
      "  1.1719345  1.03303303]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 320957.15332792193\n",
      "dev set\n",
      "[1.00567767 0.99511682 1.00495154 1.00419934 1.00560584 1.00520822\n",
      " 1.00601759 1.00514188]\n",
      "[[1.12153233 0.81769186 1.01266504 1.00286644 1.1103034  1.04478292\n",
      "  1.17337425 1.03456157]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 320957.15227035724\n",
      "dev set\n",
      "[1.00714554 0.99429235 1.00652916 1.00587888 1.00708364 1.00674758\n",
      " 1.00743336 1.00669116]\n",
      "[[1.12314799 0.8187529  1.01436083 1.00462142 1.11192703 1.04645241\n",
      "  1.17494682 1.03623799]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.6\n",
      "recall penalty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 175979.69949663084\n",
      "dev set\n",
      "[0.60078995 0.59775262 0.59970918 0.60040537 0.60068282 0.60081734\n",
      " 0.60209131 0.60071108]\n",
      "[[1.11793291 0.81460117 1.00992103 1.00022268 1.10675601 1.04093469\n",
      "  1.16881015 1.03081259]]\n",
      "{0: 744, 1: 1128}\n",
      "acc 0.4326923076923077\n",
      "(0.1356382978723404, 0.6375, 0.2236842105263158, None)\n",
      "\n",
      "1 loss 175978.86389964836\n",
      "dev set\n",
      "[0.60040571 0.59736431 0.59932393 0.60080286 0.60030274 0.60121612\n",
      " 0.60248806 0.60110764]\n",
      "[[1.11832207 0.81498607 1.01027977 0.9998245  1.1071329  1.04053601\n",
      "  1.16841625 1.03041919]]\n",
      "{0: 736, 1: 1136}\n",
      "acc 0.4284188034188034\n",
      "(0.13468309859154928, 0.6375, 0.22238372093023256, None)\n",
      "\n",
      "2 loss 175977.99161700858\n",
      "dev set\n",
      "[0.60001013 0.59696638 0.59892786 0.60120099 0.59990901 0.60161448\n",
      " 0.60288921 0.60150878]\n",
      "[[1.11872162 0.81538236 1.01065558 0.99942599 1.107524   1.04013773\n",
      "  1.16801559 1.03001864]]\n",
      "{0: 724, 1: 1148}\n",
      "acc 0.4252136752136752\n",
      "(0.13588850174216027, 0.65, 0.22478386167146971, None)\n",
      "\n",
      "3 loss 175977.0740979875\n",
      "dev set\n",
      "[0.59960243 0.59655812 0.59852022 0.60159954 0.59950084 0.60201242\n",
      " 0.60329525 0.60191498]\n",
      "[[1.11913222 0.81579091 1.01104925 0.99902721 1.10793014 1.03973986\n",
      "  1.16760751 1.0296103 ]]\n",
      "{0: 713, 1: 1159}\n",
      "acc 0.41933760683760685\n",
      "(0.13459879206212252, 0.65, 0.22301644031451037, None)\n",
      "\n",
      "4 loss 175976.10879969405\n",
      "dev set\n",
      "[0.59918301 0.59613975 0.59810135 0.6019983  0.59907881 0.60240979\n",
      " 0.60370612 0.60232618]\n",
      "[[1.11955359 0.81621137 1.01145992 0.99862835 1.10835069 1.03934254\n",
      "  1.16719213 1.02919427]]\n",
      "{0: 700, 1: 1172}\n",
      "acc 0.41452991452991456\n",
      "(0.1348122866894198, 0.6583333333333333, 0.2237960339943343, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 175893.56735967463\n",
      "dev set\n",
      "[0.7015829  0.69854903 0.70050177 0.70040866 0.70147148 0.70081683\n",
      " 0.70128487 0.69990486]\n",
      "[[1.11713854 0.81380878 1.00915202 1.00022161 1.10597073 1.04093555\n",
      "  1.16961311 1.03161494]]\n",
      "{0: 1318, 1: 554}\n",
      "acc 0.6752136752136753\n",
      "(0.16787003610108303, 0.3875, 0.23425692695214104, None)\n",
      "\n",
      "1 loss 175892.42009450062\n",
      "dev set\n",
      "[0.70198553 0.69895219 0.70090425 0.70080678 0.70187491 0.70121554\n",
      " 0.7008817  0.69950163]\n",
      "[[1.11673659 0.81340694 1.00875005 0.99982344 1.10556807 1.04053739\n",
      "  1.1700169  1.03201869]]\n",
      "{0: 1328, 1: 544}\n",
      "acc 0.6794871794871795\n",
      "(0.16911764705882354, 0.38333333333333336, 0.23469387755102042, None)\n",
      "\n",
      "2 loss 175891.24794571765\n",
      "dev set\n",
      "[0.70239056 0.69935774 0.70130952 0.70120446 0.70228081 0.70161442\n",
      " 0.70047461 0.69909459]\n",
      "[[1.11633214 0.81300354 1.00834701 0.99942578 1.10516315 1.04013928\n",
      "  1.17042324 1.03242498]]\n",
      "{0: 1333, 1: 539}\n",
      "acc 0.6810897435897436\n",
      "(0.16883116883116883, 0.37916666666666665, 0.23363286264441593, None)\n",
      "\n",
      "3 loss 175890.04219565314\n",
      "dev set\n",
      "[0.70279883 0.69976666 0.70171825 0.70160156 0.70269012 0.70201349\n",
      " 0.70006232 0.69868248]\n",
      "[[1.11592428 0.81259792 1.00794222 0.99902875 1.10475512 1.03974123\n",
      "  1.17083303 1.03283467]]\n",
      "{0: 1342, 1: 530}\n",
      "acc 0.6858974358974359\n",
      "(0.17169811320754716, 0.37916666666666665, 0.2363636363636364, None)\n",
      "\n",
      "4 loss 175888.80003974857\n",
      "dev set\n",
      "[0.70321079 0.70017963 0.70213074 0.70199789 0.70310308 0.70241264\n",
      " 0.6996445  0.69826497]\n",
      "[[1.11551282 0.81218996 1.00753552 0.99863255 1.10434381 1.03934342\n",
      "  1.17124648 1.03324799]]\n",
      "{0: 1359, 1: 513}\n",
      "acc 0.6949786324786325\n",
      "(0.17738791423001948, 0.37916666666666665, 0.2416998671978752, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 175819.11785308376\n",
      "dev set\n",
      "[0.80157759 0.79853642 0.80049971 0.80040883 0.80146553 0.80081567\n",
      " 0.8012867  0.79990674]\n",
      "[[1.11714136 0.81382648 1.00916151 1.00022123 1.10597231 1.04093749\n",
      "  1.16961136 1.03161321]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "1 loss 175818.0039779649\n",
      "dev set\n",
      "[0.80197674 0.7989248  0.80089534 0.80080681 0.80185913 0.80121322\n",
      " 0.80088523 0.79950523]\n",
      "[[1.11674272 0.81344406 1.00876762 0.99982317 1.10557282 1.04054143\n",
      "  1.1700132  1.03201505]]\n",
      "{0: 1599, 1: 273}\n",
      "acc 0.7783119658119658\n",
      "(0.1794871794871795, 0.20416666666666666, 0.19103313840155947, None)\n",
      "\n",
      "2 loss 175816.88932915477\n",
      "dev set\n",
      "[0.80237742 0.79931336 0.80128984 0.80120419 0.80225122 0.80161082\n",
      " 0.80048266 0.79910261]\n",
      "[[1.11634424 0.81306027 1.0083739  0.99942594 1.10517358 1.04014555\n",
      "  1.17041618 1.03241802]]\n",
      "{0: 1603, 1: 269}\n",
      "acc 0.780448717948718\n",
      "(0.1821561338289963, 0.20416666666666666, 0.19253438113948923, None)\n",
      "\n",
      "3 loss 175815.77175614264\n",
      "dev set\n",
      "[0.80277993 0.79970248 0.801685   0.80160081 0.80264024 0.80200842\n",
      " 0.80007856 0.79869869]\n",
      "[[1.11594556 0.81267508 1.00798006 0.99902969 1.10477417 1.03975004\n",
      "  1.17082071 1.03282254]]\n",
      "{0: 1608, 1: 264}\n",
      "acc 0.7831196581196581\n",
      "(0.1856060606060606, 0.20416666666666666, 0.19444444444444445, None)\n",
      "\n",
      "4 loss 175814.6443464557\n",
      "dev set\n",
      "[0.80318424 0.80009265 0.80208102 0.80199647 0.80303195 0.80240583\n",
      " 0.79967294 0.79829378]\n",
      "[[1.11554663 0.81228872 1.00758604 0.99863462 1.10437455 1.03935515\n",
      "  1.17122686 1.03322868]]\n",
      "{0: 1609, 1: 263}\n",
      "acc 0.7836538461538461\n",
      "(0.18631178707224336, 0.20416666666666666, 0.194831013916501, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 175883.20490985076\n",
      "dev set\n",
      "[0.9015636  0.89851993 0.9004883  0.90040977 0.90147191 0.90081419\n",
      " 0.90128676 0.89990683]\n",
      "[[1.11721171 0.81384463 1.00918717 1.00022045 1.10598419 1.04094086\n",
      "  1.16961111 1.03161296]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "1 loss 175882.8439915232\n",
      "dev set\n",
      "[0.90195269 0.89888892 0.90087158 0.90080782 0.9018694  0.9012092\n",
      " 0.90088505 0.89950502]\n",
      "[[1.1168741  0.813485   1.00882587 0.99982261 1.10560817 1.04055042\n",
      "  1.17001324 1.03201509]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "2 loss 175882.48132189427\n",
      "dev set\n",
      "[0.90234357 0.89925977 0.90125456 0.90120454 0.90226684 0.90160324\n",
      " 0.90048243 0.89910223]\n",
      "[[1.11653242 0.8131234  1.00846434 0.99942666 1.10523235 1.04016179\n",
      "  1.1704168  1.03241864]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "3 loss 175882.11503320994\n",
      "dev set\n",
      "[0.9027367  0.89963259 0.9016379  0.90159976 0.90266519 0.90199617\n",
      " 0.90007843 0.89869807]\n",
      "[[1.11618678 0.81275973 1.0081018  0.99903283 1.10485594 1.0397752\n",
      "  1.17082225 1.03282407]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "4 loss 175881.7449175997\n",
      "dev set\n",
      "[0.9031323  0.90000714 0.90202185 0.90199327 0.90306486 0.9023878\n",
      " 0.89967299 0.89829265]\n",
      "[[1.11583724 0.81239428 1.00773792 0.99864134 1.10447864 1.0393909\n",
      "  1.17122965 1.03323145]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "batch-size: 256 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 175917.1554215061\n",
      "dev set\n",
      "[1.00158846 0.99775084 1.00046766 1.0000272  1.00147729 1.00082838\n",
      " 1.00210319 1.00072472]\n",
      "[[1.11773207 0.81460836 1.00956178 1.00062431 1.10653878 1.04136399\n",
      "  1.16949163 1.03122252]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "1 loss 175917.15516080367\n",
      "dev set\n",
      "[1.00204011 0.99736673 1.00094346 1.00030618 1.00193188 1.00130426\n",
      " 1.002544   1.00120312]\n",
      "[[1.11806614 0.81501017 1.00960211 1.00062461 1.10685221 1.04149568\n",
      "  1.16988323 1.03132334]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 175917.15487911433\n",
      "dev set\n",
      "[1.00255058 0.9969751  1.00151124 1.00084712 1.00244757 1.00185614\n",
      " 1.00303398 1.00176053]\n",
      "[[1.11852472 0.81543974 1.00980291 1.00064873 1.1073011  1.04182165\n",
      "  1.17036281 1.03161679]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 175917.15456795145\n",
      "dev set\n",
      "[1.00311975 0.99657454 1.00215286 1.00150816 1.00302335 1.00247523\n",
      " 1.00357572 1.00238643]\n",
      "[[1.1190875  0.81589857 1.0102428  1.00084741 1.10786191 1.04233546\n",
      "  1.17092269 1.03211417]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 175917.15422013617\n",
      "dev set\n",
      "[1.00374046 0.99616501 1.00284975 1.00224128 1.00365114 1.00314773\n",
      " 1.00416535 1.00306598]\n",
      "[[1.11973256 0.81638461 1.01086433 1.00134248 1.10850915 1.0429801\n",
      "  1.17155164 1.03275441]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6\n",
      "recall penalty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 103459.89077783604\n",
      "dev set\n",
      "[0.60096703 0.59793245 0.59988671 0.60021915 0.60085681 0.60062739\n",
      " 0.60190461 0.60052456]\n",
      "[[1.11775379 0.814423   1.00975866 1.00041074 1.10658452 1.04112457\n",
      "  1.16899447 1.03099649]]\n",
      "{0: 752, 1: 1120}\n",
      "acc 0.43696581196581197\n",
      "(0.13660714285714284, 0.6375, 0.22499999999999998, None)\n",
      "\n",
      "1 loss 103459.45450880057\n",
      "dev set\n",
      "[0.60076487 0.59772888 0.59968401 0.60042662 0.60065614 0.60083477\n",
      " 0.60211097 0.60073086]\n",
      "[[1.11795781 0.81462462 1.00994883 1.00020326 1.1067847  1.04091721\n",
      "  1.16878942 1.03079162]]\n",
      "{0: 744, 1: 1128}\n",
      "acc 0.4326923076923077\n",
      "(0.1356382978723404, 0.6375, 0.2236842105263158, None)\n",
      "\n",
      "2 loss 103459.01550800775\n",
      "dev set\n",
      "[0.60056118 0.59752415 0.59947989 0.60063367 0.60045346 0.6010414\n",
      " 0.60231748 0.60093734]\n",
      "[[1.11816328 0.81482768 1.01014156 0.99999635 1.10698696 1.0407106\n",
      "  1.16858383 1.03058615]]\n",
      "{0: 741, 1: 1131}\n",
      "acc 0.4310897435897436\n",
      "(0.13527851458885942, 0.6375, 0.22319474835886216, None)\n",
      "\n",
      "3 loss 103458.56666828283\n",
      "dev set\n",
      "[0.60035494 0.59731727 0.59927336 0.60084075 0.60024766 0.60124783\n",
      " 0.60252491 0.60114478]\n",
      "[[1.11837108 0.81503327 1.01033822 0.99978947 1.10719245 1.04050418\n",
      "  1.1683768  1.03037914]]\n",
      "{0: 733, 1: 1139}\n",
      "acc 0.4268162393162393\n",
      "(0.13432835820895522, 0.6375, 0.22189992748368384, None)\n",
      "\n",
      "4 loss 103458.106442353\n",
      "dev set\n",
      "[0.60014574 0.59710789 0.59906401 0.60104794 0.60003831 0.60145417\n",
      " 0.6027335  0.60135342]\n",
      "[[1.11858158 0.81524184 1.01053929 0.99958252 1.10740161 1.04029785\n",
      "  1.168168   1.03017026]]\n",
      "{0: 727, 1: 1145}\n",
      "acc 0.42467948717948717\n",
      "(0.13449781659388646, 0.6416666666666667, 0.2223826714801444, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 103373.85179597886\n",
      "dev set\n",
      "[0.70139039 0.69835708 0.70031029 0.70021996 0.70127882 0.70062722\n",
      " 0.70147685 0.70009688]\n",
      "[[1.11733015 0.81399984 1.00934453 1.00041057 1.10616297 1.04112484\n",
      "  1.16942107 1.03142291]]\n",
      "{0: 1312, 1: 560}\n",
      "acc 0.6730769230769231\n",
      "(0.16785714285714284, 0.39166666666666666, 0.235, None)\n",
      "\n",
      "1 loss 103373.2579742983\n",
      "dev set\n",
      "[0.70159852 0.69856569 0.70051866 0.70042736 0.70148739 0.70083456\n",
      " 0.70126823 0.69988825]\n",
      "[[1.11712242 0.81379158 1.00913627 1.00020324 1.10595464 1.04091762\n",
      "  1.1696301  1.03163192]]\n",
      "{0: 1318, 1: 554}\n",
      "acc 0.6752136752136753\n",
      "(0.16787003610108303, 0.3875, 0.23425692695214104, None)\n",
      "\n",
      "2 loss 103372.66539690277\n",
      "dev set\n",
      "[0.70180641 0.69877415 0.7007269  0.70063403 0.70169575 0.70104127\n",
      " 0.70105954 0.69967958]\n",
      "[[1.11691494 0.81358371 1.00892848 0.99999665 1.10574656 1.04071106\n",
      "  1.16983897 1.03184077]]\n",
      "{0: 1321, 1: 551}\n",
      "acc 0.6757478632478633\n",
      "(0.16696914700544466, 0.38333333333333336, 0.23261694058154234, None)\n",
      "\n",
      "3 loss 103372.06568531302\n",
      "dev set\n",
      "[0.70201488 0.69898327 0.70093577 0.70084049 0.70190471 0.70124791\n",
      " 0.70084989 0.69946998]\n",
      "[[1.11670689 0.81337551 1.00872045 0.99979029 1.10553796 1.04050462\n",
      "  1.17004846 1.03205022]]\n",
      "{0: 1328, 1: 544}\n",
      "acc 0.6794871794871795\n",
      "(0.16911764705882354, 0.38333333333333336, 0.23469387755102042, None)\n",
      "\n",
      "4 loss 103371.45734598293\n",
      "dev set\n",
      "[0.70222415 0.69919318 0.70114556 0.70104682 0.70211455 0.7014546\n",
      " 0.70063891 0.69925907]\n",
      "[[1.11649798 0.81316674 1.00851195 0.99958408 1.10532856 1.04029819\n",
      "  1.17025882 1.03226054]]\n",
      "{0: 1331, 1: 541}\n",
      "acc 0.6800213675213675\n",
      "(0.16820702402957485, 0.37916666666666665, 0.23303457106274003, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 103299.39136910836\n",
      "dev set\n",
      "[0.80138893 0.79835225 0.80031063 0.80021994 0.80127765 0.80062687\n",
      " 0.80147759 0.80009762]\n",
      "[[1.11733098 0.81400713 1.0093443  1.00041049 1.10616327 1.04112544\n",
      "  1.16942054 1.03142239]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "1 loss 103298.80497623158\n",
      "dev set\n",
      "[0.80159615 0.79855481 0.80051808 0.8004272  0.80148365 0.80083395\n",
      " 0.80126939 0.79988943]\n",
      "[[1.11712433 0.81380739 1.00913502 1.00020323 1.10595574 1.04091869\n",
      "  1.16962899 1.03163083]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "2 loss 103298.23003300696\n",
      "dev set\n",
      "[0.80180296 0.79875674 0.8007247  0.80063371 0.80168772 0.8010404\n",
      " 0.80106167 0.79968169]\n",
      "[[1.11691847 0.8136082  1.00892638 0.99999677 1.10574898 1.0407126\n",
      "  1.16983701 1.03183885]]\n",
      "{0: 1596, 1: 276}\n",
      "acc 0.7767094017094017\n",
      "(0.17753623188405798, 0.20416666666666666, 0.18992248062015504, None)\n",
      "\n",
      "3 loss 103297.65387008528\n",
      "dev set\n",
      "[0.80201004 0.79895872 0.80093084 0.80083996 0.80189201 0.80124675\n",
      " 0.80085375 0.79947374]\n",
      "[[1.11671273 0.81340889 1.00871781 0.99979062 1.10554234 1.04050667\n",
      "  1.17004525 1.03204709]]\n",
      "{0: 1599, 1: 273}\n",
      "acc 0.7783119658119658\n",
      "(0.1794871794871795, 0.20416666666666666, 0.19103313840155947, None)\n",
      "\n",
      "4 loss 103297.07529148985\n",
      "dev set\n",
      "[0.80221757 0.79916064 0.80113639 0.80104604 0.80209633 0.8014531\n",
      " 0.80064543 0.79926539]\n",
      "[[1.11650691 0.8132093  1.00850918 0.99958469 1.10533565 1.04030082\n",
      "  1.1702539  1.03225572]]\n",
      "{0: 1602, 1: 270}\n",
      "acc 0.7799145299145299\n",
      "(0.1814814814814815, 0.20416666666666666, 0.19215686274509802, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 103363.2935331141\n",
      "dev set\n",
      "[0.90138381 0.89834489 0.90030915 0.90022019 0.90127769 0.90062669\n",
      " 0.90147749 0.90009753]\n",
      "[[1.11735942 0.81401536 1.00934893 1.00041029 1.10616928 1.04112592\n",
      "  1.16942055 1.0314224 ]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "1 loss 103363.10483745561\n",
      "dev set\n",
      "[0.90158647 0.89853847 0.90051595 0.90042748 0.90148383 0.90083362\n",
      " 0.90126897 0.899889  ]\n",
      "[[1.11717834 0.81382607 1.00914557 1.00020305 1.10596967 1.04091958\n",
      "  1.16962918 1.03163103]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "2 loss 103362.91797927009\n",
      "dev set\n",
      "[0.90178884 0.89873148 0.90072222 0.90063386 0.90168945 0.90103976\n",
      " 0.90106089 0.89968092]\n",
      "[[1.11699685 0.81363739 1.00894258 0.99999682 1.10577048 1.04071413\n",
      "  1.16983745 1.03183929]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "3 loss 103362.73068032821\n",
      "dev set\n",
      "[0.90199158 0.89892469 0.90092852 0.90083982 0.90189516 0.90124559\n",
      " 0.90085269 0.89947265]\n",
      "[[1.1168145  0.81344849 1.00873938 0.99979114 1.10557122 1.04050916\n",
      "  1.170046   1.03204784]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "4 loss 103362.54250532396\n",
      "dev set\n",
      "[0.9021949  0.89911831 0.90113503 0.90104543 0.90210117 0.90145117\n",
      " 0.90064417 0.89926403]\n",
      "[[1.11663111 0.81325919 1.0085358  0.99958596 1.10537171 1.04030464\n",
      "  1.17025504 1.03225687]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 103397.15548275135\n",
      "dev set\n",
      "[1.00139093 0.99793483 1.00029013 1.00001764 1.00127934 1.00062862\n",
      " 1.00190725 1.00052624]\n",
      "[[1.11765601 0.81442223 1.00956014 1.00062431 1.10647392 1.0413509\n",
      "  1.1693689  1.0312141 ]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "1 loss 103397.15535003418\n",
      "dev set\n",
      "[1.00160795 0.99773618 1.00050388 1.00010058 1.00149697 1.00085065\n",
      " 1.00212211 1.00074823]\n",
      "[[1.11781206 0.81462406 1.00956526 1.00062431 1.10661769 1.04138967\n",
      "  1.16955825 1.03123878]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 103397.15521486757\n",
      "dev set\n",
      "[1.00183685 0.99753699 1.00074312 1.00029233 1.00172718 1.00109064\n",
      " 1.00234625 1.00098933]\n",
      "[[1.1180019  0.81483072 1.00958886 1.00062479 1.10679908 1.04147321\n",
      "  1.16976861 1.03130198]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 103397.15507408182\n",
      "dev set\n",
      "[1.00208091 0.99733606 1.00100853 1.00053923 1.00197326 1.00135151\n",
      " 1.00258274 1.00125235]\n",
      "[[1.11822289 0.81504438 1.00965612 1.00063125 1.10701492 1.04161421\n",
      "  1.17000032 1.0314223 ]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 103397.15492649877\n",
      "dev set\n",
      "[1.00234143 0.99713291 1.00129847 1.00082538 1.00223644 1.00163338\n",
      " 1.00283304 1.0015371 ]\n",
      "[[1.118473   0.81526591 1.00979014 1.00066537 1.10726246 1.0418137\n",
      "  1.17025356 1.03160584]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6\n",
      "recall penalty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 62019.98598110012\n",
      "dev set\n",
      "[0.60107049 0.59803661 0.59999039 0.60011317 0.60095942 0.60052055\n",
      " 0.60179872 0.60041872]\n",
      "[[1.11765    0.81431941 1.00966084 1.00051723 1.10648201 1.0412314\n",
      "  1.1690997  1.03110162]]\n",
      "{0: 756, 1: 1116}\n",
      "acc 0.4391025641025641\n",
      "(0.13709677419354838, 0.6375, 0.22566371681415928, None)\n",
      "\n",
      "1 loss 62019.7663454671\n",
      "dev set\n",
      "[0.60096717 0.59793259 0.59988677 0.60021918 0.60085685 0.60062647\n",
      " 0.60190412 0.60052408]\n",
      "[[1.11775378 0.81442244 1.00975956 1.00041133 1.10658406 1.04112549\n",
      "  1.16899482 1.03099682]]\n",
      "{0: 752, 1: 1120}\n",
      "acc 0.43696581196581197\n",
      "(0.13660714285714284, 0.6375, 0.22499999999999998, None)\n",
      "\n",
      "2 loss 62019.54604718163\n",
      "dev set\n",
      "[0.60086363 0.59782843 0.59978296 0.60032512 0.60075398 0.60073224\n",
      " 0.6020095  0.60062943]\n",
      "[[1.1178577  0.81452563 1.0098587  1.00030556 1.10668635 1.04101975\n",
      "  1.1688899  1.03089198]]\n",
      "{0: 751, 1: 1121}\n",
      "acc 0.43643162393162394\n",
      "(0.13648528099910795, 0.6375, 0.22483468038207202, None)\n",
      "\n",
      "3 loss 62019.32348671989\n",
      "dev set\n",
      "[0.60075968 0.59772392 0.59967876 0.60043107 0.6006506  0.60083794\n",
      " 0.602115   0.60073492]\n",
      "[[1.11796199 0.81462922 1.00995854 1.00019982 1.10678917 1.04091406\n",
      "  1.16878477 1.0307869 ]]\n",
      "{0: 744, 1: 1128}\n",
      "acc 0.4326923076923077\n",
      "(0.1356382978723404, 0.6375, 0.2236842105263158, None)\n",
      "\n",
      "4 loss 62019.09836533936\n",
      "dev set\n",
      "[0.6006552  0.59761898 0.59957406 0.60053704 0.60054656 0.60094363\n",
      " 0.6022207  0.60084061]\n",
      "[[1.11806674 0.81473334 1.01005924 1.00009407 1.10689264 1.0408084\n",
      "  1.16867933 1.03068151]]\n",
      "{0: 743, 1: 1129}\n",
      "acc 0.4321581196581197\n",
      "(0.1355181576616475, 0.6375, 0.2235208181154127, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 61933.99106099733\n",
      "dev set\n",
      "[0.70128284 0.69824962 0.70020297 0.70011337 0.70117125 0.70052049\n",
      " 0.70158457 0.70020459]\n",
      "[[1.1174371  0.81410704 1.00945238 1.00051718 1.10627043 1.04123149\n",
      "  1.16931348 1.03131533]]\n",
      "{0: 1309, 1: 563}\n",
      "acc 0.6714743589743589\n",
      "(0.1669626998223801, 0.39166666666666666, 0.23412204234122044, None)\n",
      "\n",
      "1 loss 61933.6923175866\n",
      "dev set\n",
      "[0.70138894 0.69835592 0.70030908 0.70021933 0.70127755 0.70062634\n",
      " 0.70147825 0.70009826]\n",
      "[[1.11733061 0.81400059 1.00934664 1.00041125 1.10616417 1.04112571\n",
      "  1.16941983 1.03142168]]\n",
      "{0: 1312, 1: 560}\n",
      "acc 0.6730769230769231\n",
      "(0.16785714285714284, 0.39166666666666666, 0.235, None)\n",
      "\n",
      "2 loss 61933.39349497914\n",
      "dev set\n",
      "[0.70149493 0.69846215 0.7004151  0.70032515 0.70138376 0.70073204\n",
      " 0.70137197 0.69999198]\n",
      "[[1.11722418 0.81389422 1.00924107 1.00030547 1.10605799 1.04102009\n",
      "  1.1695261  1.03152794]]\n",
      "{0: 1314, 1: 558}\n",
      "acc 0.6730769230769231\n",
      "(0.16666666666666666, 0.3875, 0.23308270676691725, None)\n",
      "\n",
      "3 loss 61933.09300142999\n",
      "dev set\n",
      "[0.70160098 0.69856846 0.70052119 0.70043093 0.70149004 0.70083771\n",
      " 0.70126555 0.69988556]\n",
      "[[1.11711767 0.81378782 1.00913551 1.00019974 1.10595176 1.0409145\n",
      "  1.16963244 1.03163428]]\n",
      "{0: 1319, 1: 553}\n",
      "acc 0.6746794871794872\n",
      "(0.16636528028933092, 0.38333333333333336, 0.23203026481715006, None)\n",
      "\n",
      "4 loss 61932.79050526633\n",
      "dev set\n",
      "[0.70170717 0.69867492 0.70062741 0.70053667 0.70159647 0.70094338\n",
      " 0.70115891 0.69977893]\n",
      "[[1.11701101 0.81368133 1.00902988 1.00009405 1.10584539 1.04080893\n",
      "  1.16973892 1.03174075]]\n",
      "{0: 1319, 1: 553}\n",
      "acc 0.6746794871794872\n",
      "(0.16636528028933092, 0.38333333333333336, 0.23203026481715006, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 61859.52697843579\n",
      "dev set\n",
      "[0.80128266 0.79824802 0.80020282 0.80011335 0.80117097 0.80052037\n",
      " 0.80158471 0.80020472]\n",
      "[[1.11743711 0.81410961 1.00945222 1.00051717 1.10627043 1.04123169\n",
      "  1.16931336 1.03131521]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "1 loss 61859.22916598461\n",
      "dev set\n",
      "[0.8013888  0.79835213 0.80030838 0.80021926 0.80127687 0.80062605\n",
      " 0.80147853 0.80009855]\n",
      "[[1.11733039 0.81400664 1.00934609 1.00041128 1.10616411 1.04112618\n",
      "  1.16941953 1.03142138]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "2 loss 61858.93343522053\n",
      "dev set\n",
      "[0.80149485 0.79845605 0.8004137  0.80032501 0.80138208 0.80073159\n",
      " 0.80137248 0.79999249]\n",
      "[[1.11722375 0.81390386 1.00924014 1.00030555 1.10605792 1.04102083\n",
      "  1.16952557 1.03152742]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "3 loss 61858.64018256636\n",
      "dev set\n",
      "[0.80160093 0.79855993 0.80051896 0.8004307  0.80148655 0.80083708\n",
      " 0.80126642 0.79988643]\n",
      "[[1.11711711 0.8138011  1.00913423 1.00019989 1.10595177 1.04091554\n",
      "  1.16963162 1.03163347]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "4 loss 61858.34670216688\n",
      "dev set\n",
      "[0.80170708 0.79866384 0.80062421 0.80053635 0.80159079 0.80094257\n",
      " 0.80116032 0.79978031]\n",
      "[[1.11701045 0.81369831 1.00902832 1.00009428 1.10584562 1.04081026\n",
      "  1.16973772 1.03173957]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 61923.33742848626\n",
      "dev set\n",
      "[0.90128292 0.89824459 0.90020279 0.90011341 0.90117031 0.90052035\n",
      " 0.90158468 0.9002047 ]\n",
      "[[1.11743779 0.81411353 1.00945266 1.00051712 1.10627357 1.04123174\n",
      "  1.16931337 1.03131522]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "1 loss 61923.24203285895\n",
      "dev set\n",
      "[0.90139042 0.89834373 0.90030828 0.90021933 0.90127564 0.90062606\n",
      " 0.90147847 0.90009848]\n",
      "[[1.1173307  0.81401631 1.00934773 1.00041119 1.10617123 1.04112623\n",
      "  1.16941959 1.03142144]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "2 loss 61923.14699944481\n",
      "dev set\n",
      "[0.90149801 0.89844246 0.90041354 0.90032506 0.90138097 0.9007316\n",
      " 0.90137239 0.89999239]\n",
      "[[1.11722346 0.81391957 1.00924305 1.00030545 1.10606881 1.04102089\n",
      "  1.16952569 1.03152755]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "3 loss 61923.05185142775\n",
      "dev set\n",
      "[0.9016057  0.89854109 0.90051875 0.90043071 0.90148634 0.90083707\n",
      " 0.9012663  0.8998863 ]\n",
      "[[1.11711607 0.81382296 1.00913842 1.00019983 1.10596632 1.04091565\n",
      "  1.16963182 1.03163367]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "4 loss 61922.95650842781\n",
      "dev set\n",
      "[0.90171352 0.89863973 0.90062397 0.90053629 0.90159177 0.9009425\n",
      " 0.90116018 0.89978016]\n",
      "[[1.11700851 0.81372635 1.00903375 1.00009429 1.10586375 1.04081049\n",
      "  1.16973801 1.03173985]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 61957.15551236521\n",
      "dev set\n",
      "[1.00128293 0.99803709 1.00019541 1.0000129  1.00117128 1.0005208\n",
      " 1.00179948 1.00041921]\n",
      "[[1.117609   0.81431969 1.00955981 1.00062431 1.10643434 1.04134558\n",
      "  1.16929399 1.03121115]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "1 loss 61957.15544519758\n",
      "dev set\n",
      "[1.00139046 0.99793424 1.00029774 1.00003935 1.00127892 1.00062914\n",
      " 1.00190664 1.00052734]\n",
      "[[1.11768861 0.81442307 1.0095607  1.00062431 1.10650758 1.04136097\n",
      "  1.16938994 1.03121957]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 61957.15537758214\n",
      "dev set\n",
      "[1.00149984 0.99783147 1.0004045  1.00010556 1.00138853 1.00074043\n",
      " 1.00201519 1.00063853]\n",
      "[[1.11777741 0.81452707 1.00956371 1.00062432 1.10659138 1.04138723\n",
      "  1.16949076 1.03123604]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 61957.155308748625\n",
      "dev set\n",
      "[1.00161186 0.99772848 1.00051711 1.00019515 1.00150095 1.00085577\n",
      " 1.00212582 1.00075401]\n",
      "[[1.11787395 0.81463223 1.0095714  1.00062447 1.10668406 1.04142694\n",
      "  1.16959611 1.03126399]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 61957.15523849538\n",
      "dev set\n",
      "[1.00172712 0.99762511 1.0006362  1.00029947 1.00161679 1.00097588\n",
      " 1.00223901 1.00087453]\n",
      "[[1.11797773 0.81473891 1.00958758 1.00062536 1.10678494 1.04148193\n",
      "  1.1697061  1.03130653]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall penalty\n",
      "0 loss 41300.03305860571\n",
      "dev set\n",
      "[0.60112238 0.59808893 0.60004247 0.60005996 0.60101084 0.60046712\n",
      " 0.60174562 0.60036563]\n",
      "[[1.11759798 0.81426765 1.00961175 1.00057062 1.1064308  1.04128482\n",
      "  1.16915254 1.03115441]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.4407051282051282\n",
      "(0.13746630727762804, 0.6375, 0.2261640798226164, None)\n",
      "\n",
      "1 loss 41299.92245157751\n",
      "dev set\n",
      "[0.60106979 0.59803613 0.5999898  0.60011355 0.60095846 0.60052073\n",
      " 0.60179895 0.60041895]\n",
      "[[1.117651   0.81432032 1.00966279 1.00051708 1.10648315 1.04123122\n",
      "  1.16909936 1.03110126]]\n",
      "{0: 756, 1: 1116}\n",
      "acc 0.4391025641025641\n",
      "(0.13709677419354838, 0.6375, 0.22566371681415928, None)\n",
      "\n",
      "2 loss 41299.811719297795\n",
      "dev set\n",
      "[0.60101723 0.59798335 0.59993715 0.60016712 0.6009061  0.60057432\n",
      " 0.60185228 0.60047226]\n",
      "[[1.11770402 0.81437296 1.00971375 1.00046356 1.10653548 1.04117764\n",
      "  1.16904619 1.03104812]]\n",
      "{0: 755, 1: 1117}\n",
      "acc 0.43856837606837606\n",
      "(0.1369740376007162, 0.6375, 0.22549742078113483, None)\n",
      "\n",
      "3 loss 41299.70046810007\n",
      "dev set\n",
      "[0.60096464 0.59793054 0.59988446 0.60022069 0.60085369 0.60062791\n",
      " 0.60190562 0.60052559]\n",
      "[[1.11775708 0.81442565 1.00976475 1.00041004 1.10658787 1.04112406\n",
      "  1.16899299 1.03099494]]\n",
      "{0: 752, 1: 1120}\n",
      "acc 0.43696581196581197\n",
      "(0.13660714285714284, 0.6375, 0.22499999999999998, None)\n",
      "\n",
      "4 loss 41299.58863827567\n",
      "dev set\n",
      "[0.60091197 0.59787766 0.59983171 0.60027426 0.6008012  0.6006815\n",
      " 0.60195899 0.60057895]\n",
      "[[1.1178102  0.81447841 1.00981583 1.00035652 1.10664033 1.04107048\n",
      "  1.16893974 1.03094173]]\n",
      "{0: 751, 1: 1121}\n",
      "acc 0.43643162393162394\n",
      "(0.13648528099910795, 0.6375, 0.22483468038207202, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7\n",
      "recall penalty\n",
      "0 loss 41214.0607719002\n",
      "dev set\n",
      "[0.70122936 0.69819607 0.70014946 0.70005994 0.70111771 0.70046709\n",
      " 0.70163809 0.70025811]\n",
      "[[1.11749072 0.81416059 1.0095057  1.00057061 1.10632398 1.04128486\n",
      "  1.16925992 1.03126177]]\n",
      "{0: 1307, 1: 565}\n",
      "acc 0.6725427350427351\n",
      "(0.16991150442477876, 0.4, 0.23850931677018633, None)\n",
      "\n",
      "1 loss 41213.91035137499\n",
      "dev set\n",
      "[0.70128324 0.69824997 0.70020326 0.70011348 0.70117161 0.70052066\n",
      " 0.70158412 0.70020415]\n",
      "[[1.11743685 0.81410667 1.00945178 1.00051706 1.10627013 1.04123133\n",
      "  1.16931381 1.03131565]]\n",
      "{0: 1309, 1: 563}\n",
      "acc 0.6714743589743589\n",
      "(0.1669626998223801, 0.39166666666666666, 0.23412204234122044, None)\n",
      "\n",
      "2 loss 41213.75954428187\n",
      "dev set\n",
      "[0.70133713 0.69830388 0.70025707 0.700167   0.70122552 0.70057421\n",
      " 0.70153013 0.70015017]\n",
      "[[1.11738296 0.81405275 1.00939784 1.00046352 1.10621628 1.04117781\n",
      "  1.16936771 1.03136955]]\n",
      "{0: 1312, 1: 560}\n",
      "acc 0.6730769230769231\n",
      "(0.16785714285714284, 0.39166666666666666, 0.235, None)\n",
      "\n",
      "3 loss 41213.60826160875\n",
      "dev set\n",
      "[0.70139104 0.6983578  0.7003109  0.70022053 0.70127945 0.70062776\n",
      " 0.70147612 0.70009617]\n",
      "[[1.11732906 0.81399881 1.0093439  1.00040999 1.10616241 1.0411243\n",
      "  1.16942162 1.03142346]]\n",
      "{0: 1312, 1: 560}\n",
      "acc 0.6730769230769231\n",
      "(0.16785714285714284, 0.39166666666666666, 0.235, None)\n",
      "\n",
      "4 loss 41213.45648165421\n",
      "dev set\n",
      "[0.70144497 0.69841176 0.70036475 0.70027405 0.70133341 0.70068132\n",
      " 0.70142207 0.70004213]\n",
      "[[1.11727514 0.81394486 1.00928994 1.00035646 1.10610852 1.04107078\n",
      "  1.16947556 1.0314774 ]]\n",
      "{0: 1313, 1: 559}\n",
      "acc 0.6725427350427351\n",
      "(0.16636851520572452, 0.3875, 0.2327909887359199, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "recall penalty\n",
      "0 loss 41139.59483794706\n",
      "dev set\n",
      "[0.80122926 0.79819595 0.8001496  0.80005993 0.80111759 0.80046705\n",
      " 0.80163821 0.80025822]\n",
      "[[1.1174907  0.81416069 1.00950568 1.0005706  1.10632403 1.04128494\n",
      "  1.16925988 1.03126173]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "1 loss 41139.444693077596\n",
      "dev set\n",
      "[0.801283   0.79824966 0.8002036  0.80011347 0.80117131 0.80052054\n",
      " 0.80158442 0.80020443]\n",
      "[[1.11743682 0.81410692 1.00945173 1.00051704 1.10627027 1.04123152\n",
      "  1.1693137  1.03131555]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "2 loss 41139.29451703065\n",
      "dev set\n",
      "[0.80133673 0.79830336 0.80025761 0.80016699 0.80122503 0.80057401\n",
      " 0.80153063 0.80015064]\n",
      "[[1.11738293 0.81405315 1.00939777 1.00046349 1.10621651 1.04117813\n",
      "  1.16936753 1.03136938]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "3 loss 41139.144201332354\n",
      "dev set\n",
      "[0.80139048 0.79835707 0.80031161 0.8002205  0.80127875 0.80062748\n",
      " 0.80147683 0.80009685]\n",
      "[[1.11732903 0.81399938 1.00934382 1.00040995 1.10616275 1.04112474\n",
      "  1.16942137 1.03142321]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "4 loss 41138.99395679663\n",
      "dev set\n",
      "[0.80144423 0.79841079 0.80036563 0.80027402 0.80133237 0.80068095\n",
      " 0.80142302 0.80004304]\n",
      "[[1.11727514 0.8139456  1.00928986 1.00035642 1.10610898 1.04107136\n",
      "  1.16947521 1.03147706]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "recall penalty\n",
      "0 loss 41203.359380503796\n",
      "dev set\n",
      "[0.90122948 0.89819602 0.90014951 0.90005998 0.90111775 0.9004671\n",
      " 0.90163817 0.9002582 ]\n",
      "[[1.11749054 0.81416064 1.00950568 1.00057056 1.10632403 1.04128485\n",
      "  1.16925989 1.03126174]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "1 loss 41203.31123425743\n",
      "dev set\n",
      "[0.90128353 0.89824983 0.90020338 0.90011359 0.9011717  0.90052068\n",
      " 0.90158434 0.90020437]\n",
      "[[1.11743649 0.8141068  1.00945171 1.00051693 1.10627026 1.0412313\n",
      "  1.16931374 1.03131559]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "2 loss 41203.26306705283\n",
      "dev set\n",
      "[0.90133758 0.89830364 0.90025726 0.90016718 0.90122566 0.90057425\n",
      " 0.9015305  0.90015054]\n",
      "[[1.11738243 0.81405296 1.00939775 1.00046332 1.1062165  1.04117776\n",
      "  1.16936758 1.03136943]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "3 loss 41203.21485112029\n",
      "dev set\n",
      "[0.90139164 0.89835746 0.90031114 0.90022077 0.90127963 0.90062781\n",
      " 0.90147666 0.9000967 ]\n",
      "[[1.11732836 0.81399911 1.00934377 1.00040972 1.10616273 1.04112424\n",
      "  1.16942144 1.03142329]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "4 loss 41203.16658271193\n",
      "dev set\n",
      "[0.90144572 0.89841129 0.90036502 0.90027434 0.90133361 0.90068136\n",
      " 0.90142281 0.90004285]\n",
      "[[1.11727427 0.81394526 1.00928979 1.00035614 1.10610895 1.04107073\n",
      "  1.16947532 1.03147716]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n",
      "recall penalty\n",
      "0 loss 41237.15552617518\n",
      "dev set\n",
      "[1.00122927 0.99808827 1.00014689 1.00001053 1.00111761 1.00046719\n",
      " 1.00174587 1.00036581]\n",
      "[[1.1175819  0.81426841 1.00955973 1.00062431 1.10641143 1.04134323\n",
      "  1.16925307 1.03120999]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "1 loss 41237.15549164747\n",
      "dev set\n",
      "[1.00128314 0.99803444 1.00019828 1.0000217  1.00117149 1.00052117\n",
      " 1.00179968 1.00041971]\n",
      "[[1.11762429 0.81432231 1.00955997 1.00062431 1.10645087 1.04135132\n",
      "  1.16930252 1.03121406]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 41237.15545681887\n",
      "dev set\n",
      "[1.00133729 0.99798058 1.00024991 1.00004572 1.00122568 1.00057558\n",
      " 1.0018537  1.00047401]\n",
      "[[1.11766943 0.81437635 1.00956058 1.00062431 1.10649359 1.04136287\n",
      "  1.16935322 1.03122044]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 41237.1554216543\n",
      "dev set\n",
      "[1.00139184 0.99792667 1.00030228 1.00008069 1.00128029 1.00063061\n",
      " 1.00190803 1.00052894]\n",
      "[[1.11771661 0.81443058 1.00956182 1.00062431 1.10653874 1.04137815\n",
      "  1.16940493 1.03122963]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 41237.155386138795\n",
      "dev set\n",
      "[1.00144689 0.9978727  1.00035573 1.00012156 1.00133544 1.00068641\n",
      " 1.00196275 1.00058467]\n",
      "[[1.11776553 0.81448507 1.00956409 1.00062435 1.10658595 1.04139739\n",
      "  1.16945757 1.03124213]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = np.empty([len(LF_l)],dtype=np.float64)\n",
    "acc.fill(0.25)\n",
    "rec =  np.empty([len(LF_l)],dtype=np.float64)\n",
    "rec.fill(0.35*train_L_S.shape[0])\n",
    "print(rec)\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [64,128,256,512,1024,2048]:\n",
    "    for i in np.linspace(0.6,1,5):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = acc ,LF_rec = rec,\\\n",
    "                                    pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=6,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 240, -1: 1632}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.22666667, 0.1953602 , 0.30890052, 0.55192878, 0.44444444,\n",
       "       1.        , 0.55      , 1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "def get_LF_rec(L_S,true_labels):\n",
    "    #L_S : a numpy array of [NoOfDataPoints,2,NoOfLFs] \n",
    "    #true_labels : numpy array [NoOfDataPoints]\n",
    "    \n",
    "    true_l = [-1 if x==0 else x for x in true_labels]\n",
    "    unique, counts = np.unique(true_l, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "\n",
    "    # take only labels \n",
    "    L_S = L_S[:,0,:]\n",
    "    #L_S shape [NoOfDataPoints,NoOfLFs]\n",
    "    LF_rec = []\n",
    "    for i in range(L_S.shape[1]):\n",
    "#         print(accuracy_score(L_S[:,i],tl,normalize=False),accuracy_score(L_S[:,i],tl))\n",
    "       \n",
    "        LF_labels = [LF_l[i] if x==LF_l[i] else 0 for x in L_S[:,i]]\n",
    "        tl = [LF_l[i] if x==LF_l[i] else 0 for x in true_l]\n",
    "        LF_rec.append(recall_score(LF_labels,tl,pos_label=LF_l[i],average='binary'))\n",
    "#         unique, counts = np.unique(L_S[:,i], return_counts=True)\n",
    "#         print(i,dict(zip(unique, counts)))\n",
    "#         print(precision_score(L_S[:,i],tl,labels=[LF_l[i]],average='macro'))\n",
    "#         LF_acc.append(precision_score(L_S[:,i],tl,labels=[LF_l[i]],average='macro'))\n",
    "    return np.array(LF_rec)\n",
    "                      \n",
    "get_LF_rec(dev_L_S,gold_labels_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 240, -1: 1632}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.04540598, 0.08547009, 0.06303419, 0.09935897, 0.0042735 ,\n",
       "       0.00053419, 0.00587607, 0.00106838])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "def get_LF_acc(L_S,true_labels):\n",
    "    #L_S : a numpy array of [NoOfDataPoints,2,NoOfLFs] \n",
    "    #true_labels : numpy array [NoOfDataPoints]\n",
    "    \n",
    "    tl = [-1 if x==0 else x for x in true_labels]\n",
    "    unique, counts = np.unique(tl, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "\n",
    "    # take only labels \n",
    "    L_S = L_S[:,0,:]\n",
    "    #L_S shape [NoOfDataPoints,NoOfLFs]\n",
    "    LF_acc = []\n",
    "    for i in range(L_S.shape[1]):\n",
    "#         print(accuracy_score(L_S[:,i],tl,normalize=False),accuracy_score(L_S[:,i],tl))\n",
    "        LF_acc.append(accuracy_score(L_S[:,i],tl))\n",
    "#         unique, counts = np.unique(L_S[:,i], return_counts=True)\n",
    "#         print(i,dict(zip(unique, counts)))\n",
    "#         print(precision_score(L_S[:,i],tl,labels=[LF_l[i]],average='macro'))\n",
    "#         LF_acc.append(precision_score(L_S[:,i],tl,labels=[LF_l[i]],average='macro'))\n",
    "    return np.array(LF_acc)\n",
    "                      \n",
    "get_LF_acc(dev_L_S,gold_labels_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 512 alpha-init: 0.0\n",
      "precision and recall penalty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 19496.0543522807\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.00190611  0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 19486.788160600034\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041527  0.00064222  0.00083499\n",
      "  0.00211357  0.00073359]\n",
      "[[1.11796616 0.81463598 1.00998106 1.0010458  1.10679934 1.04091686\n",
      "  1.16878442 1.03078627]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 19477.659813126596\n",
      "dev set\n",
      "[ 0.0005471  -0.00248622 -0.00053276 -0.00062211  0.00043527  0.00104159\n",
      "  0.00232039  0.0009404 ]\n",
      "[[1.11817307 0.8148428  1.01018791 1.0012526  1.10700625 1.04071018\n",
      "  1.16857755 1.0305794 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 19468.547479154557\n",
      "dev set\n",
      "[ 0.0003403  -0.00269303 -0.00073956 -0.00082891  0.00022827  0.0012479\n",
      "  0.00252714  0.00114715]\n",
      "[[1.11837995 0.81504959 1.01039475 1.00145936 1.10721319 1.04050375\n",
      "  1.16837075 1.03037259]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 19459.434183482437\n",
      "dev set\n",
      "[ 1.33405029e-04 -2.89994998e-03 -9.46461415e-04 -1.03581636e-03\n",
      "  2.10570910e-05  1.45402737e-03  2.73395593e-03  1.35396020e-03]\n",
      "[[1.11858696 0.81525651 1.01060171 1.00166623 1.10742033 1.04029744\n",
      "  1.16816386 1.03016571]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.1\n",
      "precision and recall penalty\n",
      "0 loss 20070.949977898286\n",
      "dev set\n",
      "[0.10096143 0.09792812 0.09988158 0.09979222 0.10084976 0.10062756\n",
      " 0.10190609 0.10052611]\n",
      "[[1.11775862 0.81442852 1.00977357 1.00083836 1.10659184 1.04112433\n",
      "  1.16899195 1.0309938 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 20062.726066092844\n",
      "dev set\n",
      "[0.10075397 0.09772066 0.09967411 0.09958476 0.10064226 0.100835\n",
      " 0.10211355 0.10073356]\n",
      "[[1.11796613 0.81463594 1.00998101 1.00104577 1.10679929 1.04091685\n",
      "  1.16878444 1.03078629]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 20054.621464328477\n",
      "dev set\n",
      "[0.10054711 0.0975138  0.09946726 0.0993779  0.10043532 0.10104161\n",
      " 0.10232037 0.10094039]\n",
      "[[1.11817306 0.81484277 1.01018787 1.00125257 1.1070062  1.04071017\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 20046.52777510508\n",
      "dev set\n",
      "[0.10034027 0.09730694 0.09926041 0.09917106 0.1002283  0.10124794\n",
      " 0.10252716 0.10114717]\n",
      "[[1.11838    0.8150496  1.01039475 1.00145936 1.10721316 1.04050373\n",
      "  1.16837073 1.03037257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 20038.429754776756\n",
      "dev set\n",
      "[0.1001333  0.09709995 0.09905344 0.09896408 0.10002107 0.1014541\n",
      " 0.10273403 0.10135404]\n",
      "[[1.11858708 0.81525658 1.01060179 1.0016663  1.10742035 1.04029741\n",
      "  1.16816379 1.03016564]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.2\n",
      "precision and recall penalty\n",
      "0 loss 20622.598566333963\n",
      "dev set\n",
      "[0.20096146 0.19792816 0.19988161 0.19979226 0.2008498  0.20062756\n",
      " 0.20190606 0.20052608]\n",
      "[[1.11775858 0.81442848 1.00977351 1.00083834 1.10659179 1.04112433\n",
      "  1.16899198 1.03099383]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "1 loss 20615.616152727398\n",
      "dev set\n",
      "[0.20075402 0.19772071 0.19967417 0.19958481 0.20064233 0.200835\n",
      " 0.20211351 0.20073352]\n",
      "[[1.11796608 0.81463587 1.00998092 1.00104571 1.10679922 1.04091685\n",
      "  1.16878448 1.03078633]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "2 loss 20608.731195176544\n",
      "dev set\n",
      "[0.20054716 0.19751384 0.1994673  0.19937795 0.20043538 0.20104162\n",
      " 0.20232034 0.20094036]\n",
      "[[1.11817304 0.8148427  1.01018779 1.0012525  1.10700612 1.04071017\n",
      "  1.16857759 1.03057944]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "3 loss 20601.851286504763\n",
      "dev set\n",
      "[0.20034026 0.19730693 0.1992604  0.19917105 0.20022834 0.20124797\n",
      " 0.20252716 0.20114718]\n",
      "[[1.11838004 0.81504957 1.01039473 1.00145934 1.10721313 1.04050373\n",
      "  1.16837072 1.03037256]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "4 loss 20594.963251682086\n",
      "dev set\n",
      "[0.20013319 0.19709984 0.19905333 0.19896397 0.20002104 0.20145415\n",
      " 0.20273412 0.20135413]\n",
      "[[1.11858725 0.81525665 1.01060187 1.00166638 1.10742039 1.04029741\n",
      "  1.16816371 1.03016555]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.30000000000000004\n",
      "precision and recall penalty\n",
      "0 loss 21115.81650854269\n",
      "dev set\n",
      "[0.30096153 0.29792822 0.29988168 0.29979232 0.30084987 0.30062755\n",
      " 0.30190601 0.30052603]\n",
      "[[1.11775851 0.81442841 1.0097734  1.0008383  1.10659172 1.04112434\n",
      "  1.16899202 1.03099388]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "1 loss 21110.335715510646\n",
      "dev set\n",
      "[0.30075413 0.29772081 0.29967427 0.29958492 0.30064244 0.30083499\n",
      " 0.30211343 0.30073344]\n",
      "[[1.117966   0.81463575 1.00998076 1.00104558 1.10679909 1.04091687\n",
      "  1.16878456 1.03078641]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "2 loss 21104.926627465396\n",
      "dev set\n",
      "[0.30054725 0.29751393 0.29946739 0.29937804 0.3004355  0.30104161\n",
      " 0.30232027 0.30094028]\n",
      "[[1.11817299 0.81484257 1.01018763 1.00125235 1.107006   1.0407102\n",
      "  1.16857766 1.03057951]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "3 loss 21099.516214908184\n",
      "dev set\n",
      "[0.30034028 0.29730694 0.29926042 0.29917106 0.30022839 0.30124797\n",
      " 0.30252715 0.30114717]\n",
      "[[1.11838009 0.81504951 1.01039464 1.00145924 1.10721307 1.04050375\n",
      "  1.16837073 1.03037258]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "4 loss 21094.09383636579\n",
      "dev set\n",
      "[0.30013306 0.29709971 0.29905319 0.29896384 0.30002097 0.30145418\n",
      " 0.30273422 0.30135423]\n",
      "[[1.11858748 0.81525672 1.01060194 1.00166644 1.10742048 1.04029743\n",
      "  1.16816361 1.03016545]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.4\n",
      "precision and recall penalty\n",
      "0 loss 21500.09208828733\n",
      "dev set\n",
      "[0.40096166 0.39792835 0.39988181 0.39979246 0.40085001 0.40062752\n",
      " 0.40190591 0.40052593]\n",
      "[[1.11775838 0.81442827 1.00977319 1.00083824 1.10659156 1.04112438\n",
      "  1.16899212 1.03099397]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "1 loss 21496.382061639797\n",
      "dev set\n",
      "[0.40075435 0.39772102 0.39967449 0.39958514 0.40064268 0.40083495\n",
      " 0.40211327 0.40073328]\n",
      "[[1.11796582 0.81463549 1.00998041 1.0010452  1.10679883 1.04091693\n",
      "  1.16878472 1.03078658]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "2 loss 21492.714705087055\n",
      "dev set\n",
      "[0.40054747 0.39751413 0.3994676  0.39937825 0.40043573 0.40104157\n",
      " 0.40232012 0.40094013]\n",
      "[[1.11817286 0.81484229 1.01018726 1.00125177 1.10700574 1.04071026\n",
      "  1.16857782 1.03057968]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "3 loss 21489.039952539897\n",
      "dev set\n",
      "[0.40034037 0.39730703 0.3992605  0.39917115 0.40022849 0.40124794\n",
      " 0.4025271  0.40114711]\n",
      "[[1.11838015 0.81504933 1.01039438 1.00145868 1.10721295 1.04050383\n",
      "  1.1683708  1.03037265]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "4 loss 21485.350220253895\n",
      "dev set\n",
      "[0.40013288 0.39709954 0.39905302 0.39896366 0.4000208  0.40145416\n",
      " 0.40273436 0.40135438]\n",
      "[[1.11858786 0.81525679 1.01060194 1.00166617 1.10742064 1.04029752\n",
      "  1.16816349 1.03016533]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.5\n",
      "precision and recall penalty\n",
      "0 loss 21717.094084839624\n",
      "dev set\n",
      "[0.50096214 0.49792877 0.49988216 0.49979281 0.5008505  0.50062746\n",
      " 0.50190565 0.50052565]\n",
      "[[1.11775796 0.81442782 1.00977246 1.00041119 1.10659105 1.04112447\n",
      "  1.1689924  1.03099426]]\n",
      "{0: 130, 1: 1742}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.19123931623931623\n",
      "(0.13432835820895522, 0.975, 0.23612512613521697, None)\n",
      "\n",
      "1 loss 21715.31998849169\n",
      "dev set\n",
      "[0.50075514 0.49772175 0.49967488 0.49958571 0.50064347 0.50083486\n",
      " 0.50211283 0.50073283]\n",
      "[[1.11796521 0.81463464 1.00997912 1.00020333 1.10679794 1.04091706\n",
      "  1.16878523 1.0307871 ]]\n",
      "{0: 122, 1: 1750}\n",
      "acc 0.18696581196581197\n",
      "(0.1337142857142857, 0.975, 0.2351758793969849, None)\n",
      "\n",
      "2 loss 21713.55875179972\n",
      "dev set\n",
      "[0.50054829 0.4975149  0.49946777 0.49937881 0.50043652 0.50104148\n",
      " 0.50231968 0.50093968]\n",
      "[[1.11817235 0.8148413  1.01018573 0.99999604 1.10700478 1.04071042\n",
      "  1.16857838 1.03058025]]\n",
      "{0: 120, 1: 1752}\n",
      "acc 0.1858974358974359\n",
      "(0.13356164383561644, 0.975, 0.23493975903614456, None)\n",
      "\n",
      "3 loss 21711.78605284642\n",
      "dev set\n",
      "[0.50034088 0.49730753 0.49926015 0.4991714  0.5002289  0.50124786\n",
      " 0.50252687 0.50114687]\n",
      "[[1.11838008 0.81504854 1.01039299 0.99978899 1.10721231 1.040504\n",
      "  1.16837117 1.03037303]]\n",
      "{0: 117, 1: 1755}\n",
      "acc 0.1842948717948718\n",
      "(0.13333333333333333, 0.975, 0.23458646616541354, None)\n",
      "\n",
      "4 loss 21709.99780582793\n",
      "dev set\n",
      "[0.50013269 0.4970994  0.49905179 0.49896326 0.50002038 0.50145411\n",
      " 0.50273458 0.50135459]\n",
      "[[1.11858861 0.81525658 1.01060112 0.99958214 1.10742076 1.04029769\n",
      "  1.16816341 1.03016524]]\n",
      "{0: 112, 1: 1760}\n",
      "acc 0.18162393162393162\n",
      "(0.13295454545454546, 0.975, 0.234, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6000000000000001\n",
      "precision and recall penalty\n",
      "0 loss 21714.594095333698\n",
      "dev set\n",
      "[0.60096689 0.59793235 0.59988658 0.60021915 0.6008566  0.60062739\n",
      " 0.60190463 0.60052458]\n",
      "[[1.11775391 0.81442314 1.00975916 1.00041074 1.10658475 1.04112457\n",
      "  1.16899442 1.03099644]]\n",
      "{0: 752, 1: 1120}\n",
      "acc 0.43696581196581197\n",
      "(0.13660714285714284, 0.6375, 0.22499999999999998, None)\n",
      "\n",
      "1 loss 21714.153363270372\n",
      "dev set\n",
      "[0.6007645  0.59772863 0.59968368 0.60042662 0.60065562 0.60083477\n",
      " 0.60211103 0.60073092]\n",
      "[[1.1179581  0.81462498 1.00995007 1.00020326 1.10678524 1.04091721\n",
      "  1.16878929 1.03079148]]\n",
      "{0: 744, 1: 1128}\n",
      "acc 0.4326923076923077\n",
      "(0.1356382978723404, 0.6375, 0.2236842105263158, None)\n",
      "\n",
      "2 loss 21713.709905994885\n",
      "dev set\n",
      "[0.60056062 0.59752376 0.5994794  0.60063367 0.60045268 0.6010414\n",
      " 0.60231758 0.60093744]\n",
      "[[1.1181637  0.81482822 1.01014348 0.99999635 1.10698777 1.04071059\n",
      "  1.16858362 1.03058592]]\n",
      "{0: 741, 1: 1131}\n",
      "acc 0.4310897435897436\n",
      "(0.13527851458885942, 0.6375, 0.22319474835886216, None)\n",
      "\n",
      "3 loss 21713.25660152904\n",
      "dev set\n",
      "[0.60035422 0.59731678 0.59927273 0.60084075 0.60024668 0.60124783\n",
      " 0.60252504 0.60114491]\n",
      "[[1.1183716  0.81503397 1.01034073 0.99978947 1.10719347 1.04050417\n",
      "  1.16837653 1.03037884]]\n",
      "{0: 733, 1: 1139}\n",
      "acc 0.4268162393162393\n",
      "(0.13432835820895522, 0.6375, 0.22189992748368384, None)\n",
      "\n",
      "4 loss 21712.791903037953\n",
      "dev set\n",
      "[0.60014492 0.59710733 0.59906329 0.60104794 0.60003719 0.60145418\n",
      " 0.60273366 0.60135359]\n",
      "[[1.11858217 0.81524264 1.01054229 0.99958252 1.10740278 1.04029784\n",
      "  1.16816768 1.03016992]]\n",
      "{0: 727, 1: 1145}\n",
      "acc 0.42467948717948717\n",
      "(0.13449781659388646, 0.6416666666666667, 0.2223826714801444, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7000000000000001\n",
      "precision and recall penalty\n",
      "0 loss 21629.085188142937\n",
      "dev set\n",
      "[0.70139039 0.69835708 0.70031028 0.70021996 0.70127882 0.70062723\n",
      " 0.70147685 0.70009688]\n",
      "[[1.11733016 0.81399984 1.00934454 1.00041057 1.10616297 1.04112484\n",
      "  1.16942107 1.03142291]]\n",
      "{0: 1312, 1: 560}\n",
      "acc 0.6730769230769231\n",
      "(0.16785714285714284, 0.39166666666666666, 0.235, None)\n",
      "\n",
      "1 loss 21628.495874584336\n",
      "dev set\n",
      "[0.70159849 0.69856566 0.70051864 0.70042735 0.70148736 0.70083457\n",
      " 0.70126827 0.6998883 ]\n",
      "[[1.11712246 0.8137916  1.0091363  1.00020324 1.10595466 1.04091761\n",
      "  1.16963008 1.0316319 ]]\n",
      "{0: 1318, 1: 554}\n",
      "acc 0.6752136752136753\n",
      "(0.16787003610108303, 0.3875, 0.23425692695214104, None)\n",
      "\n",
      "2 loss 21627.90777560766\n",
      "dev set\n",
      "[0.70180635 0.6987741  0.70072685 0.70063403 0.7016957  0.70104128\n",
      " 0.70105963 0.69967966]\n",
      "[[1.11691502 0.81358374 1.00892854 0.99999665 1.1057466  1.04071105\n",
      "  1.16983894 1.03184074]]\n",
      "{0: 1321, 1: 551}\n",
      "acc 0.6757478632478633\n",
      "(0.16696914700544466, 0.38333333333333336, 0.23261694058154234, None)\n",
      "\n",
      "3 loss 21627.312545623743\n",
      "dev set\n",
      "[0.7020148  0.6989832  0.70093571 0.70084049 0.70190464 0.70124791\n",
      " 0.70085    0.69947008]\n",
      "[[1.116707   0.81337555 1.00872053 0.9997903  1.10553802 1.04050461\n",
      "  1.17004841 1.03205017]]\n",
      "{0: 1328, 1: 544}\n",
      "acc 0.6794871794871795\n",
      "(0.16911764705882354, 0.38333333333333336, 0.23469387755102042, None)\n",
      "\n",
      "4 loss 21626.708694551253\n",
      "dev set\n",
      "[0.70222405 0.6991931  0.70114549 0.70104682 0.70211447 0.70145461\n",
      " 0.70063904 0.6992592 ]\n",
      "[[1.11649811 0.81316679 1.00851205 0.99958409 1.10532863 1.04029818\n",
      "  1.17025876 1.03226049]]\n",
      "{0: 1331, 1: 541}\n",
      "acc 0.6800213675213675\n",
      "(0.16820702402957485, 0.37916666666666665, 0.23303457106274003, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "precision and recall penalty\n",
      "0 loss 21554.886866893496\n",
      "dev set\n",
      "[0.80138893 0.79835224 0.80031064 0.80021994 0.80127765 0.80062688\n",
      " 0.80147759 0.80009762]\n",
      "[[1.11733099 0.81400715 1.0093443  1.00041049 1.10616327 1.04112542\n",
      "  1.16942054 1.03142239]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "1 loss 21554.303110506502\n",
      "dev set\n",
      "[0.80159612 0.7985548  0.80051805 0.8004272  0.80148364 0.80083397\n",
      " 0.80126941 0.79988944]\n",
      "[[1.11712437 0.81380742 1.00913505 1.00020323 1.10595576 1.04091866\n",
      "  1.16962898 1.03163082]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "2 loss 21553.730747856047\n",
      "dev set\n",
      "[0.80180293 0.79875673 0.80072464 0.8006337  0.8016877  0.80104042\n",
      " 0.80106169 0.79968171]\n",
      "[[1.11691854 0.81360824 1.00892644 0.99999677 1.10574901 1.04071256\n",
      "  1.16983699 1.03183883]]\n",
      "{0: 1596, 1: 276}\n",
      "acc 0.7767094017094017\n",
      "(0.17753623188405798, 0.20416666666666666, 0.18992248062015504, None)\n",
      "\n",
      "3 loss 21553.15716302768\n",
      "dev set\n",
      "[0.80200999 0.79895871 0.80093075 0.80083995 0.80189198 0.80124677\n",
      " 0.80085378 0.79947377]\n",
      "[[1.11671283 0.81340895 1.00871791 0.99979063 1.10554237 1.04050663\n",
      "  1.17004522 1.03204705]]\n",
      "{0: 1599, 1: 273}\n",
      "acc 0.7783119658119658\n",
      "(0.1794871794871795, 0.20416666666666666, 0.19103313840155947, None)\n",
      "\n",
      "4 loss 21552.581164102747\n",
      "dev set\n",
      "[0.8022175  0.79916063 0.80113627 0.80104603 0.80209629 0.80145313\n",
      " 0.80064548 0.79926544]\n",
      "[[1.11650705 0.81320937 1.00850931 0.9995847  1.1053357  1.04030078\n",
      "  1.17025385 1.03225568]]\n",
      "{0: 1602, 1: 270}\n",
      "acc 0.7799145299145299\n",
      "(0.1814814814814815, 0.20416666666666666, 0.19215686274509802, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "precision and recall penalty\n",
      "0 loss 21618.49616435289\n",
      "dev set\n",
      "[0.90138365 0.89834482 0.90030903 0.90022019 0.90127766 0.90062673\n",
      " 0.9014775  0.90009753]\n",
      "[[1.11736068 0.81401549 1.00934932 1.00041029 1.10616939 1.04112585\n",
      "  1.16942055 1.0314224 ]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "1 loss 21618.30862886359\n",
      "dev set\n",
      "[0.90158607 0.89853833 0.90051563 0.90042747 0.90148376 0.90083369\n",
      " 0.90126899 0.89988902]\n",
      "[[1.11718093 0.81382633 1.00914651 1.00020305 1.10596991 1.04091945\n",
      "  1.16962916 1.03163101]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "2 loss 21618.122923041898\n",
      "dev set\n",
      "[0.90178822 0.89873126 0.90072168 0.90063385 0.90168935 0.90103985\n",
      " 0.90106093 0.89968095]\n",
      "[[1.11700074 0.81363779 1.00894404 0.99999682 1.10577085 1.04071395\n",
      "  1.16983741 1.03183925]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "3 loss 21617.9367802533\n",
      "dev set\n",
      "[0.90199073 0.8989244  0.90092777 0.90083981 0.90189502 0.9012457\n",
      " 0.90085275 0.89947271]\n",
      "[[1.11681965 0.81344903 1.00874136 0.99979114 1.10557169 1.04050894\n",
      "  1.17004594 1.03204778]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "4 loss 21617.749765137865\n",
      "dev set\n",
      "[0.90219384 0.89911795 0.90113406 0.90104542 0.90210101 0.90145129\n",
      " 0.90064425 0.8992641 ]\n",
      "[[1.11663749 0.81325985 1.00853829 0.99958596 1.10537228 1.04030439\n",
      "  1.17025496 1.03225679]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "precision and recall penalty\n",
      "0 loss 21652.065955936778\n",
      "dev set\n",
      "[1.00139093 0.99793481 1.00029013 1.00001764 1.00127934 1.00062862\n",
      " 1.00190725 1.00052624]\n",
      "[[1.11765601 0.81442227 1.00956014 1.00062431 1.10647392 1.0413509\n",
      "  1.1693689  1.0312141 ]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 21652.065804020564\n",
      "dev set\n",
      "[1.00160795 0.99773616 1.00050388 1.00010058 1.00149697 1.00085065\n",
      " 1.00212211 1.00074823]\n",
      "[[1.11781206 0.81462414 1.00956526 1.00062431 1.10661769 1.04138967\n",
      "  1.16955825 1.03123878]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 21652.06565001153\n",
      "dev set\n",
      "[1.00183685 0.99753712 1.00074312 1.00029233 1.00172718 1.00109064\n",
      " 1.00234625 1.00098933]\n",
      "[[1.1180019  0.8148307  1.00958886 1.00062479 1.10679908 1.04147321\n",
      "  1.16976861 1.03130198]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 21652.06549042031\n",
      "dev set\n",
      "[1.00208091 0.99733655 1.00100853 1.00053923 1.00197326 1.00135151\n",
      " 1.00258274 1.00125235]\n",
      "[[1.11822289 0.81504406 1.00965612 1.00063125 1.10701492 1.04161421\n",
      "  1.17000032 1.0314223 ]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 21652.065324032395\n",
      "dev set\n",
      "[1.00234143 0.99713402 1.00129847 1.00082538 1.00223644 1.00163338\n",
      " 1.00283304 1.0015371 ]\n",
      "[[1.118473   0.81526507 1.00979014 1.00066537 1.10726246 1.0418137\n",
      "  1.17025356 1.03160584]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.0\n",
      "precision and recall penalty\n",
      "0 loss 19485.849944060617\n",
      "dev set\n",
      "[ 1.06826158e-03 -1.96503990e-03 -1.15883528e-05 -1.00941842e-04\n",
      "  9.56594008e-04  5.20615795e-04  1.79924685e-03  4.19265229e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 19481.156045218333\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052524]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 19476.490480650114\n",
      "dev set\n",
      "[ 0.00085647 -0.00217684 -0.00022338 -0.00031274  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101942\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 19471.828919472977\n",
      "dev set\n",
      "[ 0.00075067 -0.00228264 -0.00032918 -0.00041853  0.00063895  0.00083823\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.10680261 1.04091362\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 19467.167833047366\n",
      "dev set\n",
      "[ 0.00064486 -0.00238845 -0.00043499 -0.00052434  0.0005331   0.00094396\n",
      "  0.00222263  0.00084265]\n",
      "[[1.11807526 0.81474509 1.01009032 1.00115491 1.10690843 1.04080785\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.1\n",
      "precision and recall penalty\n",
      "0 loss 20060.415138934695\n",
      "dev set\n",
      "[0.10106827 0.09803497 0.09998842 0.09989906 0.1009566  0.10052062\n",
      " 0.10179924 0.10041926]\n",
      "[[1.11765181 0.8143217  1.00966682 1.00073149 1.10648504 1.0412313\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 20056.24994815154\n",
      "dev set\n",
      "[0.1009623  0.097929   0.09988245 0.0997931  0.10085063 0.10062662\n",
      " 0.10190521 0.10052523]\n",
      "[[1.11775778 0.81442765 1.0097728  1.00083746 1.10659098 1.04112528\n",
      "  1.16899282 1.03099467]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 20052.10920252285\n",
      "dev set\n",
      "[0.10085648 0.09782318 0.09977663 0.09968728 0.1007448  0.10073246\n",
      " 0.10201103 0.10063105]\n",
      "[[1.11786361 0.81453346 1.00987865 1.00094329 1.10669678 1.04101942\n",
      "  1.16888698 1.03088883]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 20047.971237963862\n",
      "dev set\n",
      "[0.10075068 0.09771738 0.09967083 0.09958148 0.10063898 0.10083823\n",
      " 0.10211682 0.10073684]\n",
      "[[1.11796942 0.81463926 1.00998448 1.0010491  1.10680258 1.04091362\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 20043.83288437308\n",
      "dev set\n",
      "[0.10064487 0.09761156 0.09956502 0.09947566 0.10053312 0.10094397\n",
      " 0.10222262 0.10084264]\n",
      "[[1.11807525 0.81474507 1.01009033 1.00115492 1.1069084  1.04080785\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.2\n",
      "precision and recall penalty\n",
      "0 loss 20611.63707397606\n",
      "dev set\n",
      "[0.20106828 0.19803498 0.19998843 0.19989907 0.20095661 0.20052061\n",
      " 0.20179923 0.20041925]\n",
      "[[1.11765179 0.81432169 1.00966681 1.00073149 1.10648502 1.04123131\n",
      "  1.16909881 1.03110066]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "1 loss 20608.10156412878\n",
      "dev set\n",
      "[0.20096233 0.19792902 0.19988247 0.19979312 0.20085066 0.20062662\n",
      " 0.20190519 0.20052521]\n",
      "[[1.11775775 0.81442762 1.00977278 1.00083745 1.10659095 1.04112528\n",
      "  1.16899283 1.03099468]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "2 loss 20604.585909922323\n",
      "dev set\n",
      "[0.20085651 0.1978232  0.19977666 0.1996873  0.20074483 0.20073245\n",
      " 0.20201101 0.20063103]\n",
      "[[1.11786358 0.81453343 1.00987863 1.00094327 1.10669674 1.04101943\n",
      "  1.16888699 1.03088884]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "3 loss 20601.071628653077\n",
      "dev set\n",
      "[0.20075071 0.1977174  0.19967086 0.1995815  0.20063901 0.20083822\n",
      " 0.2021168  0.20073682]\n",
      "[[1.1179694  0.81463922 1.00998447 1.00104908 1.10680253 1.04091363\n",
      "  1.16878117 1.03078303]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "4 loss 20597.555980723926\n",
      "dev set\n",
      "[0.20064489 0.19761157 0.19956503 0.19947568 0.20053315 0.20094396\n",
      " 0.20222261 0.20084263]\n",
      "[[1.11807524 0.81474504 1.01009033 1.00115492 1.10690835 1.04080786\n",
      "  1.16867534 1.0306772 ]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.30000000000000004\n",
      "precision and recall penalty\n",
      "0 loss 21104.31150084679\n",
      "dev set\n",
      "[0.3010683  0.298035   0.29998845 0.29989909 0.30095663 0.30052061\n",
      " 0.30179922 0.30041924]\n",
      "[[1.11765177 0.81432166 1.00966678 1.00073148 1.106485   1.04123131\n",
      "  1.16909882 1.03110067]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "1 loss 21101.53742450736\n",
      "dev set\n",
      "[0.30096236 0.29792906 0.29988251 0.29979316 0.3008507  0.30062661\n",
      " 0.30190516 0.30052518]\n",
      "[[1.11775772 0.81442758 1.00977274 1.00083742 1.1065909  1.0411253\n",
      "  1.16899285 1.03099471]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "2 loss 21098.77780292455\n",
      "dev set\n",
      "[0.30085656 0.29782325 0.29977671 0.29968735 0.30074488 0.30073244\n",
      " 0.30201097 0.30063099]\n",
      "[[1.11786353 0.81453336 1.00987859 1.00094324 1.10669667 1.04101945\n",
      "  1.16888702 1.03088888]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "3 loss 21096.018017883333\n",
      "dev set\n",
      "[0.30075076 0.29771745 0.29967091 0.29958155 0.30063907 0.3008382\n",
      " 0.30211677 0.30073678]\n",
      "[[1.11796935 0.81463915 1.00998443 1.00104907 1.10680245 1.04091367\n",
      "  1.16878121 1.03078306]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "4 loss 21093.255859936635\n",
      "dev set\n",
      "[0.30064492 0.29761161 0.29956507 0.29947572 0.3005332  0.30094394\n",
      " 0.30222259 0.3008426 ]\n",
      "[[1.1180752  0.81474498 1.01009033 1.00115493 1.10690828 1.04080791\n",
      "  1.16867537 1.03067722]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.4\n",
      "precision and recall penalty\n",
      "0 loss 21487.924576468497\n",
      "dev set\n",
      "[0.40106834 0.39803503 0.39998849 0.39989914 0.40095668 0.4005206\n",
      " 0.40179919 0.40041921]\n",
      "[[1.11765173 0.81432161 1.00966673 1.00073146 1.10648495 1.04123133\n",
      "  1.16909885 1.0311007 ]]\n",
      "{0: 9, 1: 1863}\n",
      "acc 0.1330128205128205\n",
      "(0.1288244766505636, 1.0, 0.2282453637660485, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 21486.048109984997\n",
      "dev set\n",
      "[0.40096245 0.39792914 0.39988259 0.39979324 0.40085078 0.40062658\n",
      " 0.40190511 0.40052512]\n",
      "[[1.11775763 0.81442747 1.00977265 1.00083739 1.10659079 1.04112533\n",
      "  1.16899291 1.03099476]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "2 loss 21484.18004111199\n",
      "dev set\n",
      "[0.40085667 0.39782335 0.39977681 0.39968746 0.400745   0.4007324\n",
      " 0.4020109  0.40063091]\n",
      "[[1.11786342 0.81453322 1.00987849 1.00094321 1.10669652 1.04101951\n",
      "  1.1688871  1.03088895]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "3 loss 21482.310336153525\n",
      "dev set\n",
      "[0.40075087 0.39771755 0.39967102 0.39958166 0.40063919 0.40083815\n",
      " 0.40211669 0.4007367 ]\n",
      "[[1.11796923 0.81463899 1.00998435 1.00104907 1.10680228 1.04091374\n",
      "  1.16878128 1.03078314]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "4 loss 21480.437427829\n",
      "dev set\n",
      "[0.40064502 0.3976117  0.39956516 0.39947581 0.4005333  0.40094387\n",
      " 0.40222252 0.40084254]\n",
      "[[1.11807511 0.81474482 1.01009027 1.00115503 1.10690811 1.040808\n",
      "  1.16867543 1.03067728]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.5\n",
      "precision and recall penalty\n",
      "0 loss 21704.182267643766\n",
      "dev set\n",
      "[0.5010685  0.49803517 0.49998864 0.49989923 0.50095684 0.50052058\n",
      " 0.5017991  0.50041912]\n",
      "[[1.11765158 0.81432144 1.00966652 1.00051732 1.10648476 1.04123136\n",
      "  1.16909894 1.0311008 ]]\n",
      "{0: 131, 1: 1741}\n",
      "acc 0.19177350427350429\n",
      "(0.1344055140723722, 0.975, 0.23624432104997475, None)\n",
      "\n",
      "1 loss 21703.287060650866\n",
      "dev set\n",
      "[0.50096275 0.49792941 0.49988281 0.4997934  0.5008511  0.50062653\n",
      " 0.50190494 0.50052496]\n",
      "[[1.11775732 0.8144271  1.00977228 1.00041154 1.10659039 1.04112541\n",
      "  1.1689931  1.03099496]]\n",
      "{0: 130, 1: 1742}\n",
      "acc 0.19123931623931623\n",
      "(0.13432835820895522, 0.975, 0.23612512613521697, None)\n",
      "\n",
      "2 loss 21702.393596114453\n",
      "dev set\n",
      "[0.50085707 0.49782373 0.499777   0.49968766 0.50074541 0.50073232\n",
      " 0.50201069 0.5006307 ]\n",
      "[[1.117863   0.8145327  1.00987801 1.00030592 1.10669596 1.04101962\n",
      "  1.16888735 1.03088921]]\n",
      "{0: 128, 1: 1744}\n",
      "acc 0.19017094017094016\n",
      "(0.1341743119266055, 0.975, 0.23588709677419353, None)\n",
      "\n",
      "3 loss 21701.497462485266\n",
      "dev set\n",
      "[0.50075131 0.49771798 0.49967111 0.49958185 0.50063963 0.50083805\n",
      " 0.50211647 0.50073648]\n",
      "[[1.11796875 0.81463837 1.00998384 1.00020037 1.10680161 1.04091389\n",
      "  1.16878157 1.03078343]]\n",
      "{0: 122, 1: 1750}\n",
      "acc 0.18696581196581197\n",
      "(0.1337142857142857, 0.975, 0.2351758793969849, None)\n",
      "\n",
      "4 loss 21700.597848463505\n",
      "dev set\n",
      "[0.50064543 0.4976121  0.4995651  0.49947594 0.5005337  0.50094375\n",
      " 0.50222233 0.50084234]\n",
      "[[1.11807462 0.81474418 1.01008982 1.00009486 1.10690742 1.04080819\n",
      "  1.1686757  1.03067756]]\n",
      "{0: 121, 1: 1751}\n",
      "acc 0.18643162393162394\n",
      "(0.13363792118789264, 0.975, 0.23505775991963843, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6000000000000001\n",
      "precision and recall penalty\n",
      "0 loss 21701.16680157572\n",
      "dev set\n",
      "[0.60107044 0.59803658 0.59999035 0.60011317 0.60095936 0.60052055\n",
      " 0.60179873 0.60041872]\n",
      "[[1.11765003 0.81431946 1.009661   1.00051723 1.10648208 1.0412314\n",
      "  1.16909969 1.03110161]]\n",
      "{0: 756, 1: 1116}\n",
      "acc 0.4391025641025641\n",
      "(0.13709677419354838, 0.6375, 0.22566371681415928, None)\n",
      "\n",
      "1 loss 21700.94578361712\n",
      "dev set\n",
      "[0.60096704 0.5979325  0.59988666 0.60021918 0.60085667 0.60062648\n",
      " 0.60190414 0.60052411]\n",
      "[[1.11775388 0.81442256 1.00975994 1.00041133 1.10658424 1.04112549\n",
      "  1.16899477 1.03099677]]\n",
      "{0: 752, 1: 1120}\n",
      "acc 0.43696581196581197\n",
      "(0.13660714285714284, 0.6375, 0.22499999999999998, None)\n",
      "\n",
      "2 loss 21700.724092938064\n",
      "dev set\n",
      "[0.60086343 0.59782829 0.59978278 0.60032512 0.60075371 0.60073224\n",
      " 0.60200954 0.60062947]\n",
      "[[1.11785786 0.81452583 1.0098593  1.00030556 1.10668665 1.04101975\n",
      "  1.16888982 1.03089189]]\n",
      "{0: 751, 1: 1121}\n",
      "acc 0.43643162393162394\n",
      "(0.13648528099910795, 0.6375, 0.22483468038207202, None)\n",
      "\n",
      "3 loss 21700.50013752827\n",
      "dev set\n",
      "[0.60075941 0.59772373 0.59967852 0.60043107 0.60065022 0.60083795\n",
      " 0.60211506 0.60073497]\n",
      "[[1.1179622  0.8146295  1.00995935 1.00019982 1.10678957 1.04091406\n",
      "  1.16878466 1.03078679]]\n",
      "{0: 744, 1: 1128}\n",
      "acc 0.4326923076923077\n",
      "(0.1356382978723404, 0.6375, 0.2236842105263158, None)\n",
      "\n",
      "4 loss 21700.27361977206\n",
      "dev set\n",
      "[0.60065486 0.59761874 0.59957376 0.60053704 0.60054609 0.60094363\n",
      " 0.60222077 0.60084068]\n",
      "[[1.11806701 0.81473369 1.01006023 1.00009408 1.10689315 1.04080839\n",
      "  1.16867919 1.03068136]]\n",
      "{0: 743, 1: 1129}\n",
      "acc 0.4321581196581197\n",
      "(0.1355181576616475, 0.6375, 0.2235208181154127, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7000000000000001\n",
      "precision and recall penalty\n",
      "0 loss 21615.513565079862\n",
      "dev set\n",
      "[0.70128284 0.69824961 0.70020296 0.70011336 0.70117125 0.70052049\n",
      " 0.70158458 0.70020459]\n",
      "[[1.11743711 0.81410704 1.00945239 1.00051718 1.10627043 1.04123149\n",
      "  1.16931348 1.03131533]]\n",
      "{0: 1309, 1: 563}\n",
      "acc 0.6714743589743589\n",
      "(0.1669626998223801, 0.39166666666666666, 0.23412204234122044, None)\n",
      "\n",
      "1 loss 21615.21638745114\n",
      "dev set\n",
      "[0.70138892 0.69835591 0.70030907 0.70021933 0.70127754 0.70062634\n",
      " 0.70147827 0.70009828]\n",
      "[[1.11733062 0.81400059 1.00934666 1.00041125 1.10616418 1.04112571\n",
      "  1.16941982 1.03142167]]\n",
      "{0: 1312, 1: 560}\n",
      "acc 0.6730769230769231\n",
      "(0.16785714285714284, 0.39166666666666666, 0.235, None)\n",
      "\n",
      "2 loss 21614.91913245736\n",
      "dev set\n",
      "[0.7014949  0.69846213 0.70041508 0.70032515 0.70138374 0.70073204\n",
      " 0.701372   0.69999201]\n",
      "[[1.1172242  0.81389424 1.0092411  1.00030547 1.10605801 1.04102008\n",
      "  1.16952608 1.03152792]]\n",
      "{0: 1314, 1: 558}\n",
      "acc 0.6730769230769231\n",
      "(0.16666666666666666, 0.3875, 0.23308270676691725, None)\n",
      "\n",
      "3 loss 21614.620208670887\n",
      "dev set\n",
      "[0.70160094 0.69856843 0.70052115 0.70043092 0.70149001 0.70083771\n",
      " 0.7012656  0.69988561]\n",
      "[[1.1171177  0.81378785 1.00913555 1.00019975 1.10595178 1.0409145\n",
      "  1.16963241 1.03163425]]\n",
      "{0: 1319, 1: 553}\n",
      "acc 0.6746794871794872\n",
      "(0.16636528028933092, 0.38333333333333336, 0.23203026481715006, None)\n",
      "\n",
      "4 loss 21614.319284467187\n",
      "dev set\n",
      "[0.70170712 0.69867487 0.70062737 0.70053667 0.70159643 0.70094339\n",
      " 0.70115897 0.69977899]\n",
      "[[1.11701105 0.81368136 1.00902994 1.00009405 1.10584543 1.04080892\n",
      "  1.16973888 1.03174072]]\n",
      "{0: 1319, 1: 553}\n",
      "acc 0.6746794871794872\n",
      "(0.16636528028933092, 0.38333333333333336, 0.23203026481715006, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "precision and recall penalty\n",
      "0 loss 21541.23352515222\n",
      "dev set\n",
      "[0.80128266 0.79824802 0.80020282 0.80011335 0.80117097 0.80052037\n",
      " 0.80158471 0.80020473]\n",
      "[[1.11743711 0.81410962 1.00945223 1.00051717 1.10627044 1.04123169\n",
      "  1.16931335 1.03131521]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "1 loss 21540.93668303937\n",
      "dev set\n",
      "[0.8013888  0.79835213 0.80030836 0.80021926 0.80127687 0.80062606\n",
      " 0.80147853 0.80009855]\n",
      "[[1.11733039 0.81400664 1.00934611 1.00041128 1.10616411 1.04112617\n",
      "  1.16941952 1.03142137]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "2 loss 21540.641917755114\n",
      "dev set\n",
      "[0.80149484 0.79845604 0.80041367 0.80032501 0.80138207 0.8007316\n",
      " 0.80137249 0.7999925 ]\n",
      "[[1.11722375 0.81390387 1.00924018 1.00030555 1.10605793 1.04102082\n",
      "  1.16952556 1.03152741]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "3 loss 21540.349618320324\n",
      "dev set\n",
      "[0.80160092 0.79855992 0.80051891 0.8004307  0.80148653 0.80083709\n",
      " 0.80126644 0.79988645]\n",
      "[[1.11711712 0.81380112 1.00913429 1.0001999  1.10595178 1.04091551\n",
      "  1.1696316  1.03163345]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "4 loss 21540.05709012053\n",
      "dev set\n",
      "[0.80170706 0.79866383 0.80062415 0.80053635 0.80159077 0.80094258\n",
      " 0.80116034 0.79978034]\n",
      "[[1.11701047 0.81369833 1.0090284  1.00009429 1.10584563 1.04081023\n",
      "  1.1697377  1.03173955]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "precision and recall penalty\n",
      "0 loss 21604.83838498378\n",
      "dev set\n",
      "[0.90128292 0.89824457 0.90020277 0.90011341 0.9011703  0.90052036\n",
      " 0.90158468 0.9002047 ]\n",
      "[[1.11743784 0.81411357 1.0094527  1.00051712 1.10627362 1.04123172\n",
      "  1.16931337 1.03131522]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 21604.743389136256\n",
      "dev set\n",
      "[0.9013904  0.89834368 0.90030821 0.90021933 0.90127562 0.90062609\n",
      " 0.90147848 0.90009849]\n",
      "[[1.11733078 0.81401641 1.00934787 1.00041119 1.10617134 1.04112618\n",
      "  1.16941958 1.03142143]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "2 loss 21604.648755641618\n",
      "dev set\n",
      "[0.90149799 0.89844237 0.90041341 0.90032506 0.90138093 0.90073164\n",
      " 0.9013724  0.8999924 ]\n",
      "[[1.11722357 0.81391973 1.00924331 1.00030546 1.10606897 1.04102082\n",
      "  1.16952568 1.03152753]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "3 loss 21604.554007786875\n",
      "dev set\n",
      "[0.90160568 0.89854096 0.90051856 0.9004307  0.90148629 0.90083713\n",
      " 0.90126633 0.89988632]\n",
      "[[1.11711621 0.81382318 1.00913878 1.00019983 1.10596653 1.04091555\n",
      "  1.16963179 1.03163364]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "4 loss 21604.459065203948\n",
      "dev set\n",
      "[0.9017135  0.89863956 0.90062372 0.90053628 0.90159172 0.90094257\n",
      " 0.90116021 0.89978019]\n",
      "[[1.11700867 0.81372663 1.00903423 1.00009429 1.10586402 1.04081036\n",
      "  1.16973798 1.03173983]]\n",
      "{0: 1745, 1: 127}\n",
      "acc 0.8327991452991453\n",
      "(0.2125984251968504, 0.1125, 0.14713896457765668, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "precision and recall penalty\n",
      "0 loss 21638.46437600807\n",
      "dev set\n",
      "[1.00128293 0.99803701 1.00019541 1.0000129  1.00117128 1.0005208\n",
      " 1.00179948 1.00041921]\n",
      "[[1.117609   0.81431977 1.00955981 1.00062431 1.10643434 1.04134558\n",
      "  1.16929399 1.03121115]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "1 loss 21638.46430239893\n",
      "dev set\n",
      "[1.00139046 0.99793395 1.00029774 1.00003935 1.00127892 1.00062914\n",
      " 1.00190664 1.00052734]\n",
      "[[1.11768861 0.81442337 1.0095607  1.00062431 1.10650758 1.04136097\n",
      "  1.16938994 1.03121957]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 21638.464228354173\n",
      "dev set\n",
      "[1.00149984 0.99783097 1.0004045  1.00010556 1.00138853 1.00074043\n",
      " 1.00201519 1.00063853]\n",
      "[[1.11777741 0.81452759 1.00956371 1.00062432 1.10659138 1.04138723\n",
      "  1.16949076 1.03123604]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 21638.464153085424\n",
      "dev set\n",
      "[1.00161186 0.99772778 1.00051711 1.00019515 1.00150095 1.00085577\n",
      " 1.00212582 1.00075401]\n",
      "[[1.11787395 0.81463296 1.0095714  1.00062447 1.10668406 1.04142694\n",
      "  1.16959611 1.03126399]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 21638.46407638929\n",
      "dev set\n",
      "[1.00172712 0.99762425 1.0006362  1.00029947 1.00161679 1.00097588\n",
      " 1.00223901 1.00087453]\n",
      "[[1.11797773 0.81473983 1.00958758 1.00062536 1.10678494 1.04148193\n",
      "  1.1697061  1.03130653]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.0\n",
      "precision and recall penalty\n",
      "0 loss 19481.673063265764\n",
      "dev set\n",
      "[ 1.12169995e-03 -1.91160121e-03  4.18501315e-05 -4.75033480e-05\n",
      "  1.01003261e-03  4.67151740e-04  1.74580725e-03  3.65825712e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 19479.307722737423\n",
      "dev set\n",
      "[ 1.06807653e-03 -1.96522496e-03 -1.17734035e-05 -1.01126893e-04\n",
      "  9.56408958e-04  5.20803978e-04  1.79943194e-03  4.19450313e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 19476.945500835558\n",
      "dev set\n",
      "[ 1.01446159e-03 -2.01884033e-03 -6.53884877e-05 -1.54741989e-04\n",
      "  9.02792435e-04  5.74445405e-04  1.85304784e-03  4.73066097e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 19474.5834649681\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 19472.221346371036\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.1\n",
      "precision and recall penalty\n",
      "0 loss 20056.085502357044\n",
      "dev set\n",
      "[0.1011217  0.0980884  0.10004185 0.0999525  0.10101004 0.10046715\n",
      " 0.10174581 0.10036582]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 20053.986787725386\n",
      "dev set\n",
      "[0.10106808 0.09803478 0.09998823 0.09989888 0.10095642 0.1005208\n",
      " 0.10179943 0.10041945]\n",
      "[[1.11765202 0.81432191 1.009667   1.00073168 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 20051.89069353975\n",
      "dev set\n",
      "[0.10101447 0.09798117 0.09993462 0.09984527 0.1009028  0.10057445\n",
      " 0.10185304 0.10047306]\n",
      "[[1.11770564 0.81437552 1.0097206  1.0007853  1.10653884 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 20049.794585122814\n",
      "dev set\n",
      "[0.10096086 0.09792756 0.09988101 0.09979165 0.10084919 0.10062808\n",
      " 0.10190665 0.10052667]\n",
      "[[1.11775927 0.81442914 1.00977421 1.00083893 1.10659245 1.04112381\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 20047.698215691616\n",
      "dev set\n",
      "[0.10090724 0.09787394 0.09982739 0.09973804 0.10079557 0.10068172\n",
      " 0.10196027 0.10058029]\n",
      "[[1.1178129  0.81448277 1.00982782 1.00089255 1.10664607 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.2\n",
      "precision and recall penalty\n",
      "0 loss 20607.10782840745\n",
      "dev set\n",
      "[0.20112171 0.19808841 0.20004186 0.1999525  0.20101004 0.20046715\n",
      " 0.2017458  0.20036582]\n",
      "[[1.11759838 0.81426828 1.00961338 1.00067805 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "1 loss 20605.32666351649\n",
      "dev set\n",
      "[0.20106809 0.19803479 0.19998824 0.19989889 0.20095643 0.2005208\n",
      " 0.20179942 0.20041944]\n",
      "[[1.11765201 0.8143219  1.00966699 1.00073168 1.10648521 1.04123112\n",
      "  1.1690986  1.03110046]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "2 loss 20603.54754243471\n",
      "dev set\n",
      "[0.20101449 0.19798119 0.19993464 0.19984528 0.20090282 0.20057444\n",
      " 0.20185303 0.20047304]\n",
      "[[1.11770563 0.81437551 1.00972058 1.00078529 1.10653882 1.04117747\n",
      "  1.16904497 1.03104683]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "3 loss 20601.768181550717\n",
      "dev set\n",
      "[0.20096088 0.19792758 0.19988103 0.19979168 0.20084921 0.20062808\n",
      " 0.20190664 0.20052665]\n",
      "[[1.11775926 0.81442913 1.00977417 1.00083891 1.10659242 1.04112382\n",
      "  1.16899134 1.03099319]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "4 loss 20599.988360171825\n",
      "dev set\n",
      "[0.20090727 0.19787396 0.19982742 0.19973807 0.2007956  0.20068171\n",
      " 0.20196025 0.20058027]\n",
      "[[1.11781289 0.81448275 1.00982778 1.00089254 1.10664603 1.04107017\n",
      "  1.16893771 1.03093956]]\n",
      "{0: 2, 1: 1870}\n",
      "acc 0.12927350427350429\n",
      "(0.12834224598930483, 1.0, 0.2274881516587678, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.30000000000000004\n",
      "precision and recall penalty\n",
      "0 loss 21099.516732889908\n",
      "dev set\n",
      "[0.30112172 0.29808841 0.30004187 0.29995251 0.30101005 0.30046715\n",
      " 0.3017458  0.30036581]\n",
      "[[1.11759837 0.81426827 1.00961337 1.00067805 1.1064316  1.04128478\n",
      "  1.16915225 1.0311541 ]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 21098.119539319276\n",
      "dev set\n",
      "[0.30106811 0.29803481 0.29998826 0.29989891 0.30095645 0.3005208\n",
      " 0.3017994  0.30041942]\n",
      "[[1.117652   0.81432188 1.00966696 1.00073166 1.10648519 1.04123113\n",
      "  1.16909861 1.03110047]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "2 loss 21096.723732367725\n",
      "dev set\n",
      "[0.30101452 0.29798122 0.29993467 0.29984532 0.30090286 0.30057443\n",
      " 0.301853   0.30047302]\n",
      "[[1.11770561 0.81437548 1.00972053 1.00078527 1.10653878 1.04117748\n",
      "  1.16904499 1.03104684]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "3 loss 21095.327453786653\n",
      "dev set\n",
      "[0.30096092 0.29792762 0.29988107 0.29979172 0.30084926 0.30062806\n",
      " 0.3019066  0.30052662]\n",
      "[[1.11775923 0.81442909 1.00977411 1.00083889 1.10659237 1.04112384\n",
      "  1.16899136 1.03099321]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "4 loss 21093.93051554237\n",
      "dev set\n",
      "[0.30090732 0.29787401 0.29982747 0.29973812 0.30079565 0.3006817\n",
      " 0.30196021 0.30058023]\n",
      "[[1.11781286 0.8144827  1.0098277  1.00089251 1.10664597 1.0410702\n",
      "  1.16893773 1.03093958]]\n",
      "{0: 4, 1: 1868}\n",
      "acc 0.13034188034188035\n",
      "(0.1284796573875803, 1.0, 0.22770398481973433, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.4\n",
      "precision and recall penalty\n",
      "0 loss 21482.78050373768\n",
      "dev set\n",
      "[0.40112173 0.39808843 0.40004188 0.39995253 0.40101007 0.40046714\n",
      " 0.40174578 0.4003658 ]\n",
      "[[1.11759836 0.81426825 1.00961335 1.00067804 1.10643158 1.04128479\n",
      "  1.16915226 1.03115411]]\n",
      "{0: 9, 1: 1863}\n",
      "acc 0.1330128205128205\n",
      "(0.1288244766505636, 1.0, 0.2282453637660485, None)\n",
      "\n",
      "1 loss 21481.835883280633\n",
      "dev set\n",
      "[0.40106816 0.39803485 0.39998831 0.39989895 0.40095649 0.40052078\n",
      " 0.40179937 0.40041939]\n",
      "[[1.11765196 0.81432184 1.0096669  1.00073164 1.10648514 1.04123114\n",
      "  1.16909864 1.03110049]]\n",
      "{0: 9, 1: 1863}\n",
      "acc 0.1330128205128205\n",
      "(0.1288244766505636, 1.0, 0.2282453637660485, None)\n",
      "\n",
      "2 loss 21480.891946605254\n",
      "dev set\n",
      "[0.40101459 0.39798128 0.39993474 0.39984538 0.40090293 0.40057441\n",
      " 0.40185295 0.40047297]\n",
      "[[1.11770556 0.81437542 1.00972044 1.00078523 1.1065387  1.04117751\n",
      "  1.16904503 1.03104688]]\n",
      "{0: 9, 1: 1863}\n",
      "acc 0.1330128205128205\n",
      "(0.1288244766505636, 1.0, 0.2282453637660485, None)\n",
      "\n",
      "3 loss 21479.947345681045\n",
      "dev set\n",
      "[0.40096101 0.3979277  0.39988116 0.39979181 0.40084935 0.40062803\n",
      " 0.40190654 0.40052656]\n",
      "[[1.11775917 0.814429   1.00977398 1.00083884 1.10659227 1.04112388\n",
      "  1.16899141 1.03099327]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "4 loss 21479.001933950247\n",
      "dev set\n",
      "[0.40090743 0.39787412 0.39982758 0.39973822 0.40079577 0.40068166\n",
      " 0.40196013 0.40058015]\n",
      "[[1.11781278 0.8144826  1.00982754 1.00089246 1.10664584 1.04107025\n",
      "  1.16893779 1.03093964]]\n",
      "{0: 8, 1: 1864}\n",
      "acc 0.13247863247863248\n",
      "(0.12875536480686695, 1.0, 0.22813688212927757, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.5\n",
      "precision and recall penalty\n",
      "0 loss 21698.600158797963\n",
      "dev set\n",
      "[0.5011218  0.49808848 0.50004194 0.49995255 0.50101013 0.50046713\n",
      " 0.50174575 0.50036576]\n",
      "[[1.11759832 0.8142682  1.00961326 1.00057058 1.10643151 1.0412848\n",
      "  1.16915229 1.03115414]]\n",
      "{0: 131, 1: 1741}\n",
      "acc 0.19177350427350429\n",
      "(0.1344055140723722, 0.975, 0.23624432104997475, None)\n",
      "\n",
      "1 loss 21698.150366353613\n",
      "dev set\n",
      "[0.50106832 0.49803498 0.49998846 0.49989901 0.50095666 0.50052075\n",
      " 0.50179928 0.50041929]\n",
      "[[1.11765186 0.8143217  1.00966668 1.000517   1.10648498 1.04123118\n",
      "  1.16909872 1.03110058]]\n",
      "{0: 131, 1: 1741}\n",
      "acc 0.19177350427350429\n",
      "(0.1344055140723722, 0.975, 0.23624432104997475, None)\n",
      "\n",
      "2 loss 21697.70037386214\n",
      "dev set\n",
      "[0.50101485 0.49798149 0.49993496 0.49984548 0.5009032  0.50057437\n",
      " 0.5018528  0.50047282]\n",
      "[[1.11770539 0.81437519 1.00972009 1.00046343 1.10653844 1.04117757\n",
      "  1.16904516 1.03104702]]\n",
      "{0: 131, 1: 1741}\n",
      "acc 0.19177350427350429\n",
      "(0.1344055140723722, 0.975, 0.23624432104997475, None)\n",
      "\n",
      "3 loss 21697.249389839388\n",
      "dev set\n",
      "[0.50096136 0.49792798 0.49988141 0.49979194 0.50084972 0.50062797\n",
      " 0.50190634 0.50052635]\n",
      "[[1.11775894 0.8144287  1.00977351 1.00040986 1.10659191 1.04112397\n",
      "  1.1689916  1.03099345]]\n",
      "{0: 130, 1: 1742}\n",
      "acc 0.19123931623931623\n",
      "(0.13432835820895522, 0.975, 0.23612512613521697, None)\n",
      "\n",
      "4 loss 21696.797562827393\n",
      "dev set\n",
      "[0.50090786 0.49787446 0.49982784 0.49973838 0.50079622 0.50068158\n",
      " 0.50195988 0.50057989]\n",
      "[[1.1178125  0.81448223 1.00982695 1.00035631 1.10664541 1.04107036\n",
      "  1.16893801 1.03093987]]\n",
      "{0: 130, 1: 1742}\n",
      "acc 0.19123931623931623\n",
      "(0.13432835820895522, 0.975, 0.23612512613521697, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6000000000000001\n",
      "precision and recall penalty\n",
      "0 loss 21695.24763297715\n",
      "dev set\n",
      "[0.60112236 0.59808893 0.60004246 0.60005996 0.60101082 0.60046712\n",
      " 0.60174562 0.60036563]\n",
      "[[1.11759799 0.81426766 1.00961177 1.00057062 1.10643081 1.04128482\n",
      "  1.16915254 1.03115441]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.4407051282051282\n",
      "(0.13746630727762804, 0.6375, 0.2261640798226164, None)\n",
      "\n",
      "1 loss 21695.13674672315\n",
      "dev set\n",
      "[0.60106977 0.59803611 0.59998978 0.60011354 0.60095842 0.60052073\n",
      " 0.60179896 0.60041895]\n",
      "[[1.11765102 0.81432034 1.00966286 1.00051708 1.10648319 1.04123122\n",
      "  1.16909935 1.03110125]]\n",
      "{0: 756, 1: 1116}\n",
      "acc 0.4391025641025641\n",
      "(0.13709677419354838, 0.6375, 0.22566371681415928, None)\n",
      "\n",
      "2 loss 21695.02573226914\n",
      "dev set\n",
      "[0.60101719 0.59798332 0.59993711 0.60016712 0.60090604 0.60057432\n",
      " 0.60185229 0.60047227]\n",
      "[[1.11770405 0.81437301 1.00971386 1.00046356 1.10653554 1.04117764\n",
      "  1.16904617 1.0310481 ]]\n",
      "{0: 755, 1: 1117}\n",
      "acc 0.43856837606837606\n",
      "(0.1369740376007162, 0.6375, 0.22549742078113483, None)\n",
      "\n",
      "3 loss 21694.914198457016\n",
      "dev set\n",
      "[0.60096457 0.59793049 0.59988441 0.60022069 0.60085361 0.60062791\n",
      " 0.60190563 0.60052561]\n",
      "[[1.11775712 0.81442571 1.0097649  1.00041005 1.10658795 1.04112406\n",
      "  1.16899296 1.03099492]]\n",
      "{0: 752, 1: 1120}\n",
      "acc 0.43696581196581197\n",
      "(0.13660714285714284, 0.6375, 0.22499999999999998, None)\n",
      "\n",
      "4 loss 21694.80208592779\n",
      "dev set\n",
      "[0.60091189 0.59787761 0.59983164 0.60027426 0.6008011  0.6006815\n",
      " 0.60195901 0.60057897]\n",
      "[[1.11781025 0.81447848 1.00981604 1.00035652 1.10664044 1.04107048\n",
      "  1.16893971 1.03094169]]\n",
      "{0: 751, 1: 1121}\n",
      "acc 0.43643162393162394\n",
      "(0.13648528099910795, 0.6375, 0.22483468038207202, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7000000000000001\n",
      "precision and recall penalty\n",
      "0 loss 21609.4334803187\n",
      "dev set\n",
      "[0.70122936 0.69819607 0.70014946 0.70005994 0.70111771 0.70046709\n",
      " 0.70163809 0.70025811]\n",
      "[[1.11749072 0.81416059 1.0095057  1.00057061 1.10632398 1.04128486\n",
      "  1.16925992 1.03126177]]\n",
      "{0: 1307, 1: 565}\n",
      "acc 0.6725427350427351\n",
      "(0.16991150442477876, 0.4, 0.23850931677018633, None)\n",
      "\n",
      "1 loss 21609.283478955746\n",
      "dev set\n",
      "[0.70128324 0.69824997 0.70020326 0.70011348 0.70117161 0.70052066\n",
      " 0.70158412 0.70020415]\n",
      "[[1.11743685 0.81410667 1.00945178 1.00051706 1.10627014 1.04123133\n",
      "  1.16931381 1.03131565]]\n",
      "{0: 1309, 1: 563}\n",
      "acc 0.6714743589743589\n",
      "(0.1669626998223801, 0.39166666666666666, 0.23412204234122044, None)\n",
      "\n",
      "2 loss 21609.133091934767\n",
      "dev set\n",
      "[0.70133713 0.69830387 0.70025706 0.700167   0.70122552 0.70057421\n",
      " 0.70153014 0.70015018]\n",
      "[[1.11738297 0.81405275 1.00939784 1.00046352 1.10621629 1.04117781\n",
      "  1.1693677  1.03136955]]\n",
      "{0: 1312, 1: 560}\n",
      "acc 0.6730769230769231\n",
      "(0.16785714285714284, 0.39166666666666666, 0.235, None)\n",
      "\n",
      "3 loss 21608.982229852503\n",
      "dev set\n",
      "[0.70139104 0.6983578  0.70031089 0.70022052 0.70127945 0.70062776\n",
      " 0.70147612 0.70009617]\n",
      "[[1.11732907 0.81399881 1.0093439  1.00040999 1.10616242 1.0411243\n",
      "  1.16942162 1.03142346]]\n",
      "{0: 1312, 1: 560}\n",
      "acc 0.6730769230769231\n",
      "(0.16785714285714284, 0.39166666666666666, 0.235, None)\n",
      "\n",
      "4 loss 21608.830870974634\n",
      "dev set\n",
      "[0.70144497 0.69841175 0.70036474 0.70027404 0.7013334  0.70068132\n",
      " 0.70142208 0.70004214]\n",
      "[[1.11727515 0.81394486 1.00928994 1.00035647 1.10610853 1.04107078\n",
      "  1.16947556 1.03147739]]\n",
      "{0: 1313, 1: 559}\n",
      "acc 0.6725427350427351\n",
      "(0.16636851520572452, 0.3875, 0.2327909887359199, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "precision and recall penalty\n",
      "0 loss 21535.072376035198\n",
      "dev set\n",
      "[0.80122926 0.79819595 0.8001496  0.80005993 0.80111759 0.80046705\n",
      " 0.80163821 0.80025822]\n",
      "[[1.11749071 0.81416069 1.00950568 1.0005706  1.10632403 1.04128494\n",
      "  1.16925988 1.03126173]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 21534.92252826949\n",
      "dev set\n",
      "[0.801283   0.79824965 0.8002036  0.80011347 0.80117131 0.80052054\n",
      " 0.80158442 0.80020444]\n",
      "[[1.11743682 0.81410692 1.00945173 1.00051704 1.10627027 1.04123152\n",
      "  1.1693137  1.03131555]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "2 loss 21534.77264992377\n",
      "dev set\n",
      "[0.80133673 0.79830336 0.80025761 0.80016699 0.80122503 0.80057401\n",
      " 0.80153063 0.80015065]\n",
      "[[1.11738293 0.81405316 1.00939777 1.00046349 1.10621651 1.04117813\n",
      "  1.16936753 1.03136938]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "3 loss 21534.62263213058\n",
      "dev set\n",
      "[0.80139047 0.79835707 0.80031161 0.8002205  0.80127875 0.80062749\n",
      " 0.80147683 0.80009685]\n",
      "[[1.11732904 0.81399939 1.00934382 1.00040995 1.10616275 1.04112474\n",
      "  1.16942136 1.03142321]]\n",
      "{0: 1580, 1: 292}\n",
      "acc 0.7692307692307693\n",
      "(0.17123287671232876, 0.20833333333333334, 0.1879699248120301, None)\n",
      "\n",
      "4 loss 21534.472684972323\n",
      "dev set\n",
      "[0.80144422 0.79841078 0.80036563 0.80027401 0.80133236 0.80068096\n",
      " 0.80142303 0.80004304]\n",
      "[[1.11727514 0.81394561 1.00928986 1.00035642 1.10610899 1.04107135\n",
      "  1.16947521 1.03147706]]\n",
      "{0: 1595, 1: 277}\n",
      "acc 0.7761752136752137\n",
      "(0.17689530685920576, 0.20416666666666666, 0.18955512572533845, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "precision and recall penalty\n",
      "0 loss 21598.720364617628\n",
      "dev set\n",
      "[0.90122948 0.89819601 0.90014951 0.90005998 0.90111775 0.90046711\n",
      " 0.90163818 0.9002582 ]\n",
      "[[1.11749054 0.81416064 1.00950568 1.00057056 1.10632403 1.04128484\n",
      "  1.16925989 1.03126174]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "1 loss 21598.672325036445\n",
      "dev set\n",
      "[0.90128352 0.89824982 0.90020339 0.90011359 0.9011717  0.90052069\n",
      " 0.90158434 0.90020437]\n",
      "[[1.11743649 0.81410681 1.00945171 1.00051693 1.10627027 1.04123128\n",
      "  1.16931373 1.03131558]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "2 loss 21598.62426471352\n",
      "dev set\n",
      "[0.90133757 0.89830363 0.90025726 0.90016718 0.90122566 0.90057426\n",
      " 0.90153051 0.90015054]\n",
      "[[1.11738243 0.81405297 1.00939774 1.00046332 1.10621651 1.04117775\n",
      "  1.16936758 1.03136943]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "3 loss 21598.57615571881\n",
      "dev set\n",
      "[0.90139163 0.89835745 0.90031114 0.90022076 0.90127962 0.90062782\n",
      " 0.90147667 0.90009671]\n",
      "[[1.11732836 0.81399912 1.00934377 1.00040972 1.10616275 1.04112422\n",
      "  1.16942144 1.03142329]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "4 loss 21598.527994290464\n",
      "dev set\n",
      "[0.90144571 0.89841128 0.90036503 0.90027434 0.9013336  0.90068138\n",
      " 0.90142281 0.90004286]\n",
      "[[1.11727426 0.81394527 1.00928978 1.00035614 1.10610897 1.0410707\n",
      "  1.16947531 1.03147716]]\n",
      "{0: 1743, 1: 129}\n",
      "acc 0.8317307692307693\n",
      "(0.20930232558139536, 0.1125, 0.14634146341463414, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n",
      "precision and recall penalty\n",
      "0 loss 21632.422814098245\n",
      "dev set\n",
      "[1.00122927 0.99808825 1.00014689 1.00001053 1.00111761 1.00046719\n",
      " 1.00174587 1.00036581]\n",
      "[[1.1175819  0.81426843 1.00955973 1.00062431 1.10641143 1.04134323\n",
      "  1.16925307 1.03120999]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "1 loss 21632.422778055472\n",
      "dev set\n",
      "[1.00128314 0.99803438 1.00019828 1.0000217  1.00117149 1.00052117\n",
      " 1.00179968 1.00041971]\n",
      "[[1.11762429 0.81432237 1.00955997 1.00062431 1.10645087 1.04135132\n",
      "  1.16930252 1.03121406]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "2 loss 21632.422741707403\n",
      "dev set\n",
      "[1.00133729 0.99798048 1.00024991 1.00004572 1.00122568 1.00057558\n",
      " 1.0018537  1.00047401]\n",
      "[[1.11766943 0.81437644 1.00956058 1.00062431 1.10649359 1.04136287\n",
      "  1.16935322 1.03122044]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "3 loss 21632.42270502253\n",
      "dev set\n",
      "[1.00139184 0.99792654 1.00030228 1.00008069 1.00128029 1.00063061\n",
      " 1.00190803 1.00052894]\n",
      "[[1.11771661 0.81443071 1.00956182 1.00062431 1.10653874 1.04137815\n",
      "  1.16940493 1.03122963]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n",
      "4 loss 21632.422667986066\n",
      "dev set\n",
      "[1.00144689 0.99787254 1.00035573 1.00012156 1.00133544 1.00068641\n",
      " 1.00196275 1.00058467]\n",
      "[[1.11776553 0.81448523 1.00956409 1.00062435 1.10658595 1.04139739\n",
      "  1.16945757 1.03124213]]\n",
      "{0: 1819, 1: 53}\n",
      "acc 0.8605769230769231\n",
      "(0.3018867924528302, 0.06666666666666667, 0.10921501706484642, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = np.array([0.22666667, 0.1953602 , 0.30890052, 0.55192878, 0.44444444,\\\n",
    "       1.        , 0.55      , 1.        ])\n",
    "\n",
    "acc = np.array([0.04540598, 0.08547009, 0.06303419, 0.09935897, 0.0042735 ,\\\n",
    "       0.00053419, 0.00587607, 0.00106838])\n",
    "### smooth LFs with acc on discrete LFs\n",
    "for b in [512,1024,2048]:\n",
    "    for i in np.linspace(0,1,11):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(i,0.001,seed),\\\n",
    "                                    LF_acc = acc ,LF_rec = rec,\\\n",
    "                                    pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=6,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 512 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44803.77891834587\n",
      "dev set\n",
      "[-0.00665541 -0.00972818 -0.00773116 -0.00778921  0.008907    0.00826529\n",
      "  0.00955428  0.00816225 -0.00644768 -0.00726407 -0.00807588 -0.00724516\n",
      " -0.00810952  0.00863976  0.00831868  0.00833292]\n",
      "[[1.12545668 0.82209959 1.01743631 1.00849136 1.09851205 1.03345878\n",
      "  1.16132077 1.02332928 1.15424913 1.07263723 0.99148243 1.07452679\n",
      "  0.99031014 1.0707008  1.03289795 1.03432159]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44397.08388221004\n",
      "dev set\n",
      "[-0.01263042 -0.01721241 -0.0147579  -0.01409974  0.01606824  0.0153725\n",
      "  0.01676995  0.01526962 -0.01406356 -0.01488173 -0.01569542 -0.01486277\n",
      " -0.01586948  0.01576635  0.01593224  0.0159465 ]\n",
      "[[1.13261492 0.82968062 1.02487486 1.01560181 1.09115944 1.02613475\n",
      "  1.15392608 1.0159989  1.16189607 1.08027784 0.99912521 1.08214521\n",
      "  0.99804704 1.06336646 1.0252608  1.02668444]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44025.78070290206\n",
      "dev set\n",
      "[-0.01425334 -0.02439935 -0.02038755 -0.01750231  0.02232711  0.02144004\n",
      "  0.02315279  0.02131753 -0.02156681 -0.02238936 -0.02320766 -0.02237024\n",
      " -0.02371447  0.02189516  0.02343312  0.02344743]\n",
      "[[1.13863155 0.83711877 1.03182318 1.0218355  1.08433078 1.0194095\n",
      "  1.14702118 1.00927703 1.16947406 1.08784442 1.0066966  1.08965656\n",
      "  1.00584154 1.05661132 1.0177059  1.01912955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 43679.31000510526\n",
      "dev set\n",
      "[-0.01026537 -0.03122135 -0.02375714 -0.01637495  0.02729895  0.02598637\n",
      "  0.02836404  0.02580715 -0.02895906 -0.0297893  -0.03061573 -0.02976982\n",
      " -0.03168221  0.02657463  0.03082461  0.030839  ]\n",
      "[[1.14294078 0.844404   1.03811027 1.0268345  1.07817434 1.01346954\n",
      "  1.14073778 1.00335817 1.17699568 1.09534893 1.01420875 1.09706565\n",
      "  1.01372914 1.05061129 1.01022449 1.01164815]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 43348.72352688439\n",
      "dev set\n",
      "[-0.00255528 -0.03765467 -0.02425402 -0.01093269  0.03073335  0.02868332\n",
      "  0.03219104  0.02839745 -0.03624771 -0.03708922 -0.03792759 -0.03706907\n",
      " -0.03977115  0.02949995  0.03811285  0.03812736]\n",
      "[[1.14523205 0.85153873 1.04365002 1.0303954  1.07275097 1.00840279\n",
      "  1.13512558 0.99833553 1.18446985 1.10280081 1.02167106 1.10438342\n",
      "  1.02171262 1.04544663 1.00281249 1.00423617]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44883.280777072134\n",
      "dev set\n",
      "[-0.00279896 -0.00581465 -0.00386857 -0.00394329  0.00501679  0.00436879\n",
      "  0.00565154  0.00426837 -0.00250108 -0.00331725 -0.00412883 -0.00329834\n",
      " -0.00414497  0.0047415   0.00437243  0.00438667]\n",
      "[[1.12152705 0.81817403 1.01353062 1.00458509 1.10242106 1.03737832\n",
      "  1.16524186 1.02724627 1.15029993 1.06868807 0.98753552 1.07057893\n",
      "  0.98634953 1.07462123 1.03684705 1.0382707 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44669.97292537321\n",
      "dev set\n",
      "[-0.00658823 -0.009706   -0.00773163 -0.00772948  0.00886726  0.00821588\n",
      "  0.00951657  0.00811969 -0.00641332 -0.00722976 -0.00804162 -0.00721084\n",
      " -0.00807947  0.00859084  0.00828408  0.00829832]\n",
      "[[1.12542156 0.82207908 1.01744043 1.0084539  1.09854663 1.03350394\n",
      "  1.16135247 1.02336583 1.15421682 1.07260384 0.99145238 1.07449197\n",
      "  0.9902797  1.07074561 1.03293136 1.03435501]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44465.59520187443\n",
      "dev set\n",
      "[-0.00999592 -0.01355476 -0.01144523 -0.01124171  0.01260384  0.01193555\n",
      "  0.01327582  0.01184252 -0.01030724 -0.01112432 -0.01193686 -0.01110539\n",
      " -0.01202592  0.0123169   0.01217693  0.01219117]\n",
      "[[1.12918831 0.82596171 1.02128723 1.01221883 1.09474521 1.02971103\n",
      "  1.15753107 1.01956701 1.1581217  1.07650686 0.99535698 1.07838749\n",
      "  0.99421718 1.06694922 1.02902987 1.03045351]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44269.147106019096\n",
      "dev set\n",
      "[-0.01268232 -0.01734739 -0.01491608 -0.01427036  0.01617206  0.01546352\n",
      "  0.01687926  0.01537051 -0.01418161 -0.01499986 -0.01581364 -0.0149809\n",
      " -0.0159949   0.01585841  0.01604994  0.0160642 ]\n",
      "[[1.13275239 0.82981849 1.02504253 1.01582738 1.09104476 1.02603265\n",
      "  1.15380379 1.01588432 1.16201601 1.08039832 0.99925052 1.08226464\n",
      "  0.99817106 1.06326377 1.02514177 1.02656542]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44080.219820745406\n",
      "dev set\n",
      "[-0.01421681 -0.02106853 -0.01803155 -0.01654032  0.01951173  0.01872761\n",
      "  0.02027231  0.01862928 -0.01803295 -0.01885305 -0.01966879 -0.01883403\n",
      " -0.0199925   0.01914688  0.01989993  0.01991421]\n",
      "[[1.1360279  0.83364395 1.02867591 1.01921994 1.08747469 1.02250378\n",
      "  1.15019771 1.0123539  1.16589864 1.08427685 1.00313171 1.08612031\n",
      "  1.00214634 1.05972276 1.02126873 1.02269237]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(16,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 16), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 16), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 16), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 16), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(16,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 16), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(16,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(16,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 44924.19311714624\n",
      "dev set\n",
      "[-0.00082067 -0.00384316 -0.00189225 -0.00198236  0.00305     0.00240009\n",
      "  0.00368088  0.00229901 -0.00052501 -0.00134114 -0.00215268 -0.00132223\n",
      " -0.00216559  0.00277257  0.00239645  0.00241069]\n",
      "[[1.11954196 0.81620043 1.01154899 1.00261495 1.10439074 1.03935068\n",
      "  1.1672158  1.02921969 1.14832357 1.06671197 0.98555899 1.06860262\n",
      "  0.984371   1.07659371 1.03882359 1.04024723]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 44814.91539254971\n",
      "dev set\n",
      "[-0.00279845 -0.00582005 -0.00386776 -0.00395418  0.00502459  0.00437477\n",
      "  0.00565972  0.00427391 -0.00250794 -0.00332411 -0.00413569 -0.0033052\n",
      " -0.00415193  0.00474752  0.00437928  0.00439351]\n",
      "[[1.12153145 0.81817933 1.01353081 1.00459675 1.10241275 1.03737203\n",
      "  1.165233   1.02724066 1.15030763 1.06869569 0.98754225 1.07058593\n",
      "  0.98635666 1.07461491 1.03683964 1.03826329]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 44707.65912167608\n",
      "dev set\n",
      "[-0.00473876 -0.00779157 -0.00582602 -0.00589744  0.00698546  0.00633428\n",
      "  0.00762587  0.00623346 -0.00448884 -0.0053051  -0.00611678 -0.00528619\n",
      " -0.00614039  0.00670777  0.00635996  0.0063742 ]\n",
      "[[1.1235063  0.82015544 1.01550482 1.00656652 1.10044378 1.03540331\n",
      "  1.1632585  1.02527172 1.15229051 1.07067814 0.98952425 1.07256734\n",
      "  0.9883438  1.0726458  1.03485718 1.03628082]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 44602.34752224384\n",
      "dev set\n",
      "[-0.00661653 -0.00975589 -0.00775794 -0.00779482  0.00892622  0.00827136\n",
      "  0.00957332  0.00817021 -0.00646727 -0.00728369 -0.00809554 -0.00726478\n",
      " -0.00813232  0.0086463   0.00833806  0.0083523 ]\n",
      "[[1.12545857 0.82212816 1.01746755 1.00851825 1.09848761 1.0334489\n",
      "  1.16129593 1.02331732 1.15427214 1.07265919 0.9915049  1.07454645\n",
      "  0.99033348 1.07069058 1.03287641 1.03430005]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 44499.007513003715\n",
      "dev set\n",
      "[-0.00839962 -0.01171079 -0.00965303 -0.00962498  0.01083978  0.01017785\n",
      "  0.01149547  0.01007586 -0.00844254 -0.00925922 -0.01007134 -0.0092403\n",
      " -0.01012874  0.01055528  0.01031287  0.01032711]\n",
      "[[1.12737943 0.82409655 1.01941516 1.01044525 1.09654837 1.03151351\n",
      "  1.15934918 1.02138228 1.15625218 1.07463849 0.99348387 1.07652262\n",
      "  0.99232649 1.06875384 1.03089775 1.03232139]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in [512,1024,2048]:\n",
    "    for i in np.linspace(0,1,11):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.001,5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(0,0.001,seed),\\\n",
    "                                LF_acc = get_LF_acc(dev_L_S,gold_labels_dev) ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                norm=True,smooth=True,penalty=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 32 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 32 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26816.959090156495\n",
      "dev set\n",
      "[-0.00195583 -0.00498997 -0.00303594 -0.00312532 -0.00207781  0.00353034\n",
      "  0.00482125  0.00344105]\n",
      "[[1.1206748  0.81734738 1.01268406 1.00375999 1.10951252 1.03821237\n",
      "  1.16607478 1.0280766 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26679.22348918799\n",
      "dev set\n",
      "[-0.00508447 -0.00812134 -0.0061654  -0.00625486 -0.00524505  0.00656156\n",
      "  0.00794032  0.00655939]\n",
      "[[1.12381086 0.82048341 1.01581863 1.00689397 1.11267264 1.03515752\n",
      "  1.16295096 1.02495257]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 26541.46427210567\n",
      "dev set\n",
      "[-0.0082123  -0.01125385 -0.00929465 -0.00938424 -0.00843865  0.00951716\n",
      "  0.01105199  0.00966984]\n",
      "[[1.12695172 0.82362449 1.01895851 1.01003062 1.11585588 1.03215973\n",
      "  1.15983201 1.02183327]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26403.833156552482\n",
      "dev set\n",
      "[-0.01133781 -0.01438592 -0.01242216 -0.01251191 -0.01165561  0.01239712\n",
      "  0.01415546  0.01277158]\n",
      "[[1.13009562 0.82676887 1.02210156 1.01316836 1.11905927 1.02921759\n",
      "  1.15671872 1.0187195 ]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26266.41167972165\n",
      "dev set\n",
      "[-0.01446006 -0.01751655 -0.01554696 -0.01563692 -0.01489355  0.01520105\n",
      "  0.01725044  0.01586434]\n",
      "[[1.13324142 0.82991541 1.02524653 1.01630609 1.12228065 1.0263301\n",
      "  1.1536115  1.01561168]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 64 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26762.614761052864\n",
      "dev set\n",
      "[-0.00039062 -0.0034241  -0.00147052 -0.00155988 -0.00050412  0.00197946\n",
      "  0.00325787  0.00187784]\n",
      "[[1.11910985 0.81578064 1.01112252 1.00219183 1.10794365 1.03977011\n",
      "  1.16763971 1.02964156]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26693.69725487278\n",
      "dev set\n",
      "[-0.00195575 -0.00498985 -0.00303584 -0.00312522 -0.00207791  0.00352402\n",
      "  0.00482087  0.00344068]\n",
      "[[1.12067668 0.8173474  1.01268858 1.00375828 1.10951556 1.03822018\n",
      "  1.16607536 1.02807717]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26624.74166337068\n",
      "dev set\n",
      "[-0.00352127 -0.00655648 -0.0046017  -0.00469111 -0.00365927  0.00504968\n",
      "  0.00638242  0.00500193]\n",
      "[[1.12224536 0.81891607 1.01425677 1.00532597 1.11109426 1.03668488\n",
      "  1.16451188 1.02651359]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26555.78575857269\n",
      "dev set\n",
      "[-0.00508668 -0.00812349 -0.00616759 -0.00625705 -0.00524749  0.0065565\n",
      "  0.00794212  0.00656121]\n",
      "[[1.12381533 0.82048612 1.01582635 1.00689445 1.11267895 1.03516386\n",
      "  1.16294957 1.02495116]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26486.849396938862\n",
      "dev set\n",
      "[-0.00665172 -0.00969063 -0.00773327 -0.00782278 -0.00684215  0.00804449\n",
      "  0.00949983  0.00811837]\n",
      "[[1.12538634 0.82205726 1.01739701 1.00846347 1.11426919 1.03365696\n",
      "  1.16138858 1.02339001]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 128 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26739.519113145452\n",
      "dev set\n",
      "[ 0.00039219 -0.00264115 -0.00068768 -0.00077703  0.00028026  0.00119754\n",
      "  0.00247532  0.00109533]\n",
      "[[1.1183275  0.81499769 1.01034175 1.00140802 1.10716077 1.0405538\n",
      "  1.16842268 1.03042453]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26705.04049390823\n",
      "dev set\n",
      "[-0.0003906  -0.00342406 -0.0014705  -0.00155986 -0.00050418  0.00197692\n",
      "  0.00325773  0.00187771]\n",
      "[[1.11911063 0.81578074 1.01112451 1.00219113 1.10794468 1.03977327\n",
      "  1.1676399  1.02964175]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26670.55105506174\n",
      "dev set\n",
      "[-0.00117365 -0.00420735 -0.00225362 -0.00234298 -0.00129065  0.00275171\n",
      "  0.00403991  0.00265983]\n",
      "[[1.11989437 0.81656442 1.01190801 1.00297468 1.10873047 1.03899637\n",
      "  1.16685723 1.02885905]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26636.054077492045\n",
      "dev set\n",
      "[-0.00195678 -0.00499085 -0.00303686 -0.00312624 -0.00207903  0.0035218\n",
      "  0.00482172  0.00344154]\n",
      "[[1.12067856 0.81734859 1.01269203 1.00375854 1.10951796 1.03822311\n",
      "  1.16607477 1.02807657]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26601.55544452627\n",
      "dev set\n",
      "[-0.00273993 -0.00577449 -0.00382016 -0.00390955 -0.00286922  0.00428718\n",
      "  0.00560308  0.00422277]\n",
      "[[1.12146313 0.81813315 1.01347645 1.00454264 1.11030702 1.03745344\n",
      "  1.16529259 1.02729435]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 512 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26723.286895253947\n",
      "dev set\n",
      "[ 0.00096141 -0.0020719  -0.00011844 -0.0002078   0.00084974  0.00062756\n",
      "  0.0019061   0.00052612]\n",
      "[[1.11775864 0.81442855 1.0097736  1.00083837 1.10659187 1.04112433\n",
      "  1.16899194 1.03099379]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26714.023242107236\n",
      "dev set\n",
      "[ 0.00075394 -0.00227937 -0.00032591 -0.00041526  0.00064223  0.00083498\n",
      "  0.00211357  0.00073358]\n",
      "[[1.11796615 0.81463598 1.00998106 1.0010458  1.10679934 1.04091687\n",
      "  1.16878443 1.03078628]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26704.897446526447\n",
      "dev set\n",
      "[ 0.0005471  -0.00248621 -0.00053275 -0.0006221   0.00043528  0.00104158\n",
      "  0.00232038  0.00094039]\n",
      "[[1.11817306 0.81484279 1.01018791 1.00125259 1.10700624 1.04071019\n",
      "  1.16857756 1.03057941]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26695.787664213563\n",
      "dev set\n",
      "[ 0.00034031 -0.00269302 -0.00073955 -0.0008289   0.00022828  0.00124789\n",
      "  0.00252713  0.00114714]\n",
      "[[1.11837994 0.81504959 1.01039474 1.00145935 1.10721318 1.04050377\n",
      "  1.16837076 1.03037261]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26686.67691700242\n",
      "dev set\n",
      "[ 1.33417805e-04 -2.89993686e-03 -9.46448513e-04 -1.03580345e-03\n",
      "  2.10687906e-05  1.45400615e-03  2.73394102e-03  1.35394538e-03]\n",
      "[[1.11858694 0.8152565  1.0106017  1.00166621 1.10742032 1.04029746\n",
      "  1.16816387 1.03016572]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 1024 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26719.8664999681\n",
      "dev set\n",
      "[ 1.06826185e-03 -1.96503963e-03 -1.15880820e-05 -1.00941571e-04\n",
      "  9.56594252e-04  5.20615353e-04  1.79924654e-03  4.19264920e-04]\n",
      "[[1.11765181 0.81432171 1.00966683 1.0007315  1.10648504 1.04123131\n",
      "  1.1690988  1.03110065]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.17295831645\n",
      "dev set\n",
      "[ 0.00096229 -0.00207101 -0.00011756 -0.00020691  0.00085062  0.00062662\n",
      "  0.00190522  0.00052523]\n",
      "[[1.11775779 0.81442767 1.00977281 1.00083747 1.10659099 1.04112528\n",
      "  1.16899281 1.03099466]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26710.507759542073\n",
      "dev set\n",
      "[ 0.00085647 -0.00217683 -0.00022338 -0.00031273  0.00074478  0.00073246\n",
      "  0.00201104  0.00063106]\n",
      "[[1.11786362 0.81453348 1.00987866 1.0009433  1.10669681 1.04101943\n",
      "  1.16888697 1.03088882]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26705.84656531863\n",
      "dev set\n",
      "[ 0.00075067 -0.00228263 -0.00032918 -0.00041853  0.00063895  0.00083822\n",
      "  0.00211683  0.00073685]\n",
      "[[1.11796943 0.81463928 1.00998448 1.0010491  1.1068026  1.04091363\n",
      "  1.16878116 1.03078301]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26701.185845806285\n",
      "dev set\n",
      "[ 0.00064487 -0.00238844 -0.00043499 -0.00052434  0.0005331   0.00094395\n",
      "  0.00222263  0.00084264]\n",
      "[[1.11807525 0.81474508 1.01009032 1.00115491 1.10690843 1.04080786\n",
      "  1.16867534 1.03067719]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.1\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.2\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.30000000000000004\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.4\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.5\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.6000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.7000000000000001\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.8\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 0.9\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "batch-size: 2048 alpha-init: 1.0\n",
      "{1: 240, -1: 1632}\n",
      "k Tensor(\"Const:0\", shape=(8,), dtype=float64)\n",
      "s Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft aj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "ky Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "intsy Tensor(\"map/while/prec_zy/while/add:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f_p Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft_p Tensor(\"map/while/sft_p:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 26718.156258829244\n",
      "dev set\n",
      "[ 1.12169996e-03 -1.91160120e-03  4.18501418e-05 -4.75033377e-05\n",
      "  1.01003262e-03  4.67151725e-04  1.74580724e-03  3.65825700e-04]\n",
      "[[1.11759838 0.81426828 1.00961339 1.00067806 1.10643161 1.04128478\n",
      "  1.16915224 1.03115409]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "1 loss 26715.790929390085\n",
      "dev set\n",
      "[ 1.06807656e-03 -1.96522493e-03 -1.17733775e-05 -1.01126867e-04\n",
      "  9.56408981e-04  5.20803939e-04  1.79943191e-03  4.19450283e-04]\n",
      "[[1.11765202 0.81432191 1.00966701 1.00073169 1.10648523 1.04123112\n",
      "  1.1690986  1.03110045]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "2 loss 26713.428718701245\n",
      "dev set\n",
      "[ 1.01446164e-03 -2.01884029e-03 -6.53884454e-05 -1.54741947e-04\n",
      "  9.02792473e-04  5.74445341e-04  1.85304779e-03  4.73066049e-04]\n",
      "[[1.11770565 0.81437553 1.00972062 1.00078531 1.10653885 1.04117746\n",
      "  1.16904497 1.03104682]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "3 loss 26711.06669404441\n",
      "dev set\n",
      "[ 0.00096085 -0.00207246 -0.000119   -0.00020836  0.00084917  0.00062808\n",
      "  0.00190666  0.00052668]\n",
      "[[1.11775928 0.81442915 1.00977423 1.00083893 1.10659246 1.04112382\n",
      "  1.16899133 1.03099318]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n",
      "4 loss 26708.70458664201\n",
      "dev set\n",
      "[ 0.00090723 -0.00212608 -0.00017262 -0.00026198  0.00079555  0.00068172\n",
      "  0.00196028  0.0005803 ]\n",
      "[[1.11781291 0.81448278 1.00982784 1.00089256 1.10664609 1.04107017\n",
      "  1.1689377  1.03093955]]\n",
      "{1: 1872}\n",
      "acc 0.1282051282051282\n",
      "(0.1282051282051282, 1.0, 0.22727272727272727, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in [32,64,128,512,1024,2048]:\n",
    "    for i in np.linspace(0,1,11):\n",
    "        print(\"batch-size:\",b,\"alpha-init:\",i)\n",
    "        train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(0,0.001,seed),\\\n",
    "                                LF_acc = get_LF_acc(dev_L_S,gold_labels_dev) ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                norm=True,smooth=True,penalty=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 32\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 23046.985287667845\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11818873 0.81714424 1.01185072 1.00223489 1.10325958 1.03821042\n",
      "  1.16607666 1.02808064]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "1 loss 23027.15230344854\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11866923 0.82011226 1.01402426 1.00358081 1.10016156 1.03511098\n",
      "  1.16297341 1.02498082]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "2 loss 23007.861969015485\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11892961 0.82306243 1.01608345 1.00473535 1.09708345 1.03203363\n",
      "  1.15989084 1.02190334]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "3 loss 22989.091728934356\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11897729 0.82599087 1.01803009 1.00570154 1.09402473 1.02897729\n",
      "  1.15682749 1.0188471 ]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "4 loss 22970.806233168398\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11881946 0.82889731 1.01986476 1.0064811  1.0909844  1.02594076\n",
      "  1.15378209 1.01581088]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "batch-size: 64\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22752.65736803825\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11803235 0.81572237 1.01085221 1.00165076 1.10481498 1.03977219\n",
      "  1.16763929 1.02964191]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "1 loss 22742.491558725647\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11847902 0.8172446  1.01210972 1.00261123 1.10325711 1.03821352\n",
      "  1.1660792  1.02808308]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "2 loss 22732.47786683416\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11884234 0.8187639  1.01333316 1.00351454 1.10170441 1.0366608\n",
      "  1.16452488 1.02653028]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "3 loss 22722.618176471362\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11912452 0.82027798 1.01452492 1.00435872 1.10015708 1.03511398\n",
      "  1.16297605 1.02498346]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "4 loss 22712.90739776519\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11932674 0.82178624 1.0156858  1.00514269 1.09861507 1.03357292\n",
      "  1.16143251 1.02344246]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "batch-size: 128\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22622.588466459147\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11792595 0.8149814  1.01027385 1.00123482 1.10559545 1.04055494\n",
      "  1.16842245 1.03042442]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 22617.4147115639\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11832614 0.81575247 1.01097787 1.00183516 1.10481415 1.03977321\n",
      "  1.16764016 1.02964262]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "2 loss 22612.28296817468\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11869122 0.81652352 1.01167164 1.00241922 1.10403408 1.03899299\n",
      "  1.1668594  1.02886235]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "3 loss 22607.19584584605\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.1190219  0.81729352 1.01235629 1.00298637 1.10325541 1.03821436\n",
      "  1.16608016 1.02808369]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "4 loss 22602.152813661734\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11931891 0.81806212 1.01303237 1.00353643 1.1024782  1.03743731\n",
      "  1.1653024  1.02730665]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "batch-size: 512\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22550.312577304845\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.117749   0.81442774 1.00977292 1.00083656 1.10616386 1.04112445\n",
      "  1.16899188 1.03099375]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "1 loss 22548.89629161825\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11793751 0.81463465 1.00998128 1.00103489 1.10595645 1.04091697\n",
      "  1.16878431 1.03078621]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "2 loss 22547.504342421285\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11812314 0.81484096 1.01018891 1.00123071 1.10574973 1.04071021\n",
      "  1.16857745 1.03057936]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "3 loss 22546.11825056578\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.1183058  0.81504717 1.01039613 1.00142505 1.10554315 1.04050358\n",
      "  1.16837072 1.03037266]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "4 loss 22544.735594085516\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11848531 0.8152534  1.01060295 1.00161812 1.10533656 1.04029697\n",
      "  1.16816401 1.03016596]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "batch-size: 1024\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22538.759624499104\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11765066 0.81432158 1.00966721 1.00073175 1.10627069 1.04123134\n",
      "  1.16909876 1.03110063]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "1 loss 22538.040115865704\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11775383 0.81442743 1.00977413 1.00083828 1.10616473 1.04112533\n",
      "  1.1689927  1.03099459]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "2 loss 22537.32547369229\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11785688 0.81453314 1.00988094 1.00094463 1.10605893 1.04101947\n",
      "  1.16888678 1.03088871]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "3 loss 22536.6121917431\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11795959 0.81463882 1.0099877  1.00105082 1.10595318 1.04091365\n",
      "  1.1687809  1.03078286]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "4 loss 22535.89980734448\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11806183 0.8147445  1.0100944  1.00115686 1.10584743 1.04080784\n",
      "  1.16867503 1.03067701]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "batch-size: 2048\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22533.376976482286\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11759798 0.81426819 1.00961346 1.00067826 1.10632412 1.04128479\n",
      "  1.16915222 1.03115409]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "1 loss 22533.014330491937\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11765007 0.81432168 1.00966718 1.00073217 1.10627048 1.04123116\n",
      "  1.16909855 1.03110045]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "2 loss 22532.65236914109\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11770211 0.81437515 1.00972089 1.00078608 1.10621686 1.04117753\n",
      "  1.16904489 1.03104682]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "3 loss 22532.2906277918\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11775409 0.81442863 1.00977459 1.00083997 1.10616324 1.04112391\n",
      "  1.16899123 1.03099319]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "4 loss 22531.929071459825\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11780601 0.8144821  1.00982828 1.00089383 1.10610961 1.04107028\n",
      "  1.16893757 1.03093956]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in [32,64,128,512,1024,2048]:\n",
    "    print(\"batch-size:\",b)\n",
    "    train(0.1/len(train_L_S),5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(0,0.001,seed),\\\n",
    "                                LF_acc = get_LF_acc(dev_L_S,gold_labels_dev) ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                norm=True,smooth=False,penalty=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch-size: 32\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 21676.80588374223\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.34208695 1.26042274 0.43528139 0.26312153 0.46834822 0.45750283\n",
      "  0.48426506 0.45640679]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "1 loss 21074.353326680495\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.17531392 1.38099385 0.29367546 0.0770325  0.36748199 0.39017678\n",
      "  0.35393285 0.39207118]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "2 loss 21062.159204269148\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.16723904 1.41234913 0.28122199 0.06163554 0.36532769 0.3899506\n",
      "  0.34811609 0.39119302]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "3 loss 21061.962779953872\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.16861606 1.418886   0.27988063 0.06061697 0.36560056 0.39073592\n",
      "  0.34688349 0.39113044]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "4 loss 21062.033622688068\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.17017684 1.41976324 0.2796942  0.06073756 0.36519989 0.39074102\n",
      "  0.34527155 0.39028954]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "batch-size: 64\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 21776.235602456953\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.63257759 1.16417487 0.68108145 0.5669499  0.67331193 0.62374573\n",
      "  0.72182542 0.61717098]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "1 loss 20914.32524201942\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.29943595 1.3231042  0.40190217 0.22691299 0.45736968 0.44741659\n",
      "  0.47766051 0.4466387 ]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "2 loss 20774.11244715138\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.18245029 1.39233304 0.30976565 0.09876497 0.38420113 0.39990593\n",
      "  0.38336003 0.40239014]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "3 loss 20761.927076318705\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.1559632  1.42026972 0.28609091 0.06511711 0.36920153 0.39210771\n",
      "  0.36031309 0.39541495]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "4 loss 20761.236475051304\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.15204571 1.43107841 0.28070983 0.05851602 0.3680089  0.39174782\n",
      "  0.35729738 0.39521793]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "batch-size: 128\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22015.685489546413\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.87680057 1.05049876 0.9219202  0.81643632 0.84885512 0.78630993\n",
      "  0.90872356 0.77696001]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 21202.920851586525\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.58858906 1.19849737 0.65724342 0.52894557 0.66488086 0.61575753\n",
      "  0.71529883 0.60853572]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "2 loss 20822.772916188456\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.38656065 1.30212164 0.48185169 0.32502514 0.53188935 0.50201065\n",
      "  0.56908658 0.49774713]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "3 loss 20682.11495647486\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.26060603 1.36562896 0.37911686 0.19353206 0.44963199 0.44009768\n",
      "  0.47218621 0.43881049]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "4 loss 20640.29039311062\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.19372295 1.40213979 0.32609006 0.11918831 0.4045558  0.41122613\n",
      "  0.41432636 0.41215204]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "batch-size: 512\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22372.479872666725\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.07587124 0.89152612 1.06997186 1.01210905 1.02827759 0.96326679\n",
      "  1.09097735 0.95315973]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "1 loss 22014.329555555752\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.99716151 0.96027287 1.04496672 0.93961852 0.95737908 0.89289782\n",
      "  1.01961816 0.88284742]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "2 loss 21725.747128779643\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.91237337 1.02102504 0.97595758 0.85453629 0.89263566 0.82939584\n",
      "  0.95396939 0.81950499]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "3 loss 21479.01646153052\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.82661657 1.07465052 0.89553262 0.76705444 0.83347383 0.77223281\n",
      "  0.8934299  0.76261931]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "4 loss 21271.62831924874\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.74367466 1.12275455 0.81481136 0.68207133 0.77891621 0.72035775\n",
      "  0.83706308 0.71113129]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "batch-size: 1024\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22456.48710628916\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11520412 0.85351627 1.04751878 1.03124353 1.06693402 1.00189595\n",
      "  1.1297234  0.9917665 ]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "1 loss 22248.376567301806\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.08218828 0.89125185 1.06956988 1.01533332 1.02881179 0.96384215\n",
      "  1.0914891  0.95371442]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "2 loss 22074.60752093858\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.04386183 0.92729912 1.06459619 0.98178093 0.99199108 0.92721398\n",
      "  1.0544713  0.91710394]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "3 loss 21917.14036047445\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.00284783 0.96139859 1.04058857 0.9424866  0.95664788 0.89222628\n",
      "  1.01882555 0.88215746]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "4 loss 21771.206195731873\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[0.96022898 0.99345767 1.00687537 0.90038973 0.92285057 0.85897205\n",
      "  0.98460671 0.84897275]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n",
      "batch-size: 2048\n",
      "{1: 240, -1: 1632}\n",
      "Tensor(\"unstack:1\", shape=(?, 8), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 8), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 8), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 8), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(8,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(8,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "precision penalty\n",
      "sft Lj Tensor(\"map/while/map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?,), dtype=float64)\n",
      "sft kj Tensor(\"map/while/Gather:0\", shape=(), dtype=float64)\n",
      "sft aj Tensor(\"map/while/Gather_1:0\", shape=(), dtype=float64)\n",
      "sft indices Tensor(\"map/while/Where:0\", shape=(?, 1), dtype=int64)\n",
      "sft l_ij_eq_kj Tensor(\"map/while/Gather_2:0\", shape=(?, 8), dtype=float64)\n",
      "out Tensor(\"map/while/prec_zy/while/Select:0\", shape=(8,), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec_z Tensor(\"map/while/Sum:0\", shape=(), dtype=float64)\n",
      "prec_t_pout Tensor(\"map/while/truediv:0\", shape=(?, 1), dtype=float64)\n",
      "f Tensor(\"map/while/Sum_1:0\", shape=(), dtype=float64)\n",
      "sft Tensor(\"map/while/sft:0\", shape=(), dtype=float64)\n",
      "loss Tensor(\"add:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 22504.5093901236\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.13603094 0.8339986  1.02917033 1.01976874 1.08653959 1.02150288\n",
      "  1.14935453 1.0113711 ]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "1 loss 22387.40116251994\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.12639968 0.85354162 1.04699709 1.02918603 1.06688159 1.00185859\n",
      "  1.12967054 0.99172674]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "2 loss 22285.52167516231\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.11091472 0.8728003  1.06077723 1.02397562 1.04743909 0.98244875\n",
      "  1.11018846 0.97231964]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "3 loss 22192.42997573933\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.09322865 0.89170178 1.06801881 1.01123961 1.02826699 0.96333517\n",
      "  1.09095941 0.95321275]]\n",
      "{0: 760, 1: 1112}\n",
      "acc 0.5235042735042735\n",
      "(0.2068345323741007, 0.9583333333333334, 0.34023668639053256, None)\n",
      "\n",
      "4 loss 22105.287051394123\n",
      "dev set\n",
      "[ 1.17544629e-03 -1.85785468e-03  9.55965364e-05  6.24306244e-06\n",
      "  1.06377870e-03  4.13385488e-04  1.69205997e-03  3.12078490e-04]\n",
      "[[1.07427186 0.91018508 1.06779229 0.99498557 1.00941054 0.94456935\n",
      "  1.07202492 0.93445858]]\n",
      "{0: 759, 1: 1113}\n",
      "acc 0.5229700854700855\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in [32,64,128,512,1024,2048]:\n",
    "    print(\"batch-size:\",b)\n",
    "    train(0.01,5,batch_size = b, th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(0,0.001,seed),\\\n",
    "                                LF_acc = get_LF_acc(dev_L_S,gold_labels_dev) ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                norm=True,smooth=False,penalty=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3700, 5)\n",
      "(1872, 5)\n",
      "started at: 9-6-2018, 20:22:49\n",
      "trained in  0:00:06.133447\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "import _pickle as pkl\n",
    "# L_train = pkl.load(open(\"train_L_S_discrete.p\",\"rb\"))\n",
    "# L_train = sp.csr_matrix(L_train)\n",
    "\n",
    "# L_gold = pkl.load(open(\"gold_discrete.p\",\"rb\"))\n",
    "# print(np.array(L_gold).shape)\n",
    "# L_gold = sp.csr_matrix(L_gold)\n",
    "\n",
    "L_train = np.load(\"train_L_S_discrete.npy\")\n",
    "L_train = L_train[:,0,:].astype(int)\n",
    "print(np.array(L_train).shape)\n",
    "L_train = sp.csr_matrix(L_train)\n",
    "\n",
    "L_gold = np.load(\"test_L_S_discrete.npy\")\n",
    "L_gold = L_gold[:,0,:].astype(int)\n",
    "print(np.array(L_gold).shape)\n",
    "L_gold = sp.csr_matrix(L_gold)\n",
    "\n",
    "from snorkel.learning import GenerativeModel\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lt = time.localtime()\n",
    "\n",
    "print(\"started at: {}-{}-{}, {}:{}:{}\".format(lt.tm_mday,lt.tm_mon,lt.tm_year,lt.tm_hour,lt.tm_min,lt.tm_sec))\n",
    "\n",
    "gen_model.train(L_train, epochs = 100, cardinality=2)\n",
    "# gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)\n",
    "\n",
    "\n",
    "print(\"trained in \",str(datetime.timedelta(seconds=time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872,)\n",
      "(1872,)\n",
      "(0.18799212598425197, 0.7958333333333333, 0.3041401273885351, None)\n"
     ]
    }
   ],
   "source": [
    "# 5 LFs\n",
    "import numpy as np\n",
    "dev_marginals = gen_model.marginals(L_gold)\n",
    "dev_marginals = np.array(dev_marginals)\n",
    "print(dev_marginals.shape)\n",
    "\n",
    "# GenLabels = np.argmax(dev_marginals,axis=1)\n",
    "GenLabels =  np.array([1 if m > 0.5 else 0 for m in dev_marginals])\n",
    "print(GenLabels.shape)\n",
    "\n",
    "print(precision_recall_fscore_support(np.array(true_labels),GenLabels,average=\"binary\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1872,)\n",
      "(1872,)\n",
      "(0.20664869721473494, 0.9583333333333334, 0.33998521803399856, None)\n"
     ]
    }
   ],
   "source": [
    "# 8 discrete LFs\n",
    "import numpy as np\n",
    "dev_marginals = gen_model.marginals(L_gold)\n",
    "dev_marginals = np.array(dev_marginals)\n",
    "print(dev_marginals.shape)\n",
    "\n",
    "# GenLabels = np.argmax(dev_marginals,axis=1)\n",
    "GenLabels =  np.array([1 if m > 0.5 else 0 for m in dev_marginals])\n",
    "print(GenLabels.shape)\n",
    "\n",
    "print(precision_recall_fscore_support(np.array(true_labels),GenLabels,average=\"binary\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
